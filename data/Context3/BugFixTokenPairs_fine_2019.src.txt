CWE-000 static av_cold int vqa_decode_init ( AVCodecContext * avctx ) { VqaContext * s = avctx -> priv_data ; int i , j , codebook_index , ret ; s -> avctx = avctx ; avctx -> pix_fmt = AV_PIX_FMT_PAL8 ; if ( s -> avctx -> extradata_size != VQA_HEADER_SIZE ) { av_log ( s -> avctx , AV_LOG_ERROR , "expected<S2SV_blank>extradata<S2SV_blank>size<S2SV_blank>of<S2SV_blank>%d\\n" , VQA_HEADER_SIZE ) ; return AVERROR ( EINVAL ) ; } s -> vqa_version = s -> avctx -> extradata [ 0 ] ; switch ( s -> vqa_version ) { case 1 : case 2 : break ; case 3 : avpriv_report_missing_feature ( avctx , "VQA<S2SV_blank>Version<S2SV_blank>%d" , s -> vqa_version ) ; return AVERROR_PATCHWELCOME ; default : avpriv_request_sample ( avctx , "VQA<S2SV_blank>Version<S2SV_blank>%i" , s -> vqa_version ) ; return AVERROR_PATCHWELCOME ; } s -> width = AV_RL16 ( & s -> avctx -> extradata [ 6 ] ) ; s -> height = AV_RL16 ( & s -> avctx -> extradata [ 8 ] ) ; <S2SV_StartBug> if ( ( ret = av_image_check_size ( s -> width , s -> height , 0 , avctx ) ) < 0 ) { <S2SV_EndBug> s -> width = s -> height = 0 ; return ret ; } s -> vector_width = s -> avctx -> extradata [ 10 ] ; s -> vector_height = s -> avctx -> extradata [ 11 ] ; s -> partial_count = s -> partial_countdown = s -> avctx -> extradata [ 13 ] ; if ( ( s -> vector_width != 4 ) || ( ( s -> vector_height != 2 ) && ( s -> vector_height != 4 ) ) ) { return AVERROR_INVALIDDATA ; } if ( s -> width % s -> vector_width || s -> height % s -> vector_height ) { av_log ( avctx , AV_LOG_ERROR , "Image<S2SV_blank>size<S2SV_blank>not<S2SV_blank>multiple<S2SV_blank>of<S2SV_blank>block<S2SV_blank>size\\n" ) ; return AVERROR_INVALIDDATA ; } s -> codebook_size = MAX_CODEBOOK_SIZE ; s -> codebook = av_malloc ( s -> codebook_size ) ; if ( ! s -> codebook ) goto fail ; s -> next_codebook_buffer = av_malloc ( s -> codebook_size ) ; if ( ! s -> next_codebook_buffer ) goto fail ; s -> decode_buffer_size = ( s -> width / s -> vector_width ) * ( s -> height / s -> vector_height ) * 2 ; s -> decode_buffer = av_mallocz ( s -> decode_buffer_size ) ; if ( ! s -> decode_buffer ) goto fail ; if ( s -> vector_height == 4 ) { codebook_index = 0xFF00 * 16 ; for ( i = 0 ; i < 256 ; i ++ ) for ( j = 0 ; j < 16 ; j ++ ) s -> codebook [ codebook_index ++ ] = i ; } else { codebook_index = 0xF00 * 8 ; for ( i = 0 ; i < 256 ; i ++ ) for ( j = 0 ; j < 8 ; j ++ ) s -> codebook [ codebook_index ++ ] = i ; } s -> next_codebook_buffer_index = 0 ; return 0 ; fail : av_freep ( & s -> codebook ) ; av_freep ( & s -> next_codebook_buffer ) ; av_freep ( & s -> decode_buffer ) ; return AVERROR ( ENOMEM ) ; }
CWE-000 static int decode_slice_header ( H264Context * h , H264Context * h0 ) { unsigned int first_mb_in_slice ; unsigned int pps_id ; int ret ; unsigned int slice_type , tmp , i , j ; int last_pic_structure , last_pic_droppable ; int must_reinit ; int needs_reinit = 0 ; int field_pic_flag , bottom_field_flag ; h -> me . qpel_put = h -> h264qpel . put_h264_qpel_pixels_tab ; h -> me . qpel_avg = h -> h264qpel . avg_h264_qpel_pixels_tab ; first_mb_in_slice = get_ue_golomb_long ( & h -> gb ) ; if ( first_mb_in_slice == 0 ) { if ( h0 -> current_slice && FIELD_PICTURE ( h ) ) { field_end ( h , 1 ) ; } h0 -> current_slice = 0 ; if ( ! h0 -> first_field ) { if ( h -> cur_pic_ptr && ! h -> droppable ) { ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , h -> picture_structure == PICT_BOTTOM_FIELD ) ; } h -> cur_pic_ptr = NULL ; } } slice_type = get_ue_golomb_31 ( & h -> gb ) ; if ( slice_type > 9 ) { av_log ( h -> avctx , AV_LOG_ERROR , "slice<S2SV_blank>type<S2SV_blank>too<S2SV_blank>large<S2SV_blank>(%d)<S2SV_blank>at<S2SV_blank>%d<S2SV_blank>%d\\n" , slice_type , h -> mb_x , h -> mb_y ) ; return AVERROR_INVALIDDATA ; } if ( slice_type > 4 ) { slice_type -= 5 ; h -> slice_type_fixed = 1 ; } else h -> slice_type_fixed = 0 ; slice_type = golomb_to_pict_type [ slice_type ] ; h -> slice_type = slice_type ; h -> slice_type_nos = slice_type & 3 ; h -> pict_type = h -> slice_type ; pps_id = get_ue_golomb ( & h -> gb ) ; if ( pps_id >= MAX_PPS_COUNT ) { av_log ( h -> avctx , AV_LOG_ERROR , "pps_id<S2SV_blank>%d<S2SV_blank>out<S2SV_blank>of<S2SV_blank>range\\n" , pps_id ) ; return AVERROR_INVALIDDATA ; } if ( ! h0 -> pps_buffers [ pps_id ] ) { av_log ( h -> avctx , AV_LOG_ERROR , "non-existing<S2SV_blank>PPS<S2SV_blank>%u<S2SV_blank>referenced\\n" , pps_id ) ; return AVERROR_INVALIDDATA ; } h -> pps = * h0 -> pps_buffers [ pps_id ] ; if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] ) { av_log ( h -> avctx , AV_LOG_ERROR , "non-existing<S2SV_blank>SPS<S2SV_blank>%u<S2SV_blank>referenced\\n" , h -> pps . sps_id ) ; return AVERROR_INVALIDDATA ; } if ( h -> pps . sps_id != h -> current_sps_id || h0 -> sps_buffers [ h -> pps . sps_id ] -> new ) { h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 ; h -> current_sps_id = h -> pps . sps_id ; h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ] ; if ( h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc ) needs_reinit = 1 ; if ( h -> bit_depth_luma != h -> sps . bit_depth_luma || h -> chroma_format_idc != h -> sps . chroma_format_idc ) { h -> bit_depth_luma = h -> sps . bit_depth_luma ; h -> chroma_format_idc = h -> sps . chroma_format_idc ; needs_reinit = 1 ; } if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 ) return ret ; } h -> avctx -> profile = ff_h264_get_profile ( & h -> sps ) ; h -> avctx -> level = h -> sps . level_idc ; h -> avctx -> refs = h -> sps . ref_frame_count ; must_reinit = ( h -> context_initialized && ( 16 * h -> sps . mb_width != h -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != h -> avctx -> coded_height || h -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , h -> avctx -> sample_aspect_ratio ) || h -> mb_width != h -> sps . mb_width || h -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ) ) ; if ( h0 -> avctx -> pix_fmt != get_pixel_format ( h0 , 0 ) ) must_reinit = 1 ; h -> mb_width = h -> sps . mb_width ; h -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) ; h -> mb_num = h -> mb_width * h -> mb_height ; h -> mb_stride = h -> mb_width + 1 ; h -> b_stride = h -> mb_width * 4 ; h -> chroma_y_shift = h -> sps . chroma_format_idc <= 1 ; h -> width = 16 * h -> mb_width ; h -> height = 16 * h -> mb_height ; ret = init_dimensions ( h ) ; if ( ret < 0 ) return ret ; if ( h -> sps . video_signal_type_present_flag ) { h -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG ; if ( h -> sps . colour_description_present_flag ) { if ( h -> avctx -> colorspace != h -> sps . colorspace ) needs_reinit = 1 ; h -> avctx -> color_primaries = h -> sps . color_primaries ; h -> avctx -> color_trc = h -> sps . color_trc ; h -> avctx -> colorspace = h -> sps . colorspace ; } } if ( h -> context_initialized && ( h -> width != h -> avctx -> coded_width || h -> height != h -> avctx -> coded_height || must_reinit || needs_reinit ) ) { if ( h != h0 ) { av_log ( h -> avctx , AV_LOG_ERROR , "changing<S2SV_blank>width/height<S2SV_blank>on<S2SV_blank>" "slice<S2SV_blank>%d\\n" , h0 -> current_slice + 1 ) ; return AVERROR_INVALIDDATA ; } flush_change ( h ) ; if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 ) return ret ; h -> avctx -> pix_fmt = ret ; av_log ( h -> avctx , AV_LOG_INFO , "Reinit<S2SV_blank>context<S2SV_blank>to<S2SV_blank>%dx%d,<S2SV_blank>" "pix_fmt:<S2SV_blank>%s\\n" , h -> width , h -> height , av_get_pix_fmt_name ( h -> avctx -> pix_fmt ) ) ; if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 ) { av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init()<S2SV_blank>failed\\n" ) ; return ret ; } } if ( ! h -> context_initialized ) { if ( h != h0 ) { av_log ( h -> avctx , AV_LOG_ERROR , "Cannot<S2SV_blank>(re-)initialize<S2SV_blank>context<S2SV_blank>during<S2SV_blank>parallel<S2SV_blank>decoding.\\n" ) ; return AVERROR_PATCHWELCOME ; } if ( ( ret = get_pixel_format ( h , 1 ) ) < 0 ) return ret ; h -> avctx -> pix_fmt = ret ; if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 ) { av_log ( h -> avctx , AV_LOG_ERROR , "h264_slice_header_init()<S2SV_blank>failed\\n" ) ; return ret ; } } if ( h == h0 && h -> dequant_coeff_pps != pps_id ) { h -> dequant_coeff_pps = pps_id ; init_dequant_tables ( h ) ; } h -> frame_num = get_bits ( & h -> gb , h -> sps . log2_max_frame_num ) ; h -> mb_mbaff = 0 ; h -> mb_aff_frame = 0 ; last_pic_structure = h0 -> picture_structure ; last_pic_droppable = h0 -> droppable ; h -> droppable = h -> nal_ref_idc == 0 ; if ( h -> sps . frame_mbs_only_flag ) { h -> picture_structure = PICT_FRAME ; } else { if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B ) { av_log ( h -> avctx , AV_LOG_ERROR , "This<S2SV_blank>stream<S2SV_blank>was<S2SV_blank>generated<S2SV_blank>by<S2SV_blank>a<S2SV_blank>broken<S2SV_blank>encoder,<S2SV_blank>invalid<S2SV_blank>8x8<S2SV_blank>inference\\n" ) ; return - 1 ; } field_pic_flag = get_bits1 ( & h -> gb ) ; if ( field_pic_flag ) { bottom_field_flag = get_bits1 ( & h -> gb ) ; h -> picture_structure = PICT_TOP_FIELD + bottom_field_flag ; } else { h -> picture_structure = PICT_FRAME ; h -> mb_aff_frame = h -> sps . mb_aff ; } } h -> mb_field_decoding_flag = h -> picture_structure != PICT_FRAME ; if ( h0 -> current_slice != 0 ) { if ( last_pic_structure != h -> picture_structure || last_pic_droppable != h -> droppable ) { av_log ( h -> avctx , AV_LOG_ERROR , "Changing<S2SV_blank>field<S2SV_blank>mode<S2SV_blank>(%d<S2SV_blank>-><S2SV_blank>%d)<S2SV_blank>between<S2SV_blank>slices<S2SV_blank>is<S2SV_blank>not<S2SV_blank>allowed\\n" , last_pic_structure , h -> picture_structure ) ; h -> picture_structure = last_pic_structure ; h -> droppable = last_pic_droppable ; return AVERROR_INVALIDDATA ; } else if ( ! h0 -> cur_pic_ptr ) { av_log ( h -> avctx , AV_LOG_ERROR , "unset<S2SV_blank>cur_pic_ptr<S2SV_blank>on<S2SV_blank>%d.<S2SV_blank>slice\\n" , h0 -> current_slice + 1 ) ; return AVERROR_INVALIDDATA ; } } else { if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 ) { int unwrap_prev_frame_num = h -> prev_frame_num ; int max_frame_num = 1 << h -> sps . log2_max_frame_num ; if ( unwrap_prev_frame_num > h -> frame_num ) unwrap_prev_frame_num -= max_frame_num ; if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count ) { unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 ; if ( unwrap_prev_frame_num < 0 ) unwrap_prev_frame_num += max_frame_num ; h -> prev_frame_num = unwrap_prev_frame_num ; } } if ( h0 -> first_field ) { assert ( h0 -> cur_pic_ptr ) ; assert ( h0 -> cur_pic_ptr -> f . data [ 0 ] ) ; assert ( h0 -> cur_pic_ptr -> reference != DELAYED_PIC_REF ) ; <S2SV_StartBug> if ( ! last_pic_droppable && h0 -> cur_pic_ptr -> tf . owner == h0 -> avctx ) { <S2SV_EndBug> ff_thread_report_progress ( & h0 -> cur_pic_ptr -> tf , INT_MAX , last_pic_structure == PICT_BOTTOM_FIELD ) ; } if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure ) { <S2SV_StartBug> if ( ! last_pic_droppable && last_pic_structure != PICT_FRAME ) { <S2SV_EndBug> ff_thread_report_progress ( & h0 -> cur_pic_ptr -> tf , INT_MAX , last_pic_structure == PICT_TOP_FIELD ) ; } } else { if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num ) { <S2SV_StartBug> if ( ! last_pic_droppable && last_pic_structure != PICT_FRAME ) { <S2SV_EndBug> ff_thread_report_progress ( & h0 -> cur_pic_ptr -> tf , INT_MAX , last_pic_structure == PICT_TOP_FIELD ) ; } } else { if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && h -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && h -> picture_structure == PICT_TOP_FIELD ) ) ) { av_log ( h -> avctx , AV_LOG_ERROR , "Invalid<S2SV_blank>field<S2SV_blank>mode<S2SV_blank>combination<S2SV_blank>%d/%d\\n" , last_pic_structure , h -> picture_structure ) ; h -> picture_structure = last_pic_structure ; h -> droppable = last_pic_droppable ; return AVERROR_INVALIDDATA ; } else if ( last_pic_droppable != h -> droppable ) { avpriv_request_sample ( h -> avctx , "Found<S2SV_blank>reference<S2SV_blank>and<S2SV_blank>non-reference<S2SV_blank>fields<S2SV_blank>in<S2SV_blank>the<S2SV_blank>same<S2SV_blank>frame,<S2SV_blank>which" ) ; h -> picture_structure = last_pic_structure ; h -> droppable = last_pic_droppable ; return AVERROR_PATCHWELCOME ; } } } } while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! h0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) ) { Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; av_log ( h -> avctx , AV_LOG_DEBUG , "Frame<S2SV_blank>num<S2SV_blank>gap<S2SV_blank>%d<S2SV_blank>%d\\n" , h -> frame_num , h -> prev_frame_num ) ; if ( ! h -> sps . gaps_in_frame_num_allowed_flag ) for ( i = 0 ; i < FF_ARRAY_ELEMS ( h -> last_pocs ) ; i ++ ) h -> last_pocs [ i ] = INT_MIN ; ret = h264_frame_start ( h ) ; if ( ret < 0 ) return ret ; h -> prev_frame_num ++ ; h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num ; h -> cur_pic_ptr -> frame_num = h -> prev_frame_num ; ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 0 ) ; ff_thread_report_progress ( & h -> cur_pic_ptr -> tf , INT_MAX , 1 ) ; ret = ff_generate_sliding_window_mmcos ( h , 1 ) ; if ( ret < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) ) return ret ; ret = ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) ; if ( ret < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) ) return ret ; if ( h -> short_ref_count ) { if ( prev ) { av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , h -> avctx -> pix_fmt , h -> mb_width * 16 , h -> mb_height * 16 ) ; h -> short_ref [ 0 ] -> poc = prev -> poc + 2 ; } h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num ; } } if ( h0 -> first_field ) { assert ( h0 -> cur_pic_ptr ) ; assert ( h0 -> cur_pic_ptr -> f . data [ 0 ] ) ; assert ( h0 -> cur_pic_ptr -> reference != DELAYED_PIC_REF ) ; if ( ! FIELD_PICTURE ( h ) || h -> picture_structure == last_pic_structure ) { h0 -> cur_pic_ptr = NULL ; h0 -> first_field = FIELD_PICTURE ( h ) ; } else { if ( h0 -> cur_pic_ptr -> frame_num != h -> frame_num ) { ff_thread_report_progress ( & h0 -> cur_pic_ptr -> tf , INT_MAX , h0 -> picture_structure == PICT_BOTTOM_FIELD ) ; h0 -> first_field = 1 ; h0 -> cur_pic_ptr = NULL ; } else { h0 -> first_field = 0 ; } } } else { h0 -> first_field = FIELD_PICTURE ( h ) ; } if ( ! FIELD_PICTURE ( h ) || h0 -> first_field ) { if ( h264_frame_start ( h ) < 0 ) { h0 -> first_field = 0 ; return AVERROR_INVALIDDATA ; } } else { release_unused_pictures ( h , 0 ) ; } if ( FIELD_PICTURE ( h ) ) { for ( i = ( h -> picture_structure == PICT_BOTTOM_FIELD ) ; i < h -> mb_height ; i ++ ) memset ( h -> slice_table + i * h -> mb_stride , - 1 , ( h -> mb_stride - ( i + 1 == h -> mb_height ) ) * sizeof ( * h -> slice_table ) ) ; } else { memset ( h -> slice_table , - 1 , ( h -> mb_height * h -> mb_stride - 1 ) * sizeof ( * h -> slice_table ) ) ; } h0 -> last_slice_type = - 1 ; } if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 ) return ret ; for ( i = 0 ; i < h -> slice_context_count ; i ++ ) if ( h -> thread_context [ i ] ) { ret = alloc_scratch_buffers ( h -> thread_context [ i ] , h -> linesize ) ; if ( ret < 0 ) return ret ; } h -> cur_pic_ptr -> frame_num = h -> frame_num ; av_assert1 ( h -> mb_num == h -> mb_width * h -> mb_height ) ; if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE ( h ) >= h -> mb_num || first_mb_in_slice >= h -> mb_num ) { av_log ( h -> avctx , AV_LOG_ERROR , "first_mb_in_slice<S2SV_blank>overflow\\n" ) ; return AVERROR_INVALIDDATA ; } h -> resync_mb_x = h -> mb_x = first_mb_in_slice % h -> mb_width ; h -> resync_mb_y = h -> mb_y = ( first_mb_in_slice / h -> mb_width ) << FIELD_OR_MBAFF_PICTURE ( h ) ; if ( h -> picture_structure == PICT_BOTTOM_FIELD ) h -> resync_mb_y = h -> mb_y = h -> mb_y + 1 ; av_assert1 ( h -> mb_y < h -> mb_height ) ; if ( h -> picture_structure == PICT_FRAME ) { h -> curr_pic_num = h -> frame_num ; h -> max_pic_num = 1 << h -> sps . log2_max_frame_num ; } else { h -> curr_pic_num = 2 * h -> frame_num + 1 ; h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ) ; } if ( h -> nal_unit_type == NAL_IDR_SLICE ) get_ue_golomb ( & h -> gb ) ; if ( h -> sps . poc_type == 0 ) { h -> poc_lsb = get_bits ( & h -> gb , h -> sps . log2_max_poc_lsb ) ; if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME ) h -> delta_poc_bottom = get_se_golomb ( & h -> gb ) ; } if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag ) { h -> delta_poc [ 0 ] = get_se_golomb ( & h -> gb ) ; if ( h -> pps . pic_order_present == 1 && h -> picture_structure == PICT_FRAME ) h -> delta_poc [ 1 ] = get_se_golomb ( & h -> gb ) ; } ff_init_poc ( h , h -> cur_pic_ptr -> field_poc , & h -> cur_pic_ptr -> poc ) ; if ( h -> pps . redundant_pic_cnt_present ) h -> redundant_pic_count = get_ue_golomb ( & h -> gb ) ; ret = ff_set_ref_count ( h ) ; if ( ret < 0 ) return ret ; if ( slice_type != AV_PICTURE_TYPE_I && ( h0 -> current_slice == 0 || slice_type != h0 -> last_slice_type || memcmp ( h0 -> last_ref_count , h0 -> ref_count , sizeof ( h0 -> ref_count ) ) ) ) { ff_h264_fill_default_ref_list ( h ) ; } if ( h -> slice_type_nos != AV_PICTURE_TYPE_I ) { ret = ff_h264_decode_ref_pic_list_reordering ( h ) ; if ( ret < 0 ) { h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0 ; return ret ; } } if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) ) ff_pred_weight_table ( h ) ; else if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) { implicit_weight_table ( h , - 1 ) ; } else { h -> use_weight = 0 ; for ( i = 0 ; i < 2 ; i ++ ) { h -> luma_weight_flag [ i ] = 0 ; h -> chroma_weight_flag [ i ] = 0 ; } } if ( h -> nal_ref_idc ) { ret = ff_h264_decode_ref_pic_marking ( h0 , & h -> gb , ! ( h -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) ; if ( ret < 0 && ( h -> avctx -> err_recognition & AV_EF_EXPLODE ) ) return AVERROR_INVALIDDATA ; } if ( FRAME_MBAFF ( h ) ) { ff_h264_fill_mbaff_ref_list ( h ) ; if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) { implicit_weight_table ( h , 0 ) ; implicit_weight_table ( h , 1 ) ; } } if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred ) ff_h264_direct_dist_scale_factor ( h ) ; ff_h264_direct_ref_list_init ( h ) ; if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac ) { tmp = get_ue_golomb_31 ( & h -> gb ) ; if ( tmp > 2 ) { av_log ( h -> avctx , AV_LOG_ERROR , "cabac_init_idc<S2SV_blank>overflow\\n" ) ; return AVERROR_INVALIDDATA ; } h -> cabac_init_idc = tmp ; } h -> last_qscale_diff = 0 ; tmp = h -> pps . init_qp + get_se_golomb ( & h -> gb ) ; if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) ) { av_log ( h -> avctx , AV_LOG_ERROR , "QP<S2SV_blank>%u<S2SV_blank>out<S2SV_blank>of<S2SV_blank>range\\n" , tmp ) ; return AVERROR_INVALIDDATA ; } h -> qscale = tmp ; h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , h -> qscale ) ; h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , h -> qscale ) ; if ( h -> slice_type == AV_PICTURE_TYPE_SP ) get_bits1 ( & h -> gb ) ; if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI ) get_se_golomb ( & h -> gb ) ; h -> deblocking_filter = 1 ; h -> slice_alpha_c0_offset = 52 ; h -> slice_beta_offset = 52 ; if ( h -> pps . deblocking_filter_parameters_present ) { tmp = get_ue_golomb_31 ( & h -> gb ) ; if ( tmp > 2 ) { av_log ( h -> avctx , AV_LOG_ERROR , "deblocking_filter_idc<S2SV_blank>%u<S2SV_blank>out<S2SV_blank>of<S2SV_blank>range\\n" , tmp ) ; return AVERROR_INVALIDDATA ; } h -> deblocking_filter = tmp ; if ( h -> deblocking_filter < 2 ) h -> deblocking_filter ^= 1 ; if ( h -> deblocking_filter ) { h -> slice_alpha_c0_offset += get_se_golomb ( & h -> gb ) << 1 ; h -> slice_beta_offset += get_se_golomb ( & h -> gb ) << 1 ; if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U ) { av_log ( h -> avctx , AV_LOG_ERROR , "deblocking<S2SV_blank>filter<S2SV_blank>parameters<S2SV_blank>%d<S2SV_blank>%d<S2SV_blank>out<S2SV_blank>of<S2SV_blank>range\\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ) ; return AVERROR_INVALIDDATA ; } } } if ( h -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( h -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) ) h -> deblocking_filter = 0 ; if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 ) { if ( h -> avctx -> flags2 & CODEC_FLAG2_FAST ) { h -> deblocking_filter = 2 ; } else { h0 -> max_contexts = 1 ; if ( ! h0 -> single_decode_warning ) { av_log ( h -> avctx , AV_LOG_INFO , "Cannot<S2SV_blank>parallelize<S2SV_blank>deblocking<S2SV_blank>type<S2SV_blank>1,<S2SV_blank>decoding<S2SV_blank>such<S2SV_blank>frames<S2SV_blank>in<S2SV_blank>sequential<S2SV_blank>order\\n" ) ; h0 -> single_decode_warning = 1 ; } if ( h != h0 ) { av_log ( h -> avctx , AV_LOG_ERROR , "Deblocking<S2SV_blank>switched<S2SV_blank>inside<S2SV_blank>frame.\\n" ) ; return 1 ; } } } h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ) ; h0 -> last_slice_type = slice_type ; memcpy ( h0 -> last_ref_count , h0 -> ref_count , sizeof ( h0 -> last_ref_count ) ) ; h -> slice_num = ++ h0 -> current_slice ; if ( h -> slice_num ) h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = h -> resync_mb_y ; if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= h -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= h -> resync_mb_y && h -> slice_num >= MAX_SLICES ) { av_log ( h -> avctx , AV_LOG_WARNING , "Possibly<S2SV_blank>too<S2SV_blank>many<S2SV_blank>slices<S2SV_blank>(%d<S2SV_blank>>=<S2SV_blank>%d),<S2SV_blank>increase<S2SV_blank>MAX_SLICES<S2SV_blank>and<S2SV_blank>recompile<S2SV_blank>if<S2SV_blank>there<S2SV_blank>are<S2SV_blank>artifacts\\n" , h -> slice_num , MAX_SLICES ) ; } for ( j = 0 ; j < 2 ; j ++ ) { int id_list [ 16 ] ; int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; for ( i = 0 ; i < 16 ; i ++ ) { id_list [ i ] = 60 ; if ( j < h -> list_count && i < h -> ref_count [ j ] && h -> ref_list [ j ] [ i ] . f . buf [ 0 ] ) { int k ; AVBuffer * buf = h -> ref_list [ j ] [ i ] . f . buf [ 0 ] -> buffer ; for ( k = 0 ; k < h -> short_ref_count ; k ++ ) if ( h -> short_ref [ k ] -> f . buf [ 0 ] -> buffer == buf ) { id_list [ i ] = k ; break ; } for ( k = 0 ; k < h -> long_ref_count ; k ++ ) if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . buf [ 0 ] -> buffer == buf ) { id_list [ i ] = h -> short_ref_count + k ; break ; } } } ref2frm [ 0 ] = ref2frm [ 1 ] = - 1 ; for ( i = 0 ; i < 16 ; i ++ ) ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ) ; ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1 ; for ( i = 16 ; i < 48 ; i ++ ) ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . reference & 3 ) ; } if ( h -> ref_count [ 0 ] ) h -> er . last_pic = & h -> ref_list [ 0 ] [ 0 ] ; if ( h -> ref_count [ 1 ] ) h -> er . next_pic = & h -> ref_list [ 1 ] [ 0 ] ; h -> er . ref_count = h -> ref_count [ 0 ] ; if ( h -> avctx -> debug & FF_DEBUG_PICT_INFO ) { av_log ( h -> avctx , AV_LOG_DEBUG , "slice:%d<S2SV_blank>%s<S2SV_blank>mb:%d<S2SV_blank>%c%s%s<S2SV_blank>pps:%u<S2SV_blank>frame:%d<S2SV_blank>poc:%d/%d<S2SV_blank>ref:%d/%d<S2SV_blank>qp:%d<S2SV_blank>loop:%d:%d:%d<S2SV_blank>weight:%d%s<S2SV_blank>%s\\n" , h -> slice_num , ( h -> picture_structure == PICT_FRAME ? "F" : h -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? "<S2SV_blank>fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? "<S2SV_blank>IDR" : "" , pps_id , h -> frame_num , h -> cur_pic_ptr -> field_poc [ 0 ] , h -> cur_pic_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , h -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ) ; } return 0 ; }
CWE-000 void ff_jpeg2000_cleanup ( Jpeg2000Component * comp , Jpeg2000CodingStyle * codsty ) { int reslevelno , bandno , precno ; for ( reslevelno = 0 ; comp -> reslevel && reslevelno < codsty -> nreslevels ; reslevelno ++ ) { Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; for ( bandno = 0 ; bandno < reslevel -> nbands ; bandno ++ ) { Jpeg2000Band * band = reslevel -> band + bandno ; for ( precno = 0 ; precno < reslevel -> num_precincts_x * reslevel -> num_precincts_y ; precno ++ ) { <S2SV_StartBug> Jpeg2000Prec * prec = band -> prec + precno ; <S2SV_EndBug> av_freep ( & prec -> zerobits ) ; av_freep ( & prec -> cblkincl ) ; av_freep ( & prec -> cblk ) ; } <S2SV_StartBug> av_freep ( & band -> prec ) ; <S2SV_EndBug> } av_freep ( & reslevel -> band ) ; } ff_dwt_destroy ( & comp -> dwt ) ; av_freep ( & comp -> reslevel ) ; av_freep ( & comp -> i_data ) ; av_freep ( & comp -> f_data ) ; }
CWE-000 int ff_jpeg2000_init_component ( Jpeg2000Component * comp , Jpeg2000CodingStyle * codsty , Jpeg2000QuantStyle * qntsty , int cbps , int dx , int dy , AVCodecContext * avctx ) { uint8_t log2_band_prec_width , log2_band_prec_height ; int reslevelno , bandno , gbandno = 0 , ret , i , j ; uint32_t csize ; if ( codsty -> nreslevels2decode <= 0 ) { av_log ( avctx , AV_LOG_ERROR , "nreslevels2decode<S2SV_blank>%d<S2SV_blank>invalid<S2SV_blank>or<S2SV_blank>uninitialized\\n" , codsty -> nreslevels2decode ) ; return AVERROR_INVALIDDATA ; } if ( ret = ff_jpeg2000_dwt_init ( & comp -> dwt , comp -> coord , codsty -> nreslevels2decode - 1 , codsty -> transform ) ) return ret ; csize = ( comp -> coord [ 0 ] [ 1 ] - comp -> coord [ 0 ] [ 0 ] ) * ( comp -> coord [ 1 ] [ 1 ] - comp -> coord [ 1 ] [ 0 ] ) ; if ( codsty -> transform == FF_DWT97 ) { comp -> i_data = NULL ; comp -> f_data = av_malloc_array ( csize , sizeof ( * comp -> f_data ) ) ; if ( ! comp -> f_data ) return AVERROR ( ENOMEM ) ; } else { comp -> f_data = NULL ; comp -> i_data = av_malloc_array ( csize , sizeof ( * comp -> i_data ) ) ; if ( ! comp -> i_data ) return AVERROR ( ENOMEM ) ; } comp -> reslevel = av_malloc_array ( codsty -> nreslevels , sizeof ( * comp -> reslevel ) ) ; if ( ! comp -> reslevel ) return AVERROR ( ENOMEM ) ; for ( reslevelno = 0 ; reslevelno < codsty -> nreslevels ; reslevelno ++ ) { int declvl = codsty -> nreslevels - reslevelno ; Jpeg2000ResLevel * reslevel = comp -> reslevel + reslevelno ; for ( i = 0 ; i < 2 ; i ++ ) for ( j = 0 ; j < 2 ; j ++ ) reslevel -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] , declvl - 1 ) ; reslevel -> log2_prec_width = codsty -> log2_prec_widths [ reslevelno ] ; reslevel -> log2_prec_height = codsty -> log2_prec_heights [ reslevelno ] ; if ( reslevelno == 0 ) reslevel -> nbands = 1 ; else reslevel -> nbands = 3 ; if ( reslevel -> coord [ 0 ] [ 1 ] == reslevel -> coord [ 0 ] [ 0 ] ) reslevel -> num_precincts_x = 0 ; else reslevel -> num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 0 ] [ 1 ] , reslevel -> log2_prec_width ) - ( reslevel -> coord [ 0 ] [ 0 ] >> reslevel -> log2_prec_width ) ; if ( reslevel -> coord [ 1 ] [ 1 ] == reslevel -> coord [ 1 ] [ 0 ] ) reslevel -> num_precincts_y = 0 ; else reslevel -> num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel -> coord [ 1 ] [ 1 ] , reslevel -> log2_prec_height ) - ( reslevel -> coord [ 1 ] [ 0 ] >> reslevel -> log2_prec_height ) ; <S2SV_StartBug> reslevel -> band = av_malloc_array ( reslevel -> nbands , sizeof ( * reslevel -> band ) ) ; <S2SV_EndBug> if ( ! reslevel -> band ) return AVERROR ( ENOMEM ) ; for ( bandno = 0 ; bandno < reslevel -> nbands ; bandno ++ , gbandno ++ ) { Jpeg2000Band * band = reslevel -> band + bandno ; int cblkno , precno ; int nb_precincts ; switch ( qntsty -> quantsty ) { uint8_t gain ; int numbps ; case JPEG2000_QSTY_NONE : band -> f_stepsize = 1 ; break ; case JPEG2000_QSTY_SI : numbps = cbps + lut_gain [ codsty -> transform == FF_DWT53 ] [ bandno + ( reslevelno > 0 ) ] ; band -> f_stepsize = SHL ( 2048 + qntsty -> mant [ gbandno ] , 2 + numbps - qntsty -> expn [ gbandno ] ) ; break ; case JPEG2000_QSTY_SE : gain = cbps ; band -> f_stepsize = pow ( 2.0 , gain - qntsty -> expn [ gbandno ] ) ; band -> f_stepsize *= qntsty -> mant [ gbandno ] / 2048.0 + 1.0 ; break ; default : band -> f_stepsize = 0 ; av_log ( avctx , AV_LOG_ERROR , "Unknown<S2SV_blank>quantization<S2SV_blank>format\\n" ) ; break ; } if ( ! av_codec_is_encoder ( avctx -> codec ) ) band -> f_stepsize *= 0.5 ; band -> i_stepsize = band -> f_stepsize * ( 1 << 15 ) ; if ( reslevelno == 0 ) { for ( i = 0 ; i < 2 ; i ++ ) for ( j = 0 ; j < 2 ; j ++ ) band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] , declvl - 1 ) ; log2_band_prec_width = reslevel -> log2_prec_width ; log2_band_prec_height = reslevel -> log2_prec_height ; band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width ) ; band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height ) ; } else { for ( i = 0 ; i < 2 ; i ++ ) for ( j = 0 ; j < 2 ; j ++ ) band -> coord [ i ] [ j ] = ff_jpeg2000_ceildivpow2 ( comp -> coord_o [ i ] [ j ] - comp -> coord_o [ i ] [ 0 ] - ( ( ( bandno + 1 >> i ) & 1 ) << declvl - 1 ) , declvl ) ; band -> log2_cblk_width = FFMIN ( codsty -> log2_cblk_width , reslevel -> log2_prec_width - 1 ) ; band -> log2_cblk_height = FFMIN ( codsty -> log2_cblk_height , reslevel -> log2_prec_height - 1 ) ; log2_band_prec_width = reslevel -> log2_prec_width - 1 ; log2_band_prec_height = reslevel -> log2_prec_height - 1 ; } for ( j = 0 ; j < 2 ; j ++ ) band -> coord [ 0 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 0 ] [ j ] , dx ) ; for ( j = 0 ; j < 2 ; j ++ ) band -> coord [ 1 ] [ j ] = ff_jpeg2000_ceildiv ( band -> coord [ 1 ] [ j ] , dy ) ; <S2SV_StartBug> band -> prec = av_malloc_array ( reslevel -> num_precincts_x * <S2SV_EndBug> ( uint64_t ) reslevel -> num_precincts_y , sizeof ( * band -> prec ) ) ; if ( ! band -> prec ) return AVERROR ( ENOMEM ) ; nb_precincts = reslevel -> num_precincts_x * reslevel -> num_precincts_y ; for ( precno = 0 ; precno < nb_precincts ; precno ++ ) { Jpeg2000Prec * prec = band -> prec + precno ; prec -> coord [ 0 ] [ 0 ] = ( precno % reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_width ) ; prec -> coord [ 0 ] [ 0 ] = FFMAX ( prec -> coord [ 0 ] [ 0 ] , band -> coord [ 0 ] [ 0 ] ) ; prec -> coord [ 1 ] [ 0 ] = ( precno / reslevel -> num_precincts_x ) * ( 1 << log2_band_prec_height ) ; prec -> coord [ 1 ] [ 0 ] = FFMAX ( prec -> coord [ 1 ] [ 0 ] , band -> coord [ 1 ] [ 0 ] ) ; prec -> coord [ 0 ] [ 1 ] = prec -> coord [ 0 ] [ 0 ] + ( 1 << log2_band_prec_width ) ; prec -> coord [ 0 ] [ 1 ] = FFMIN ( prec -> coord [ 0 ] [ 1 ] , band -> coord [ 0 ] [ 1 ] ) ; prec -> coord [ 1 ] [ 1 ] = prec -> coord [ 1 ] [ 0 ] + ( 1 << log2_band_prec_height ) ; prec -> coord [ 1 ] [ 1 ] = FFMIN ( prec -> coord [ 1 ] [ 1 ] , band -> coord [ 1 ] [ 1 ] ) ; prec -> nb_codeblocks_width = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 0 ] [ 1 ] - prec -> coord [ 0 ] [ 0 ] , band -> log2_cblk_width ) ; prec -> nb_codeblocks_height = ff_jpeg2000_ceildivpow2 ( prec -> coord [ 1 ] [ 1 ] - prec -> coord [ 1 ] [ 0 ] , band -> log2_cblk_height ) ; prec -> cblkincl = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ) ; if ( ! prec -> cblkincl ) return AVERROR ( ENOMEM ) ; prec -> zerobits = ff_jpeg2000_tag_tree_init ( prec -> nb_codeblocks_width , prec -> nb_codeblocks_height ) ; if ( ! prec -> zerobits ) return AVERROR ( ENOMEM ) ; prec -> cblk = av_mallocz_array ( prec -> nb_codeblocks_width * ( uint64_t ) prec -> nb_codeblocks_height , sizeof ( * prec -> cblk ) ) ; if ( ! prec -> cblk ) return AVERROR ( ENOMEM ) ; for ( cblkno = 0 ; cblkno < prec -> nb_codeblocks_width * prec -> nb_codeblocks_height ; cblkno ++ ) { Jpeg2000Cblk * cblk = prec -> cblk + cblkno ; uint16_t Cx0 , Cy0 ; Cx0 = ( prec -> coord [ 0 ] [ 0 ] >> band -> log2_cblk_width ) << band -> log2_cblk_width ; Cx0 = Cx0 + ( ( cblkno % prec -> nb_codeblocks_width ) << band -> log2_cblk_width ) ; cblk -> coord [ 0 ] [ 0 ] = FFMAX ( Cx0 , prec -> coord [ 0 ] [ 0 ] ) ; Cy0 = ( prec -> coord [ 1 ] [ 0 ] >> band -> log2_cblk_height ) << band -> log2_cblk_height ; Cy0 = Cy0 + ( ( cblkno / prec -> nb_codeblocks_width ) << band -> log2_cblk_height ) ; cblk -> coord [ 1 ] [ 0 ] = FFMAX ( Cy0 , prec -> coord [ 1 ] [ 0 ] ) ; cblk -> coord [ 0 ] [ 1 ] = FFMIN ( Cx0 + ( 1 << band -> log2_cblk_width ) , prec -> coord [ 0 ] [ 1 ] ) ; cblk -> coord [ 1 ] [ 1 ] = FFMIN ( Cy0 + ( 1 << band -> log2_cblk_height ) , prec -> coord [ 1 ] [ 1 ] ) ; if ( ( bandno + ! ! reslevelno ) & 1 ) { cblk -> coord [ 0 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ] ; cblk -> coord [ 0 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 0 ] [ 0 ] ; } if ( ( bandno + ! ! reslevelno ) & 2 ) { cblk -> coord [ 1 ] [ 0 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ] ; cblk -> coord [ 1 ] [ 1 ] += comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 1 ] - comp -> reslevel [ reslevelno - 1 ] . coord [ 1 ] [ 0 ] ; } cblk -> zero = 0 ; cblk -> lblock = 3 ; cblk -> length = 0 ; cblk -> lengthinc = 0 ; cblk -> npasses = 0 ; } } } } return 0 ; }
CWE-000 int av_reallocp_array ( void * ptr , size_t nmemb , size_t size ) { void * * ptrptr = ptr ; * ptrptr = av_realloc_f ( * ptrptr , nmemb , size ) ; <S2SV_StartBug> if ( ! * ptrptr && ! ( nmemb && size ) ) <S2SV_EndBug> return AVERROR ( ENOMEM ) ; return 0 ; }
CWE-000 void ff_h264_free_tables ( H264Context * h , int free_rbsp ) { int i ; H264Context * hx ; av_freep ( & h -> intra4x4_pred_mode ) ; av_freep ( & h -> chroma_pred_mode_table ) ; av_freep ( & h -> cbp_table ) ; av_freep ( & h -> mvd_table [ 0 ] ) ; av_freep ( & h -> mvd_table [ 1 ] ) ; av_freep ( & h -> direct_table ) ; av_freep ( & h -> non_zero_count ) ; av_freep ( & h -> slice_table_base ) ; h -> slice_table = NULL ; av_freep ( & h -> list_counts ) ; av_freep ( & h -> mb2b_xy ) ; av_freep ( & h -> mb2br_xy ) ; av_buffer_pool_uninit ( & h -> qscale_table_pool ) ; av_buffer_pool_uninit ( & h -> mb_type_pool ) ; av_buffer_pool_uninit ( & h -> motion_val_pool ) ; av_buffer_pool_uninit ( & h -> ref_index_pool ) ; if ( free_rbsp && h -> DPB ) { for ( i = 0 ; i < H264_MAX_PICTURE_COUNT ; i ++ ) ff_h264_unref_picture ( h , & h -> DPB [ i ] ) ; <S2SV_StartBug> av_freep ( & h -> DPB ) ; <S2SV_EndBug> } else if ( h -> DPB ) { for ( i = 0 ; i < H264_MAX_PICTURE_COUNT ; i ++ ) h -> DPB [ i ] . needs_realloc = 1 ; } h -> cur_pic_ptr = NULL ; for ( i = 0 ; i < H264_MAX_THREADS ; i ++ ) { hx = h -> thread_context [ i ] ; if ( ! hx ) continue ; av_freep ( & hx -> top_borders [ 1 ] ) ; av_freep ( & hx -> top_borders [ 0 ] ) ; av_freep ( & hx -> bipred_scratchpad ) ; av_freep ( & hx -> edge_emu_buffer ) ; av_freep ( & hx -> dc_val_base ) ; av_freep ( & hx -> er . mb_index2xy ) ; av_freep ( & hx -> er . error_status_table ) ; av_freep ( & hx -> er . er_temp_buffer ) ; av_freep ( & hx -> er . mbintra_table ) ; av_freep ( & hx -> er . mbskip_table ) ; if ( free_rbsp ) { av_freep ( & hx -> rbsp_buffer [ 1 ] ) ; av_freep ( & hx -> rbsp_buffer [ 0 ] ) ; hx -> rbsp_buffer_size [ 0 ] = 0 ; hx -> rbsp_buffer_size [ 1 ] = 0 ; } if ( i ) av_freep ( & h -> thread_context [ i ] ) ; } }
CWE-000 bgp_attr_parse_ret_t bgp_attr_parse ( struct peer * peer , struct attr * attr , bgp_size_t size , struct bgp_nlri * mp_update , struct bgp_nlri * mp_withdraw ) { bgp_attr_parse_ret_t ret ; uint8_t flag = 0 ; uint8_t type = 0 ; bgp_size_t length ; uint8_t * startp , * endp ; uint8_t * attr_endp ; uint8_t seen [ BGP_ATTR_BITMAP_SIZE ] ; struct aspath * as4_path = NULL ; as_t as4_aggregator = 0 ; struct in_addr as4_aggregator_addr = { . s_addr = 0 } ; memset ( seen , 0 , BGP_ATTR_BITMAP_SIZE ) ; endp = BGP_INPUT_PNT ( peer ) + size ; while ( BGP_INPUT_PNT ( peer ) < endp ) { if ( endp - BGP_INPUT_PNT ( peer ) < BGP_ATTR_MIN_LEN ) { flog_warn ( EC_BGP_ATTRIBUTE_TOO_SMALL , "%s:<S2SV_blank>error<S2SV_blank>BGP<S2SV_blank>attribute<S2SV_blank>length<S2SV_blank>%lu<S2SV_blank>is<S2SV_blank>smaller<S2SV_blank>than<S2SV_blank>min<S2SV_blank>len" , peer -> host , ( unsigned long ) ( endp - stream_pnt ( BGP_INPUT ( peer ) ) ) ) ; bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_ATTR_LENG_ERR ) ; return BGP_ATTR_PARSE_ERROR ; } startp = BGP_INPUT_PNT ( peer ) ; flag = 0xF0 & stream_getc ( BGP_INPUT ( peer ) ) ; type = stream_getc ( BGP_INPUT ( peer ) ) ; if ( CHECK_FLAG ( flag , BGP_ATTR_FLAG_EXTLEN ) && ( ( endp - startp ) < ( BGP_ATTR_MIN_LEN + 1 ) ) ) { flog_warn ( EC_BGP_EXT_ATTRIBUTE_TOO_SMALL , "%s:<S2SV_blank>Extended<S2SV_blank>length<S2SV_blank>set,<S2SV_blank>but<S2SV_blank>just<S2SV_blank>%lu<S2SV_blank>bytes<S2SV_blank>of<S2SV_blank>attr<S2SV_blank>header" , peer -> host , ( unsigned long ) ( endp - stream_pnt ( BGP_INPUT ( peer ) ) ) ) ; bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_ATTR_LENG_ERR ) ; return BGP_ATTR_PARSE_ERROR ; } if ( CHECK_FLAG ( flag , BGP_ATTR_FLAG_EXTLEN ) ) length = stream_getw ( BGP_INPUT ( peer ) ) ; else length = stream_getc ( BGP_INPUT ( peer ) ) ; if ( CHECK_BITMAP ( seen , type ) ) { flog_warn ( EC_BGP_ATTRIBUTE_REPEATED , "%s:<S2SV_blank>error<S2SV_blank>BGP<S2SV_blank>attribute<S2SV_blank>type<S2SV_blank>%d<S2SV_blank>appears<S2SV_blank>twice<S2SV_blank>in<S2SV_blank>a<S2SV_blank>message" , peer -> host , type ) ; bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_MAL_ATTR ) ; return BGP_ATTR_PARSE_ERROR ; } SET_BITMAP ( seen , type ) ; attr_endp = BGP_INPUT_PNT ( peer ) + length ; if ( attr_endp > endp ) { flog_warn ( EC_BGP_ATTRIBUTE_TOO_LARGE , "%s:<S2SV_blank>BGP<S2SV_blank>type<S2SV_blank>%d<S2SV_blank>length<S2SV_blank>%d<S2SV_blank>is<S2SV_blank>too<S2SV_blank>large,<S2SV_blank>attribute<S2SV_blank>total<S2SV_blank>length<S2SV_blank>is<S2SV_blank>%d.<S2SV_blank><S2SV_blank>attr_endp<S2SV_blank>is<S2SV_blank>%p.<S2SV_blank><S2SV_blank>endp<S2SV_blank>is<S2SV_blank>%p" , peer -> host , type , length , size , attr_endp , endp ) ; unsigned char ndata [ BGP_MAX_PACKET_SIZE ] ; memset ( ndata , 0x00 , sizeof ( ndata ) ) ; size_t lfl = CHECK_FLAG ( flag , BGP_ATTR_FLAG_EXTLEN ) ? 2 : 1 ; stream_forward_getp ( BGP_INPUT ( peer ) , - ( 1 + lfl ) ) ; stream_get ( & ndata [ 0 ] , BGP_INPUT ( peer ) , 1 ) ; stream_get ( & ndata [ 1 ] , BGP_INPUT ( peer ) , lfl ) ; size_t atl = attr_endp - startp ; size_t ndl = MIN ( atl , STREAM_READABLE ( BGP_INPUT ( peer ) ) ) ; stream_get ( & ndata [ lfl + 1 ] , BGP_INPUT ( peer ) , ndl ) ; bgp_notify_send_with_data ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_ATTR_LENG_ERR , ndata , ndl + lfl + 1 ) ; return BGP_ATTR_PARSE_ERROR ; } struct bgp_attr_parser_args attr_args = { . peer = peer , . length = length , . attr = attr , . type = type , . flags = flag , . startp = startp , . total = attr_endp - startp , } ; if ( bgp_attr_flag_invalid ( & attr_args ) ) { ret = bgp_attr_malformed ( & attr_args , BGP_NOTIFY_UPDATE_ATTR_FLAG_ERR , attr_args . total ) ; if ( ret == BGP_ATTR_PARSE_PROCEED ) continue ; return ret ; } switch ( type ) { case BGP_ATTR_ORIGIN : ret = bgp_attr_origin ( & attr_args ) ; break ; case BGP_ATTR_AS_PATH : ret = bgp_attr_aspath ( & attr_args ) ; break ; case BGP_ATTR_AS4_PATH : ret = bgp_attr_as4_path ( & attr_args , & as4_path ) ; break ; case BGP_ATTR_NEXT_HOP : ret = bgp_attr_nexthop ( & attr_args ) ; break ; case BGP_ATTR_MULTI_EXIT_DISC : ret = bgp_attr_med ( & attr_args ) ; break ; case BGP_ATTR_LOCAL_PREF : ret = bgp_attr_local_pref ( & attr_args ) ; break ; case BGP_ATTR_ATOMIC_AGGREGATE : ret = bgp_attr_atomic ( & attr_args ) ; break ; case BGP_ATTR_AGGREGATOR : ret = bgp_attr_aggregator ( & attr_args ) ; break ; case BGP_ATTR_AS4_AGGREGATOR : ret = bgp_attr_as4_aggregator ( & attr_args , & as4_aggregator , & as4_aggregator_addr ) ; break ; case BGP_ATTR_COMMUNITIES : ret = bgp_attr_community ( & attr_args ) ; break ; case BGP_ATTR_LARGE_COMMUNITIES : ret = bgp_attr_large_community ( & attr_args ) ; break ; case BGP_ATTR_ORIGINATOR_ID : ret = bgp_attr_originator_id ( & attr_args ) ; break ; case BGP_ATTR_CLUSTER_LIST : ret = bgp_attr_cluster_list ( & attr_args ) ; break ; case BGP_ATTR_MP_REACH_NLRI : ret = bgp_mp_reach_parse ( & attr_args , mp_update ) ; break ; case BGP_ATTR_MP_UNREACH_NLRI : ret = bgp_mp_unreach_parse ( & attr_args , mp_withdraw ) ; break ; case BGP_ATTR_EXT_COMMUNITIES : ret = bgp_attr_ext_communities ( & attr_args ) ; break ; <S2SV_StartBug> # if ENABLE_BGP_VNC <S2SV_EndBug> case BGP_ATTR_VNC : # endif case BGP_ATTR_ENCAP : ret = bgp_attr_encap ( type , peer , length , attr , flag , startp ) ; break ; case BGP_ATTR_PREFIX_SID : ret = bgp_attr_prefix_sid ( length , & attr_args , mp_update ) ; break ; case BGP_ATTR_PMSI_TUNNEL : ret = bgp_attr_pmsi_tunnel ( & attr_args ) ; break ; default : ret = bgp_attr_unknown ( & attr_args ) ; break ; } if ( ret == BGP_ATTR_PARSE_ERROR_NOTIFYPLS ) { bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_MAL_ATTR ) ; ret = BGP_ATTR_PARSE_ERROR ; } if ( ret == BGP_ATTR_PARSE_EOR ) { if ( as4_path ) aspath_unintern ( & as4_path ) ; return ret ; } if ( ret == BGP_ATTR_PARSE_ERROR ) { flog_warn ( EC_BGP_ATTRIBUTE_PARSE_ERROR , "%s:<S2SV_blank>Attribute<S2SV_blank>%s,<S2SV_blank>parse<S2SV_blank>error" , peer -> host , lookup_msg ( attr_str , type , NULL ) ) ; if ( as4_path ) aspath_unintern ( & as4_path ) ; return ret ; } if ( ret == BGP_ATTR_PARSE_WITHDRAW ) { flog_warn ( EC_BGP_ATTRIBUTE_PARSE_WITHDRAW , "%s:<S2SV_blank>Attribute<S2SV_blank>%s,<S2SV_blank>parse<S2SV_blank>error<S2SV_blank>-<S2SV_blank>treating<S2SV_blank>as<S2SV_blank>withdrawal" , peer -> host , lookup_msg ( attr_str , type , NULL ) ) ; if ( as4_path ) aspath_unintern ( & as4_path ) ; return ret ; } if ( BGP_INPUT_PNT ( peer ) != attr_endp ) { flog_warn ( EC_BGP_ATTRIBUTE_FETCH_ERROR , "%s:<S2SV_blank>BGP<S2SV_blank>attribute<S2SV_blank>%s,<S2SV_blank>fetch<S2SV_blank>error" , peer -> host , lookup_msg ( attr_str , type , NULL ) ) ; bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_ATTR_LENG_ERR ) ; if ( as4_path ) aspath_unintern ( & as4_path ) ; return BGP_ATTR_PARSE_ERROR ; } } if ( BGP_INPUT_PNT ( peer ) != endp ) { flog_warn ( EC_BGP_ATTRIBUTES_MISMATCH , "%s:<S2SV_blank>BGP<S2SV_blank>attribute<S2SV_blank>%s,<S2SV_blank>length<S2SV_blank>mismatch" , peer -> host , lookup_msg ( attr_str , type , NULL ) ) ; bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_ATTR_LENG_ERR ) ; if ( as4_path ) aspath_unintern ( & as4_path ) ; return BGP_ATTR_PARSE_ERROR ; } if ( ( ret = bgp_attr_check ( peer , attr ) ) < 0 ) { if ( as4_path ) aspath_unintern ( & as4_path ) ; return ret ; } if ( CHECK_FLAG ( attr -> flag , ATTR_FLAG_BIT ( BGP_ATTR_AS_PATH ) ) && bgp_attr_munge_as4_attrs ( peer , attr , as4_path , as4_aggregator , & as4_aggregator_addr ) ) { bgp_notify_send ( peer , BGP_NOTIFY_UPDATE_ERR , BGP_NOTIFY_UPDATE_MAL_ATTR ) ; if ( as4_path ) aspath_unintern ( & as4_path ) ; return BGP_ATTR_PARSE_ERROR ; } if ( as4_path ) { aspath_unintern ( & as4_path ) ; } if ( attr -> flag & ( ATTR_FLAG_BIT ( BGP_ATTR_AS_PATH ) ) ) { ret = bgp_attr_aspath_check ( peer , attr ) ; if ( ret != BGP_ATTR_PARSE_PROCEED ) return ret ; } if ( attr -> transit ) attr -> transit = transit_intern ( attr -> transit ) ; if ( attr -> encap_subtlvs ) attr -> encap_subtlvs = encap_intern ( attr -> encap_subtlvs , ENCAP_SUBTLV_TYPE ) ; # if ENABLE_BGP_VNC if ( attr -> vnc_subtlvs ) attr -> vnc_subtlvs = encap_intern ( attr -> vnc_subtlvs , VNC_SUBTLV_TYPE ) ; # endif return BGP_ATTR_PARSE_PROCEED ; }
CWE-000 bgp_size_t bgp_packet_attribute ( struct bgp * bgp , struct peer * peer , struct stream * s , struct attr * attr , struct bpacket_attr_vec_arr * vecarr , struct prefix * p , afi_t afi , safi_t safi , struct peer * from , struct prefix_rd * prd , mpls_label_t * label , uint32_t num_labels , int addpath_encode , uint32_t addpath_tx_id ) { size_t cp ; size_t aspath_sizep ; struct aspath * aspath ; int send_as4_path = 0 ; int send_as4_aggregator = 0 ; int use32bit = ( CHECK_FLAG ( peer -> cap , PEER_CAP_AS4_RCV ) ) ? 1 : 0 ; if ( ! bgp ) bgp = peer -> bgp ; cp = stream_get_endp ( s ) ; if ( p && ! ( ( afi == AFI_IP && safi == SAFI_UNICAST ) && ! peer_cap_enhe ( peer , afi , safi ) ) ) { size_t mpattrlen_pos = 0 ; mpattrlen_pos = bgp_packet_mpattr_start ( s , peer , afi , safi , vecarr , attr ) ; bgp_packet_mpattr_prefix ( s , afi , safi , p , prd , label , num_labels , addpath_encode , addpath_tx_id , attr ) ; bgp_packet_mpattr_end ( s , mpattrlen_pos ) ; } stream_putc ( s , BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_ORIGIN ) ; stream_putc ( s , 1 ) ; stream_putc ( s , attr -> origin ) ; if ( peer -> sort == BGP_PEER_EBGP && ( ! CHECK_FLAG ( peer -> af_flags [ afi ] [ safi ] , PEER_FLAG_AS_PATH_UNCHANGED ) || attr -> aspath -> segments == NULL ) && ( ! CHECK_FLAG ( peer -> af_flags [ afi ] [ safi ] , PEER_FLAG_RSERVER_CLIENT ) ) ) { aspath = aspath_dup ( attr -> aspath ) ; aspath = aspath_delete_confed_seq ( aspath ) ; if ( CHECK_FLAG ( bgp -> config , BGP_CONFIG_CONFEDERATION ) ) { aspath = aspath_add_seq ( aspath , bgp -> confed_id ) ; } else { if ( peer -> change_local_as ) { if ( ! CHECK_FLAG ( peer -> flags , PEER_FLAG_LOCAL_AS_REPLACE_AS ) ) { aspath = aspath_add_seq ( aspath , peer -> local_as ) ; } aspath = aspath_add_seq ( aspath , peer -> change_local_as ) ; } else { aspath = aspath_add_seq ( aspath , peer -> local_as ) ; } } } else if ( peer -> sort == BGP_PEER_CONFED ) { aspath = aspath_dup ( attr -> aspath ) ; aspath = aspath_add_confed_seq ( aspath , peer -> local_as ) ; } else aspath = attr -> aspath ; stream_putc ( s , BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_AS_PATH ) ; aspath_sizep = stream_get_endp ( s ) ; stream_putw ( s , 0 ) ; stream_putw_at ( s , aspath_sizep , aspath_put ( s , aspath , use32bit ) ) ; if ( ! use32bit && aspath_has_as4 ( aspath ) ) send_as4_path = 1 ; if ( afi == AFI_IP && safi == SAFI_UNICAST && ! peer_cap_enhe ( peer , afi , safi ) ) { if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_NEXT_HOP ) ) { stream_putc ( s , BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_NEXT_HOP ) ; bpacket_attr_vec_arr_set_vec ( vecarr , BGP_ATTR_VEC_NH , s , attr ) ; stream_putc ( s , 4 ) ; stream_put_ipv4 ( s , attr -> nexthop . s_addr ) ; } else if ( peer_cap_enhe ( from , afi , safi ) ) { stream_putc ( s , BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_NEXT_HOP ) ; bpacket_attr_vec_arr_set_vec ( vecarr , BGP_ATTR_VEC_NH , s , NULL ) ; stream_putc ( s , 4 ) ; stream_put_ipv4 ( s , 0 ) ; } } if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_MULTI_EXIT_DISC ) || bgp -> maxmed_active ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL ) ; stream_putc ( s , BGP_ATTR_MULTI_EXIT_DISC ) ; stream_putc ( s , 4 ) ; stream_putl ( s , ( bgp -> maxmed_active ? bgp -> maxmed_value : attr -> med ) ) ; } if ( peer -> sort == BGP_PEER_IBGP || peer -> sort == BGP_PEER_CONFED ) { stream_putc ( s , BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_LOCAL_PREF ) ; stream_putc ( s , 4 ) ; stream_putl ( s , attr -> local_pref ) ; } if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_ATOMIC_AGGREGATE ) ) { stream_putc ( s , BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_ATOMIC_AGGREGATE ) ; stream_putc ( s , 0 ) ; } if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_AGGREGATOR ) ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_AGGREGATOR ) ; if ( use32bit ) { stream_putc ( s , 8 ) ; stream_putl ( s , attr -> aggregator_as ) ; } else { stream_putc ( s , 6 ) ; if ( attr -> aggregator_as > 65535 ) { stream_putw ( s , BGP_AS_TRANS ) ; send_as4_aggregator = 1 ; } else stream_putw ( s , ( uint16_t ) attr -> aggregator_as ) ; } stream_put_ipv4 ( s , attr -> aggregator_addr . s_addr ) ; } if ( CHECK_FLAG ( peer -> af_flags [ afi ] [ safi ] , PEER_FLAG_SEND_COMMUNITY ) && ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_COMMUNITIES ) ) ) { if ( attr -> community -> size * 4 > 255 ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_COMMUNITIES ) ; stream_putw ( s , attr -> community -> size * 4 ) ; } else { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_COMMUNITIES ) ; stream_putc ( s , attr -> community -> size * 4 ) ; } stream_put ( s , attr -> community -> val , attr -> community -> size * 4 ) ; } if ( CHECK_FLAG ( peer -> af_flags [ afi ] [ safi ] , PEER_FLAG_SEND_LARGE_COMMUNITY ) && ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_LARGE_COMMUNITIES ) ) ) { if ( lcom_length ( attr -> lcommunity ) > 255 ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_LARGE_COMMUNITIES ) ; stream_putw ( s , lcom_length ( attr -> lcommunity ) ) ; } else { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_LARGE_COMMUNITIES ) ; stream_putc ( s , lcom_length ( attr -> lcommunity ) ) ; } stream_put ( s , attr -> lcommunity -> val , lcom_length ( attr -> lcommunity ) ) ; } if ( peer -> sort == BGP_PEER_IBGP && from && from -> sort == BGP_PEER_IBGP ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL ) ; stream_putc ( s , BGP_ATTR_ORIGINATOR_ID ) ; stream_putc ( s , 4 ) ; if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_ORIGINATOR_ID ) ) stream_put_in_addr ( s , & attr -> originator_id ) ; else stream_put_in_addr ( s , & from -> remote_id ) ; stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL ) ; stream_putc ( s , BGP_ATTR_CLUSTER_LIST ) ; if ( attr -> cluster ) { stream_putc ( s , attr -> cluster -> length + 4 ) ; if ( bgp -> config & BGP_CONFIG_CLUSTER_ID ) stream_put_in_addr ( s , & bgp -> cluster_id ) ; else stream_put_in_addr ( s , & bgp -> router_id ) ; stream_put ( s , attr -> cluster -> list , attr -> cluster -> length ) ; } else { stream_putc ( s , 4 ) ; if ( bgp -> config & BGP_CONFIG_CLUSTER_ID ) stream_put_in_addr ( s , & bgp -> cluster_id ) ; else stream_put_in_addr ( s , & bgp -> router_id ) ; } } if ( CHECK_FLAG ( peer -> af_flags [ afi ] [ safi ] , PEER_FLAG_SEND_EXT_COMMUNITY ) && ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_EXT_COMMUNITIES ) ) ) { if ( peer -> sort == BGP_PEER_IBGP || peer -> sort == BGP_PEER_CONFED ) { if ( attr -> ecommunity -> size * 8 > 255 ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_EXT_COMMUNITIES ) ; stream_putw ( s , attr -> ecommunity -> size * 8 ) ; } else { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_EXT_COMMUNITIES ) ; stream_putc ( s , attr -> ecommunity -> size * 8 ) ; } stream_put ( s , attr -> ecommunity -> val , attr -> ecommunity -> size * 8 ) ; } else { uint8_t * pnt ; int tbit ; int ecom_tr_size = 0 ; int i ; for ( i = 0 ; i < attr -> ecommunity -> size ; i ++ ) { pnt = attr -> ecommunity -> val + ( i * 8 ) ; tbit = * pnt ; if ( CHECK_FLAG ( tbit , ECOMMUNITY_FLAG_NON_TRANSITIVE ) ) continue ; ecom_tr_size ++ ; } if ( ecom_tr_size ) { if ( ecom_tr_size * 8 > 255 ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_EXT_COMMUNITIES ) ; stream_putw ( s , ecom_tr_size * 8 ) ; } else { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_EXT_COMMUNITIES ) ; stream_putc ( s , ecom_tr_size * 8 ) ; } for ( i = 0 ; i < attr -> ecommunity -> size ; i ++ ) { pnt = attr -> ecommunity -> val + ( i * 8 ) ; tbit = * pnt ; if ( CHECK_FLAG ( tbit , ECOMMUNITY_FLAG_NON_TRANSITIVE ) ) continue ; stream_put ( s , pnt , 8 ) ; } } } } if ( safi == SAFI_LABELED_UNICAST ) { if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_PREFIX_SID ) ) { uint32_t label_index ; label_index = attr -> label_index ; if ( label_index != BGP_INVALID_LABEL_INDEX ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_PREFIX_SID ) ; stream_putc ( s , 10 ) ; stream_putc ( s , BGP_PREFIX_SID_LABEL_INDEX ) ; stream_putw ( s , BGP_PREFIX_SID_LABEL_INDEX_LENGTH ) ; stream_putc ( s , 0 ) ; stream_putw ( s , 0 ) ; stream_putl ( s , label_index ) ; } } } if ( send_as4_path ) { aspath = aspath_delete_confed_seq ( aspath ) ; stream_putc ( s , BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , BGP_ATTR_AS4_PATH ) ; aspath_sizep = stream_get_endp ( s ) ; stream_putw ( s , 0 ) ; stream_putw_at ( s , aspath_sizep , aspath_put ( s , aspath , 1 ) ) ; } if ( aspath != attr -> aspath ) aspath_free ( aspath ) ; if ( send_as4_aggregator ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_AS4_AGGREGATOR ) ; stream_putc ( s , 8 ) ; stream_putl ( s , attr -> aggregator_as ) ; stream_put_ipv4 ( s , attr -> aggregator_addr . s_addr ) ; } if ( ( ( afi == AFI_IP || afi == AFI_IP6 ) && ( safi == SAFI_ENCAP || safi == SAFI_MPLS_VPN ) ) || ( afi == AFI_L2VPN && safi == SAFI_EVPN ) ) { bgp_packet_mpattr_tea ( bgp , peer , s , attr , BGP_ATTR_ENCAP ) ; <S2SV_StartBug> # if ENABLE_BGP_VNC <S2SV_EndBug> bgp_packet_mpattr_tea ( bgp , peer , s , attr , BGP_ATTR_VNC ) ; # endif } if ( attr -> flag & ATTR_FLAG_BIT ( BGP_ATTR_PMSI_TUNNEL ) ) { stream_putc ( s , BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_TRANS ) ; stream_putc ( s , BGP_ATTR_PMSI_TUNNEL ) ; stream_putc ( s , 9 ) ; stream_putc ( s , 0 ) ; stream_putc ( s , PMSI_TNLTYPE_INGR_REPL ) ; stream_put ( s , & ( attr -> label ) , BGP_LABEL_BYTES ) ; stream_put_ipv4 ( s , attr -> nexthop . s_addr ) ; } if ( attr -> transit ) stream_put ( s , attr -> transit -> val , attr -> transit -> length ) ; return stream_get_endp ( s ) - cp ; }
CWE-000 static void bgp_packet_mpattr_tea ( struct bgp * bgp , struct peer * peer , struct stream * s , struct attr * attr , uint8_t attrtype ) { unsigned int attrlenfield = 0 ; unsigned int attrhdrlen = 0 ; struct bgp_attr_encap_subtlv * subtlvs ; struct bgp_attr_encap_subtlv * st ; const char * attrname ; if ( ! attr || ( attrtype == BGP_ATTR_ENCAP && ( ! attr -> encap_tunneltype || attr -> encap_tunneltype == BGP_ENCAP_TYPE_MPLS ) ) ) return ; switch ( attrtype ) { case BGP_ATTR_ENCAP : attrname = "Tunnel<S2SV_blank>Encap" ; subtlvs = attr -> encap_subtlvs ; if ( subtlvs == NULL ) return ; attrlenfield = 2 + 2 ; attrhdrlen = 1 + 1 ; break ; <S2SV_StartBug> # if ENABLE_BGP_VNC <S2SV_EndBug> case BGP_ATTR_VNC : attrname = "VNC" ; subtlvs = attr -> vnc_subtlvs ; if ( subtlvs == NULL ) return ; attrlenfield = 0 ; attrhdrlen = 2 + 2 ; break ; # endif default : assert ( 0 ) ; } for ( st = subtlvs ; st ; st = st -> next ) { attrlenfield += ( attrhdrlen + st -> length ) ; } if ( attrlenfield > 0xffff ) { zlog_info ( "%s<S2SV_blank>attribute<S2SV_blank>is<S2SV_blank>too<S2SV_blank>long<S2SV_blank>(length=%d),<S2SV_blank>can\'t<S2SV_blank>send<S2SV_blank>it" , attrname , attrlenfield ) ; return ; } if ( attrlenfield > 0xff ) { stream_putc ( s , BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_OPTIONAL | BGP_ATTR_FLAG_EXTLEN ) ; stream_putc ( s , attrtype ) ; stream_putw ( s , attrlenfield & 0xffff ) ; } else { stream_putc ( s , BGP_ATTR_FLAG_TRANS | BGP_ATTR_FLAG_OPTIONAL ) ; stream_putc ( s , attrtype ) ; stream_putc ( s , attrlenfield & 0xff ) ; } if ( attrtype == BGP_ATTR_ENCAP ) { stream_putw ( s , attr -> encap_tunneltype ) ; stream_putw ( s , attrlenfield - 4 ) ; } for ( st = subtlvs ; st ; st = st -> next ) { if ( attrtype == BGP_ATTR_ENCAP ) { stream_putc ( s , st -> type ) ; stream_putc ( s , st -> length ) ; # if ENABLE_BGP_VNC } else { stream_putw ( s , st -> type ) ; stream_putw ( s , st -> length ) ; # endif } stream_put ( s , st -> value , st -> length ) ; } }
CWE-000 static gboolean comics_check_decompress_command ( gchar * mime_type , ComicsDocument * comics_document , GError * * error ) { gboolean success ; gchar * std_out , * std_err ; gint retval ; GError * err = NULL ; if ( g_content_type_is_a ( mime_type , "application/x-cbr" ) || g_content_type_is_a ( mime_type , "application/x-rar" ) ) { comics_document -> selected_command = g_find_program_in_path ( "unrar" ) ; if ( comics_document -> selected_command ) { success = g_spawn_command_line_sync ( comics_document -> selected_command , & std_out , & std_err , & retval , & err ) ; if ( ! success ) { g_propagate_error ( error , err ) ; g_error_free ( err ) ; return FALSE ; } else if ( WIFEXITED ( retval ) ) { if ( g_strrstr ( std_out , "freeware" ) != NULL ) comics_document -> command_usage = RARLABS ; else comics_document -> command_usage = GNAUNRAR ; g_free ( std_out ) ; g_free ( std_err ) ; return TRUE ; } } comics_document -> selected_command = g_find_program_in_path ( "unrar-free" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = GNAUNRAR ; return TRUE ; } <S2SV_StartBug> comics_document -> selected_command = <S2SV_EndBug> g_find_program_in_path ( "bsdtar" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = TAR ; return TRUE ; } } else if ( g_content_type_is_a ( mime_type , "application/x-cbz" ) || g_content_type_is_a ( mime_type , "application/zip" ) ) { comics_document -> selected_command = g_find_program_in_path ( "unzip" ) ; comics_document -> alternative_command = g_find_program_in_path ( "zipnote" ) ; if ( comics_document -> selected_command && comics_document -> alternative_command ) { comics_document -> command_usage = UNZIP ; return TRUE ; } comics_document -> selected_command = g_find_program_in_path ( "7za" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = P7ZIP ; return TRUE ; } comics_document -> selected_command = g_find_program_in_path ( "7z" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = P7ZIP ; return TRUE ; } <S2SV_StartBug> comics_document -> selected_command = <S2SV_EndBug> g_find_program_in_path ( "bsdtar" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = TAR ; return TRUE ; } } else if ( g_content_type_is_a ( mime_type , "application/x-cb7" ) || g_content_type_is_a ( mime_type , "application/x-7z-compressed" ) ) { comics_document -> selected_command = g_find_program_in_path ( "7zr" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = P7ZIP ; return TRUE ; } comics_document -> selected_command = g_find_program_in_path ( "7za" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = P7ZIP ; return TRUE ; } comics_document -> selected_command = g_find_program_in_path ( "7z" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = P7ZIP ; return TRUE ; } <S2SV_StartBug> comics_document -> selected_command = <S2SV_EndBug> g_find_program_in_path ( "bsdtar" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = TAR ; return TRUE ; } } else if ( g_content_type_is_a ( mime_type , "application/x-cbt" ) || g_content_type_is_a ( mime_type , "application/x-tar" ) ) { comics_document -> selected_command = g_find_program_in_path ( "tar" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = TAR ; return TRUE ; } comics_document -> selected_command = g_find_program_in_path ( "bsdtar" ) ; if ( comics_document -> selected_command ) { comics_document -> command_usage = TAR ; return TRUE ; } } else { g_set_error ( error , EV_DOCUMENT_ERROR , EV_DOCUMENT_ERROR_INVALID , _ ( "Not<S2SV_blank>a<S2SV_blank>comic<S2SV_blank>book<S2SV_blank>MIME<S2SV_blank>type:<S2SV_blank>%s" ) , mime_type ) ; return FALSE ; } g_set_error_literal ( error , EV_DOCUMENT_ERROR , EV_DOCUMENT_ERROR_INVALID , _ ( "Can’t<S2SV_blank>find<S2SV_blank>an<S2SV_blank>appropriate<S2SV_blank>command<S2SV_blank>to<S2SV_blank>" "decompress<S2SV_blank>this<S2SV_blank>type<S2SV_blank>of<S2SV_blank>comic<S2SV_blank>book" ) ) ; return FALSE ; }
CWE-000 gchar * _rsvg_io_get_file_path ( const gchar * filename , const gchar * base_uri ) { gchar * absolute_filename ; <S2SV_StartBug> if ( g_file_test ( filename , G_FILE_TEST_EXISTS ) || g_path_is_absolute ( filename ) ) { <S2SV_EndBug> absolute_filename = g_strdup ( filename ) ; } else { gchar * tmpcdir ; gchar * base_filename ; if ( base_uri ) { base_filename = g_filename_from_uri ( base_uri , NULL , NULL ) ; if ( base_filename != NULL ) { tmpcdir = g_path_get_dirname ( base_filename ) ; g_free ( base_filename ) ; } else return NULL ; } else tmpcdir = g_get_current_dir ( ) ; absolute_filename = g_build_filename ( tmpcdir , filename , NULL ) ; g_free ( tmpcdir ) ; } return absolute_filename ; }
CWE-000 static xsltCompMatchPtr xsltCompilePatternInternal ( const xmlChar * pattern , xmlDocPtr doc , xmlNodePtr node , xsltStylesheetPtr style , xsltTransformContextPtr runtime , int novar ) { xsltParserContextPtr ctxt = NULL ; xsltCompMatchPtr element , first = NULL , previous = NULL ; int current , start , end , level , j ; if ( pattern == NULL ) { xsltTransformError ( NULL , NULL , node , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>NULL<S2SV_blank>pattern\\n" ) ; return ( NULL ) ; } ctxt = xsltNewParserContext ( style , runtime ) ; if ( ctxt == NULL ) return ( NULL ) ; ctxt -> doc = doc ; ctxt -> elem = node ; current = end = 0 ; while ( pattern [ current ] != 0 ) { start = current ; while ( IS_BLANK_CH ( pattern [ current ] ) ) current ++ ; end = current ; level = 0 ; while ( ( pattern [ end ] != 0 ) && ( ( pattern [ end ] != '|' ) || ( level != 0 ) ) ) { if ( pattern [ end ] == '[' ) level ++ ; else if ( pattern [ end ] == ']' ) level -- ; else if ( pattern [ end ] == '\\'' ) { end ++ ; while ( ( pattern [ end ] != 0 ) && ( pattern [ end ] != '\\'' ) ) end ++ ; } else if ( pattern [ end ] == \'"\' ) { end ++ ; while ( ( pattern [ end ] != 0 ) && ( pattern [ end ] != \'"\' ) ) end ++ ; } <S2SV_StartBug> end ++ ; <S2SV_EndBug> } if ( current == end ) { xsltTransformError ( NULL , NULL , node , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>NULL<S2SV_blank>pattern\\n" ) ; goto error ; } element = xsltNewCompMatch ( ) ; if ( element == NULL ) { goto error ; } if ( first == NULL ) first = element ; else if ( previous != NULL ) previous -> next = element ; previous = element ; ctxt -> comp = element ; ctxt -> base = xmlStrndup ( & pattern [ start ] , end - start ) ; if ( ctxt -> base == NULL ) goto error ; ctxt -> cur = & ( ctxt -> base ) [ current - start ] ; element -> pattern = ctxt -> base ; element -> nsList = xmlGetNsList ( doc , node ) ; j = 0 ; if ( element -> nsList != NULL ) { while ( element -> nsList [ j ] != NULL ) j ++ ; } element -> nsNr = j ; # ifdef WITH_XSLT_DEBUG_PATTERN xsltGenericDebug ( xsltGenericDebugContext , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>parsing<S2SV_blank>\'%s\'\\n" , element -> pattern ) ; # endif element -> priority = 0 ; xsltCompileLocationPathPattern ( ctxt , novar ) ; if ( ctxt -> error ) { xsltTransformError ( NULL , style , node , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>failed<S2SV_blank>to<S2SV_blank>compile<S2SV_blank>\'%s\'\\n" , element -> pattern ) ; if ( style != NULL ) style -> errors ++ ; goto error ; } xsltReverseCompMatch ( ctxt , element ) ; if ( element -> priority == 0 ) { if ( ( ( element -> steps [ 0 ] . op == XSLT_OP_ELEM ) || ( element -> steps [ 0 ] . op == XSLT_OP_ATTR ) || ( element -> steps [ 0 ] . op == XSLT_OP_PI ) ) && ( element -> steps [ 0 ] . value != NULL ) && ( element -> steps [ 1 ] . op == XSLT_OP_END ) ) { ; } else if ( ( element -> steps [ 0 ] . op == XSLT_OP_ATTR ) && ( element -> steps [ 0 ] . value2 != NULL ) && ( element -> steps [ 1 ] . op == XSLT_OP_END ) ) { element -> priority = - 0.25 ; } else if ( ( element -> steps [ 0 ] . op == XSLT_OP_NS ) && ( element -> steps [ 0 ] . value != NULL ) && ( element -> steps [ 1 ] . op == XSLT_OP_END ) ) { element -> priority = - 0.25 ; } else if ( ( element -> steps [ 0 ] . op == XSLT_OP_ATTR ) && ( element -> steps [ 0 ] . value == NULL ) && ( element -> steps [ 0 ] . value2 == NULL ) && ( element -> steps [ 1 ] . op == XSLT_OP_END ) ) { element -> priority = - 0.5 ; } else if ( ( ( element -> steps [ 0 ] . op == XSLT_OP_PI ) || ( element -> steps [ 0 ] . op == XSLT_OP_TEXT ) || ( element -> steps [ 0 ] . op == XSLT_OP_ALL ) || ( element -> steps [ 0 ] . op == XSLT_OP_NODE ) || ( element -> steps [ 0 ] . op == XSLT_OP_COMMENT ) ) && ( element -> steps [ 1 ] . op == XSLT_OP_END ) ) { element -> priority = - 0.5 ; } else { element -> priority = 0.5 ; } } # ifdef WITH_XSLT_DEBUG_PATTERN xsltGenericDebug ( xsltGenericDebugContext , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>parsed<S2SV_blank>%s,<S2SV_blank>default<S2SV_blank>priority<S2SV_blank>%f\\n" , element -> pattern , element -> priority ) ; # endif if ( pattern [ end ] == '|' ) end ++ ; current = end ; } if ( end == 0 ) { xsltTransformError ( NULL , style , node , "xsltCompilePattern<S2SV_blank>:<S2SV_blank>NULL<S2SV_blank>pattern\\n" ) ; if ( style != NULL ) style -> errors ++ ; goto error ; } xsltFreeParserContext ( ctxt ) ; return ( first ) ; error : if ( ctxt != NULL ) xsltFreeParserContext ( ctxt ) ; if ( first != NULL ) xsltFreeCompMatchList ( first ) ; return ( NULL ) ; }
CWE-000 static HB_Bool myanmar_shape_syllable ( HB_Bool openType , HB_ShaperItem * item , HB_Bool invalid ) { # ifndef NO_OPENTYPE const int availableGlyphs = item -> num_glyphs ; # endif const HB_UChar16 * uc = item -> string + item -> item . pos ; int vowel_e = - 1 ; int kinzi = - 1 ; int medial_ra = - 1 ; int base = - 1 ; int i ; int len = 0 ; unsigned short reordered [ 32 ] ; unsigned char properties [ 32 ] ; enum { AboveForm = 0x01 , PreForm = 0x02 , PostForm = 0x04 , BelowForm = 0x08 } ; HB_Bool lastWasVirama = FALSE ; int basePos = - 1 ; memset ( properties , 0 , 32 * sizeof ( unsigned char ) ) ; assert ( item -> item . length < 32 ) ; # ifdef MYANMAR_DEBUG printf ( "original:" ) ; for ( i = 0 ; i < ( int ) item -> item . length ; i ++ ) { printf ( "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>%d:<S2SV_blank>%4x" , i , uc [ i ] ) ; } # endif for ( i = 0 ; i < ( int ) item -> item . length ; ++ i ) { HB_UChar16 chr = uc [ i ] ; if ( chr == Mymr_C_VOWEL_E ) { vowel_e = i ; continue ; } if ( i == 0 && chr == Mymr_C_NGA && i + 2 < ( int ) item -> item . length && uc [ i + 1 ] == Mymr_C_VIRAMA ) { int mc = getMyanmarCharClass ( uc [ i + 2 ] ) ; if ( ( mc & Mymr_CF_CONSONANT ) == Mymr_CF_CONSONANT ) { kinzi = i ; continue ; } } if ( base >= 0 && chr == Mymr_C_VIRAMA && i + 1 < ( int ) item -> item . length && uc [ i + 1 ] == Mymr_C_RA ) { medial_ra = i ; continue ; } if ( base < 0 ) base = i ; } MMDEBUG ( "\\n<S2SV_blank><S2SV_blank>base=%d,<S2SV_blank>vowel_e=%d,<S2SV_blank>kinzi=%d,<S2SV_blank>medial_ra=%d" , base , vowel_e , kinzi , medial_ra ) ; if ( vowel_e >= 0 ) { reordered [ 0 ] = Mymr_C_VOWEL_E ; len = 1 ; } if ( medial_ra >= 0 ) { reordered [ len ] = Mymr_C_VIRAMA ; reordered [ len + 1 ] = Mymr_C_RA ; properties [ len ] = PreForm ; properties [ len + 1 ] = PreForm ; len += 2 ; } if ( invalid ) { reordered [ len ] = C_DOTTED_CIRCLE ; ++ len ; } for ( i = 0 ; i < ( int ) item -> item . length ; ++ i ) { hb_uint16 chr = uc [ i ] ; MymrCharClass cc ; if ( i == vowel_e ) continue ; if ( i == medial_ra || i == kinzi ) { ++ i ; continue ; } cc = getMyanmarCharClass ( uc [ i ] ) ; if ( kinzi >= 0 && i > base && ( cc & Mymr_CF_AFTER_KINZI ) ) { reordered [ len ] = Mymr_C_NGA ; <S2SV_StartBug> reordered [ len + 1 ] = Mymr_C_VIRAMA ; <S2SV_EndBug> properties [ len - 1 ] = AboveForm ; properties [ len ] = AboveForm ; len += 2 ; kinzi = - 1 ; } if ( lastWasVirama ) { int prop = 0 ; switch ( cc & Mymr_CF_POS_MASK ) { case Mymr_CF_POS_BEFORE : prop = PreForm ; break ; case Mymr_CF_POS_BELOW : prop = BelowForm ; break ; case Mymr_CF_POS_ABOVE : prop = AboveForm ; break ; case Mymr_CF_POS_AFTER : prop = PostForm ; break ; default : break ; } properties [ len - 1 ] = prop ; properties [ len ] = prop ; if ( basePos >= 0 && basePos == len - 2 ) properties [ len - 2 ] = prop ; } lastWasVirama = ( chr == Mymr_C_VIRAMA ) ; if ( i == base ) basePos = len ; if ( ( chr != Mymr_C_SIGN_ZWNJ && chr != Mymr_C_SIGN_ZWJ ) || ! len ) { reordered [ len ] = chr ; ++ len ; } } if ( kinzi >= 0 ) { reordered [ len ] = Mymr_C_NGA ; reordered [ len + 1 ] = Mymr_C_VIRAMA ; properties [ len ] = AboveForm ; properties [ len + 1 ] = AboveForm ; len += 2 ; } if ( ! item -> font -> klass -> convertStringToGlyphIndices ( item -> font , reordered , len , item -> glyphs , & item -> num_glyphs , item -> item . bidiLevel % 2 ) ) return FALSE ; MMDEBUG ( "after<S2SV_blank>shaping:<S2SV_blank>len=%d" , len ) ; for ( i = 0 ; i < len ; i ++ ) { item -> attributes [ i ] . mark = FALSE ; item -> attributes [ i ] . clusterStart = FALSE ; item -> attributes [ i ] . justification = 0 ; item -> attributes [ i ] . zeroWidth = FALSE ; MMDEBUG ( "<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>%d:<S2SV_blank>%4x<S2SV_blank>property=%x" , i , reordered [ i ] , properties [ i ] ) ; } # ifndef NO_OPENTYPE if ( openType ) { hb_uint32 where [ 32 ] ; for ( i = 0 ; i < len ; ++ i ) { where [ i ] = ~ ( PreSubstProperty | BelowSubstProperty | AboveSubstProperty | PostSubstProperty | CligProperty | PositioningProperties ) ; if ( properties [ i ] & PreForm ) where [ i ] &= ~ PreFormProperty ; if ( properties [ i ] & BelowForm ) where [ i ] &= ~ BelowFormProperty ; if ( properties [ i ] & AboveForm ) where [ i ] &= ~ AboveFormProperty ; if ( properties [ i ] & PostForm ) where [ i ] &= ~ PostFormProperty ; } HB_OpenTypeShape ( item , where ) ; if ( ! HB_OpenTypePosition ( item , availableGlyphs , FALSE ) ) return FALSE ; } else # endif { MMDEBUG ( "Not<S2SV_blank>using<S2SV_blank>openType" ) ; HB_HeuristicPosition ( item ) ; } item -> attributes [ 0 ] . clusterStart = TRUE ; return TRUE ; }
CWE-000 void xmlParseElement ( xmlParserCtxtPtr ctxt ) { const xmlChar * name ; const xmlChar * prefix = NULL ; const xmlChar * URI = NULL ; xmlParserNodeInfo node_info ; int line , tlen ; xmlNodePtr ret ; int nsNr = ctxt -> nsNr ; if ( ( ( unsigned int ) ctxt -> nameNr > xmlParserMaxDepth ) && ( ( ctxt -> options & XML_PARSE_HUGE ) == 0 ) ) { xmlFatalErrMsgInt ( ctxt , XML_ERR_INTERNAL_ERROR , "Excessive<S2SV_blank>depth<S2SV_blank>in<S2SV_blank>document:<S2SV_blank>%d<S2SV_blank>use<S2SV_blank>XML_PARSE_HUGE<S2SV_blank>option\\n" , xmlParserMaxDepth ) ; ctxt -> instate = XML_PARSER_EOF ; return ; } if ( ctxt -> record_info ) { node_info . begin_pos = ctxt -> input -> consumed + ( CUR_PTR - ctxt -> input -> base ) ; node_info . begin_line = ctxt -> input -> line ; } if ( ctxt -> spaceNr == 0 ) spacePush ( ctxt , - 1 ) ; else if ( * ctxt -> space == - 2 ) spacePush ( ctxt , - 1 ) ; else spacePush ( ctxt , * ctxt -> space ) ; line = ctxt -> input -> line ; # ifdef LIBXML_SAX1_ENABLED if ( ctxt -> sax2 ) # endif name = xmlParseStartTag2 ( ctxt , & prefix , & URI , & tlen ) ; # ifdef LIBXML_SAX1_ENABLED else name = xmlParseStartTag ( ctxt ) ; # endif <S2SV_StartBug> if ( name == NULL ) { <S2SV_EndBug> spacePop ( ctxt ) ; return ; } namePush ( ctxt , name ) ; ret = ctxt -> node ; # ifdef LIBXML_VALID_ENABLED if ( ctxt -> validate && ctxt -> wellFormed && ctxt -> myDoc && ctxt -> node && ( ctxt -> node == ctxt -> myDoc -> children ) ) ctxt -> valid &= xmlValidateRoot ( & ctxt -> vctxt , ctxt -> myDoc ) ; # endif if ( ( RAW == '/' ) && ( NXT ( 1 ) == '>' ) ) { SKIP ( 2 ) ; if ( ctxt -> sax2 ) { if ( ( ctxt -> sax != NULL ) && ( ctxt -> sax -> endElementNs != NULL ) && ( ! ctxt -> disableSAX ) ) ctxt -> sax -> endElementNs ( ctxt -> userData , name , prefix , URI ) ; # ifdef LIBXML_SAX1_ENABLED } else { if ( ( ctxt -> sax != NULL ) && ( ctxt -> sax -> endElement != NULL ) && ( ! ctxt -> disableSAX ) ) ctxt -> sax -> endElement ( ctxt -> userData , name ) ; # endif } namePop ( ctxt ) ; spacePop ( ctxt ) ; if ( nsNr != ctxt -> nsNr ) nsPop ( ctxt , ctxt -> nsNr - nsNr ) ; if ( ret != NULL && ctxt -> record_info ) { node_info . end_pos = ctxt -> input -> consumed + ( CUR_PTR - ctxt -> input -> base ) ; node_info . end_line = ctxt -> input -> line ; node_info . node = ret ; xmlParserAddNodeInfo ( ctxt , & node_info ) ; } return ; } if ( RAW == '>' ) { NEXT1 ; } else { xmlFatalErrMsgStrIntStr ( ctxt , XML_ERR_GT_REQUIRED , "Couldn\'t<S2SV_blank>find<S2SV_blank>end<S2SV_blank>of<S2SV_blank>Start<S2SV_blank>Tag<S2SV_blank>%s<S2SV_blank>line<S2SV_blank>%d\\n" , name , line , NULL ) ; nodePop ( ctxt ) ; namePop ( ctxt ) ; spacePop ( ctxt ) ; if ( nsNr != ctxt -> nsNr ) nsPop ( ctxt , ctxt -> nsNr - nsNr ) ; if ( ret != NULL && ctxt -> record_info ) { node_info . end_pos = ctxt -> input -> consumed + ( CUR_PTR - ctxt -> input -> base ) ; node_info . end_line = ctxt -> input -> line ; node_info . node = ret ; xmlParserAddNodeInfo ( ctxt , & node_info ) ; } return ; } xmlParseContent ( ctxt ) ; if ( ! IS_BYTE_CHAR ( RAW ) ) { xmlFatalErrMsgStrIntStr ( ctxt , XML_ERR_TAG_NOT_FINISHED , "Premature<S2SV_blank>end<S2SV_blank>of<S2SV_blank>data<S2SV_blank>in<S2SV_blank>tag<S2SV_blank>%s<S2SV_blank>line<S2SV_blank>%d\\n" , name , line , NULL ) ; nodePop ( ctxt ) ; namePop ( ctxt ) ; spacePop ( ctxt ) ; if ( nsNr != ctxt -> nsNr ) nsPop ( ctxt , ctxt -> nsNr - nsNr ) ; return ; } if ( ctxt -> sax2 ) { xmlParseEndTag2 ( ctxt , prefix , URI , line , ctxt -> nsNr - nsNr , tlen ) ; namePop ( ctxt ) ; } # ifdef LIBXML_SAX1_ENABLED else xmlParseEndTag1 ( ctxt , line ) ; # endif if ( ret != NULL && ctxt -> record_info ) { node_info . end_pos = ctxt -> input -> consumed + ( CUR_PTR - ctxt -> input -> base ) ; node_info . end_line = ctxt -> input -> line ; node_info . node = ret ; xmlParserAddNodeInfo ( ctxt , & node_info ) ; } }
CWE-000 void xmlParsePI ( xmlParserCtxtPtr ctxt ) { xmlChar * buf = NULL ; int len = 0 ; int size = XML_PARSER_BUFFER_SIZE ; int cur , l ; const xmlChar * target ; xmlParserInputState state ; int count = 0 ; if ( ( RAW == '<' ) && ( NXT ( 1 ) == '?' ) ) { xmlParserInputPtr input = ctxt -> input ; state = ctxt -> instate ; ctxt -> instate = XML_PARSER_PI ; SKIP ( 2 ) ; SHRINK ; target = xmlParsePITarget ( ctxt ) ; if ( target != NULL ) { if ( ( RAW == '?' ) && ( NXT ( 1 ) == '>' ) ) { if ( input != ctxt -> input ) { xmlFatalErrMsg ( ctxt , XML_ERR_ENTITY_BOUNDARY , "PI<S2SV_blank>declaration<S2SV_blank>doesn\'t<S2SV_blank>start<S2SV_blank>and<S2SV_blank>stop<S2SV_blank>in<S2SV_blank>the<S2SV_blank>same<S2SV_blank>entity\\n" ) ; } SKIP ( 2 ) ; if ( ( ctxt -> sax ) && ( ! ctxt -> disableSAX ) && ( ctxt -> sax -> processingInstruction != NULL ) ) ctxt -> sax -> processingInstruction ( ctxt -> userData , <S2SV_StartBug> target , NULL ) ; <S2SV_EndBug> ctxt -> instate = state ; return ; } buf = ( xmlChar * ) xmlMallocAtomic ( size * sizeof ( xmlChar ) ) ; if ( buf == NULL ) { xmlErrMemory ( ctxt , NULL ) ; ctxt -> instate = state ; return ; } cur = CUR ; if ( ! IS_BLANK ( cur ) ) { xmlFatalErrMsgStr ( ctxt , XML_ERR_SPACE_REQUIRED , "ParsePI:<S2SV_blank>PI<S2SV_blank>%s<S2SV_blank>space<S2SV_blank>expected\\n" , target ) ; } SKIP_BLANKS ; cur = CUR_CHAR ( l ) ; while ( IS_CHAR ( cur ) && ( ( cur != '?' ) || ( NXT ( 1 ) != '>' ) ) ) { if ( len + 5 >= size ) { xmlChar * tmp ; size *= 2 ; tmp = ( xmlChar * ) xmlRealloc ( buf , size * sizeof ( xmlChar ) ) ; if ( tmp == NULL ) { xmlErrMemory ( ctxt , NULL ) ; xmlFree ( buf ) ; ctxt -> instate = state ; return ; } buf = tmp ; } count ++ ; if ( count > 50 ) { GROW ; count = 0 ; } COPY_BUF ( l , buf , len , cur ) ; NEXTL ( l ) ; cur = CUR_CHAR ( l ) ; if ( cur == 0 ) { SHRINK ; GROW ; cur = CUR_CHAR ( l ) ; } } buf [ len ] = 0 ; if ( cur != '?' ) { xmlFatalErrMsgStr ( ctxt , XML_ERR_PI_NOT_FINISHED , "ParsePI:<S2SV_blank>PI<S2SV_blank>%s<S2SV_blank>never<S2SV_blank>end<S2SV_blank>...\\n" , target ) ; } else { if ( input != ctxt -> input ) { xmlFatalErrMsg ( ctxt , XML_ERR_SPACE_REQUIRED , "PI<S2SV_blank>declaration<S2SV_blank>doesn\'t<S2SV_blank>start<S2SV_blank>and<S2SV_blank>stop<S2SV_blank>in<S2SV_blank>the<S2SV_blank>same<S2SV_blank>entity\\n" ) ; } SKIP ( 2 ) ; # ifdef LIBXML_CATALOG_ENABLED if ( ( ( state == XML_PARSER_MISC ) || ( state == XML_PARSER_START ) ) && ( xmlStrEqual ( target , XML_CATALOG_PI ) ) ) { xmlCatalogAllow allow = xmlCatalogGetDefaults ( ) ; if ( ( allow == XML_CATA_ALLOW_DOCUMENT ) || ( allow == XML_CATA_ALLOW_ALL ) ) xmlParseCatalogPI ( ctxt , buf ) ; } # endif if ( ( ctxt -> sax ) && ( ! ctxt -> disableSAX ) && ( ctxt -> sax -> processingInstruction != NULL ) ) ctxt -> sax -> processingInstruction ( ctxt -> userData , target , buf ) ; } xmlFree ( buf ) ; } else { xmlFatalErr ( ctxt , XML_ERR_PI_NOT_STARTED , NULL ) ; } <S2SV_StartBug> ctxt -> instate = state ; <S2SV_EndBug> } }
CWE-000 EAPI_MAIN int elm_main ( int argc , char * argv [ ] ) { int args = 1 ; unsigned char quitOption = 0 ; <S2SV_StartBug> Browser_Window * window ; <S2SV_EndBug> Ecore_Getopt_Value values [ ] = { ECORE_GETOPT_VALUE_STR ( evas_engine_name ) , <S2SV_StartBug> ECORE_GETOPT_VALUE_BOOL ( quitOption ) , <S2SV_EndBug> ECORE_GETOPT_VALUE_BOOL ( frame_flattening_enabled ) , ECORE_GETOPT_VALUE_BOOL ( quitOption ) , ECORE_GETOPT_VALUE_BOOL ( quitOption ) , ECORE_GETOPT_VALUE_BOOL ( quitOption ) , ECORE_GETOPT_VALUE_NONE } ; if ( ! ewk_init ( ) ) return EXIT_FAILURE ; ewk_view_smart_class_set ( miniBrowserViewSmartClass ( ) ) ; ecore_app_args_set ( argc , ( const char * * ) argv ) ; args = ecore_getopt_parse ( & options , values , argc , argv ) ; if ( args < 0 ) return quit ( EINA_FALSE , "ERROR:<S2SV_blank>could<S2SV_blank>not<S2SV_blank>parse<S2SV_blank>options.\\n" ) ; if ( quitOption ) return quit ( EINA_TRUE , NULL ) ; if ( evas_engine_name ) elm_config_preferred_engine_set ( evas_engine_name ) ; # if defined ( WTF_USE_ACCELERATED_COMPOSITING ) && defined ( HAVE_ECORE_X ) else { evas_engine_name = "opengl_x11" ; elm_config_preferred_engine_set ( evas_engine_name ) ; } # endif Ewk_Context * context = ewk_context_default_get ( ) ; ewk_context_favicon_database_directory_set ( context , NULL ) ; <S2SV_StartBug> if ( args < argc ) { <S2SV_EndBug> char * url = url_from_user_input ( argv [ args ] ) ; window = window_create ( url ) ; free ( url ) ; } else window = window_create ( DEFAULT_URL ) ; if ( ! window ) return quit ( EINA_FALSE , "ERROR:<S2SV_blank>could<S2SV_blank>not<S2SV_blank>create<S2SV_blank>browser<S2SV_blank>window.\\n" ) ; windows = eina_list_append ( windows , window ) ; elm_run ( ) ; return quit ( EINA_TRUE , NULL ) ; }
CWE-000 static Browser_Window * window_create ( const char * url ) { Browser_Window * app_data = malloc ( sizeof ( Browser_Window ) ) ; if ( ! app_data ) { info ( "ERROR:<S2SV_blank>could<S2SV_blank>not<S2SV_blank>create<S2SV_blank>browser<S2SV_blank>window.\\n" ) ; return NULL ; } app_data -> window = elm_win_add ( NULL , "minibrowser-window" , ELM_WIN_BASIC ) ; elm_win_title_set ( app_data -> window , APP_NAME ) ; evas_object_smart_callback_add ( app_data -> window , "delete,request" , on_window_deletion , & app_data ) ; Evas_Object * bg = elm_bg_add ( app_data -> window ) ; elm_bg_color_set ( bg , 193 , 192 , 191 ) ; evas_object_size_hint_weight_set ( bg , EVAS_HINT_EXPAND , EVAS_HINT_EXPAND ) ; elm_win_resize_object_add ( app_data -> window , bg ) ; evas_object_show ( bg ) ; Evas_Object * vertical_layout = elm_box_add ( app_data -> window ) ; elm_box_padding_set ( vertical_layout , 0 , 2 ) ; evas_object_size_hint_weight_set ( vertical_layout , EVAS_HINT_EXPAND , EVAS_HINT_EXPAND ) ; elm_win_resize_object_add ( app_data -> window , vertical_layout ) ; evas_object_show ( vertical_layout ) ; Evas_Object * horizontal_layout = elm_box_add ( app_data -> window ) ; elm_box_horizontal_set ( horizontal_layout , EINA_TRUE ) ; evas_object_size_hint_weight_set ( horizontal_layout , EVAS_HINT_EXPAND , 0.0 ) ; evas_object_size_hint_align_set ( horizontal_layout , EVAS_HINT_FILL , 0.0 ) ; elm_box_pack_end ( vertical_layout , horizontal_layout ) ; evas_object_show ( horizontal_layout ) ; app_data -> back_button = create_toolbar_button ( app_data -> window , "arrow_left" ) ; evas_object_smart_callback_add ( app_data -> back_button , "clicked" , on_back_button_clicked , app_data ) ; elm_object_disabled_set ( app_data -> back_button , EINA_TRUE ) ; evas_object_size_hint_weight_set ( app_data -> back_button , 0.0 , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( app_data -> back_button , 0.0 , 0.5 ) ; elm_box_pack_end ( horizontal_layout , app_data -> back_button ) ; evas_object_show ( app_data -> back_button ) ; app_data -> forward_button = create_toolbar_button ( app_data -> window , "arrow_right" ) ; evas_object_smart_callback_add ( app_data -> forward_button , "clicked" , on_forward_button_clicked , app_data ) ; elm_object_disabled_set ( app_data -> forward_button , EINA_TRUE ) ; evas_object_size_hint_weight_set ( app_data -> forward_button , 0.0 , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( app_data -> forward_button , 0.0 , 0.5 ) ; elm_box_pack_end ( horizontal_layout , app_data -> forward_button ) ; evas_object_show ( app_data -> forward_button ) ; app_data -> url_bar = elm_entry_add ( app_data -> window ) ; elm_entry_scrollable_set ( app_data -> url_bar , EINA_TRUE ) ; elm_entry_scrollbar_policy_set ( app_data -> url_bar , ELM_SCROLLER_POLICY_OFF , ELM_SCROLLER_POLICY_OFF ) ; elm_entry_single_line_set ( app_data -> url_bar , EINA_TRUE ) ; elm_entry_cnp_mode_set ( app_data -> url_bar , ELM_CNP_MODE_PLAINTEXT ) ; elm_entry_text_style_user_push ( app_data -> url_bar , "DEFAULT=\'font_size=18\'" ) ; evas_object_smart_callback_add ( app_data -> url_bar , "activated" , on_url_bar_activated , app_data ) ; evas_object_smart_callback_add ( app_data -> url_bar , "clicked" , on_url_bar_clicked , app_data ) ; evas_object_size_hint_weight_set ( app_data -> url_bar , EVAS_HINT_EXPAND , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( app_data -> url_bar , EVAS_HINT_FILL , EVAS_HINT_FILL ) ; elm_box_pack_end ( horizontal_layout , app_data -> url_bar ) ; evas_object_show ( app_data -> url_bar ) ; Evas_Object * refresh_button = create_toolbar_button ( app_data -> window , "refresh" ) ; evas_object_smart_callback_add ( refresh_button , "clicked" , on_refresh_button_clicked , app_data ) ; evas_object_size_hint_weight_set ( refresh_button , 0.0 , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( refresh_button , 1.0 , 0.5 ) ; elm_box_pack_end ( horizontal_layout , refresh_button ) ; evas_object_show ( refresh_button ) ; Evas_Object * home_button = create_toolbar_button ( app_data -> window , "home" ) ; evas_object_smart_callback_add ( home_button , "clicked" , on_home_button_clicked , app_data ) ; evas_object_size_hint_weight_set ( home_button , 0.0 , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( home_button , 1.0 , 0.5 ) ; elm_box_pack_end ( horizontal_layout , home_button ) ; evas_object_show ( home_button ) ; Ewk_View_Smart_Class * ewkViewClass = miniBrowserViewSmartClass ( ) ; ewkViewClass -> run_javascript_alert = on_javascript_alert ; ewkViewClass -> run_javascript_confirm = on_javascript_confirm ; ewkViewClass -> run_javascript_prompt = on_javascript_prompt ; Evas * evas = evas_object_evas_get ( app_data -> window ) ; Evas_Smart * smart = evas_smart_class_new ( & ewkViewClass -> sc ) ; app_data -> webview = ewk_view_smart_add ( evas , smart , ewk_context_default_get ( ) ) ; ewk_view_theme_set ( app_data -> webview , THEME_DIR "/default.edj" ) ; Ewk_Settings * settings = ewk_view_settings_get ( app_data -> webview ) ; ewk_settings_file_access_from_file_urls_allowed_set ( settings , EINA_TRUE ) ; ewk_settings_frame_flattening_enabled_set ( settings , frame_flattening_enabled ) ; ewk_settings_developer_extras_enabled_set ( settings , EINA_TRUE ) ; evas_object_smart_callback_add ( app_data -> webview , "authentication,request" , on_authentication_request , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "close,window" , on_close_window , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "create,window" , on_new_window , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "download,failed" , on_download_failed , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "download,finished" , on_download_finished , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "download,request" , on_download_request , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "file,chooser,request" , on_file_chooser_request , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "icon,changed" , on_view_icon_changed , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "load,error" , on_error , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "load,progress" , on_progress , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "title,changed" , on_title_changed , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "url,changed" , on_url_changed , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "back,forward,list,changed" , on_back_forward_list_changed , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "tooltip,text,set" , on_tooltip_text_set , app_data ) ; evas_object_smart_callback_add ( app_data -> webview , "tooltip,text,unset" , on_tooltip_text_unset , app_data ) ; evas_object_event_callback_add ( app_data -> webview , EVAS_CALLBACK_KEY_DOWN , on_key_down , app_data ) ; evas_object_event_callback_add ( app_data -> webview , EVAS_CALLBACK_MOUSE_DOWN , on_mouse_down , app_data ) ; evas_object_size_hint_weight_set ( app_data -> webview , EVAS_HINT_EXPAND , EVAS_HINT_EXPAND ) ; evas_object_size_hint_align_set ( app_data -> webview , EVAS_HINT_FILL , EVAS_HINT_FILL ) ; elm_box_pack_end ( vertical_layout , app_data -> webview ) ; evas_object_show ( app_data -> webview ) ; if ( url ) ewk_view_url_set ( app_data -> webview , url ) ; <S2SV_StartBug> evas_object_resize ( app_data -> window , DEFAULT_WIDTH , DEFAULT_HEIGHT ) ; <S2SV_EndBug> evas_object_show ( app_data -> window ) ; view_focus_set ( app_data , EINA_TRUE ) ; return app_data ; }
CWE-000 static int init_nss_hash ( struct crypto_instance * instance ) { PK11SlotInfo * hash_slot = NULL ; SECItem hash_param ; if ( ! hash_to_nss [ instance -> crypto_hash_type ] ) { return 0 ; } hash_param . type = siBuffer ; <S2SV_StartBug> hash_param . data = 0 ; <S2SV_EndBug> <S2SV_StartBug> hash_param . len = 0 ; <S2SV_EndBug> hash_slot = PK11_GetBestSlot ( hash_to_nss [ instance -> crypto_hash_type ] , NULL ) ; if ( hash_slot == NULL ) { log_printf ( instance -> log_level_security , "Unable<S2SV_blank>to<S2SV_blank>find<S2SV_blank>security<S2SV_blank>slot<S2SV_blank>(err<S2SV_blank>%d)" , PR_GetError ( ) ) ; return - 1 ; } instance -> nss_sym_key_sign = PK11_ImportSymKey ( hash_slot , hash_to_nss [ instance -> crypto_hash_type ] , PK11_OriginUnwrap , CKA_SIGN , & hash_param , NULL ) ; if ( instance -> nss_sym_key_sign == NULL ) { log_printf ( instance -> log_level_security , "Failure<S2SV_blank>to<S2SV_blank>import<S2SV_blank>key<S2SV_blank>into<S2SV_blank>NSS<S2SV_blank>(err<S2SV_blank>%d)" , PR_GetError ( ) ) ; return - 1 ; } PK11_FreeSlot ( hash_slot ) ; return 0 ; }
CWE-000 int config__parse_args ( struct mosquitto_db * db , struct mosquitto__config * config , int argc , char * argv [ ] ) { int i ; int port_tmp ; for ( i = 1 ; i < argc ; i ++ ) { if ( ! strcmp ( argv [ i ] , "-c" ) || ! strcmp ( argv [ i ] , "--config-file" ) ) { if ( i < argc - 1 ) { db -> config_file = argv [ i + 1 ] ; if ( config__read ( db , config , false ) ) { log__printf ( NULL , MOSQ_LOG_ERR , "Error:<S2SV_blank>Unable<S2SV_blank>to<S2SV_blank>open<S2SV_blank>configuration<S2SV_blank>file." ) ; return MOSQ_ERR_INVAL ; } } else { log__printf ( NULL , MOSQ_LOG_ERR , "Error:<S2SV_blank>-c<S2SV_blank>argument<S2SV_blank>given,<S2SV_blank>but<S2SV_blank>no<S2SV_blank>config<S2SV_blank>file<S2SV_blank>specified." ) ; return MOSQ_ERR_INVAL ; } i ++ ; } else if ( ! strcmp ( argv [ i ] , "-d" ) || ! strcmp ( argv [ i ] , "--daemon" ) ) { config -> daemon = true ; } else if ( ! strcmp ( argv [ i ] , "-h" ) || ! strcmp ( argv [ i ] , "--help" ) ) { print_usage ( ) ; return MOSQ_ERR_INVAL ; } else if ( ! strcmp ( argv [ i ] , "-p" ) || ! strcmp ( argv [ i ] , "--port" ) ) { if ( i < argc - 1 ) { port_tmp = atoi ( argv [ i + 1 ] ) ; if ( port_tmp < 1 || port_tmp > 65535 ) { log__printf ( NULL , MOSQ_LOG_ERR , "Error:<S2SV_blank>Invalid<S2SV_blank>port<S2SV_blank>specified<S2SV_blank>(%d)." , port_tmp ) ; return MOSQ_ERR_INVAL ; } else { if ( config -> default_listener . port ) { log__printf ( NULL , MOSQ_LOG_WARNING , "Warning:<S2SV_blank>Default<S2SV_blank>listener<S2SV_blank>port<S2SV_blank>specified<S2SV_blank>multiple<S2SV_blank>times.<S2SV_blank>Only<S2SV_blank>the<S2SV_blank>latest<S2SV_blank>will<S2SV_blank>be<S2SV_blank>used." ) ; } config -> default_listener . port = port_tmp ; } } else { log__printf ( NULL , MOSQ_LOG_ERR , "Error:<S2SV_blank>-p<S2SV_blank>argument<S2SV_blank>given,<S2SV_blank>but<S2SV_blank>no<S2SV_blank>port<S2SV_blank>specified." ) ; return MOSQ_ERR_INVAL ; } i ++ ; } else if ( ! strcmp ( argv [ i ] , "-v" ) || ! strcmp ( argv [ i ] , "--verbose" ) ) { db -> verbose = true ; } else { fprintf ( stderr , "Error:<S2SV_blank>Unknown<S2SV_blank>option<S2SV_blank>\'%s\'.\\n" , argv [ i ] ) ; print_usage ( ) ; return MOSQ_ERR_INVAL ; } } if ( config -> listener_count == 0 # ifdef WITH_TLS || config -> default_listener . cafile || config -> default_listener . capath || config -> default_listener . certfile || config -> default_listener . keyfile || config -> default_listener . ciphers || config -> default_listener . psk_hint || config -> default_listener . require_certificate || config -> default_listener . crlfile || config -> default_listener . use_identity_as_username || config -> default_listener . use_subject_as_username # endif || config -> default_listener . use_username_as_clientid || config -> default_listener . host || config -> default_listener . port || config -> default_listener . max_connections != - 1 || config -> default_listener . mount_point || config -> default_listener . protocol != mp_mqtt || config -> default_listener . socket_domain || config -> default_listener . security_options . password_file || config -> default_listener . security_options . psk_file || config -> default_listener . security_options . auth_plugin_config_count || config -> default_listener . security_options . allow_anonymous != - 1 ) { config -> listener_count ++ ; config -> listeners = mosquitto__realloc ( config -> listeners , sizeof ( struct mosquitto__listener ) * config -> listener_count ) ; if ( ! config -> listeners ) { log__printf ( NULL , MOSQ_LOG_ERR , "Error:<S2SV_blank>Out<S2SV_blank>of<S2SV_blank>memory." ) ; return MOSQ_ERR_NOMEM ; } memset ( & config -> listeners [ config -> listener_count - 1 ] , 0 , sizeof ( struct mosquitto__listener ) ) ; if ( config -> default_listener . port ) { config -> listeners [ config -> listener_count - 1 ] . port = config -> default_listener . port ; } else { config -> listeners [ config -> listener_count - 1 ] . port = 1883 ; } if ( config -> default_listener . host ) { config -> listeners [ config -> listener_count - 1 ] . host = config -> default_listener . host ; } else { config -> listeners [ config -> listener_count - 1 ] . host = NULL ; } if ( config -> default_listener . mount_point ) { config -> listeners [ config -> listener_count - 1 ] . mount_point = config -> default_listener . mount_point ; } else { config -> listeners [ config -> listener_count - 1 ] . mount_point = NULL ; } config -> listeners [ config -> listener_count - 1 ] . max_connections = config -> default_listener . max_connections ; config -> listeners [ config -> listener_count - 1 ] . protocol = config -> default_listener . protocol ; config -> listeners [ config -> listener_count - 1 ] . socket_domain = config -> default_listener . socket_domain ; config -> listeners [ config -> listener_count - 1 ] . client_count = 0 ; config -> listeners [ config -> listener_count - 1 ] . socks = NULL ; config -> listeners [ config -> listener_count - 1 ] . sock_count = 0 ; config -> listeners [ config -> listener_count - 1 ] . client_count = 0 ; config -> listeners [ config -> listener_count - 1 ] . use_username_as_clientid = config -> default_listener . use_username_as_clientid ; # ifdef WITH_TLS config -> listeners [ config -> listener_count - 1 ] . tls_version = config -> default_listener . tls_version ; config -> listeners [ config -> listener_count - 1 ] . cafile = config -> default_listener . cafile ; config -> listeners [ config -> listener_count - 1 ] . capath = config -> default_listener . capath ; config -> listeners [ config -> listener_count - 1 ] . certfile = config -> default_listener . certfile ; config -> listeners [ config -> listener_count - 1 ] . keyfile = config -> default_listener . keyfile ; config -> listeners [ config -> listener_count - 1 ] . ciphers = config -> default_listener . ciphers ; config -> listeners [ config -> listener_count - 1 ] . psk_hint = config -> default_listener . psk_hint ; config -> listeners [ config -> listener_count - 1 ] . require_certificate = config -> default_listener . require_certificate ; config -> listeners [ config -> listener_count - 1 ] . ssl_ctx = NULL ; config -> listeners [ config -> listener_count - 1 ] . crlfile = config -> default_listener . crlfile ; config -> listeners [ config -> listener_count - 1 ] . use_identity_as_username = config -> default_listener . use_identity_as_username ; config -> listeners [ config -> listener_count - 1 ] . use_subject_as_username = config -> default_listener . use_subject_as_username ; # endif <S2SV_StartBug> config -> listeners [ config -> listener_count - 1 ] . security_options . password_file = config -> default_listener . security_options . password_file ; <S2SV_EndBug> config -> listeners [ config -> listener_count - 1 ] . security_options . psk_file = config -> default_listener . security_options . psk_file ; config -> listeners [ config -> listener_count - 1 ] . security_options . auth_plugin_configs = config -> default_listener . security_options . auth_plugin_configs ; config -> listeners [ config -> listener_count - 1 ] . security_options . auth_plugin_config_count = config -> default_listener . security_options . auth_plugin_config_count ; config -> listeners [ config -> listener_count - 1 ] . security_options . allow_anonymous = config -> default_listener . security_options . allow_anonymous ; } if ( ! config -> user ) { config -> user = "mosquitto" ; } if ( db -> verbose ) { config -> log_type = INT_MAX ; } return config__check ( config ) ; }
CWE-000 WORD32 ih264d_parse_sps ( dec_struct_t * ps_dec , dec_bit_stream_t * ps_bitstrm ) { UWORD8 i ; dec_seq_params_t * ps_seq = NULL ; UWORD8 u1_profile_idc , u1_level_idc , u1_seq_parameter_set_id ; UWORD16 i2_max_frm_num ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; UWORD8 u1_frm , uc_constraint_set0_flag , uc_constraint_set1_flag ; UWORD32 u4_temp ; WORD32 pic_height_in_map_units_minus1 = 0 ; UWORD32 u2_pic_wd = 0 ; UWORD32 u2_pic_ht = 0 ; UWORD32 u2_frm_wd_y = 0 ; UWORD32 u2_frm_ht_y = 0 ; UWORD32 u2_frm_wd_uv = 0 ; UWORD32 u2_frm_ht_uv = 0 ; UWORD32 u2_crop_offset_y = 0 ; UWORD32 u2_crop_offset_uv = 0 ; WORD32 ret ; WORD32 i4_i ; UWORD8 u1_frame_cropping_flag , u1_frame_cropping_rect_left_ofst , u1_frame_cropping_rect_right_ofst , u1_frame_cropping_rect_top_ofst , u1_frame_cropping_rect_bottom_ofst ; SWITCHONTRACE ; u1_profile_idc = ih264d_get_bits_h264 ( ps_bitstrm , 8 ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>profile_idc" , u1_profile_idc ) ; uc_constraint_set0_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; uc_constraint_set1_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; ih264d_get_bit_h264 ( ps_bitstrm ) ; ih264d_get_bits_h264 ( ps_bitstrm , 5 ) ; if ( ( u1_profile_idc != MAIN_PROFILE_IDC ) && ( u1_profile_idc != BASE_PROFILE_IDC ) && ( u1_profile_idc != HIGH_PROFILE_IDC ) ) { if ( ( u1_profile_idc != EXTENDED_PROFILE_IDC ) || ( ( uc_constraint_set1_flag != 1 ) && ( uc_constraint_set0_flag != 1 ) ) ) { return ( ERROR_FEATURE_UNAVAIL ) ; } } u1_level_idc = ih264d_get_bits_h264 ( ps_bitstrm , 8 ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>u4_level_idc" , u1_level_idc ) ; u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp & MASK_ERR_SEQ_SET_ID ) return ERROR_INV_SPS_PPS_T ; u1_seq_parameter_set_id = u4_temp ; COPYTHECONTEXT ( "SPS:<S2SV_blank>seq_parameter_set_id" , u1_seq_parameter_set_id ) ; ps_seq = ps_dec -> pv_scratch_sps_pps ; * ps_seq = ps_dec -> ps_sps [ u1_seq_parameter_set_id ] ; if ( NULL == ps_dec -> ps_cur_sps ) ps_dec -> ps_cur_sps = ps_seq ; ps_seq -> u1_profile_idc = u1_profile_idc ; ps_seq -> u1_level_idc = u1_level_idc ; ps_seq -> u1_seq_parameter_set_id = u1_seq_parameter_set_id ; ps_seq -> i4_chroma_format_idc = 1 ; ps_seq -> i4_bit_depth_luma_minus8 = 0 ; ps_seq -> i4_bit_depth_chroma_minus8 = 0 ; ps_seq -> i4_qpprime_y_zero_transform_bypass_flag = 0 ; ps_seq -> i4_seq_scaling_matrix_present_flag = 0 ; if ( u1_profile_idc == HIGH_PROFILE_IDC ) { ps_seq -> i4_chroma_format_idc = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( ps_seq -> i4_chroma_format_idc != 1 ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> i4_bit_depth_luma_minus8 = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( ps_seq -> i4_bit_depth_luma_minus8 != 0 ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> i4_bit_depth_chroma_minus8 = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( ps_seq -> i4_bit_depth_chroma_minus8 != 0 ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> i4_qpprime_y_zero_transform_bypass_flag = ( WORD32 ) ih264d_get_bit_h264 ( ps_bitstrm ) ; if ( ps_seq -> i4_qpprime_y_zero_transform_bypass_flag != 0 ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> i4_seq_scaling_matrix_present_flag = ( WORD32 ) ih264d_get_bit_h264 ( ps_bitstrm ) ; if ( ps_seq -> i4_seq_scaling_matrix_present_flag ) { for ( i4_i = 0 ; i4_i < 8 ; i4_i ++ ) { ps_seq -> u1_seq_scaling_list_present_flag [ i4_i ] = ih264d_get_bit_h264 ( ps_bitstrm ) ; ps_seq -> u1_use_default_scaling_matrix_flag [ i4_i ] = 0 ; if ( ps_seq -> u1_seq_scaling_list_present_flag [ i4_i ] ) { if ( i4_i < 6 ) { ih264d_scaling_list ( ps_seq -> i2_scalinglist4x4 [ i4_i ] , 16 , & ps_seq -> u1_use_default_scaling_matrix_flag [ i4_i ] , ps_bitstrm ) ; } else { ih264d_scaling_list ( ps_seq -> i2_scalinglist8x8 [ i4_i - 6 ] , 64 , & ps_seq -> u1_use_default_scaling_matrix_flag [ i4_i ] , ps_bitstrm ) ; } } } } } u4_temp = 4 + ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > MAX_BITS_IN_FRAME_NUM ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> u1_bits_in_frm_num = u4_temp ; COPYTHECONTEXT ( "SPS:<S2SV_blank>log2_max_frame_num_minus4" , ( ps_seq -> u1_bits_in_frm_num - 4 ) ) ; i2_max_frm_num = ( 1 << ( ps_seq -> u1_bits_in_frm_num ) ) ; ps_seq -> u2_u4_max_pic_num_minus1 = i2_max_frm_num - 1 ; u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > MAX_PIC_ORDER_CNT_TYPE ) { return ERROR_INV_POC_TYPE_T ; } ps_seq -> u1_pic_order_cnt_type = u4_temp ; COPYTHECONTEXT ( "SPS:<S2SV_blank>pic_order_cnt_type" , ps_seq -> u1_pic_order_cnt_type ) ; ps_seq -> u1_num_ref_frames_in_pic_order_cnt_cycle = 1 ; if ( ps_seq -> u1_pic_order_cnt_type == 0 ) { u4_temp = 4 + ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > MAX_BITS_IN_POC_LSB ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> u1_log2_max_pic_order_cnt_lsb_minus = u4_temp ; ps_seq -> i4_max_pic_order_cntLsb = ( 1 << u4_temp ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>log2_max_pic_order_cnt_lsb_minus4" , ( u4_temp - 4 ) ) ; } else if ( ps_seq -> u1_pic_order_cnt_type == 1 ) { ps_seq -> u1_delta_pic_order_always_zero_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>delta_pic_order_always_zero_flag" , ps_seq -> u1_delta_pic_order_always_zero_flag ) ; ps_seq -> i4_ofst_for_non_ref_pic = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>offset_for_non_ref_pic" , ps_seq -> i4_ofst_for_non_ref_pic ) ; ps_seq -> i4_ofst_for_top_to_bottom_field = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>offset_for_top_to_bottom_field" , ps_seq -> i4_ofst_for_top_to_bottom_field ) ; u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > 255 ) return ERROR_INV_SPS_PPS_T ; ps_seq -> u1_num_ref_frames_in_pic_order_cnt_cycle = u4_temp ; COPYTHECONTEXT ( "SPS:<S2SV_blank>num_ref_frames_in_pic_order_cnt_cycle" , ps_seq -> u1_num_ref_frames_in_pic_order_cnt_cycle ) ; for ( i = 0 ; i < ps_seq -> u1_num_ref_frames_in_pic_order_cnt_cycle ; i ++ ) { ps_seq -> i4_ofst_for_ref_frame [ i ] = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>offset_for_ref_frame" , ps_seq -> i4_ofst_for_ref_frame [ i ] ) ; } } u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( ( u4_temp > H264_MAX_REF_PICS ) ) { return ERROR_NUM_REF ; } ps_seq -> u1_num_ref_frames = u4_temp ; COPYTHECONTEXT ( "SPS:<S2SV_blank>num_ref_frames" , ps_seq -> u1_num_ref_frames ) ; ps_seq -> u1_gaps_in_frame_num_value_allowed_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>gaps_in_frame_num_value_allowed_flag" , ps_seq -> u1_gaps_in_frame_num_value_allowed_flag ) ; ps_seq -> u2_frm_wd_in_mbs = 1 + ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>pic_width_in_mbs_minus1" , ps_seq -> u2_frm_wd_in_mbs - 1 ) ; u2_pic_wd = ( ps_seq -> u2_frm_wd_in_mbs << 4 ) ; pic_height_in_map_units_minus1 = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; ps_seq -> u2_frm_ht_in_mbs = 1 + pic_height_in_map_units_minus1 ; u2_pic_ht = ( ps_seq -> u2_frm_ht_in_mbs << 4 ) ; ps_seq -> u2_max_mb_addr = ( ps_seq -> u2_frm_wd_in_mbs * ps_seq -> u2_frm_ht_in_mbs ) - 1 ; ps_seq -> u2_total_num_of_mbs = ps_seq -> u2_max_mb_addr + 1 ; ps_seq -> u1_level_idc = ih264d_correct_level_idc ( u1_level_idc , ps_seq -> u2_total_num_of_mbs ) ; u1_frm = ih264d_get_bit_h264 ( ps_bitstrm ) ; ps_seq -> u1_frame_mbs_only_flag = u1_frm ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_mbs_only_flag" , u1_frm ) ; if ( ! u1_frm ) { u2_pic_ht <<= 1 ; ps_seq -> u1_mb_aff_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>mb_adaptive_frame_field_flag" , ps_seq -> u1_mb_aff_flag ) ; } else ps_seq -> u1_mb_aff_flag = 0 ; ps_seq -> u1_direct_8x8_inference_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>direct_8x8_inference_flag" , ps_seq -> u1_direct_8x8_inference_flag ) ; u1_frame_cropping_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_cropping_flag" , u1_frame_cropping_flag ) ; if ( u1_frame_cropping_flag ) { u1_frame_cropping_rect_left_ofst = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_cropping_rect_left_offset" , u1_frame_cropping_rect_left_ofst ) ; u1_frame_cropping_rect_right_ofst = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_cropping_rect_right_offset" , u1_frame_cropping_rect_right_ofst ) ; u1_frame_cropping_rect_top_ofst = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_cropping_rect_top_offset" , u1_frame_cropping_rect_top_ofst ) ; u1_frame_cropping_rect_bottom_ofst = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>frame_cropping_rect_bottom_offset" , u1_frame_cropping_rect_bottom_ofst ) ; } ps_seq -> u1_vui_parameters_present_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SPS:<S2SV_blank>vui_parameters_present_flag" , ps_seq -> u1_vui_parameters_present_flag ) ; u2_frm_wd_y = u2_pic_wd + ( UWORD8 ) ( PAD_LEN_Y_H << 1 ) ; if ( 1 == ps_dec -> u4_share_disp_buf ) { if ( ps_dec -> u4_app_disp_width > u2_frm_wd_y ) u2_frm_wd_y = ps_dec -> u4_app_disp_width ; } u2_frm_ht_y = u2_pic_ht + ( UWORD8 ) ( PAD_LEN_Y_V << 2 ) ; u2_frm_wd_uv = u2_pic_wd + ( UWORD8 ) ( PAD_LEN_UV_H << 2 ) ; u2_frm_wd_uv = MAX ( u2_frm_wd_uv , u2_frm_wd_y ) ; u2_frm_ht_uv = ( u2_pic_ht >> 1 ) + ( UWORD8 ) ( PAD_LEN_UV_V << 2 ) ; u2_frm_ht_uv = MAX ( u2_frm_ht_uv , ( u2_frm_ht_y >> 1 ) ) ; { UWORD16 u2_rgt_ofst = 0 ; UWORD16 u2_lft_ofst = 0 ; UWORD16 u2_top_ofst = 0 ; UWORD16 u2_btm_ofst = 0 ; UWORD8 u1_frm_mbs_flag ; UWORD8 u1_vert_mult_factor ; WORD32 i4_cropped_ht , i4_cropped_wd ; if ( u1_frame_cropping_flag ) { u2_rgt_ofst = u1_frame_cropping_rect_right_ofst << 1 ; u2_lft_ofst = u1_frame_cropping_rect_left_ofst << 1 ; u1_frm_mbs_flag = ( 1 == ps_seq -> u1_frame_mbs_only_flag ) ; u1_vert_mult_factor = ( 2 - u1_frm_mbs_flag ) ; u2_btm_ofst = ( u1_frame_cropping_rect_bottom_ofst << u1_vert_mult_factor ) ; u2_top_ofst = ( u1_frame_cropping_rect_top_ofst << u1_vert_mult_factor ) ; } u2_crop_offset_y = ( u2_frm_wd_y * u2_top_ofst ) + ( u2_lft_ofst ) ; u2_crop_offset_uv = ( u2_frm_wd_uv * ( u2_top_ofst >> 1 ) ) + ( u2_lft_ofst >> 1 ) * YUV420SP_FACTOR ; i4_cropped_ht = u2_pic_ht - ( u2_btm_ofst + u2_top_ofst ) ; i4_cropped_wd = u2_pic_wd - ( u2_rgt_ofst + u2_lft_ofst ) ; if ( ( i4_cropped_ht < MB_SIZE ) || ( i4_cropped_wd < MB_SIZE ) ) { return ERROR_INV_SPS_PPS_T ; } if ( ( 3 == ps_dec -> i4_header_decoded ) && ( ps_dec -> u2_pic_wd != u2_pic_wd ) ) { ps_dec -> u1_res_changed = 1 ; return IVD_RES_CHANGED ; } if ( ( 3 == ps_dec -> i4_header_decoded ) && ( ps_dec -> u2_pic_ht != u2_pic_ht ) ) { ps_dec -> u1_res_changed = 1 ; return IVD_RES_CHANGED ; } if ( ( u2_pic_wd > H264_MAX_FRAME_WIDTH ) || ( u2_pic_ht > H264_MAX_FRAME_HEIGHT ) ) { return IVD_STREAM_WIDTH_HEIGHT_NOT_SUPPORTED ; } <S2SV_StartBug> ps_dec -> u2_disp_height = i4_cropped_ht ; <S2SV_EndBug> ps_dec -> u2_disp_width = i4_cropped_wd ; } if ( 1 == ps_seq -> u1_vui_parameters_present_flag ) { ret = ih264d_parse_vui_parametres ( & ps_seq -> s_vui , ps_bitstrm ) ; if ( ret != OK ) return ret ; } ps_dec -> u2_pic_wd = u2_pic_wd ; ps_dec -> u2_pic_ht = u2_pic_ht ; ps_dec -> u2_frm_wd_y = u2_frm_wd_y ; ps_dec -> u2_frm_ht_y = u2_frm_ht_y ; ps_dec -> u2_frm_wd_uv = u2_frm_wd_uv ; ps_dec -> u2_frm_ht_uv = u2_frm_ht_uv ; ps_dec -> s_pad_mgr . u1_pad_len_y_v = ( UWORD8 ) ( PAD_LEN_Y_V << ( 1 - u1_frm ) ) ; ps_dec -> s_pad_mgr . u1_pad_len_cr_v = ( UWORD8 ) ( PAD_LEN_UV_V << ( 1 - u1_frm ) ) ; ps_dec -> u2_frm_wd_in_mbs = ps_seq -> u2_frm_wd_in_mbs ; ps_dec -> u2_frm_ht_in_mbs = ps_seq -> u2_frm_ht_in_mbs ; ps_dec -> u2_crop_offset_y = u2_crop_offset_y ; ps_dec -> u2_crop_offset_uv = u2_crop_offset_uv ; if ( ps_bitstrm -> u4_ofst > ps_bitstrm -> u4_max_ofst ) { return ERROR_INV_SPS_PPS_T ; } ps_seq -> u1_is_valid = TRUE ; ps_dec -> ps_sps [ u1_seq_parameter_set_id ] = * ps_seq ; return OK ; }
CWE-000 WORD32 ih264d_parse_islice_data_cavlc ( dec_struct_t * ps_dec , dec_slice_params_t * ps_slice , UWORD16 u2_first_mb_in_slice ) { UWORD8 uc_more_data_flag ; UWORD8 u1_num_mbs , u1_mb_idx ; dec_mb_info_t * ps_cur_mb_info ; deblk_mb_t * ps_cur_deblk_mb ; dec_bit_stream_t * const ps_bitstrm = ps_dec -> ps_bitstrm ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD16 i2_pic_wdin_mbs = ps_dec -> u2_frm_wd_in_mbs ; WORD16 i2_cur_mb_addr ; UWORD8 u1_mbaff ; UWORD8 u1_num_mbs_next , u1_end_of_row , u1_tfr_n_mb ; WORD32 ret = OK ; ps_dec -> u1_qp = ps_slice -> u1_slice_qp ; ih264d_update_qp ( ps_dec , 0 ) ; u1_mbaff = ps_slice -> u1_mbaff_frame_flag ; u1_mb_idx = ps_dec -> u1_mb_idx ; u1_num_mbs = u1_mb_idx ; uc_more_data_flag = 1 ; i2_cur_mb_addr = u2_first_mb_in_slice << u1_mbaff ; do { UWORD8 u1_mb_type ; ps_dec -> pv_prev_mb_parse_tu_coeff_data = ps_dec -> pv_parse_tu_coeff_data ; if ( i2_cur_mb_addr > ps_dec -> ps_cur_sps -> u2_max_mb_addr ) { ret = ERROR_MB_ADDRESS_T ; break ; } ps_cur_mb_info = ps_dec -> ps_nmb_info + u1_num_mbs ; ps_dec -> u4_num_mbs_cur_nmb = u1_num_mbs ; ps_dec -> u4_num_pmbair = ( u1_num_mbs >> u1_mbaff ) ; ps_cur_mb_info -> u1_end_of_slice = 0 ; ps_dec -> pf_get_mb_info ( ps_dec , i2_cur_mb_addr , ps_cur_mb_info , 0 ) ; ps_cur_deblk_mb = ps_dec -> ps_deblk_mbn + u1_num_mbs ; if ( ps_dec -> u4_app_disable_deblk_frm == 0 ) ih264d_set_deblocking_parameters ( ps_cur_deblk_mb , ps_slice , ps_dec -> u1_mb_ngbr_availablity , ps_dec -> u1_cur_mb_fld_dec_flag ) ; ps_cur_deblk_mb -> u1_mb_type = ps_cur_deblk_mb -> u1_mb_type | D_INTRA_MB ; { UWORD32 u4_bitstream_offset = * pu4_bitstrm_ofst ; UWORD32 u4_word , u4_ldz , u4_temp ; NEXTBITS_32 ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf ) ; u4_ldz = CLZ ( u4_word ) ; u4_bitstream_offset += ( u4_ldz + 1 ) ; u4_word = 0 ; if ( u4_ldz ) GETBITS ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf , u4_ldz ) ; * pu4_bitstrm_ofst = u4_bitstream_offset ; u4_temp = ( ( 1 << u4_ldz ) + u4_word - 1 ) ; if ( u4_temp > 25 ) return ERROR_MB_TYPE ; u1_mb_type = u4_temp ; } ps_cur_mb_info -> u1_mb_type = u1_mb_type ; COPYTHECONTEXT ( "u1_mb_type" , u1_mb_type ) ; if ( 25 == u1_mb_type ) { ps_cur_mb_info -> ps_curmb -> u1_mb_type = I_PCM_MB ; ret = ih264d_parse_ipcm_mb ( ps_dec , ps_cur_mb_info , u1_num_mbs ) ; if ( ret != OK ) return ret ; ps_cur_deblk_mb -> u1_mb_qp = 0 ; } else { ret = ih264d_parse_imb_cavlc ( ps_dec , ps_cur_mb_info , u1_num_mbs , u1_mb_type ) ; if ( ret != OK ) return ret ; ps_cur_deblk_mb -> u1_mb_qp = ps_dec -> u1_qp ; } if ( u1_mbaff ) { ih264d_update_mbaff_left_nnz ( ps_dec , ps_cur_mb_info ) ; <S2SV_StartBug> } <S2SV_EndBug> i2_cur_mb_addr ++ ; uc_more_data_flag = MORE_RBSP_DATA ( ps_bitstrm ) ; { mv_pred_t * ps_mv_nmb_start = ps_dec -> ps_mv_cur + ( u1_num_mbs << 4 ) ; mv_pred_t s_mvPred = { { 0 , 0 , 0 , 0 } , { - 1 , - 1 } , 0 , 0 } ; ih264d_rep_mv_colz ( ps_dec , & s_mvPred , ps_mv_nmb_start , 0 , ( UWORD8 ) ( ps_dec -> u1_cur_mb_fld_dec_flag << 1 ) , 4 , 4 ) ; } if ( ps_dec -> u4_num_cores < 3 ) { if ( ps_dec -> u4_app_disable_deblk_frm == 0 ) ps_dec -> pf_compute_bs ( ps_dec , ps_cur_mb_info , ( UWORD16 ) ( u1_num_mbs >> u1_mbaff ) ) ; } u1_num_mbs ++ ; u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec -> u2_mbx - 1 ; u1_end_of_row = ( ! u1_num_mbs_next ) && ( ! ( u1_mbaff && ( u1_num_mbs & 0x01 ) ) ) ; u1_tfr_n_mb = ( u1_num_mbs == ps_dec -> u1_recon_mb_grp ) || u1_end_of_row || ( ! uc_more_data_flag ) ; ps_cur_mb_info -> u1_end_of_slice = ( ! uc_more_data_flag ) ; if ( u1_tfr_n_mb || ( ! uc_more_data_flag ) ) { if ( ps_dec -> u1_separate_parse ) { ih264d_parse_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; ps_dec -> ps_nmb_info += u1_num_mbs ; } else { ih264d_decode_recon_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; } ps_dec -> u2_total_mbs_coded += u1_num_mbs ; if ( u1_tfr_n_mb ) u1_num_mbs = 0 ; u1_mb_idx = u1_num_mbs ; ps_dec -> u1_mb_idx = u1_num_mbs ; } } while ( uc_more_data_flag ) ; ps_dec -> u4_num_mbs_cur_nmb = 0 ; ps_dec -> ps_cur_slice -> u4_mbs_in_slice = i2_cur_mb_addr - ( u2_first_mb_in_slice << u1_mbaff ) ; return ret ; }
CWE-000 WORD32 ih264d_parse_inter_slice_data_cavlc ( dec_struct_t * ps_dec , dec_slice_params_t * ps_slice , UWORD16 u2_first_mb_in_slice ) { UWORD32 uc_more_data_flag ; WORD32 i2_cur_mb_addr ; UWORD32 u1_num_mbs , u1_num_mbsNby2 , u1_mb_idx ; UWORD32 i2_mb_skip_run ; UWORD32 u1_read_mb_type ; UWORD32 u1_mbaff ; UWORD32 u1_num_mbs_next , u1_end_of_row ; const UWORD32 i2_pic_wdin_mbs = ps_dec -> u2_frm_wd_in_mbs ; UWORD32 u1_slice_end = 0 ; UWORD32 u1_tfr_n_mb = 0 ; UWORD32 u1_decode_nmb = 0 ; dec_bit_stream_t * const ps_bitstrm = ps_dec -> ps_bitstrm ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; deblk_mb_t * ps_cur_deblk_mb ; dec_mb_info_t * ps_cur_mb_info ; parse_pmbarams_t * ps_parse_mb_data = ps_dec -> ps_parse_mb_data ; UWORD32 u1_inter_mb_type ; UWORD32 u1_deblk_mb_type ; UWORD32 u1_mb_threshold ; WORD32 ret = OK ; if ( ps_slice -> u1_slice_type == P_SLICE ) { u1_inter_mb_type = P_MB ; u1_deblk_mb_type = D_INTER_MB ; u1_mb_threshold = 5 ; } else { u1_inter_mb_type = B_MB ; u1_deblk_mb_type = D_B_SLICE ; u1_mb_threshold = 23 ; } ps_dec -> u1_qp = ps_slice -> u1_slice_qp ; ih264d_update_qp ( ps_dec , 0 ) ; u1_mb_idx = ps_dec -> u1_mb_idx ; u1_num_mbs = u1_mb_idx ; u1_num_mbsNby2 = 0 ; u1_mbaff = ps_slice -> u1_mbaff_frame_flag ; i2_cur_mb_addr = u2_first_mb_in_slice << u1_mbaff ; i2_mb_skip_run = 0 ; uc_more_data_flag = 1 ; u1_read_mb_type = 0 ; while ( ! u1_slice_end ) { UWORD8 u1_mb_type ; ps_dec -> pv_prev_mb_parse_tu_coeff_data = ps_dec -> pv_parse_tu_coeff_data ; if ( i2_cur_mb_addr > ps_dec -> ps_cur_sps -> u2_max_mb_addr ) { ret = ERROR_MB_ADDRESS_T ; break ; } ps_cur_mb_info = ps_dec -> ps_nmb_info + u1_num_mbs ; ps_dec -> u4_num_mbs_cur_nmb = u1_num_mbs ; ps_cur_mb_info -> u1_Mux = 0 ; ps_dec -> u4_num_pmbair = ( u1_num_mbs >> u1_mbaff ) ; ps_cur_deblk_mb = ps_dec -> ps_deblk_mbn + u1_num_mbs ; ps_cur_mb_info -> u1_end_of_slice = 0 ; ps_parse_mb_data -> u1_num_part = 1 ; ps_parse_mb_data -> u1_isI_mb = 0 ; if ( ( ! i2_mb_skip_run ) && ( ! u1_read_mb_type ) ) { UWORD32 u4_bitstream_offset = * pu4_bitstrm_ofst ; UWORD32 u4_word , u4_ldz ; NEXTBITS_32 ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf ) ; u4_ldz = CLZ ( u4_word ) ; u4_bitstream_offset += ( u4_ldz + 1 ) ; u4_word = 0 ; if ( u4_ldz ) { GETBITS ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf , u4_ldz ) ; } * pu4_bitstrm_ofst = u4_bitstream_offset ; i2_mb_skip_run = ( ( 1 << u4_ldz ) + u4_word - 1 ) ; COPYTHECONTEXT ( "mb_skip_run" , i2_mb_skip_run ) ; uc_more_data_flag = MORE_RBSP_DATA ( ps_bitstrm ) ; u1_read_mb_type = uc_more_data_flag ; } ps_dec -> pf_get_mb_info ( ps_dec , i2_cur_mb_addr , ps_cur_mb_info , i2_mb_skip_run ) ; if ( ps_dec -> u4_app_disable_deblk_frm == 0 ) ih264d_set_deblocking_parameters ( ps_cur_deblk_mb , ps_slice , ps_dec -> u1_mb_ngbr_availablity , ps_dec -> u1_cur_mb_fld_dec_flag ) ; if ( i2_mb_skip_run ) { ps_dec -> i1_prev_mb_qp_delta = 0 ; ps_dec -> u1_sub_mb_num = 0 ; ps_cur_mb_info -> u1_mb_type = MB_SKIP ; ps_cur_mb_info -> u1_mb_mc_mode = PRED_16x16 ; ps_cur_mb_info -> u1_cbp = 0 ; { parse_part_params_t * ps_part_info = ps_dec -> ps_part ; ps_part_info -> u1_is_direct = PART_DIRECT_16x16 ; ps_part_info -> u1_sub_mb_num = 0 ; ps_dec -> ps_part ++ ; } ih264d_update_nnz_for_skipmb ( ps_dec , ps_cur_mb_info , CAVLC ) ; ps_cur_mb_info -> ps_curmb -> u1_mb_type = u1_inter_mb_type ; ps_cur_deblk_mb -> u1_mb_type |= u1_deblk_mb_type ; i2_mb_skip_run -- ; } else { u1_read_mb_type = 0 ; { UWORD32 u4_bitstream_offset = * pu4_bitstrm_ofst ; UWORD32 u4_word , u4_ldz , u4_temp ; NEXTBITS_32 ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf ) ; u4_ldz = CLZ ( u4_word ) ; u4_bitstream_offset += ( u4_ldz + 1 ) ; u4_word = 0 ; if ( u4_ldz ) GETBITS ( u4_word , u4_bitstream_offset , pu4_bitstrm_buf , u4_ldz ) ; * pu4_bitstrm_ofst = u4_bitstream_offset ; u4_temp = ( ( 1 << u4_ldz ) + u4_word - 1 ) ; if ( u4_temp > ( UWORD32 ) ( 25 + u1_mb_threshold ) ) return ERROR_MB_TYPE ; u1_mb_type = u4_temp ; COPYTHECONTEXT ( "u1_mb_type" , u1_mb_type ) ; } ps_cur_mb_info -> u1_mb_type = u1_mb_type ; if ( u1_mb_type < u1_mb_threshold ) { ps_cur_mb_info -> ps_curmb -> u1_mb_type = u1_inter_mb_type ; ret = ps_dec -> pf_parse_inter_mb ( ps_dec , ps_cur_mb_info , u1_num_mbs , u1_num_mbsNby2 ) ; if ( ret != OK ) return ret ; ps_cur_deblk_mb -> u1_mb_type |= u1_deblk_mb_type ; } else { ps_parse_mb_data -> u1_num_part = 0 ; ps_parse_mb_data -> u1_isI_mb = 1 ; if ( ( 25 + u1_mb_threshold ) == u1_mb_type ) { ps_cur_mb_info -> ps_curmb -> u1_mb_type = I_PCM_MB ; ret = ih264d_parse_ipcm_mb ( ps_dec , ps_cur_mb_info , u1_num_mbs ) ; if ( ret != OK ) return ret ; ps_dec -> u1_qp = 0 ; } else { ret = ih264d_parse_imb_cavlc ( ps_dec , ps_cur_mb_info , u1_num_mbs , ( UWORD8 ) ( u1_mb_type - u1_mb_threshold ) ) ; if ( ret != OK ) return ret ; } ps_cur_deblk_mb -> u1_mb_type |= D_INTRA_MB ; } uc_more_data_flag = MORE_RBSP_DATA ( ps_bitstrm ) ; } ps_cur_deblk_mb -> u1_mb_qp = ps_dec -> u1_qp ; if ( u1_mbaff ) { ih264d_update_mbaff_left_nnz ( ps_dec , ps_cur_mb_info ) ; <S2SV_StartBug> } <S2SV_EndBug> i2_cur_mb_addr ++ ; u1_num_mbs ++ ; u1_num_mbsNby2 ++ ; ps_parse_mb_data ++ ; u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec -> u2_mbx - 1 ; u1_end_of_row = ( ! u1_num_mbs_next ) && ( ! ( u1_mbaff && ( u1_num_mbs & 0x01 ) ) ) ; u1_slice_end = ( ! ( uc_more_data_flag || i2_mb_skip_run ) ) ; u1_tfr_n_mb = ( u1_num_mbs == ps_dec -> u1_recon_mb_grp ) || u1_end_of_row || u1_slice_end ; u1_decode_nmb = u1_tfr_n_mb || u1_slice_end ; ps_cur_mb_info -> u1_end_of_slice = u1_slice_end ; if ( u1_decode_nmb ) { ps_dec -> pf_mvpred_ref_tfr_nby2mb ( ps_dec , u1_mb_idx , u1_num_mbs ) ; u1_num_mbsNby2 = 0 ; { ps_parse_mb_data = ps_dec -> ps_parse_mb_data ; ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; } } if ( u1_decode_nmb ) { if ( ps_dec -> u1_separate_parse ) { ih264d_parse_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; ps_dec -> ps_nmb_info += u1_num_mbs ; } else { ih264d_decode_recon_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; } ps_dec -> u2_total_mbs_coded += u1_num_mbs ; if ( u1_tfr_n_mb ) u1_num_mbs = 0 ; u1_mb_idx = u1_num_mbs ; ps_dec -> u1_mb_idx = u1_num_mbs ; } } ps_dec -> u4_num_mbs_cur_nmb = 0 ; ps_dec -> ps_cur_slice -> u4_mbs_in_slice = i2_cur_mb_addr - ( u2_first_mb_in_slice << u1_mbaff ) ; return ret ; }
CWE-000 WORD32 ih264d_parse_decode_slice ( UWORD8 u1_is_idr_slice , UWORD8 u1_nal_ref_idc , dec_struct_t * ps_dec ) { dec_bit_stream_t * ps_bitstrm = ps_dec -> ps_bitstrm ; dec_pic_params_t * ps_pps ; dec_seq_params_t * ps_seq ; dec_slice_params_t * ps_cur_slice = ps_dec -> ps_cur_slice ; pocstruct_t s_tmp_poc ; WORD32 i_delta_poc [ 2 ] ; WORD32 i4_poc = 0 ; UWORD16 u2_first_mb_in_slice , u2_frame_num ; UWORD8 u1_field_pic_flag , u1_redundant_pic_cnt = 0 , u1_slice_type ; UWORD32 u4_idr_pic_id = 0 ; UWORD8 u1_bottom_field_flag , u1_pic_order_cnt_type ; UWORD8 u1_nal_unit_type ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; WORD8 i1_is_end_of_poc ; WORD32 ret , end_of_frame ; WORD32 prev_slice_err , num_mb_skipped ; UWORD8 u1_mbaff ; pocstruct_t * ps_cur_poc ; UWORD32 u4_temp ; WORD32 i_temp ; UWORD32 u4_call_end_of_pic = 0 ; ps_dec -> ps_dpb_cmds -> u1_dpb_commands_read_slc = 0 ; u2_first_mb_in_slice = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u2_first_mb_in_slice > ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) ) { return ERROR_CORRUPTED_SLICE ; } if ( ( ( u2_first_mb_in_slice << ps_cur_slice -> u1_mbaff_frame_flag ) <= ps_dec -> u2_cur_mb_addr ) && ( ps_dec -> u4_first_slice_in_pic == 0 ) ) { return ERROR_CORRUPTED_SLICE ; } COPYTHECONTEXT ( "SH:<S2SV_blank>first_mb_in_slice" , u2_first_mb_in_slice ) ; u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > 9 ) return ERROR_INV_SLC_TYPE_T ; u1_slice_type = u4_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>slice_type" , ( u1_slice_type ) ) ; ps_dec -> u1_sl_typ_5_9 = 0 ; if ( u1_slice_type > 4 ) { u1_slice_type -= 5 ; ps_dec -> u1_sl_typ_5_9 = 1 ; } { UWORD32 skip ; if ( ( ps_dec -> i4_app_skip_mode == IVD_SKIP_PB ) || ( ps_dec -> i4_dec_skip_mode == IVD_SKIP_PB ) ) { UWORD32 u4_bit_stream_offset = 0 ; if ( ps_dec -> u1_nal_unit_type == IDR_SLICE_NAL ) { skip = 0 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_NONE ; } else if ( ( I_SLICE == u1_slice_type ) && ( 1 >= ps_dec -> ps_cur_sps -> u1_num_ref_frames ) ) { skip = 0 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_NONE ; } else { skip = 1 ; } if ( ( 0 == u2_first_mb_in_slice ) && ( 1 == ps_dec -> u4_prev_nal_skipped ) ) { skip = 0 ; } if ( skip ) { ps_dec -> u4_prev_nal_skipped = 1 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_PB ; return 0 ; } else { if ( 1 == ps_dec -> u4_prev_nal_skipped ) { ps_dec -> u4_return_to_app = 1 ; return 0 ; } } } } u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp & MASK_ERR_PIC_SET_ID ) return ERROR_INV_SLICE_HDR_T ; COPYTHECONTEXT ( "SH:<S2SV_blank>pic_parameter_set_id" , u4_temp ) ; ps_pps = & ps_dec -> ps_pps [ u4_temp ] ; if ( FALSE == ps_pps -> u1_is_valid ) { return ERROR_INV_SLICE_HDR_T ; } ps_seq = ps_pps -> ps_sps ; if ( ! ps_seq ) return ERROR_INV_SLICE_HDR_T ; if ( FALSE == ps_seq -> u1_is_valid ) return ERROR_INV_SLICE_HDR_T ; u2_frame_num = ih264d_get_bits_h264 ( ps_bitstrm , ps_seq -> u1_bits_in_frm_num ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>frame_num" , u2_frame_num ) ; if ( ! ps_seq -> u1_frame_mbs_only_flag ) { u1_field_pic_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>field_pic_flag" , u1_field_pic_flag ) ; u1_bottom_field_flag = 0 ; if ( u1_field_pic_flag ) { ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan_fld ; u1_bottom_field_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>bottom_field_flag" , u1_bottom_field_flag ) ; } else { ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan ; } } else { u1_field_pic_flag = 0 ; u1_bottom_field_flag = 0 ; ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan ; } u1_nal_unit_type = SLICE_NAL ; if ( u1_is_idr_slice ) { if ( 0 == u1_field_pic_flag ) { ps_dec -> u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY ; } u1_nal_unit_type = IDR_SLICE_NAL ; u4_idr_pic_id = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_idr_pic_id > 65535 ) return ERROR_INV_SLICE_HDR_T ; COPYTHECONTEXT ( "SH:<S2SV_blank><S2SV_blank>" , u4_idr_pic_id ) ; } i_delta_poc [ 0 ] = i_delta_poc [ 1 ] = 0 ; s_tmp_poc . i4_pic_order_cnt_lsb = 0 ; s_tmp_poc . i4_delta_pic_order_cnt_bottom = 0 ; u1_pic_order_cnt_type = ps_seq -> u1_pic_order_cnt_type ; if ( u1_pic_order_cnt_type == 0 ) { i_temp = ih264d_get_bits_h264 ( ps_bitstrm , ps_seq -> u1_log2_max_pic_order_cnt_lsb_minus ) ; if ( i_temp < 0 || i_temp >= ps_seq -> i4_max_pic_order_cntLsb ) return ERROR_INV_SLICE_HDR_T ; s_tmp_poc . i4_pic_order_cnt_lsb = i_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>pic_order_cnt_lsb" , s_tmp_poc . i4_pic_order_cnt_lsb ) ; if ( ( ps_pps -> u1_pic_order_present_flag == 1 ) && ( ! u1_field_pic_flag ) ) { s_tmp_poc . i4_delta_pic_order_cnt_bottom = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt_bottom" , s_tmp_poc . i4_delta_pic_order_cnt_bottom ) ; } } s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] = 0 ; s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] = 0 ; if ( u1_pic_order_cnt_type == 1 && ( ! ps_seq -> u1_delta_pic_order_always_zero_flag ) ) { s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt[0]" , s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] ) ; if ( ps_pps -> u1_pic_order_present_flag && ! u1_field_pic_flag ) { s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt[1]" , s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] ) ; } } if ( ps_pps -> u1_redundant_pic_cnt_present_flag ) { u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > MAX_REDUNDANT_PIC_CNT ) return ERROR_INV_SLICE_HDR_T ; u1_redundant_pic_cnt = u4_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>redundant_pic_cnt" , u1_redundant_pic_cnt ) ; } <S2SV_StartBug> i1_is_end_of_poc = 0 ; <S2SV_EndBug> if ( ! ps_dec -> u1_first_slice_in_stream ) { i1_is_end_of_poc = ih264d_is_end_of_pic ( u2_frame_num , u1_nal_ref_idc , & s_tmp_poc , & ps_dec -> s_cur_pic_poc , ps_cur_slice , u1_pic_order_cnt_type , u1_nal_unit_type , u4_idr_pic_id , u1_field_pic_flag , u1_bottom_field_flag ) ; if ( ( ps_dec -> u4_first_slice_in_pic == 2 ) && ( i1_is_end_of_poc == 0 ) ) { ps_dec -> ps_dec_err_status -> u1_err_flag |= REJECT_CUR_PIC ; i1_is_end_of_poc = 1 ; } else { ps_dec -> ps_dec_err_status -> u1_err_flag &= MASK_REJECT_CUR_PIC ; <S2SV_StartBug> } <S2SV_EndBug> } u1_mbaff = ps_seq -> u1_mb_aff_flag && ( ! u1_field_pic_flag ) ; prev_slice_err = 0 ; if ( i1_is_end_of_poc || ps_dec -> u1_first_slice_in_stream ) { if ( u2_frame_num != ps_dec -> u2_prv_frame_num && ps_dec -> u1_top_bottom_decoded != 0 && ps_dec -> u1_top_bottom_decoded != ( TOP_FIELD_ONLY | BOT_FIELD_ONLY ) ) { ps_dec -> u1_dangling_field = 1 ; if ( ps_dec -> u4_first_slice_in_pic ) { prev_slice_err = 1 ; } else { prev_slice_err = 2 ; } if ( ps_dec -> u1_top_bottom_decoded == TOP_FIELD_ONLY ) ps_cur_slice -> u1_bottom_field_flag = 1 ; else ps_cur_slice -> u1_bottom_field_flag = 0 ; num_mb_skipped = ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) - ps_dec -> u2_total_mbs_coded ; ps_cur_poc = & ps_dec -> s_cur_pic_poc ; u1_is_idr_slice = ps_cur_slice -> u1_nal_unit_type == IDR_SLICE_NAL ; } else if ( ps_dec -> u4_first_slice_in_pic == 2 ) { if ( u2_first_mb_in_slice > 0 ) { prev_slice_err = 1 ; num_mb_skipped = u2_first_mb_in_slice << u1_mbaff ; ps_cur_poc = & s_tmp_poc ; ps_cur_slice -> u4_idr_pic_id = u4_idr_pic_id ; ps_cur_slice -> u1_field_pic_flag = u1_field_pic_flag ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_cur_slice -> i4_pic_order_cnt_lsb = s_tmp_poc . i4_pic_order_cnt_lsb ; ps_cur_slice -> u1_nal_unit_type = u1_nal_unit_type ; ps_cur_slice -> u1_redundant_pic_cnt = u1_redundant_pic_cnt ; ps_cur_slice -> u1_nal_ref_idc = u1_nal_ref_idc ; ps_cur_slice -> u1_pic_order_cnt_type = u1_pic_order_cnt_type ; ps_cur_slice -> u1_mbaff_frame_flag = ps_seq -> u1_mb_aff_flag && ( ! u1_field_pic_flag ) ; } } else { if ( ps_dec -> u4_first_slice_in_pic ) { prev_slice_err = 1 ; num_mb_skipped = u2_first_mb_in_slice << u1_mbaff ; } else { prev_slice_err = 2 ; num_mb_skipped = ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) - ps_dec -> u2_total_mbs_coded ; } ps_cur_poc = & s_tmp_poc ; } } else { if ( ( u2_first_mb_in_slice << u1_mbaff ) > ps_dec -> u2_total_mbs_coded ) { prev_slice_err = 2 ; num_mb_skipped = ( u2_first_mb_in_slice << u1_mbaff ) - ps_dec -> u2_total_mbs_coded ; ps_cur_poc = & s_tmp_poc ; } else if ( ( u2_first_mb_in_slice << u1_mbaff ) < ps_dec -> u2_total_mbs_coded ) { return ERROR_CORRUPTED_SLICE ; } } if ( prev_slice_err ) { ret = ih264d_mark_err_slice_skip ( ps_dec , num_mb_skipped , u1_is_idr_slice , u2_frame_num , ps_cur_poc , prev_slice_err ) ; if ( ps_dec -> u1_dangling_field == 1 ) { ps_dec -> u1_second_field = 1 - ps_dec -> u1_second_field ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_dec -> u2_prv_frame_num = u2_frame_num ; ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_DANGLING_FIELD_IN_PIC ; } if ( prev_slice_err == 2 ) { ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_INCOMPLETE_FRAME ; } if ( ps_dec -> u2_total_mbs_coded >= ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) { ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_IN_LAST_SLICE_OF_PIC ; } if ( ps_dec -> ps_dec_err_status -> u1_err_flag & REJECT_CUR_PIC ) { ih264d_err_pic_dispbuf_mgr ( ps_dec ) ; return ERROR_NEW_FRAME_EXPECTED ; } if ( ret != OK ) return ret ; i1_is_end_of_poc = 0 ; } if ( ps_dec -> u4_first_slice_in_pic == 0 ) { ps_dec -> ps_parse_cur_slice ++ ; ps_dec -> u2_cur_slice_num ++ ; } if ( ( ps_dec -> u1_separate_parse == 0 ) && ( ps_dec -> u4_first_slice_in_pic == 0 ) ) { ps_dec -> ps_decode_cur_slice ++ ; } ps_dec -> u1_slice_header_done = 0 ; if ( ! ps_dec -> u1_first_slice_in_stream ) { UWORD8 uc_mbs_exceed = 0 ; if ( ps_dec -> u2_total_mbs_coded == ( ps_dec -> ps_cur_sps -> u2_max_mb_addr + 1 ) ) { if ( ps_dec -> u4_first_slice_in_pic == 0 ) uc_mbs_exceed = 1 ; } if ( i1_is_end_of_poc || uc_mbs_exceed ) { if ( 1 == ps_dec -> u1_last_pic_not_decoded ) { ret = ih264d_end_of_pic_dispbuf_mgr ( ps_dec ) ; if ( ret != OK ) return ret ; ret = ih264d_end_of_pic ( ps_dec , u1_is_idr_slice , u2_frame_num ) ; if ( ret != OK ) return ret ; # if WIN32 H264_DEC_DEBUG_PRINT ( "<S2SV_blank>------<S2SV_blank>PIC<S2SV_blank>SKIPPED<S2SV_blank>------\\n" ) ; # endif return RET_LAST_SKIP ; } else { ret = ih264d_end_of_pic ( ps_dec , u1_is_idr_slice , u2_frame_num ) ; if ( ret != OK ) return ret ; } } } if ( u1_field_pic_flag ) { ps_dec -> u2_prv_frame_num = u2_frame_num ; } if ( ps_cur_slice -> u1_mmco_equalto5 ) { WORD32 i4_temp_poc ; WORD32 i4_top_field_order_poc , i4_bot_field_order_poc ; if ( ! ps_cur_slice -> u1_field_pic_flag ) { i4_top_field_order_poc = ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; i4_bot_field_order_poc = ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; i4_temp_poc = MIN ( i4_top_field_order_poc , i4_bot_field_order_poc ) ; } else if ( ! ps_cur_slice -> u1_bottom_field_flag ) i4_temp_poc = ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; else i4_temp_poc = ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_top_field_order_cnt = i4_temp_poc - ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt = i4_temp_poc - ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_poc = i4_temp_poc ; ps_dec -> ps_cur_pic -> i4_avg_poc = i4_temp_poc ; } if ( ps_dec -> u4_first_slice_in_pic == 2 ) { ret = ih264d_decode_pic_order_cnt ( u1_is_idr_slice , u2_frame_num , & ps_dec -> s_prev_pic_poc , & s_tmp_poc , ps_cur_slice , ps_pps , u1_nal_ref_idc , u1_bottom_field_flag , u1_field_pic_flag , & i4_poc ) ; if ( ret != OK ) return ret ; if ( i4_poc >= ps_dec -> i4_max_poc ) ps_dec -> i4_max_poc = i4_poc ; if ( i4_poc == 0 ) { ps_dec -> i4_prev_max_display_seq = ps_dec -> i4_prev_max_display_seq + ps_dec -> i4_max_poc + ps_dec -> u1_max_dec_frame_buffering + 1 ; ps_dec -> i4_max_poc = 0 ; } } ps_cur_slice -> i4_delta_pic_order_cnt [ 0 ] = i_delta_poc [ 0 ] ; ps_cur_slice -> i4_delta_pic_order_cnt [ 1 ] = i_delta_poc [ 1 ] ; ps_cur_slice -> u4_idr_pic_id = u4_idr_pic_id ; ps_cur_slice -> u2_first_mb_in_slice = u2_first_mb_in_slice ; ps_cur_slice -> u1_field_pic_flag = u1_field_pic_flag ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_cur_slice -> u1_slice_type = u1_slice_type ; ps_cur_slice -> i4_pic_order_cnt_lsb = s_tmp_poc . i4_pic_order_cnt_lsb ; ps_cur_slice -> u1_nal_unit_type = u1_nal_unit_type ; ps_cur_slice -> u1_redundant_pic_cnt = u1_redundant_pic_cnt ; ps_cur_slice -> u1_nal_ref_idc = u1_nal_ref_idc ; ps_cur_slice -> u1_pic_order_cnt_type = u1_pic_order_cnt_type ; if ( ps_seq -> u1_frame_mbs_only_flag ) ps_cur_slice -> u1_direct_8x8_inference_flag = ps_seq -> u1_direct_8x8_inference_flag ; else ps_cur_slice -> u1_direct_8x8_inference_flag = 1 ; if ( u1_slice_type == B_SLICE ) { ps_cur_slice -> u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>direct_spatial_mv_pred_flag" , ps_cur_slice -> u1_direct_spatial_mv_pred_flag ) ; if ( ps_cur_slice -> u1_direct_spatial_mv_pred_flag ) ps_cur_slice -> pf_decodeDirect = ih264d_decode_spatial_direct ; else ps_cur_slice -> pf_decodeDirect = ih264d_decode_temporal_direct ; if ( ! ( ( ps_pps -> ps_sps -> u1_mb_aff_flag ) && ( ! u1_field_pic_flag ) ) ) ps_dec -> pf_mvpred = ih264d_mvpred_nonmbaffB ; } else { if ( ! ( ( ps_pps -> ps_sps -> u1_mb_aff_flag ) && ( ! u1_field_pic_flag ) ) ) ps_dec -> pf_mvpred = ih264d_mvpred_nonmbaff ; } if ( ps_dec -> u4_first_slice_in_pic == 2 ) { if ( u2_first_mb_in_slice == 0 ) { ret = ih264d_start_of_pic ( ps_dec , i4_poc , & s_tmp_poc , u2_frame_num , ps_pps ) ; if ( ret != OK ) return ret ; } ps_dec -> u4_output_present = 0 ; { ih264d_get_next_display_field ( ps_dec , ps_dec -> ps_out_buffer , & ( ps_dec -> s_disp_op ) ) ; if ( 0 != ps_dec -> s_disp_op . u4_error_code ) { ps_dec -> u4_fmt_conv_cur_row = ps_dec -> s_disp_frame_info . u4_y_ht ; } else ps_dec -> u4_output_present = 1 ; } if ( ps_dec -> u1_separate_parse == 1 ) { if ( ps_dec -> u4_dec_thread_created == 0 ) { ithread_create ( ps_dec -> pv_dec_thread_handle , NULL , ( void * ) ih264d_decode_picture_thread , ( void * ) ps_dec ) ; ps_dec -> u4_dec_thread_created = 1 ; } if ( ( ps_dec -> u4_num_cores == 3 ) && ( ( ps_dec -> u4_app_disable_deblk_frm == 0 ) || ps_dec -> i1_recon_in_thread3_flag ) && ( ps_dec -> u4_bs_deblk_thread_created == 0 ) ) { ps_dec -> u4_start_recon_deblk = 0 ; ithread_create ( ps_dec -> pv_bs_deblk_thread_handle , NULL , ( void * ) ih264d_recon_deblk_thread , ( void * ) ps_dec ) ; ps_dec -> u4_bs_deblk_thread_created = 1 ; } } } { UWORD8 uc_nofield_nombaff ; uc_nofield_nombaff = ( ( ps_dec -> ps_cur_slice -> u1_field_pic_flag == 0 ) && ( ps_dec -> ps_cur_slice -> u1_mbaff_frame_flag == 0 ) && ( u1_slice_type != B_SLICE ) && ( ps_dec -> ps_cur_pps -> u1_wted_pred_flag == 0 ) ) ; if ( uc_nofield_nombaff ) { ps_dec -> p_form_mb_part_info = ih264d_form_mb_part_info_bp ; ps_dec -> p_motion_compensate = ih264d_motion_compensate_bp ; } else { ps_dec -> p_form_mb_part_info = ih264d_form_mb_part_info_mp ; ps_dec -> p_motion_compensate = ih264d_motion_compensate_mp ; } } { dec_err_status_t * ps_err = ps_dec -> ps_dec_err_status ; if ( ps_err -> u4_frm_sei_sync == u2_frame_num ) { ps_err -> u1_err_flag = ACCEPT_ALL_PICS ; ps_err -> u4_frm_sei_sync = SYNC_FRM_DEFAULT ; } ps_err -> u4_cur_frm = u2_frame_num ; } { WORD32 i4_skip_b_pic , i4_skip_p_pic ; i4_skip_b_pic = ( ps_dec -> u4_skip_frm_mask & B_SLC_BIT ) && ( B_SLICE == u1_slice_type ) && ( 0 == u1_nal_ref_idc ) ; i4_skip_p_pic = ( ps_dec -> u4_skip_frm_mask & P_SLC_BIT ) && ( P_SLICE == u1_slice_type ) && ( 0 == u1_nal_ref_idc ) ; if ( i4_skip_b_pic ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= B_SLC_BIT ; ps_dec -> u1_last_pic_not_decoded = 1 ; return OK ; } if ( i4_skip_p_pic ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= P_SLC_BIT ; ps_dec -> u1_last_pic_not_decoded = 1 ; return OK ; } } { UWORD16 u2_mb_x , u2_mb_y ; ps_dec -> i4_submb_ofst = ( ( u2_first_mb_in_slice << ps_cur_slice -> u1_mbaff_frame_flag ) * SUB_BLK_SIZE ) - SUB_BLK_SIZE ; if ( u2_first_mb_in_slice ) { UWORD8 u1_mb_aff ; UWORD8 u1_field_pic ; UWORD16 u2_frm_wd_in_mbs ; u2_frm_wd_in_mbs = ps_seq -> u2_frm_wd_in_mbs ; u1_mb_aff = ps_cur_slice -> u1_mbaff_frame_flag ; u1_field_pic = ps_cur_slice -> u1_field_pic_flag ; { UWORD32 x_offset ; UWORD32 y_offset ; UWORD32 u4_frame_stride ; tfr_ctxt_t * ps_trns_addr ; if ( ps_dec -> u1_separate_parse ) { ps_trns_addr = & ps_dec -> s_tran_addrecon_parse ; } else { ps_trns_addr = & ps_dec -> s_tran_addrecon ; } u2_mb_x = MOD ( u2_first_mb_in_slice , u2_frm_wd_in_mbs ) ; u2_mb_y = DIV ( u2_first_mb_in_slice , u2_frm_wd_in_mbs ) ; u2_mb_y <<= u1_mb_aff ; if ( ( u2_mb_x > u2_frm_wd_in_mbs - 1 ) || ( u2_mb_y > ps_dec -> u2_frm_ht_in_mbs - 1 ) ) { return ERROR_CORRUPTED_SLICE ; } u4_frame_stride = ps_dec -> u2_frm_wd_y << u1_field_pic ; x_offset = u2_mb_x << 4 ; y_offset = ( u2_mb_y * u4_frame_stride ) << 4 ; ps_trns_addr -> pu1_dest_y = ps_dec -> s_cur_pic . pu1_buf1 + x_offset + y_offset ; u4_frame_stride = ps_dec -> u2_frm_wd_uv << u1_field_pic ; x_offset >>= 1 ; y_offset = ( u2_mb_y * u4_frame_stride ) << 3 ; x_offset *= YUV420SP_FACTOR ; ps_trns_addr -> pu1_dest_u = ps_dec -> s_cur_pic . pu1_buf2 + x_offset + y_offset ; ps_trns_addr -> pu1_dest_v = ps_dec -> s_cur_pic . pu1_buf3 + x_offset + y_offset ; ps_trns_addr -> pu1_mb_y = ps_trns_addr -> pu1_dest_y ; ps_trns_addr -> pu1_mb_u = ps_trns_addr -> pu1_dest_u ; ps_trns_addr -> pu1_mb_v = ps_trns_addr -> pu1_dest_v ; if ( ps_dec -> u1_separate_parse == 1 ) { ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic + ( u2_first_mb_in_slice << u1_mb_aff ) ; } else { ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic + ( u2_first_mb_in_slice << u1_mb_aff ) ; } ps_dec -> u2_cur_mb_addr = ( u2_first_mb_in_slice << u1_mb_aff ) ; ps_dec -> ps_mv_cur = ps_dec -> s_cur_pic . ps_mv + ( ( u2_first_mb_in_slice << u1_mb_aff ) << 4 ) ; } } else { tfr_ctxt_t * ps_trns_addr ; if ( ps_dec -> u1_separate_parse ) { ps_trns_addr = & ps_dec -> s_tran_addrecon_parse ; } else { ps_trns_addr = & ps_dec -> s_tran_addrecon ; } u2_mb_x = 0xffff ; u2_mb_y = 0 ; ps_dec -> u2_cur_mb_addr = 0 ; ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic ; ps_dec -> ps_mv_cur = ps_dec -> s_cur_pic . ps_mv ; ps_trns_addr -> pu1_dest_y = ps_dec -> s_cur_pic . pu1_buf1 ; ps_trns_addr -> pu1_dest_u = ps_dec -> s_cur_pic . pu1_buf2 ; ps_trns_addr -> pu1_dest_v = ps_dec -> s_cur_pic . pu1_buf3 ; ps_trns_addr -> pu1_mb_y = ps_trns_addr -> pu1_dest_y ; ps_trns_addr -> pu1_mb_u = ps_trns_addr -> pu1_dest_u ; ps_trns_addr -> pu1_mb_v = ps_trns_addr -> pu1_dest_v ; } ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; ps_dec -> u2_mbx = ( MOD ( u2_first_mb_in_slice - 1 , ps_seq -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby = ( DIV ( u2_first_mb_in_slice - 1 , ps_seq -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby <<= ps_cur_slice -> u1_mbaff_frame_flag ; ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; } ps_bitstrm -> u4_max_ofst += ps_dec -> ps_cur_pps -> u1_entropy_coding_mode ; ps_dec -> u1_B = ( u1_slice_type == B_SLICE ) ; ps_dec -> u4_next_mb_skip = 0 ; ps_dec -> ps_parse_cur_slice -> u4_first_mb_in_slice = ps_dec -> ps_cur_slice -> u2_first_mb_in_slice ; ps_dec -> ps_parse_cur_slice -> slice_type = ps_dec -> ps_cur_slice -> u1_slice_type ; ps_dec -> u4_start_recon_deblk = 1 ; { WORD32 num_entries ; WORD32 size ; UWORD8 * pu1_buf ; num_entries = MIN ( MAX_FRAMES , ps_dec -> u4_num_ref_frames_at_init ) ; num_entries = 2 * ( ( 2 * num_entries ) + 1 ) ; size = num_entries * sizeof ( void * ) ; size += PAD_MAP_IDX_POC * sizeof ( void * ) ; pu1_buf = ( UWORD8 * ) ps_dec -> pv_map_ref_idx_to_poc_buf ; pu1_buf += size * ps_dec -> u2_cur_slice_num ; ps_dec -> ps_parse_cur_slice -> ppv_map_ref_idx_to_poc = ( void * ) pu1_buf ; } if ( ps_dec -> u1_separate_parse ) { ps_dec -> ps_parse_cur_slice -> pv_tu_coeff_data_start = ps_dec -> pv_parse_tu_coeff_data ; } else { ps_dec -> pv_proc_tu_coeff_data = ps_dec -> pv_parse_tu_coeff_data ; } if ( u1_slice_type == I_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= I_SLC_BIT ; ret = ih264d_parse_islice ( ps_dec , u2_first_mb_in_slice ) ; if ( ps_dec -> i4_pic_type != B_SLICE && ps_dec -> i4_pic_type != P_SLICE ) ps_dec -> i4_pic_type = I_SLICE ; } else if ( u1_slice_type == P_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= P_SLC_BIT ; ret = ih264d_parse_pslice ( ps_dec , u2_first_mb_in_slice ) ; ps_dec -> u1_pr_sl_type = u1_slice_type ; if ( ps_dec -> i4_pic_type != B_SLICE ) ps_dec -> i4_pic_type = P_SLICE ; } else if ( u1_slice_type == B_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= B_SLC_BIT ; ret = ih264d_parse_bslice ( ps_dec , u2_first_mb_in_slice ) ; ps_dec -> u1_pr_sl_type = u1_slice_type ; ps_dec -> i4_pic_type = B_SLICE ; } else return ERROR_INV_SLC_TYPE_T ; if ( ps_dec -> u1_slice_header_done ) { ps_dec -> u4_first_slice_in_pic = 0 ; ps_dec -> u1_first_slice_in_stream = 0 ; } if ( ret != OK ) return ret ; ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; if ( ps_dec -> u2_total_mbs_coded >= ( ps_seq -> u2_max_mb_addr + 1 ) ) { ps_dec -> u1_pic_decode_done = 1 ; } { dec_err_status_t * ps_err = ps_dec -> ps_dec_err_status ; if ( ( ps_err -> u1_err_flag & REJECT_PB_PICS ) && ( ps_err -> u1_cur_pic_type == PIC_TYPE_I ) ) { ps_err -> u1_err_flag = ACCEPT_ALL_PICS ; } } PRINT_BIN_BIT_RATIO ( ps_dec ) return ret ; }
CWE-000 WORD32 ih264d_mark_err_slice_skip ( dec_struct_t * ps_dec , WORD32 num_mb_skip , UWORD8 u1_is_idr_slice , UWORD16 u2_frame_num , pocstruct_t * ps_cur_poc , WORD32 prev_slice_err ) { WORD32 i2_cur_mb_addr ; UWORD32 u1_num_mbs , u1_num_mbsNby2 ; UWORD32 u1_mb_idx = ps_dec -> u1_mb_idx ; UWORD32 i2_mb_skip_run ; UWORD32 u1_num_mbs_next , u1_end_of_row ; const UWORD32 i2_pic_wdin_mbs = ps_dec -> u2_frm_wd_in_mbs ; UWORD32 u1_slice_end ; UWORD32 u1_tfr_n_mb ; UWORD32 u1_decode_nmb ; dec_bit_stream_t * const ps_bitstrm = ps_dec -> ps_bitstrm ; dec_slice_params_t * ps_slice = ps_dec -> ps_cur_slice ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; deblk_mb_t * ps_cur_deblk_mb ; dec_mb_info_t * ps_cur_mb_info ; parse_pmbarams_t * ps_parse_mb_data ; UWORD32 u1_inter_mb_type ; UWORD32 u1_deblk_mb_type ; UWORD16 u2_total_mbs_coded ; UWORD32 u1_mbaff = ps_slice -> u1_mbaff_frame_flag ; parse_part_params_t * ps_part_info ; WORD32 ret ; if ( ps_dec -> ps_dec_err_status -> u1_err_flag & REJECT_CUR_PIC ) { ih264d_err_pic_dispbuf_mgr ( ps_dec ) ; return 0 ; } if ( ps_dec -> ps_cur_slice -> u1_mbaff_frame_flag && ( num_mb_skip & 1 ) ) { num_mb_skip ++ ; } ps_dec -> ps_dpb_cmds -> u1_long_term_reference_flag = 0 ; if ( prev_slice_err == 1 ) { ps_dec -> ps_cur_slice -> u2_frame_num = u2_frame_num ; if ( ! ps_dec -> u1_first_slice_in_stream ) { ih264d_end_of_pic ( ps_dec , u1_is_idr_slice , ps_dec -> ps_cur_slice -> u2_frame_num ) ; ps_dec -> s_cur_pic_poc . u2_frame_num = ps_dec -> ps_cur_slice -> u2_frame_num ; } { WORD32 i , j , poc = 0 ; ps_dec -> ps_cur_slice -> u2_first_mb_in_slice = 0 ; ps_dec -> pf_mvpred = ih264d_mvpred_nonmbaff ; ps_dec -> p_form_mb_part_info = ih264d_form_mb_part_info_bp ; ps_dec -> p_motion_compensate = ih264d_motion_compensate_bp ; if ( ps_dec -> ps_cur_pic != NULL ) poc = ps_dec -> ps_cur_pic -> i4_poc + 2 ; j = - 1 ; for ( i = 0 ; i < MAX_NUM_PIC_PARAMS ; i ++ ) { if ( ps_dec -> ps_pps [ i ] . u1_is_valid == TRUE ) { if ( ps_dec -> ps_pps [ i ] . ps_sps -> u1_is_valid == TRUE ) { j = i ; break ; } } } if ( j == - 1 ) { <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> } if ( ps_dec -> u4_pic_buf_got == 0 ) { ps_dec -> ps_cur_slice -> u1_slice_type = P_SLICE ; ps_dec -> ps_cur_slice -> u1_nal_ref_idc = 1 ; ps_dec -> ps_cur_slice -> u1_nal_unit_type = 1 ; ret = ih264d_start_of_pic ( ps_dec , poc , ps_cur_poc , ps_dec -> ps_cur_slice -> u2_frame_num , & ps_dec -> ps_pps [ j ] ) ; if ( ret != OK ) { return ret ; } } ps_dec -> ps_ref_pic_buf_lx [ 0 ] [ 0 ] -> u1_pic_buf_id = 0 ; ps_dec -> u4_output_present = 0 ; { ih264d_get_next_display_field ( ps_dec , ps_dec -> ps_out_buffer , & ( ps_dec -> s_disp_op ) ) ; if ( 0 != ps_dec -> s_disp_op . u4_error_code ) { ps_dec -> u4_fmt_conv_cur_row = ps_dec -> s_disp_frame_info . u4_y_ht ; } else ps_dec -> u4_output_present = 1 ; } if ( ps_dec -> u1_separate_parse == 1 ) { if ( ps_dec -> u4_dec_thread_created == 0 ) { ithread_create ( ps_dec -> pv_dec_thread_handle , NULL , ( void * ) ih264d_decode_picture_thread , ( void * ) ps_dec ) ; ps_dec -> u4_dec_thread_created = 1 ; } if ( ( ps_dec -> u4_num_cores == 3 ) && ( ( ps_dec -> u4_app_disable_deblk_frm == 0 ) || ps_dec -> i1_recon_in_thread3_flag ) && ( ps_dec -> u4_bs_deblk_thread_created == 0 ) ) { ps_dec -> u4_start_recon_deblk = 0 ; ithread_create ( ps_dec -> pv_bs_deblk_thread_handle , NULL , ( void * ) ih264d_recon_deblk_thread , ( void * ) ps_dec ) ; ps_dec -> u4_bs_deblk_thread_created = 1 ; } } } ps_dec -> u4_first_slice_in_pic = 0 ; } else { dec_slice_struct_t * ps_parse_cur_slice ; ps_parse_cur_slice = ps_dec -> ps_dec_slice_buf + ps_dec -> u2_cur_slice_num ; if ( ps_dec -> u1_slice_header_done && ps_parse_cur_slice == ps_dec -> ps_parse_cur_slice ) { if ( ( u1_mbaff ) && ( ps_dec -> u4_num_mbs_cur_nmb & 1 ) ) { ps_dec -> u4_num_mbs_cur_nmb = ps_dec -> u4_num_mbs_cur_nmb - 1 ; ps_dec -> u2_cur_mb_addr -- ; } u1_num_mbs = ps_dec -> u4_num_mbs_cur_nmb ; if ( u1_num_mbs ) { ps_cur_mb_info = ps_dec -> ps_nmb_info + u1_num_mbs - 1 ; } else { if ( ps_dec -> u1_separate_parse ) { ps_cur_mb_info = ps_dec -> ps_nmb_info ; } else { ps_cur_mb_info = ps_dec -> ps_nmb_info + ps_dec -> u4_num_mbs_prev_nmb - 1 ; } } ps_dec -> u2_mby = ps_cur_mb_info -> u2_mby ; ps_dec -> u2_mbx = ps_cur_mb_info -> u2_mbx ; ps_dec -> u1_mb_ngbr_availablity = ps_cur_mb_info -> u1_mb_ngbr_availablity ; if ( u1_num_mbs ) { ps_dec -> pv_parse_tu_coeff_data = ps_dec -> pv_prev_mb_parse_tu_coeff_data ; ps_dec -> u2_cur_mb_addr -- ; ps_dec -> i4_submb_ofst -= SUB_BLK_SIZE ; if ( ps_dec -> u1_pr_sl_type == P_SLICE || ps_dec -> u1_pr_sl_type == B_SLICE ) { ps_dec -> pf_mvpred_ref_tfr_nby2mb ( ps_dec , u1_mb_idx , u1_num_mbs ) ; ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; } u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec -> u2_mbx - 1 ; u1_end_of_row = ( ! u1_num_mbs_next ) && ( ! ( u1_mbaff && ( u1_num_mbs & 0x01 ) ) ) ; u1_slice_end = 1 ; u1_tfr_n_mb = 1 ; ps_cur_mb_info -> u1_end_of_slice = u1_slice_end ; if ( ps_dec -> u1_separate_parse ) { ih264d_parse_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; ps_dec -> ps_nmb_info += u1_num_mbs ; } else { ih264d_decode_recon_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; } ps_dec -> u2_total_mbs_coded += u1_num_mbs ; ps_dec -> u1_mb_idx = 0 ; ps_dec -> u4_num_mbs_cur_nmb = 0 ; } if ( ps_dec -> u2_total_mbs_coded >= ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) { ps_dec -> u1_pic_decode_done = 1 ; return 0 ; } if ( ps_dec -> ps_parse_cur_slice -> u4_first_mb_in_slice < ( UWORD32 ) ( ps_dec -> u2_total_mbs_coded >> ps_slice -> u1_mbaff_frame_flag ) ) { ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; ps_dec -> u2_cur_slice_num ++ ; ps_dec -> ps_parse_cur_slice ++ ; } } else { ps_dec -> ps_parse_cur_slice = ps_dec -> ps_dec_slice_buf + ps_dec -> u2_cur_slice_num ; } } { WORD32 num_entries ; WORD32 size ; UWORD8 * pu1_buf ; num_entries = MIN ( MAX_FRAMES , ps_dec -> u4_num_ref_frames_at_init ) ; num_entries = 2 * ( ( 2 * num_entries ) + 1 ) ; size = num_entries * sizeof ( void * ) ; size += PAD_MAP_IDX_POC * sizeof ( void * ) ; pu1_buf = ( UWORD8 * ) ps_dec -> pv_map_ref_idx_to_poc_buf ; pu1_buf += size * ps_dec -> u2_cur_slice_num ; ps_dec -> ps_parse_cur_slice -> ppv_map_ref_idx_to_poc = ( volatile void * * ) pu1_buf ; } ps_dec -> ps_cur_slice -> u2_first_mb_in_slice = ps_dec -> u2_total_mbs_coded >> u1_mbaff ; ps_dec -> ps_cur_slice -> i1_slice_alpha_c0_offset = 0 ; ps_dec -> ps_cur_slice -> i1_slice_beta_offset = 0 ; if ( ps_dec -> ps_cur_slice -> u1_field_pic_flag ) ps_dec -> u2_prv_frame_num = ps_dec -> ps_cur_slice -> u2_frame_num ; ps_dec -> ps_parse_cur_slice -> u4_first_mb_in_slice = ps_dec -> u2_total_mbs_coded >> u1_mbaff ; ps_dec -> ps_parse_cur_slice -> u2_log2Y_crwd = ps_dec -> ps_cur_slice -> u2_log2Y_crwd ; if ( ps_dec -> u1_separate_parse ) { ps_dec -> ps_parse_cur_slice -> pv_tu_coeff_data_start = ps_dec -> pv_parse_tu_coeff_data ; } else { ps_dec -> pv_proc_tu_coeff_data = ps_dec -> pv_parse_tu_coeff_data ; } u1_inter_mb_type = P_MB ; u1_deblk_mb_type = D_INTER_MB ; ps_dec -> ps_cur_slice -> u1_slice_type = P_SLICE ; ps_dec -> ps_parse_cur_slice -> slice_type = P_SLICE ; ps_dec -> pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb ; ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; ps_dec -> u2_mbx = ( MOD ( ps_dec -> ps_cur_slice -> u2_first_mb_in_slice - 1 , ps_dec -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby = ( DIV ( ps_dec -> ps_cur_slice -> u2_first_mb_in_slice - 1 , ps_dec -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby <<= u1_mbaff ; ps_dec -> u1_slice_header_done = 2 ; ps_dec -> u1_qp = ps_slice -> u1_slice_qp ; ih264d_update_qp ( ps_dec , 0 ) ; u1_mb_idx = ps_dec -> u1_mb_idx ; ps_parse_mb_data = ps_dec -> ps_parse_mb_data ; u1_num_mbs = u1_mb_idx ; u1_slice_end = 0 ; u1_tfr_n_mb = 0 ; u1_decode_nmb = 0 ; u1_num_mbsNby2 = 0 ; i2_cur_mb_addr = ps_dec -> u2_total_mbs_coded ; i2_mb_skip_run = num_mb_skip ; while ( ! u1_slice_end ) { UWORD8 u1_mb_type ; if ( i2_cur_mb_addr > ps_dec -> ps_cur_sps -> u2_max_mb_addr ) break ; ps_cur_mb_info = ps_dec -> ps_nmb_info + u1_num_mbs ; ps_dec -> u4_num_mbs_cur_nmb = u1_num_mbs ; ps_cur_mb_info -> u1_Mux = 0 ; ps_dec -> u4_num_pmbair = ( u1_num_mbs >> u1_mbaff ) ; ps_cur_deblk_mb = ps_dec -> ps_deblk_mbn + u1_num_mbs ; ps_cur_mb_info -> u1_end_of_slice = 0 ; ps_parse_mb_data -> u1_num_part = 1 ; ps_parse_mb_data -> u1_isI_mb = 0 ; if ( u1_mbaff ) ih264d_get_mb_info_cavlc_mbaff ( ps_dec , i2_cur_mb_addr , ps_cur_mb_info , i2_mb_skip_run ) ; else ih264d_get_mb_info_cavlc_nonmbaff ( ps_dec , i2_cur_mb_addr , ps_cur_mb_info , i2_mb_skip_run ) ; if ( ps_dec -> u4_app_disable_deblk_frm == 0 ) { ih264d_set_deblocking_parameters ( ps_cur_deblk_mb , ps_slice , ps_dec -> u1_mb_ngbr_availablity , ps_dec -> u1_cur_mb_fld_dec_flag ) ; } ps_dec -> i1_prev_mb_qp_delta = 0 ; ps_dec -> u1_sub_mb_num = 0 ; ps_cur_mb_info -> u1_mb_type = MB_SKIP ; ps_cur_mb_info -> u1_mb_mc_mode = PRED_16x16 ; ps_cur_mb_info -> u1_cbp = 0 ; ps_part_info = ps_dec -> ps_part ; ps_part_info -> u1_is_direct = PART_DIRECT_16x16 ; ps_part_info -> u1_sub_mb_num = 0 ; ps_dec -> ps_part ++ ; ih264d_update_nnz_for_skipmb ( ps_dec , ps_cur_mb_info , CAVLC ) ; ps_cur_mb_info -> ps_curmb -> u1_mb_type = u1_inter_mb_type ; ps_cur_deblk_mb -> u1_mb_type |= u1_deblk_mb_type ; i2_mb_skip_run -- ; ps_cur_deblk_mb -> u1_mb_qp = ps_dec -> u1_qp ; if ( u1_mbaff ) { ih264d_update_mbaff_left_nnz ( ps_dec , ps_cur_mb_info ) ; } i2_cur_mb_addr ++ ; u1_num_mbs ++ ; u1_num_mbsNby2 ++ ; ps_parse_mb_data ++ ; u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec -> u2_mbx - 1 ; u1_end_of_row = ( ! u1_num_mbs_next ) && ( ! ( u1_mbaff && ( u1_num_mbs & 0x01 ) ) ) ; u1_slice_end = ! i2_mb_skip_run ; u1_tfr_n_mb = ( u1_num_mbs == ps_dec -> u1_recon_mb_grp ) || u1_end_of_row || u1_slice_end ; u1_decode_nmb = u1_tfr_n_mb || u1_slice_end ; ps_cur_mb_info -> u1_end_of_slice = u1_slice_end ; if ( u1_decode_nmb ) { ps_dec -> pf_mvpred_ref_tfr_nby2mb ( ps_dec , u1_mb_idx , u1_num_mbs ) ; u1_num_mbsNby2 = 0 ; ps_parse_mb_data = ps_dec -> ps_parse_mb_data ; ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; if ( ps_dec -> u1_separate_parse ) { ih264d_parse_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; ps_dec -> ps_nmb_info += u1_num_mbs ; } else { ih264d_decode_recon_tfr_nmb ( ps_dec , u1_mb_idx , u1_num_mbs , u1_num_mbs_next , u1_tfr_n_mb , u1_end_of_row ) ; } ps_dec -> u2_total_mbs_coded += u1_num_mbs ; if ( u1_tfr_n_mb ) u1_num_mbs = 0 ; u1_mb_idx = u1_num_mbs ; ps_dec -> u1_mb_idx = u1_num_mbs ; } } ps_dec -> u4_num_mbs_cur_nmb = 0 ; ps_dec -> ps_cur_slice -> u4_mbs_in_slice = i2_cur_mb_addr - ps_dec -> ps_parse_cur_slice -> u4_first_mb_in_slice ; H264_DEC_DEBUG_PRINT ( "Mbs<S2SV_blank>in<S2SV_blank>slice:<S2SV_blank>%d\\n" , ps_dec -> ps_cur_slice -> u4_mbs_in_slice ) ; if ( ps_dec -> u4_first_slice_in_pic != 0 ) { ps_dec -> ps_parse_cur_slice ++ ; ps_dec -> u2_cur_slice_num ++ ; } ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; if ( ps_dec -> u2_total_mbs_coded >= ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) { ps_dec -> u1_pic_decode_done = 1 ; } return 0 ; }
CWE-000 WORD32 ih264d_parse_decode_slice ( UWORD8 u1_is_idr_slice , UWORD8 u1_nal_ref_idc , dec_struct_t * ps_dec ) { dec_bit_stream_t * ps_bitstrm = ps_dec -> ps_bitstrm ; dec_pic_params_t * ps_pps ; dec_seq_params_t * ps_seq ; dec_slice_params_t * ps_cur_slice = ps_dec -> ps_cur_slice ; pocstruct_t s_tmp_poc ; WORD32 i_delta_poc [ 2 ] ; WORD32 i4_poc = 0 ; UWORD16 u2_first_mb_in_slice , u2_frame_num ; UWORD8 u1_field_pic_flag , u1_redundant_pic_cnt = 0 , u1_slice_type ; UWORD32 u4_idr_pic_id = 0 ; UWORD8 u1_bottom_field_flag , u1_pic_order_cnt_type ; UWORD8 u1_nal_unit_type ; UWORD32 * pu4_bitstrm_buf = ps_bitstrm -> pu4_buffer ; UWORD32 * pu4_bitstrm_ofst = & ps_bitstrm -> u4_ofst ; WORD8 i1_is_end_of_poc ; WORD32 ret , end_of_frame ; WORD32 prev_slice_err , num_mb_skipped ; UWORD8 u1_mbaff ; pocstruct_t * ps_cur_poc ; UWORD32 u4_temp ; WORD32 i_temp ; UWORD32 u4_call_end_of_pic = 0 ; ps_dec -> ps_dpb_cmds -> u1_dpb_commands_read_slc = 0 ; u2_first_mb_in_slice = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u2_first_mb_in_slice > ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) ) { return ERROR_CORRUPTED_SLICE ; } if ( ( ( u2_first_mb_in_slice << ps_cur_slice -> u1_mbaff_frame_flag ) <= ps_dec -> u2_cur_mb_addr ) && ( ps_dec -> u4_first_slice_in_pic == 0 ) ) { return ERROR_CORRUPTED_SLICE ; } COPYTHECONTEXT ( "SH:<S2SV_blank>first_mb_in_slice" , u2_first_mb_in_slice ) ; u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > 9 ) return ERROR_INV_SLC_TYPE_T ; u1_slice_type = u4_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>slice_type" , ( u1_slice_type ) ) ; ps_dec -> u1_sl_typ_5_9 = 0 ; if ( u1_slice_type > 4 ) { u1_slice_type -= 5 ; ps_dec -> u1_sl_typ_5_9 = 1 ; } { UWORD32 skip ; if ( ( ps_dec -> i4_app_skip_mode == IVD_SKIP_PB ) || ( ps_dec -> i4_dec_skip_mode == IVD_SKIP_PB ) ) { UWORD32 u4_bit_stream_offset = 0 ; if ( ps_dec -> u1_nal_unit_type == IDR_SLICE_NAL ) { skip = 0 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_NONE ; } else if ( ( I_SLICE == u1_slice_type ) && ( 1 >= ps_dec -> ps_cur_sps -> u1_num_ref_frames ) ) { skip = 0 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_NONE ; } else { skip = 1 ; } if ( ( 0 == u2_first_mb_in_slice ) && ( 1 == ps_dec -> u4_prev_nal_skipped ) ) { skip = 0 ; } if ( skip ) { ps_dec -> u4_prev_nal_skipped = 1 ; ps_dec -> i4_dec_skip_mode = IVD_SKIP_PB ; return 0 ; } else { if ( 1 == ps_dec -> u4_prev_nal_skipped ) { ps_dec -> u4_return_to_app = 1 ; return 0 ; } } } } u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp & MASK_ERR_PIC_SET_ID ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> COPYTHECONTEXT ( "SH:<S2SV_blank>pic_parameter_set_id" , u4_temp ) ; ps_pps = & ps_dec -> ps_pps [ u4_temp ] ; if ( FALSE == ps_pps -> u1_is_valid ) { <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> } ps_seq = ps_pps -> ps_sps ; if ( ! ps_seq ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> if ( FALSE == ps_seq -> u1_is_valid ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> u2_frame_num = ih264d_get_bits_h264 ( ps_bitstrm , ps_seq -> u1_bits_in_frm_num ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>frame_num" , u2_frame_num ) ; if ( ! ps_seq -> u1_frame_mbs_only_flag ) { u1_field_pic_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>field_pic_flag" , u1_field_pic_flag ) ; u1_bottom_field_flag = 0 ; if ( u1_field_pic_flag ) { ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan_fld ; u1_bottom_field_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>bottom_field_flag" , u1_bottom_field_flag ) ; } else { ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan ; } } else { u1_field_pic_flag = 0 ; u1_bottom_field_flag = 0 ; ps_dec -> pu1_inv_scan = ( UWORD8 * ) gau1_ih264d_inv_scan ; } u1_nal_unit_type = SLICE_NAL ; if ( u1_is_idr_slice ) { if ( 0 == u1_field_pic_flag ) { ps_dec -> u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY ; } u1_nal_unit_type = IDR_SLICE_NAL ; u4_idr_pic_id = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_idr_pic_id > 65535 ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> COPYTHECONTEXT ( "SH:<S2SV_blank><S2SV_blank>" , u4_idr_pic_id ) ; } i_delta_poc [ 0 ] = i_delta_poc [ 1 ] = 0 ; s_tmp_poc . i4_pic_order_cnt_lsb = 0 ; s_tmp_poc . i4_delta_pic_order_cnt_bottom = 0 ; u1_pic_order_cnt_type = ps_seq -> u1_pic_order_cnt_type ; if ( u1_pic_order_cnt_type == 0 ) { i_temp = ih264d_get_bits_h264 ( ps_bitstrm , ps_seq -> u1_log2_max_pic_order_cnt_lsb_minus ) ; if ( i_temp < 0 || i_temp >= ps_seq -> i4_max_pic_order_cntLsb ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> s_tmp_poc . i4_pic_order_cnt_lsb = i_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>pic_order_cnt_lsb" , s_tmp_poc . i4_pic_order_cnt_lsb ) ; if ( ( ps_pps -> u1_pic_order_present_flag == 1 ) && ( ! u1_field_pic_flag ) ) { s_tmp_poc . i4_delta_pic_order_cnt_bottom = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt_bottom" , s_tmp_poc . i4_delta_pic_order_cnt_bottom ) ; } } s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] = 0 ; s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] = 0 ; if ( u1_pic_order_cnt_type == 1 && ( ! ps_seq -> u1_delta_pic_order_always_zero_flag ) ) { s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt[0]" , s_tmp_poc . i4_delta_pic_order_cnt [ 0 ] ) ; if ( ps_pps -> u1_pic_order_present_flag && ! u1_field_pic_flag ) { s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] = ih264d_sev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>delta_pic_order_cnt[1]" , s_tmp_poc . i4_delta_pic_order_cnt [ 1 ] ) ; } } if ( ps_pps -> u1_redundant_pic_cnt_present_flag ) { u4_temp = ih264d_uev ( pu4_bitstrm_ofst , pu4_bitstrm_buf ) ; if ( u4_temp > MAX_REDUNDANT_PIC_CNT ) <S2SV_StartBug> return ERROR_INV_SPS_PPS_T ; <S2SV_EndBug> u1_redundant_pic_cnt = u4_temp ; COPYTHECONTEXT ( "SH:<S2SV_blank>redundant_pic_cnt" , u1_redundant_pic_cnt ) ; } i1_is_end_of_poc = 0 ; if ( ! ps_dec -> u1_first_slice_in_stream ) { i1_is_end_of_poc = ih264d_is_end_of_pic ( u2_frame_num , u1_nal_ref_idc , & s_tmp_poc , & ps_dec -> s_cur_pic_poc , ps_cur_slice , u1_pic_order_cnt_type , u1_nal_unit_type , u4_idr_pic_id , u1_field_pic_flag , u1_bottom_field_flag ) ; if ( ( ps_dec -> u4_first_slice_in_pic == 2 ) && ( i1_is_end_of_poc == 0 ) ) { ps_dec -> ps_dec_err_status -> u1_err_flag |= REJECT_CUR_PIC ; i1_is_end_of_poc = 1 ; } else { ps_dec -> ps_dec_err_status -> u1_err_flag &= MASK_REJECT_CUR_PIC ; } } u1_mbaff = ps_seq -> u1_mb_aff_flag && ( ! u1_field_pic_flag ) ; prev_slice_err = 0 ; if ( i1_is_end_of_poc || ps_dec -> u1_first_slice_in_stream ) { if ( u2_frame_num != ps_dec -> u2_prv_frame_num && ps_dec -> u1_top_bottom_decoded != 0 && ps_dec -> u1_top_bottom_decoded != ( TOP_FIELD_ONLY | BOT_FIELD_ONLY ) ) { ps_dec -> u1_dangling_field = 1 ; if ( ps_dec -> u4_first_slice_in_pic ) { prev_slice_err = 1 ; } else { prev_slice_err = 2 ; } if ( ps_dec -> u1_top_bottom_decoded == TOP_FIELD_ONLY ) ps_cur_slice -> u1_bottom_field_flag = 1 ; else ps_cur_slice -> u1_bottom_field_flag = 0 ; num_mb_skipped = ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) - ps_dec -> u2_total_mbs_coded ; ps_cur_poc = & ps_dec -> s_cur_pic_poc ; u1_is_idr_slice = ps_cur_slice -> u1_nal_unit_type == IDR_SLICE_NAL ; } else if ( ps_dec -> u4_first_slice_in_pic == 2 ) { if ( u2_first_mb_in_slice > 0 ) { prev_slice_err = 1 ; num_mb_skipped = u2_first_mb_in_slice << u1_mbaff ; ps_cur_poc = & s_tmp_poc ; ps_cur_slice -> u4_idr_pic_id = u4_idr_pic_id ; ps_cur_slice -> u1_field_pic_flag = u1_field_pic_flag ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_cur_slice -> i4_pic_order_cnt_lsb = s_tmp_poc . i4_pic_order_cnt_lsb ; ps_cur_slice -> u1_nal_unit_type = u1_nal_unit_type ; ps_cur_slice -> u1_redundant_pic_cnt = u1_redundant_pic_cnt ; ps_cur_slice -> u1_nal_ref_idc = u1_nal_ref_idc ; ps_cur_slice -> u1_pic_order_cnt_type = u1_pic_order_cnt_type ; ps_cur_slice -> u1_mbaff_frame_flag = ps_seq -> u1_mb_aff_flag && ( ! u1_field_pic_flag ) ; } } else { if ( ps_dec -> u4_first_slice_in_pic ) { prev_slice_err = 1 ; num_mb_skipped = u2_first_mb_in_slice << u1_mbaff ; } else { prev_slice_err = 2 ; num_mb_skipped = ( ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) - ps_dec -> u2_total_mbs_coded ; } ps_cur_poc = & s_tmp_poc ; } } else { if ( ( u2_first_mb_in_slice << u1_mbaff ) > ps_dec -> u2_total_mbs_coded ) { prev_slice_err = 2 ; num_mb_skipped = ( u2_first_mb_in_slice << u1_mbaff ) - ps_dec -> u2_total_mbs_coded ; ps_cur_poc = & s_tmp_poc ; } else if ( ( u2_first_mb_in_slice << u1_mbaff ) < ps_dec -> u2_total_mbs_coded ) { return ERROR_CORRUPTED_SLICE ; } } if ( prev_slice_err ) { ret = ih264d_mark_err_slice_skip ( ps_dec , num_mb_skipped , u1_is_idr_slice , u2_frame_num , ps_cur_poc , prev_slice_err ) ; if ( ps_dec -> u1_dangling_field == 1 ) { ps_dec -> u1_second_field = 1 - ps_dec -> u1_second_field ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_dec -> u2_prv_frame_num = u2_frame_num ; ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_DANGLING_FIELD_IN_PIC ; } if ( prev_slice_err == 2 ) { ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_INCOMPLETE_FRAME ; } if ( ps_dec -> u2_total_mbs_coded >= ps_dec -> u2_frm_ht_in_mbs * ps_dec -> u2_frm_wd_in_mbs ) { ps_dec -> u1_first_slice_in_stream = 0 ; return ERROR_IN_LAST_SLICE_OF_PIC ; } if ( ps_dec -> ps_dec_err_status -> u1_err_flag & REJECT_CUR_PIC ) { ih264d_err_pic_dispbuf_mgr ( ps_dec ) ; return ERROR_NEW_FRAME_EXPECTED ; } if ( ret != OK ) return ret ; i1_is_end_of_poc = 0 ; } if ( ps_dec -> u4_first_slice_in_pic == 0 ) { ps_dec -> ps_parse_cur_slice ++ ; ps_dec -> u2_cur_slice_num ++ ; } if ( ( ps_dec -> u1_separate_parse == 0 ) && ( ps_dec -> u4_first_slice_in_pic == 0 ) ) { ps_dec -> ps_decode_cur_slice ++ ; } ps_dec -> u1_slice_header_done = 0 ; if ( ! ps_dec -> u1_first_slice_in_stream ) { UWORD8 uc_mbs_exceed = 0 ; if ( ps_dec -> u2_total_mbs_coded == ( ps_dec -> ps_cur_sps -> u2_max_mb_addr + 1 ) ) { if ( ps_dec -> u4_first_slice_in_pic == 0 ) uc_mbs_exceed = 1 ; } if ( i1_is_end_of_poc || uc_mbs_exceed ) { if ( 1 == ps_dec -> u1_last_pic_not_decoded ) { ret = ih264d_end_of_pic_dispbuf_mgr ( ps_dec ) ; if ( ret != OK ) return ret ; ret = ih264d_end_of_pic ( ps_dec , u1_is_idr_slice , u2_frame_num ) ; if ( ret != OK ) return ret ; # if WIN32 H264_DEC_DEBUG_PRINT ( "<S2SV_blank>------<S2SV_blank>PIC<S2SV_blank>SKIPPED<S2SV_blank>------\\n" ) ; # endif return RET_LAST_SKIP ; } else { ret = ih264d_end_of_pic ( ps_dec , u1_is_idr_slice , u2_frame_num ) ; if ( ret != OK ) return ret ; } } } if ( u1_field_pic_flag ) { ps_dec -> u2_prv_frame_num = u2_frame_num ; } if ( ps_cur_slice -> u1_mmco_equalto5 ) { WORD32 i4_temp_poc ; WORD32 i4_top_field_order_poc , i4_bot_field_order_poc ; if ( ! ps_cur_slice -> u1_field_pic_flag ) { i4_top_field_order_poc = ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; i4_bot_field_order_poc = ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; i4_temp_poc = MIN ( i4_top_field_order_poc , i4_bot_field_order_poc ) ; } else if ( ! ps_cur_slice -> u1_bottom_field_flag ) i4_temp_poc = ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; else i4_temp_poc = ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_top_field_order_cnt = i4_temp_poc - ps_dec -> ps_cur_pic -> i4_top_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt = i4_temp_poc - ps_dec -> ps_cur_pic -> i4_bottom_field_order_cnt ; ps_dec -> ps_cur_pic -> i4_poc = i4_temp_poc ; ps_dec -> ps_cur_pic -> i4_avg_poc = i4_temp_poc ; } if ( ps_dec -> u4_first_slice_in_pic == 2 ) { ret = ih264d_decode_pic_order_cnt ( u1_is_idr_slice , u2_frame_num , & ps_dec -> s_prev_pic_poc , & s_tmp_poc , ps_cur_slice , ps_pps , u1_nal_ref_idc , u1_bottom_field_flag , u1_field_pic_flag , & i4_poc ) ; if ( ret != OK ) return ret ; if ( i4_poc >= ps_dec -> i4_max_poc ) ps_dec -> i4_max_poc = i4_poc ; if ( i4_poc == 0 ) { ps_dec -> i4_prev_max_display_seq = ps_dec -> i4_prev_max_display_seq + ps_dec -> i4_max_poc + ps_dec -> u1_max_dec_frame_buffering + 1 ; ps_dec -> i4_max_poc = 0 ; } } ps_cur_slice -> i4_delta_pic_order_cnt [ 0 ] = i_delta_poc [ 0 ] ; ps_cur_slice -> i4_delta_pic_order_cnt [ 1 ] = i_delta_poc [ 1 ] ; ps_cur_slice -> u4_idr_pic_id = u4_idr_pic_id ; ps_cur_slice -> u2_first_mb_in_slice = u2_first_mb_in_slice ; ps_cur_slice -> u1_field_pic_flag = u1_field_pic_flag ; ps_cur_slice -> u1_bottom_field_flag = u1_bottom_field_flag ; ps_cur_slice -> u1_slice_type = u1_slice_type ; ps_cur_slice -> i4_pic_order_cnt_lsb = s_tmp_poc . i4_pic_order_cnt_lsb ; ps_cur_slice -> u1_nal_unit_type = u1_nal_unit_type ; ps_cur_slice -> u1_redundant_pic_cnt = u1_redundant_pic_cnt ; ps_cur_slice -> u1_nal_ref_idc = u1_nal_ref_idc ; ps_cur_slice -> u1_pic_order_cnt_type = u1_pic_order_cnt_type ; if ( ps_seq -> u1_frame_mbs_only_flag ) ps_cur_slice -> u1_direct_8x8_inference_flag = ps_seq -> u1_direct_8x8_inference_flag ; else ps_cur_slice -> u1_direct_8x8_inference_flag = 1 ; if ( u1_slice_type == B_SLICE ) { ps_cur_slice -> u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264 ( ps_bitstrm ) ; COPYTHECONTEXT ( "SH:<S2SV_blank>direct_spatial_mv_pred_flag" , ps_cur_slice -> u1_direct_spatial_mv_pred_flag ) ; if ( ps_cur_slice -> u1_direct_spatial_mv_pred_flag ) ps_cur_slice -> pf_decodeDirect = ih264d_decode_spatial_direct ; else ps_cur_slice -> pf_decodeDirect = ih264d_decode_temporal_direct ; if ( ! ( ( ps_pps -> ps_sps -> u1_mb_aff_flag ) && ( ! u1_field_pic_flag ) ) ) ps_dec -> pf_mvpred = ih264d_mvpred_nonmbaffB ; } else { if ( ! ( ( ps_pps -> ps_sps -> u1_mb_aff_flag ) && ( ! u1_field_pic_flag ) ) ) ps_dec -> pf_mvpred = ih264d_mvpred_nonmbaff ; } if ( ps_dec -> u4_first_slice_in_pic == 2 ) { if ( u2_first_mb_in_slice == 0 ) { ret = ih264d_start_of_pic ( ps_dec , i4_poc , & s_tmp_poc , u2_frame_num , ps_pps ) ; if ( ret != OK ) return ret ; } ps_dec -> u4_output_present = 0 ; { ih264d_get_next_display_field ( ps_dec , ps_dec -> ps_out_buffer , & ( ps_dec -> s_disp_op ) ) ; if ( 0 != ps_dec -> s_disp_op . u4_error_code ) { ps_dec -> u4_fmt_conv_cur_row = ps_dec -> s_disp_frame_info . u4_y_ht ; } else ps_dec -> u4_output_present = 1 ; } if ( ps_dec -> u1_separate_parse == 1 ) { if ( ps_dec -> u4_dec_thread_created == 0 ) { ithread_create ( ps_dec -> pv_dec_thread_handle , NULL , ( void * ) ih264d_decode_picture_thread , ( void * ) ps_dec ) ; ps_dec -> u4_dec_thread_created = 1 ; } if ( ( ps_dec -> u4_num_cores == 3 ) && ( ( ps_dec -> u4_app_disable_deblk_frm == 0 ) || ps_dec -> i1_recon_in_thread3_flag ) && ( ps_dec -> u4_bs_deblk_thread_created == 0 ) ) { ps_dec -> u4_start_recon_deblk = 0 ; ithread_create ( ps_dec -> pv_bs_deblk_thread_handle , NULL , ( void * ) ih264d_recon_deblk_thread , ( void * ) ps_dec ) ; ps_dec -> u4_bs_deblk_thread_created = 1 ; } } } { UWORD8 uc_nofield_nombaff ; uc_nofield_nombaff = ( ( ps_dec -> ps_cur_slice -> u1_field_pic_flag == 0 ) && ( ps_dec -> ps_cur_slice -> u1_mbaff_frame_flag == 0 ) && ( u1_slice_type != B_SLICE ) && ( ps_dec -> ps_cur_pps -> u1_wted_pred_flag == 0 ) ) ; if ( uc_nofield_nombaff ) { ps_dec -> p_form_mb_part_info = ih264d_form_mb_part_info_bp ; ps_dec -> p_motion_compensate = ih264d_motion_compensate_bp ; } else { ps_dec -> p_form_mb_part_info = ih264d_form_mb_part_info_mp ; ps_dec -> p_motion_compensate = ih264d_motion_compensate_mp ; } } { dec_err_status_t * ps_err = ps_dec -> ps_dec_err_status ; if ( ps_err -> u4_frm_sei_sync == u2_frame_num ) { ps_err -> u1_err_flag = ACCEPT_ALL_PICS ; ps_err -> u4_frm_sei_sync = SYNC_FRM_DEFAULT ; } ps_err -> u4_cur_frm = u2_frame_num ; } { WORD32 i4_skip_b_pic , i4_skip_p_pic ; i4_skip_b_pic = ( ps_dec -> u4_skip_frm_mask & B_SLC_BIT ) && ( B_SLICE == u1_slice_type ) && ( 0 == u1_nal_ref_idc ) ; i4_skip_p_pic = ( ps_dec -> u4_skip_frm_mask & P_SLC_BIT ) && ( P_SLICE == u1_slice_type ) && ( 0 == u1_nal_ref_idc ) ; if ( i4_skip_b_pic ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= B_SLC_BIT ; ps_dec -> u1_last_pic_not_decoded = 1 ; return OK ; } if ( i4_skip_p_pic ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= P_SLC_BIT ; ps_dec -> u1_last_pic_not_decoded = 1 ; return OK ; } } { UWORD16 u2_mb_x , u2_mb_y ; ps_dec -> i4_submb_ofst = ( ( u2_first_mb_in_slice << ps_cur_slice -> u1_mbaff_frame_flag ) * SUB_BLK_SIZE ) - SUB_BLK_SIZE ; if ( u2_first_mb_in_slice ) { UWORD8 u1_mb_aff ; UWORD8 u1_field_pic ; UWORD16 u2_frm_wd_in_mbs ; u2_frm_wd_in_mbs = ps_seq -> u2_frm_wd_in_mbs ; u1_mb_aff = ps_cur_slice -> u1_mbaff_frame_flag ; u1_field_pic = ps_cur_slice -> u1_field_pic_flag ; { UWORD32 x_offset ; UWORD32 y_offset ; UWORD32 u4_frame_stride ; tfr_ctxt_t * ps_trns_addr ; if ( ps_dec -> u1_separate_parse ) { ps_trns_addr = & ps_dec -> s_tran_addrecon_parse ; } else { ps_trns_addr = & ps_dec -> s_tran_addrecon ; } u2_mb_x = MOD ( u2_first_mb_in_slice , u2_frm_wd_in_mbs ) ; u2_mb_y = DIV ( u2_first_mb_in_slice , u2_frm_wd_in_mbs ) ; u2_mb_y <<= u1_mb_aff ; if ( ( u2_mb_x > u2_frm_wd_in_mbs - 1 ) || ( u2_mb_y > ps_dec -> u2_frm_ht_in_mbs - 1 ) ) { return ERROR_CORRUPTED_SLICE ; } u4_frame_stride = ps_dec -> u2_frm_wd_y << u1_field_pic ; x_offset = u2_mb_x << 4 ; y_offset = ( u2_mb_y * u4_frame_stride ) << 4 ; ps_trns_addr -> pu1_dest_y = ps_dec -> s_cur_pic . pu1_buf1 + x_offset + y_offset ; u4_frame_stride = ps_dec -> u2_frm_wd_uv << u1_field_pic ; x_offset >>= 1 ; y_offset = ( u2_mb_y * u4_frame_stride ) << 3 ; x_offset *= YUV420SP_FACTOR ; ps_trns_addr -> pu1_dest_u = ps_dec -> s_cur_pic . pu1_buf2 + x_offset + y_offset ; ps_trns_addr -> pu1_dest_v = ps_dec -> s_cur_pic . pu1_buf3 + x_offset + y_offset ; ps_trns_addr -> pu1_mb_y = ps_trns_addr -> pu1_dest_y ; ps_trns_addr -> pu1_mb_u = ps_trns_addr -> pu1_dest_u ; ps_trns_addr -> pu1_mb_v = ps_trns_addr -> pu1_dest_v ; if ( ps_dec -> u1_separate_parse == 1 ) { ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic + ( u2_first_mb_in_slice << u1_mb_aff ) ; } else { ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic + ( u2_first_mb_in_slice << u1_mb_aff ) ; } ps_dec -> u2_cur_mb_addr = ( u2_first_mb_in_slice << u1_mb_aff ) ; ps_dec -> ps_mv_cur = ps_dec -> s_cur_pic . ps_mv + ( ( u2_first_mb_in_slice << u1_mb_aff ) << 4 ) ; } } else { tfr_ctxt_t * ps_trns_addr ; if ( ps_dec -> u1_separate_parse ) { ps_trns_addr = & ps_dec -> s_tran_addrecon_parse ; } else { ps_trns_addr = & ps_dec -> s_tran_addrecon ; } u2_mb_x = 0xffff ; u2_mb_y = 0 ; ps_dec -> u2_cur_mb_addr = 0 ; ps_dec -> ps_deblk_mbn = ps_dec -> ps_deblk_pic ; ps_dec -> ps_mv_cur = ps_dec -> s_cur_pic . ps_mv ; ps_trns_addr -> pu1_dest_y = ps_dec -> s_cur_pic . pu1_buf1 ; ps_trns_addr -> pu1_dest_u = ps_dec -> s_cur_pic . pu1_buf2 ; ps_trns_addr -> pu1_dest_v = ps_dec -> s_cur_pic . pu1_buf3 ; ps_trns_addr -> pu1_mb_y = ps_trns_addr -> pu1_dest_y ; ps_trns_addr -> pu1_mb_u = ps_trns_addr -> pu1_dest_u ; ps_trns_addr -> pu1_mb_v = ps_trns_addr -> pu1_dest_v ; } ps_dec -> ps_part = ps_dec -> ps_parse_part_params ; ps_dec -> u2_mbx = ( MOD ( u2_first_mb_in_slice - 1 , ps_seq -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby = ( DIV ( u2_first_mb_in_slice - 1 , ps_seq -> u2_frm_wd_in_mbs ) ) ; ps_dec -> u2_mby <<= ps_cur_slice -> u1_mbaff_frame_flag ; ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; } ps_bitstrm -> u4_max_ofst += ps_dec -> ps_cur_pps -> u1_entropy_coding_mode ; ps_dec -> u1_B = ( u1_slice_type == B_SLICE ) ; ps_dec -> u4_next_mb_skip = 0 ; ps_dec -> ps_parse_cur_slice -> u4_first_mb_in_slice = ps_dec -> ps_cur_slice -> u2_first_mb_in_slice ; ps_dec -> ps_parse_cur_slice -> slice_type = ps_dec -> ps_cur_slice -> u1_slice_type ; ps_dec -> u4_start_recon_deblk = 1 ; { WORD32 num_entries ; WORD32 size ; UWORD8 * pu1_buf ; num_entries = MIN ( MAX_FRAMES , ps_dec -> u4_num_ref_frames_at_init ) ; num_entries = 2 * ( ( 2 * num_entries ) + 1 ) ; size = num_entries * sizeof ( void * ) ; size += PAD_MAP_IDX_POC * sizeof ( void * ) ; pu1_buf = ( UWORD8 * ) ps_dec -> pv_map_ref_idx_to_poc_buf ; pu1_buf += size * ps_dec -> u2_cur_slice_num ; ps_dec -> ps_parse_cur_slice -> ppv_map_ref_idx_to_poc = ( void * ) pu1_buf ; } if ( ps_dec -> u1_separate_parse ) { ps_dec -> ps_parse_cur_slice -> pv_tu_coeff_data_start = ps_dec -> pv_parse_tu_coeff_data ; } else { ps_dec -> pv_proc_tu_coeff_data = ps_dec -> pv_parse_tu_coeff_data ; } if ( u1_slice_type == I_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= I_SLC_BIT ; ret = ih264d_parse_islice ( ps_dec , u2_first_mb_in_slice ) ; if ( ps_dec -> i4_pic_type != B_SLICE && ps_dec -> i4_pic_type != P_SLICE ) ps_dec -> i4_pic_type = I_SLICE ; } else if ( u1_slice_type == P_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= P_SLC_BIT ; ret = ih264d_parse_pslice ( ps_dec , u2_first_mb_in_slice ) ; ps_dec -> u1_pr_sl_type = u1_slice_type ; if ( ps_dec -> i4_pic_type != B_SLICE ) ps_dec -> i4_pic_type = P_SLICE ; } else if ( u1_slice_type == B_SLICE ) { ps_dec -> ps_cur_pic -> u4_pack_slc_typ |= B_SLC_BIT ; ret = ih264d_parse_bslice ( ps_dec , u2_first_mb_in_slice ) ; ps_dec -> u1_pr_sl_type = u1_slice_type ; ps_dec -> i4_pic_type = B_SLICE ; } else return ERROR_INV_SLC_TYPE_T ; if ( ps_dec -> u1_slice_header_done ) { ps_dec -> u4_first_slice_in_pic = 0 ; ps_dec -> u1_first_slice_in_stream = 0 ; } if ( ret != OK ) return ret ; ps_dec -> i2_prev_slice_mbx = ps_dec -> u2_mbx ; ps_dec -> i2_prev_slice_mby = ps_dec -> u2_mby ; if ( ps_dec -> u2_total_mbs_coded >= ( ps_seq -> u2_max_mb_addr + 1 ) ) { ps_dec -> u1_pic_decode_done = 1 ; } { dec_err_status_t * ps_err = ps_dec -> ps_dec_err_status ; if ( ( ps_err -> u1_err_flag & REJECT_PB_PICS ) && ( ps_err -> u1_cur_pic_type == PIC_TYPE_I ) ) { ps_err -> u1_err_flag = ACCEPT_ALL_PICS ; } } PRINT_BIN_BIT_RATIO ( ps_dec ) return ret ; }
CWE-000 IHEVCD_ERROR_T ihevcd_parse_pps ( codec_t * ps_codec ) { IHEVCD_ERROR_T ret = ( IHEVCD_ERROR_T ) IHEVCD_SUCCESS ; WORD32 value ; WORD32 pps_id ; pps_t * ps_pps ; sps_t * ps_sps ; bitstrm_t * ps_bitstrm = & ps_codec -> s_parse . s_bitstrm ; if ( 0 == ps_codec -> i4_sps_done ) return IHEVCD_INVALID_HEADER ; UEV_PARSE ( "pic_parameter_set_id" , value , ps_bitstrm ) ; pps_id = value ; if ( ( pps_id >= MAX_PPS_CNT ) || ( pps_id < 0 ) ) { if ( ps_codec -> i4_pps_done ) return IHEVCD_UNSUPPORTED_PPS_ID ; else pps_id = 0 ; } ps_pps = ( ps_codec -> s_parse . ps_pps_base + MAX_PPS_CNT - 1 ) ; ps_pps -> i1_pps_id = pps_id ; UEV_PARSE ( "seq_parameter_set_id" , value , ps_bitstrm ) ; ps_pps -> i1_sps_id = value ; ps_pps -> i1_sps_id = CLIP3 ( ps_pps -> i1_sps_id , 0 , MAX_SPS_CNT - 2 ) ; ps_sps = ( ps_codec -> s_parse . ps_sps_base + ps_pps -> i1_sps_id ) ; if ( 0 == ps_sps -> i1_sps_valid ) { return IHEVCD_INVALID_HEADER ; } BITS_PARSE ( "dependent_slices_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_dependent_slice_enabled_flag = value ; BITS_PARSE ( "output_flag_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_output_flag_present_flag = value ; BITS_PARSE ( "num_extra_slice_header_bits" , value , ps_bitstrm , 3 ) ; ps_pps -> i1_num_extra_slice_header_bits = value ; BITS_PARSE ( "sign_data_hiding_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_sign_data_hiding_flag = value ; BITS_PARSE ( "cabac_init_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_cabac_init_present_flag = value ; UEV_PARSE ( "num_ref_idx_l0_default_active_minus1" , value , ps_bitstrm ) ; ps_pps -> i1_num_ref_idx_l0_default_active = value + 1 ; UEV_PARSE ( "num_ref_idx_l1_default_active_minus1" , value , ps_bitstrm ) ; ps_pps -> i1_num_ref_idx_l1_default_active = value + 1 ; SEV_PARSE ( "pic_init_qp_minus26" , value , ps_bitstrm ) ; ps_pps -> i1_pic_init_qp = value + 26 ; BITS_PARSE ( "constrained_intra_pred_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_constrained_intra_pred_flag = value ; BITS_PARSE ( "transform_skip_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_transform_skip_enabled_flag = value ; BITS_PARSE ( "cu_qp_delta_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_cu_qp_delta_enabled_flag = value ; if ( ps_pps -> i1_cu_qp_delta_enabled_flag ) { UEV_PARSE ( "diff_cu_qp_delta_depth" , value , ps_bitstrm ) ; ps_pps -> i1_diff_cu_qp_delta_depth = value ; } else { ps_pps -> i1_diff_cu_qp_delta_depth = 0 ; } ps_pps -> i1_log2_min_cu_qp_delta_size = ps_sps -> i1_log2_ctb_size - ps_pps -> i1_diff_cu_qp_delta_depth ; SEV_PARSE ( "cb_qp_offset" , value , ps_bitstrm ) ; ps_pps -> i1_pic_cb_qp_offset = value ; SEV_PARSE ( "cr_qp_offset" , value , ps_bitstrm ) ; ps_pps -> i1_pic_cr_qp_offset = value ; BITS_PARSE ( "slicelevel_chroma_qp_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_pic_slice_level_chroma_qp_offsets_present_flag = value ; BITS_PARSE ( "weighted_pred_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_weighted_pred_flag = value ; BITS_PARSE ( "weighted_bipred_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_weighted_bipred_flag = value ; BITS_PARSE ( "transquant_bypass_enable_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_transquant_bypass_enable_flag = value ; BITS_PARSE ( "tiles_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_tiles_enabled_flag = value ; <S2SV_StartBug> BITS_PARSE ( "entropy_coding_sync_enabled_flag" , value , ps_bitstrm , 1 ) ; <S2SV_EndBug> ps_pps -> i1_entropy_coding_sync_enabled_flag = value ; ps_pps -> i1_loop_filter_across_tiles_enabled_flag = 0 ; if ( ps_pps -> i1_tiles_enabled_flag ) { WORD32 wd = ALIGN64 ( ps_codec -> i4_wd ) ; WORD32 ht = ALIGN64 ( ps_codec -> i4_ht ) ; WORD32 max_tile_cols = ( wd + MIN_TILE_WD - 1 ) / MIN_TILE_WD ; WORD32 max_tile_rows = ( ht + MIN_TILE_HT - 1 ) / MIN_TILE_HT ; UEV_PARSE ( "num_tile_columns_minus1" , value , ps_bitstrm ) ; ps_pps -> i1_num_tile_columns = value + 1 ; UEV_PARSE ( "num_tile_rows_minus1" , value , ps_bitstrm ) ; ps_pps -> i1_num_tile_rows = value + 1 ; if ( ( ps_pps -> i1_num_tile_columns < 1 ) || ( ps_pps -> i1_num_tile_columns > max_tile_cols ) || ( ps_pps -> i1_num_tile_rows < 1 ) || ( ps_pps -> i1_num_tile_rows > max_tile_rows ) ) return IHEVCD_INVALID_HEADER ; BITS_PARSE ( "uniform_spacing_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_uniform_spacing_flag = value ; { WORD32 start ; WORD32 i , j ; start = 0 ; for ( i = 0 ; i < ps_pps -> i1_num_tile_columns ; i ++ ) { tile_t * ps_tile ; if ( ! ps_pps -> i1_uniform_spacing_flag ) { if ( i < ( ps_pps -> i1_num_tile_columns - 1 ) ) { UEV_PARSE ( "column_width_minus1[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm ) ; value += 1 ; } else { value = ps_sps -> i2_pic_wd_in_ctb - start ; } } else { value = ( ( i + 1 ) * ps_sps -> i2_pic_wd_in_ctb ) / ps_pps -> i1_num_tile_columns - ( i * ps_sps -> i2_pic_wd_in_ctb ) / ps_pps -> i1_num_tile_columns ; } for ( j = 0 ; j < ps_pps -> i1_num_tile_rows ; j ++ ) { ps_tile = ps_pps -> ps_tile + j * ps_pps -> i1_num_tile_columns + i ; ps_tile -> u1_pos_x = start ; ps_tile -> u2_wd = value ; } start += value ; if ( ( start > ps_sps -> i2_pic_wd_in_ctb ) || ( value <= 0 ) ) return IHEVCD_INVALID_HEADER ; } start = 0 ; for ( i = 0 ; i < ( ps_pps -> i1_num_tile_rows ) ; i ++ ) { tile_t * ps_tile ; if ( ! ps_pps -> i1_uniform_spacing_flag ) { if ( i < ( ps_pps -> i1_num_tile_rows - 1 ) ) { UEV_PARSE ( "row_height_minus1[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm ) ; value += 1 ; } else { value = ps_sps -> i2_pic_ht_in_ctb - start ; } } else { value = ( ( i + 1 ) * ps_sps -> i2_pic_ht_in_ctb ) / ps_pps -> i1_num_tile_rows - ( i * ps_sps -> i2_pic_ht_in_ctb ) / ps_pps -> i1_num_tile_rows ; } for ( j = 0 ; j < ps_pps -> i1_num_tile_columns ; j ++ ) { ps_tile = ps_pps -> ps_tile + i * ps_pps -> i1_num_tile_columns + j ; ps_tile -> u1_pos_y = start ; ps_tile -> u2_ht = value ; } start += value ; if ( ( start > ps_sps -> i2_pic_ht_in_ctb ) || ( value <= 0 ) ) return IHEVCD_INVALID_HEADER ; } } BITS_PARSE ( "loop_filter_across_tiles_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_loop_filter_across_tiles_enabled_flag = value ; } else { ps_pps -> i1_num_tile_columns = 1 ; ps_pps -> i1_num_tile_rows = 1 ; ps_pps -> i1_uniform_spacing_flag = 1 ; ps_pps -> ps_tile -> u1_pos_x = 0 ; ps_pps -> ps_tile -> u1_pos_y = 0 ; ps_pps -> ps_tile -> u2_wd = ps_sps -> i2_pic_wd_in_ctb ; ps_pps -> ps_tile -> u2_ht = ps_sps -> i2_pic_ht_in_ctb ; } BITS_PARSE ( "loop_filter_across_slices_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_loop_filter_across_slices_enabled_flag = value ; BITS_PARSE ( "deblocking_filter_control_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_deblocking_filter_control_present_flag = value ; ps_pps -> i1_pic_disable_deblocking_filter_flag = 0 ; ps_pps -> i1_deblocking_filter_override_enabled_flag = 0 ; ps_pps -> i1_beta_offset_div2 = 0 ; ps_pps -> i1_tc_offset_div2 = 0 ; if ( ps_pps -> i1_deblocking_filter_control_present_flag ) { BITS_PARSE ( "deblocking_filter_override_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_deblocking_filter_override_enabled_flag = value ; BITS_PARSE ( "pic_disable_deblocking_filter_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_pic_disable_deblocking_filter_flag = value ; if ( ! ps_pps -> i1_pic_disable_deblocking_filter_flag ) { SEV_PARSE ( "pps_beta_offset_div2" , value , ps_bitstrm ) ; ps_pps -> i1_beta_offset_div2 = value ; SEV_PARSE ( "pps_tc_offset_div2" , value , ps_bitstrm ) ; ps_pps -> i1_tc_offset_div2 = value ; } } BITS_PARSE ( "pps_scaling_list_data_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_pps_scaling_list_data_present_flag = value ; if ( ps_pps -> i1_pps_scaling_list_data_present_flag ) { COPY_DEFAULT_SCALING_LIST ( ps_pps -> pi2_scaling_mat ) ; ihevcd_scaling_list_data ( ps_codec , ps_pps -> pi2_scaling_mat ) ; } BITS_PARSE ( "lists_modification_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_lists_modification_present_flag = value ; UEV_PARSE ( "log2_parallel_merge_level_minus2" , value , ps_bitstrm ) ; ps_pps -> i1_log2_parallel_merge_level = value + 2 ; BITS_PARSE ( "slice_header_extension_present_flag" , value , ps_bitstrm , 1 ) ; ps_pps -> i1_slice_header_extension_present_flag = value ; BITS_PARSE ( "pps_extension_flag" , value , ps_bitstrm , 1 ) ; if ( ( UWORD8 * ) ps_bitstrm -> pu4_buf > ps_bitstrm -> pu1_buf_max ) return IHEVCD_INVALID_PARAMETER ; ps_codec -> i4_pps_done = 1 ; return ret ; }
CWE-000 IHEVCD_ERROR_T ihevcd_parse_slice_header ( codec_t * ps_codec , nal_header_t * ps_nal ) { IHEVCD_ERROR_T ret = ( IHEVCD_ERROR_T ) IHEVCD_SUCCESS ; WORD32 value ; <S2SV_StartBug> WORD32 i ; <S2SV_EndBug> WORD32 sps_id ; pps_t * ps_pps ; sps_t * ps_sps ; slice_header_t * ps_slice_hdr ; WORD32 disable_deblocking_filter_flag ; bitstrm_t * ps_bitstrm = & ps_codec -> s_parse . s_bitstrm ; WORD32 idr_pic_flag ; WORD32 pps_id ; WORD32 first_slice_in_pic_flag ; WORD32 no_output_of_prior_pics_flag = 0 ; WORD8 i1_nal_unit_type = ps_nal -> i1_nal_unit_type ; WORD32 num_poc_total_curr = 0 ; WORD32 slice_address ; if ( ps_codec -> i4_slice_error == 1 ) return ret ; idr_pic_flag = ( NAL_IDR_W_LP == i1_nal_unit_type ) || ( NAL_IDR_N_LP == i1_nal_unit_type ) ; BITS_PARSE ( "first_slice_in_pic_flag" , first_slice_in_pic_flag , ps_bitstrm , 1 ) ; if ( ( NAL_BLA_W_LP <= i1_nal_unit_type ) && ( NAL_RSV_RAP_VCL23 >= i1_nal_unit_type ) ) { BITS_PARSE ( "no_output_of_prior_pics_flag" , no_output_of_prior_pics_flag , ps_bitstrm , 1 ) ; } UEV_PARSE ( "pic_parameter_set_id" , pps_id , ps_bitstrm ) ; pps_id = CLIP3 ( pps_id , 0 , MAX_PPS_CNT - 2 ) ; ps_pps = ps_codec -> s_parse . ps_pps_base + pps_id ; if ( 0 == ps_pps -> i1_pps_valid ) { pps_t * ps_pps_ref = ps_codec -> ps_pps_base ; while ( 0 == ps_pps_ref -> i1_pps_valid ) ps_pps_ref ++ ; if ( ( ps_pps_ref - ps_codec -> ps_pps_base >= MAX_PPS_CNT - 1 ) ) return IHEVCD_INVALID_HEADER ; ihevcd_copy_pps ( ps_codec , pps_id , ps_pps_ref -> i1_pps_id ) ; } sps_id = ps_pps -> i1_sps_id ; ps_sps = ps_codec -> s_parse . ps_sps_base + sps_id ; if ( ( 0 != ps_codec -> u4_pic_cnt || ps_codec -> i4_pic_present ) && first_slice_in_pic_flag ) { if ( ps_codec -> i4_pic_present ) { slice_header_t * ps_slice_hdr_next ; ps_codec -> i4_slice_error = 1 ; ps_codec -> s_parse . i4_cur_slice_idx -- ; if ( ps_codec -> s_parse . i4_cur_slice_idx < 0 ) ps_codec -> s_parse . i4_cur_slice_idx = 0 ; ps_slice_hdr_next = ps_codec -> s_parse . ps_slice_hdr_base + ( ( ps_codec -> s_parse . i4_cur_slice_idx + 1 ) & ( MAX_SLICE_HDR_CNT - 1 ) ) ; ps_slice_hdr_next -> i2_ctb_x = 0 ; ps_slice_hdr_next -> i2_ctb_y = ps_codec -> s_parse . ps_sps -> i2_pic_ht_in_ctb ; return ret ; } else { ps_codec -> i4_slice_error = 0 ; } } if ( first_slice_in_pic_flag ) { ps_codec -> s_parse . i4_cur_slice_idx = 0 ; } else { if ( 0 == ps_codec -> i4_pic_present ) ps_codec -> s_parse . i4_cur_slice_idx = 1 ; } ps_slice_hdr = ps_codec -> s_parse . ps_slice_hdr_base + ( ps_codec -> s_parse . i4_cur_slice_idx & ( MAX_SLICE_HDR_CNT - 1 ) ) ; if ( ( ps_pps -> i1_dependent_slice_enabled_flag ) && ( ! first_slice_in_pic_flag ) ) { BITS_PARSE ( "dependent_slice_flag" , value , ps_bitstrm , 1 ) ; if ( value && ( ps_codec -> s_parse . i4_cur_slice_idx > 0 ) ) { ihevcd_copy_slice_hdr ( ps_codec , ( ps_codec -> s_parse . i4_cur_slice_idx & ( MAX_SLICE_HDR_CNT - 1 ) ) , ( ( ps_codec -> s_parse . i4_cur_slice_idx - 1 ) & ( MAX_SLICE_HDR_CNT - 1 ) ) ) ; } ps_slice_hdr -> i1_dependent_slice_flag = value ; } else { ps_slice_hdr -> i1_dependent_slice_flag = 0 ; } ps_slice_hdr -> i1_nal_unit_type = i1_nal_unit_type ; ps_slice_hdr -> i1_pps_id = pps_id ; ps_slice_hdr -> i1_first_slice_in_pic_flag = first_slice_in_pic_flag ; ps_slice_hdr -> i1_no_output_of_prior_pics_flag = 1 ; if ( ( NAL_BLA_W_LP <= i1_nal_unit_type ) && ( NAL_RSV_RAP_VCL23 >= i1_nal_unit_type ) ) { ps_slice_hdr -> i1_no_output_of_prior_pics_flag = no_output_of_prior_pics_flag ; } ps_slice_hdr -> i1_pps_id = pps_id ; if ( ! ps_slice_hdr -> i1_first_slice_in_pic_flag ) { WORD32 num_bits ; num_bits = 32 - CLZ ( ps_sps -> i4_pic_size_in_ctb - 1 ) ; BITS_PARSE ( "slice_address" , value , ps_bitstrm , num_bits ) ; slice_address = value ; if ( value >= ps_sps -> i4_pic_size_in_ctb ) return IHEVCD_IGNORE_SLICE ; } else { slice_address = 0 ; } if ( ! ps_slice_hdr -> i1_dependent_slice_flag ) { ps_slice_hdr -> i1_pic_output_flag = 1 ; ps_slice_hdr -> i4_pic_order_cnt_lsb = 0 ; ps_slice_hdr -> i1_num_long_term_sps = 0 ; ps_slice_hdr -> i1_num_long_term_pics = 0 ; for ( i = 0 ; i < ps_pps -> i1_num_extra_slice_header_bits ; i ++ ) { BITS_PARSE ( "slice_reserved_undetermined_flag[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm , 1 ) ; } UEV_PARSE ( "slice_type" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_slice_type = value ; if ( ( ps_slice_hdr -> i1_nal_unit_type >= NAL_BLA_W_LP ) && ( ps_slice_hdr -> i1_nal_unit_type <= NAL_RSV_RAP_VCL23 ) ) ps_slice_hdr -> i1_slice_type = ISLICE ; if ( ( ps_slice_hdr -> i1_slice_type < 0 ) || ( ps_slice_hdr -> i1_slice_type > 2 ) ) return IHEVCD_IGNORE_SLICE ; if ( ps_pps -> i1_output_flag_present_flag ) { BITS_PARSE ( "pic_output_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_pic_output_flag = value ; } ps_slice_hdr -> i1_colour_plane_id = 0 ; if ( 1 == ps_sps -> i1_separate_colour_plane_flag ) { BITS_PARSE ( "colour_plane_id" , value , ps_bitstrm , 2 ) ; ps_slice_hdr -> i1_colour_plane_id = value ; } ps_slice_hdr -> i1_slice_temporal_mvp_enable_flag = 0 ; if ( ! idr_pic_flag ) { WORD32 st_rps_idx ; WORD32 num_neg_pics ; WORD32 num_pos_pics ; WORD8 * pi1_used ; BITS_PARSE ( "pic_order_cnt_lsb" , value , ps_bitstrm , ps_sps -> i1_log2_max_pic_order_cnt_lsb ) ; ps_slice_hdr -> i4_pic_order_cnt_lsb = value ; BITS_PARSE ( "short_term_ref_pic_set_sps_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_short_term_ref_pic_set_sps_flag = value ; if ( 1 == ps_slice_hdr -> i1_short_term_ref_pic_set_sps_flag ) { WORD32 numbits ; ps_slice_hdr -> i1_short_term_ref_pic_set_idx = 0 ; if ( ps_sps -> i1_num_short_term_ref_pic_sets > 1 ) { numbits = 32 - CLZ ( ps_sps -> i1_num_short_term_ref_pic_sets - 1 ) ; BITS_PARSE ( "short_term_ref_pic_set_idx" , value , ps_bitstrm , numbits ) ; ps_slice_hdr -> i1_short_term_ref_pic_set_idx = value ; } st_rps_idx = ps_slice_hdr -> i1_short_term_ref_pic_set_idx ; num_neg_pics = ps_sps -> as_stref_picset [ st_rps_idx ] . i1_num_neg_pics ; num_pos_pics = ps_sps -> as_stref_picset [ st_rps_idx ] . i1_num_pos_pics ; pi1_used = ps_sps -> as_stref_picset [ st_rps_idx ] . ai1_used ; } else { ihevcd_short_term_ref_pic_set ( ps_bitstrm , & ps_sps -> as_stref_picset [ 0 ] , ps_sps -> i1_num_short_term_ref_pic_sets , ps_sps -> i1_num_short_term_ref_pic_sets , & ps_slice_hdr -> s_stref_picset ) ; st_rps_idx = ps_sps -> i1_num_short_term_ref_pic_sets ; num_neg_pics = ps_slice_hdr -> s_stref_picset . i1_num_neg_pics ; num_pos_pics = ps_slice_hdr -> s_stref_picset . i1_num_pos_pics ; pi1_used = ps_slice_hdr -> s_stref_picset . ai1_used ; } if ( ps_sps -> i1_long_term_ref_pics_present_flag ) { if ( ps_sps -> i1_num_long_term_ref_pics_sps > 0 ) { UEV_PARSE ( "num_long_term_sps" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_num_long_term_sps = value ; ps_slice_hdr -> i1_num_long_term_sps = CLIP3 ( ps_slice_hdr -> i1_num_long_term_sps , 0 , MAX_DPB_SIZE - num_neg_pics - num_pos_pics ) ; } UEV_PARSE ( "num_long_term_pics" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_num_long_term_pics = value ; ps_slice_hdr -> i1_num_long_term_pics = CLIP3 ( ps_slice_hdr -> i1_num_long_term_pics , 0 , MAX_DPB_SIZE - num_neg_pics - num_pos_pics - ps_slice_hdr -> i1_num_long_term_sps ) ; for ( i = 0 ; i < ( ps_slice_hdr -> i1_num_long_term_sps + ps_slice_hdr -> i1_num_long_term_pics ) ; i ++ ) { if ( i < ps_slice_hdr -> i1_num_long_term_sps ) { WORD32 num_bits = 32 - CLZ ( ps_sps -> i1_num_long_term_ref_pics_sps ) ; BITS_PARSE ( "lt_idx_sps[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm , num_bits ) ; ps_slice_hdr -> ai4_poc_lsb_lt [ i ] = ps_sps -> ai1_lt_ref_pic_poc_lsb_sps [ value ] ; ps_slice_hdr -> ai1_used_by_curr_pic_lt_flag [ i ] = ps_sps -> ai1_used_by_curr_pic_lt_sps_flag [ value ] ; } else { BITS_PARSE ( "poc_lsb_lt[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm , ps_sps -> i1_log2_max_pic_order_cnt_lsb ) ; ps_slice_hdr -> ai4_poc_lsb_lt [ i ] = value ; BITS_PARSE ( "used_by_curr_pic_lt_flag[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> ai1_used_by_curr_pic_lt_flag [ i ] = value ; } BITS_PARSE ( "delta_poc_msb_present_flag[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> ai1_delta_poc_msb_present_flag [ i ] = value ; ps_slice_hdr -> ai1_delta_poc_msb_cycle_lt [ i ] = 0 ; if ( ps_slice_hdr -> ai1_delta_poc_msb_present_flag [ i ] ) { UEV_PARSE ( "delata_poc_msb_cycle_lt[<S2SV_blank>i<S2SV_blank>]" , value , ps_bitstrm ) ; ps_slice_hdr -> ai1_delta_poc_msb_cycle_lt [ i ] = value ; } if ( ( i != 0 ) && ( i != ps_slice_hdr -> i1_num_long_term_sps ) ) { ps_slice_hdr -> ai1_delta_poc_msb_cycle_lt [ i ] += ps_slice_hdr -> ai1_delta_poc_msb_cycle_lt [ i - 1 ] ; } } } for ( i = 0 ; i < num_neg_pics + num_pos_pics ; i ++ ) { if ( pi1_used [ i ] ) { num_poc_total_curr ++ ; } } for ( i = 0 ; i < ps_slice_hdr -> i1_num_long_term_sps + ps_slice_hdr -> i1_num_long_term_pics ; i ++ ) { if ( ps_slice_hdr -> ai1_used_by_curr_pic_lt_flag [ i ] ) { num_poc_total_curr ++ ; } } if ( ps_sps -> i1_sps_temporal_mvp_enable_flag ) { BITS_PARSE ( "enable_temporal_mvp_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_slice_temporal_mvp_enable_flag = value ; } } ps_slice_hdr -> i1_slice_sao_luma_flag = 0 ; ps_slice_hdr -> i1_slice_sao_chroma_flag = 0 ; if ( ps_sps -> i1_sample_adaptive_offset_enabled_flag ) { BITS_PARSE ( "slice_sao_luma_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_slice_sao_luma_flag = value ; BITS_PARSE ( "slice_sao_chroma_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_slice_sao_chroma_flag = value ; } ps_slice_hdr -> i1_max_num_merge_cand = 1 ; ps_slice_hdr -> i1_cabac_init_flag = 0 ; ps_slice_hdr -> i1_num_ref_idx_l0_active = 0 ; ps_slice_hdr -> i1_num_ref_idx_l1_active = 0 ; ps_slice_hdr -> i1_slice_cb_qp_offset = 0 ; ps_slice_hdr -> i1_slice_cr_qp_offset = 0 ; if ( ( PSLICE == ps_slice_hdr -> i1_slice_type ) || ( BSLICE == ps_slice_hdr -> i1_slice_type ) ) { BITS_PARSE ( "num_ref_idx_active_override_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_num_ref_idx_active_override_flag = value ; if ( ps_slice_hdr -> i1_num_ref_idx_active_override_flag ) { UEV_PARSE ( "num_ref_idx_l0_active_minus1" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_num_ref_idx_l0_active = value + 1 ; if ( BSLICE == ps_slice_hdr -> i1_slice_type ) { UEV_PARSE ( "num_ref_idx_l1_active_minus1" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_num_ref_idx_l1_active = value + 1 ; } } else { ps_slice_hdr -> i1_num_ref_idx_l0_active = ps_pps -> i1_num_ref_idx_l0_default_active ; if ( BSLICE == ps_slice_hdr -> i1_slice_type ) { ps_slice_hdr -> i1_num_ref_idx_l1_active = ps_pps -> i1_num_ref_idx_l1_default_active ; } } ps_slice_hdr -> i1_num_ref_idx_l0_active = CLIP3 ( ps_slice_hdr -> i1_num_ref_idx_l0_active , 0 , MAX_DPB_SIZE - 1 ) ; ps_slice_hdr -> i1_num_ref_idx_l1_active = CLIP3 ( ps_slice_hdr -> i1_num_ref_idx_l1_active , 0 , MAX_DPB_SIZE - 1 ) ; if ( 0 == num_poc_total_curr ) return IHEVCD_IGNORE_SLICE ; if ( ( ps_pps -> i1_lists_modification_present_flag ) && ( num_poc_total_curr > 1 ) ) { ihevcd_ref_pic_list_modification ( ps_bitstrm , ps_slice_hdr , num_poc_total_curr ) ; } else { ps_slice_hdr -> s_rplm . i1_ref_pic_list_modification_flag_l0 = 0 ; ps_slice_hdr -> s_rplm . i1_ref_pic_list_modification_flag_l1 = 0 ; } if ( BSLICE == ps_slice_hdr -> i1_slice_type ) { BITS_PARSE ( "mvd_l1_zero_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_mvd_l1_zero_flag = value ; } ps_slice_hdr -> i1_cabac_init_flag = 0 ; if ( ps_pps -> i1_cabac_init_present_flag ) { BITS_PARSE ( "cabac_init_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_cabac_init_flag = value ; } ps_slice_hdr -> i1_collocated_from_l0_flag = 1 ; ps_slice_hdr -> i1_collocated_ref_idx = 0 ; if ( ps_slice_hdr -> i1_slice_temporal_mvp_enable_flag ) { if ( BSLICE == ps_slice_hdr -> i1_slice_type ) { BITS_PARSE ( "collocated_from_l0_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_collocated_from_l0_flag = value ; } if ( ( ps_slice_hdr -> i1_collocated_from_l0_flag && ( ps_slice_hdr -> i1_num_ref_idx_l0_active > 1 ) ) || ( ! ps_slice_hdr -> i1_collocated_from_l0_flag && ( ps_slice_hdr -> i1_num_ref_idx_l1_active > 1 ) ) ) { UEV_PARSE ( "collocated_ref_idx" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_collocated_ref_idx = value ; } } ps_slice_hdr -> i1_collocated_ref_idx = CLIP3 ( ps_slice_hdr -> i1_collocated_ref_idx , 0 , MAX_DPB_SIZE - 1 ) ; if ( ( ps_pps -> i1_weighted_pred_flag && ( PSLICE == ps_slice_hdr -> i1_slice_type ) ) || ( ps_pps -> i1_weighted_bipred_flag && ( BSLICE == ps_slice_hdr -> i1_slice_type ) ) ) { ihevcd_parse_pred_wt_ofst ( ps_bitstrm , ps_sps , ps_pps , ps_slice_hdr ) ; } UEV_PARSE ( "five_minus_max_num_merge_cand" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_max_num_merge_cand = 5 - value ; } ps_slice_hdr -> i1_max_num_merge_cand = CLIP3 ( ps_slice_hdr -> i1_max_num_merge_cand , 1 , 5 ) ; SEV_PARSE ( "slice_qp_delta" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_slice_qp_delta = value ; if ( ps_pps -> i1_pic_slice_level_chroma_qp_offsets_present_flag ) { SEV_PARSE ( "slice_cb_qp_offset" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_slice_cb_qp_offset = value ; SEV_PARSE ( "slice_cr_qp_offset" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_slice_cr_qp_offset = value ; } ps_slice_hdr -> i1_deblocking_filter_override_flag = 0 ; ps_slice_hdr -> i1_slice_disable_deblocking_filter_flag = ps_pps -> i1_pic_disable_deblocking_filter_flag ; ps_slice_hdr -> i1_beta_offset_div2 = ps_pps -> i1_beta_offset_div2 ; ps_slice_hdr -> i1_tc_offset_div2 = ps_pps -> i1_tc_offset_div2 ; disable_deblocking_filter_flag = ps_pps -> i1_pic_disable_deblocking_filter_flag ; if ( ps_pps -> i1_deblocking_filter_control_present_flag ) { if ( ps_pps -> i1_deblocking_filter_override_enabled_flag ) { BITS_PARSE ( "deblocking_filter_override_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_deblocking_filter_override_flag = value ; } if ( ps_slice_hdr -> i1_deblocking_filter_override_flag ) { BITS_PARSE ( "slice_disable_deblocking_filter_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_slice_disable_deblocking_filter_flag = value ; disable_deblocking_filter_flag = ps_slice_hdr -> i1_slice_disable_deblocking_filter_flag ; if ( ! ps_slice_hdr -> i1_slice_disable_deblocking_filter_flag ) { SEV_PARSE ( "beta_offset_div2" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_beta_offset_div2 = value ; SEV_PARSE ( "tc_offset_div2" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_tc_offset_div2 = value ; } } } ps_slice_hdr -> i1_slice_loop_filter_across_slices_enabled_flag = ps_pps -> i1_loop_filter_across_slices_enabled_flag ; if ( ps_pps -> i1_loop_filter_across_slices_enabled_flag && ( ps_slice_hdr -> i1_slice_sao_luma_flag || ps_slice_hdr -> i1_slice_sao_chroma_flag || ! disable_deblocking_filter_flag ) ) { BITS_PARSE ( "slice_loop_filter_across_slices_enabled_flag" , value , ps_bitstrm , 1 ) ; ps_slice_hdr -> i1_slice_loop_filter_across_slices_enabled_flag = value ; } } if ( ( ! first_slice_in_pic_flag ) && ( ps_codec -> i4_pic_present ) ) { slice_header_t * ps_slice_hdr_base = ps_codec -> ps_slice_hdr_base ; if ( ( ps_slice_hdr_base -> i1_pps_id != ps_slice_hdr -> i1_pps_id ) || ( ps_slice_hdr_base -> i4_pic_order_cnt_lsb != ps_slice_hdr -> i4_pic_order_cnt_lsb ) ) { return IHEVCD_IGNORE_SLICE ; } } if ( 0 == ps_codec -> i4_pic_present ) { ps_slice_hdr -> i4_abs_pic_order_cnt = ihevcd_calc_poc ( ps_codec , ps_nal , ps_sps -> i1_log2_max_pic_order_cnt_lsb , ps_slice_hdr -> i4_pic_order_cnt_lsb ) ; } else { ps_slice_hdr -> i4_abs_pic_order_cnt = ps_codec -> s_parse . i4_abs_pic_order_cnt ; } if ( ! first_slice_in_pic_flag ) { if ( ps_codec -> s_parse . i4_abs_pic_order_cnt == ps_slice_hdr -> i4_abs_pic_order_cnt ) { if ( slice_address > ps_codec -> s_parse . i4_next_ctb_indx ) { if ( ps_codec -> i4_pic_present ) { ps_codec -> i4_slice_error = 1 ; ps_codec -> s_parse . i4_cur_slice_idx -- ; if ( ps_codec -> s_parse . i4_cur_slice_idx < 0 ) ps_codec -> s_parse . i4_cur_slice_idx = 0 ; return ret ; } else { return IHEVCD_IGNORE_SLICE ; } } else if ( slice_address < ps_codec -> s_parse . i4_next_ctb_indx ) { return IHEVCD_IGNORE_SLICE ; } else { ps_codec -> i4_slice_error = 0 ; } } else { if ( ps_codec -> i4_pic_present ) { slice_header_t * ps_slice_hdr_next ; ps_codec -> i4_slice_error = 1 ; ps_codec -> s_parse . i4_cur_slice_idx -- ; if ( ps_codec -> s_parse . i4_cur_slice_idx < 0 ) ps_codec -> s_parse . i4_cur_slice_idx = 0 ; ps_slice_hdr_next = ps_codec -> s_parse . ps_slice_hdr_base + ( ( ps_codec -> s_parse . i4_cur_slice_idx + 1 ) & ( MAX_SLICE_HDR_CNT - 1 ) ) ; ps_slice_hdr_next -> i2_ctb_x = 0 ; ps_slice_hdr_next -> i2_ctb_y = ps_codec -> s_parse . ps_sps -> i2_pic_ht_in_ctb ; return ret ; } else { if ( ps_slice_hdr -> i1_dependent_slice_flag ) return IHEVCD_IGNORE_SLICE ; ps_codec -> s_parse . i4_abs_pic_order_cnt = ps_slice_hdr -> i4_abs_pic_order_cnt ; } } } else { if ( ps_codec -> s_parse . i4_abs_pic_order_cnt == ps_slice_hdr -> i4_abs_pic_order_cnt ) return IHEVCD_IGNORE_SLICE ; ps_codec -> s_parse . i4_abs_pic_order_cnt = ps_slice_hdr -> i4_abs_pic_order_cnt ; } ps_slice_hdr -> i4_num_entry_point_offsets = 0 ; if ( ( ps_pps -> i1_tiles_enabled_flag ) || ( ps_pps -> i1_entropy_coding_sync_enabled_flag ) ) { UEV_PARSE ( "num_entry_point_offsets" , value , ps_bitstrm ) ; ps_slice_hdr -> i4_num_entry_point_offsets = value ; { WORD32 max_num_entry_point_offsets ; if ( ( ps_pps -> i1_tiles_enabled_flag ) && ( ps_pps -> i1_entropy_coding_sync_enabled_flag ) ) { max_num_entry_point_offsets = ps_pps -> i1_num_tile_columns * ( ps_sps -> i2_pic_ht_in_ctb - 1 ) ; } else if ( ps_pps -> i1_tiles_enabled_flag ) { max_num_entry_point_offsets = ps_pps -> i1_num_tile_columns * ps_pps -> i1_num_tile_rows ; } else { max_num_entry_point_offsets = ( ps_sps -> i2_pic_ht_in_ctb - 1 ) ; } ps_slice_hdr -> i4_num_entry_point_offsets = CLIP3 ( ps_slice_hdr -> i4_num_entry_point_offsets , 0 , max_num_entry_point_offsets ) ; } if ( ps_slice_hdr -> i4_num_entry_point_offsets > 0 ) { UEV_PARSE ( "offset_len_minus1" , value , ps_bitstrm ) ; ps_slice_hdr -> i1_offset_len = value + 1 ; for ( i = 0 ; i < ps_slice_hdr -> i4_num_entry_point_offsets ; i ++ ) { BITS_PARSE ( "entry_point_offset" , value , ps_bitstrm , ps_slice_hdr -> i1_offset_len ) ; } } } if ( ps_pps -> i1_slice_header_extension_present_flag ) { UEV_PARSE ( "slice_header_extension_length" , value , ps_bitstrm ) ; ps_slice_hdr -> i2_slice_header_extension_length = value ; for ( i = 0 ; i < ps_slice_hdr -> i2_slice_header_extension_length ; i ++ ) { BITS_PARSE ( "slice_header_extension_data_byte" , value , ps_bitstrm , 8 ) ; } } ihevcd_bits_flush_to_byte_boundary ( ps_bitstrm ) ; { dpb_mgr_t * ps_dpb_mgr = ( dpb_mgr_t * ) ps_codec -> pv_dpb_mgr ; WORD32 r_idx ; if ( ( NAL_IDR_W_LP == ps_slice_hdr -> i1_nal_unit_type ) || ( NAL_IDR_N_LP == ps_slice_hdr -> i1_nal_unit_type ) || ( NAL_BLA_N_LP == ps_slice_hdr -> i1_nal_unit_type ) || ( NAL_BLA_W_DLP == ps_slice_hdr -> i1_nal_unit_type ) || ( NAL_BLA_W_LP == ps_slice_hdr -> i1_nal_unit_type ) || ( 0 == ps_codec -> u4_pic_cnt ) ) { for ( i = 0 ; i < MAX_DPB_BUFS ; i ++ ) { if ( ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf ) { pic_buf_t * ps_pic_buf = ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf ; mv_buf_t * ps_mv_buf ; ihevc_dpb_mgr_del_ref ( ( dpb_mgr_t * ) ps_codec -> pv_dpb_mgr , ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_pic_buf -> i4_abs_poc ) ; ps_mv_buf = ( mv_buf_t * ) ps_codec -> ps_mv_buf ; <S2SV_StartBug> for ( i = 0 ; i < BUF_MGR_MAX_CNT ; i ++ ) <S2SV_EndBug> { if ( ps_mv_buf && ps_mv_buf -> i4_abs_poc == ps_pic_buf -> i4_abs_poc ) { <S2SV_StartBug> ihevc_buf_mgr_release ( ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr , i , BUF_MGR_REF ) ; <S2SV_EndBug> break ; } ps_mv_buf ++ ; } } } for ( r_idx = 0 ; r_idx < MAX_DPB_SIZE ; r_idx ++ ) { ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf = NULL ; ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_mv_buf = NULL ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf = NULL ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_mv_buf = NULL ; } } else { ret = ihevcd_ref_list ( ps_codec , ps_pps , ps_sps , ps_slice_hdr ) ; if ( ( WORD32 ) IHEVCD_SUCCESS != ret ) { return ret ; } } } if ( ps_codec -> i4_pic_present ) { pic_buf_t * ps_pic_buf_ref ; mv_buf_t * ps_mv_buf_ref ; WORD32 r_idx ; dpb_mgr_t * ps_dpb_mgr = ( dpb_mgr_t * ) ps_codec -> pv_dpb_mgr ; buf_mgr_t * ps_mv_buf_mgr = ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr ; ps_pic_buf_ref = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ps_slice_hdr -> i4_abs_pic_order_cnt ) ; if ( NULL == ps_pic_buf_ref ) { ps_pic_buf_ref = ps_codec -> as_process [ 0 ] . ps_cur_pic ; ps_mv_buf_ref = ps_codec -> s_parse . ps_cur_mv_buf ; } else { ps_mv_buf_ref = ihevcd_mv_mgr_get_poc ( ps_mv_buf_mgr , ps_pic_buf_ref -> i4_abs_poc ) ; } for ( r_idx = 0 ; r_idx < ps_slice_hdr -> i1_num_ref_idx_l0_active ; r_idx ++ ) { if ( NULL == ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf ) { ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf = ( void * ) ps_pic_buf_ref ; ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_mv_buf = ( void * ) ps_mv_buf_ref ; } } for ( r_idx = ps_slice_hdr -> i1_num_ref_idx_l0_active ; r_idx < MAX_DPB_SIZE ; r_idx ++ ) { ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf = ( void * ) ps_pic_buf_ref ; ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_mv_buf = ( void * ) ps_mv_buf_ref ; } for ( r_idx = 0 ; r_idx < ps_slice_hdr -> i1_num_ref_idx_l1_active ; r_idx ++ ) { if ( NULL == ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf ) { ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf = ( void * ) ps_pic_buf_ref ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_mv_buf = ( void * ) ps_mv_buf_ref ; } } for ( r_idx = ps_slice_hdr -> i1_num_ref_idx_l1_active ; r_idx < MAX_DPB_SIZE ; r_idx ++ ) { ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf = ( void * ) ps_pic_buf_ref ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_mv_buf = ( void * ) ps_mv_buf_ref ; } } if ( ! ps_slice_hdr -> i1_first_slice_in_pic_flag ) { ps_slice_hdr -> i2_ctb_x = slice_address % ps_sps -> i2_pic_wd_in_ctb ; ps_slice_hdr -> i2_ctb_y = slice_address / ps_sps -> i2_pic_wd_in_ctb ; if ( ! ps_slice_hdr -> i1_dependent_slice_flag ) { ps_slice_hdr -> i2_independent_ctb_x = ps_slice_hdr -> i2_ctb_x ; ps_slice_hdr -> i2_independent_ctb_y = ps_slice_hdr -> i2_ctb_y ; } } else { ps_slice_hdr -> i2_ctb_x = 0 ; ps_slice_hdr -> i2_ctb_y = 0 ; ps_slice_hdr -> i2_independent_ctb_x = 0 ; ps_slice_hdr -> i2_independent_ctb_y = 0 ; } if ( ( ! first_slice_in_pic_flag ) && ( 0 == ps_codec -> i4_pic_present ) ) { slice_header_t * ps_slice_hdr_prev = ps_codec -> s_parse . ps_slice_hdr_base ; ihevcd_copy_slice_hdr ( ps_codec , 0 , ( ps_codec -> s_parse . i4_cur_slice_idx & ( MAX_SLICE_HDR_CNT - 1 ) ) ) ; ps_codec -> i4_slice_error = 1 ; ps_slice_hdr_prev -> i2_ctb_x = 0 ; ps_slice_hdr_prev -> i2_ctb_y = 0 ; ps_codec -> s_parse . i4_ctb_x = 0 ; ps_codec -> s_parse . i4_ctb_y = 0 ; ps_codec -> s_parse . i4_cur_slice_idx = 0 ; if ( ( ps_slice_hdr -> i2_ctb_x == 0 ) && ( ps_slice_hdr -> i2_ctb_y == 0 ) ) { ps_slice_hdr -> i2_ctb_x ++ ; } } { if ( ( i1_nal_unit_type < NAL_BLA_W_LP ) && ( i1_nal_unit_type % 2 == 0 ) ) { if ( IVD_SKIP_B == ps_codec -> e_pic_skip_mode ) return IHEVCD_IGNORE_SLICE ; } if ( ( IVD_SKIP_PB == ps_codec -> e_pic_skip_mode ) && ( ISLICE != ps_slice_hdr -> i1_slice_type ) ) { return IHEVCD_IGNORE_SLICE ; } } return ret ; }
CWE-000 WORD32 ihevcd_ref_list ( codec_t * ps_codec , pps_t * ps_pps , sps_t * ps_sps , slice_header_t * ps_slice_hdr ) { <S2SV_StartBug> WORD32 i ; <S2SV_EndBug> WORD32 st_rps_idx ; WORD32 num_neg_pics , num_pos_pics ; WORD8 * pi1_used ; WORD16 * pi2_delta_poc ; UWORD32 u4_max_poc_lsb ; pic_buf_t * ps_pic_buf ; mv_buf_t * ps_mv_buf ; UWORD32 r_idx ; dpb_mgr_t * ps_dpb_mgr = ( dpb_mgr_t * ) ps_codec -> pv_dpb_mgr ; buf_mgr_t * ps_mv_buf_mgr = ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr ; WORD32 ai4_poc_st_curr_before [ MAX_DPB_SIZE ] , ai4_poc_st_foll [ MAX_DPB_SIZE ] , ai4_poc_st_curr_after [ MAX_DPB_SIZE ] ; WORD32 ai4_poc_lt_curr [ MAX_DPB_SIZE ] , ai4_poc_lt_foll [ MAX_DPB_SIZE ] ; UWORD32 u4_num_st_curr_before , u4_num_st_foll , u4_num_st_curr_after , u4_num_lt_curr , u4_num_lt_foll ; UWORD32 u4_num_total_curr ; WORD8 ai1_curr_delta_poc_msb_present_flag [ MAX_DPB_SIZE ] , ai1_foll_delta_poc_msb_present_flag [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_lt_curr [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_lt_foll [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_st_curr_after [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_st_curr_before [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_st_foll [ MAX_DPB_SIZE ] ; pic_buf_t * as_ref_pic_list_temp0 [ MAX_DPB_SIZE ] , * as_ref_pic_list_temp1 [ MAX_DPB_SIZE ] ; UWORD32 u4_num_rps_curr_temp_list0 , u4_num_rps_curr_temp_list1 ; WORD32 i4_pic_order_cnt_val ; WORD32 i4_poc_lt ; UNUSED ( as_ref_pic_lt_foll ) ; UNUSED ( as_ref_pic_st_foll ) ; UNUSED ( ps_pps ) ; RETURN_IF_NAL_INFO ; u4_max_poc_lsb = ( 1 << ps_sps -> i1_log2_max_pic_order_cnt_lsb ) ; i4_pic_order_cnt_val = ps_slice_hdr -> i4_abs_pic_order_cnt ; if ( 1 == ps_slice_hdr -> i1_short_term_ref_pic_set_sps_flag ) { st_rps_idx = ps_slice_hdr -> i1_short_term_ref_pic_set_idx ; num_neg_pics = ps_sps -> as_stref_picset [ st_rps_idx ] . i1_num_neg_pics ; num_pos_pics = ps_sps -> as_stref_picset [ st_rps_idx ] . i1_num_pos_pics ; pi1_used = ps_sps -> as_stref_picset [ st_rps_idx ] . ai1_used ; pi2_delta_poc = ps_sps -> as_stref_picset [ st_rps_idx ] . ai2_delta_poc ; } else { st_rps_idx = ps_sps -> i1_num_short_term_ref_pic_sets ; num_neg_pics = ps_slice_hdr -> s_stref_picset . i1_num_neg_pics ; num_pos_pics = ps_slice_hdr -> s_stref_picset . i1_num_pos_pics ; pi1_used = ps_slice_hdr -> s_stref_picset . ai1_used ; pi2_delta_poc = ps_slice_hdr -> s_stref_picset . ai2_delta_poc ; } u4_num_st_curr_before = 0 ; u4_num_st_foll = 0 ; for ( i = 0 ; i < num_neg_pics ; i ++ ) { if ( pi1_used [ i ] ) { ai4_poc_st_curr_before [ u4_num_st_curr_before ] = i4_pic_order_cnt_val + pi2_delta_poc [ i ] ; u4_num_st_curr_before ++ ; } else { ai4_poc_st_foll [ u4_num_st_foll ] = i4_pic_order_cnt_val + pi2_delta_poc [ i ] ; u4_num_st_foll ++ ; } } u4_num_st_curr_after = 0 ; for ( i = num_neg_pics ; i < num_neg_pics + num_pos_pics ; i ++ ) { if ( pi1_used [ i ] ) { ai4_poc_st_curr_after [ u4_num_st_curr_after ] = i4_pic_order_cnt_val + pi2_delta_poc [ i ] ; u4_num_st_curr_after ++ ; } else { ai4_poc_st_foll [ u4_num_st_foll ] = i4_pic_order_cnt_val + pi2_delta_poc [ i ] ; u4_num_st_foll ++ ; } } u4_num_lt_curr = 0 ; u4_num_lt_foll = 0 ; for ( i = 0 ; i < ps_slice_hdr -> i1_num_long_term_sps + ps_slice_hdr -> i1_num_long_term_pics ; i ++ ) { i4_poc_lt = ps_slice_hdr -> ai4_poc_lsb_lt [ i ] ; if ( ps_slice_hdr -> ai1_delta_poc_msb_present_flag [ i ] ) { i4_poc_lt += i4_pic_order_cnt_val - ps_slice_hdr -> ai1_delta_poc_msb_cycle_lt [ i ] * u4_max_poc_lsb - ps_slice_hdr -> i4_pic_order_cnt_lsb ; } if ( ps_slice_hdr -> ai1_used_by_curr_pic_lt_flag [ i ] ) { ai4_poc_lt_curr [ u4_num_lt_curr ] = i4_poc_lt ; ai1_curr_delta_poc_msb_present_flag [ u4_num_lt_curr ] = ps_slice_hdr -> ai1_delta_poc_msb_present_flag [ i ] ; u4_num_lt_curr ++ ; } else { ai4_poc_lt_foll [ u4_num_lt_foll ] = i4_poc_lt ; ai1_foll_delta_poc_msb_present_flag [ u4_num_lt_foll ] = ps_slice_hdr -> ai1_delta_poc_msb_present_flag [ i ] ; u4_num_lt_foll ++ ; } } u4_num_total_curr = u4_num_lt_curr + u4_num_st_curr_after + u4_num_st_curr_before ; if ( 0 == ps_codec -> i4_pic_present ) { for ( i = 0 ; i < MAX_DPB_BUFS ; i ++ ) { if ( ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf ) ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf -> u1_used_as_ref = UNUSED_FOR_REF ; } } for ( i = 0 ; i < ( WORD32 ) u4_num_lt_curr ; i ++ ) { if ( 0 == ai1_curr_delta_poc_msb_present_flag [ i ] ) { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc_lsb ( ps_dpb_mgr , ai4_poc_lt_curr [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = LONG_TERM_REF ; as_ref_pic_lt_curr [ i ] = ps_pic_buf ; } else { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc ( ps_dpb_mgr , ai4_poc_lt_curr [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = LONG_TERM_REF ; as_ref_pic_lt_curr [ i ] = ps_pic_buf ; } } for ( i = 0 ; i < ( WORD32 ) u4_num_lt_foll ; i ++ ) { if ( 0 == ai1_foll_delta_poc_msb_present_flag [ i ] ) { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc_lsb ( ps_dpb_mgr , ai4_poc_lt_foll [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = LONG_TERM_REF ; as_ref_pic_lt_foll [ i ] = ps_pic_buf ; } else { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc ( ps_dpb_mgr , ai4_poc_lt_foll [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = LONG_TERM_REF ; as_ref_pic_lt_foll [ i ] = ps_pic_buf ; } } for ( i = 0 ; i < ( WORD32 ) u4_num_st_curr_before ; i ++ ) { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc ( ps_dpb_mgr , ai4_poc_st_curr_before [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = SHORT_TERM_REF ; as_ref_pic_st_curr_before [ i ] = ps_pic_buf ; } for ( i = 0 ; i < ( WORD32 ) u4_num_st_curr_after ; i ++ ) { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc ( ps_dpb_mgr , ai4_poc_st_curr_after [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = SHORT_TERM_REF ; as_ref_pic_st_curr_after [ i ] = ps_pic_buf ; } for ( i = 0 ; i < ( WORD32 ) u4_num_st_foll ; i ++ ) { ps_pic_buf = ihevc_dpb_mgr_get_ref_by_poc ( ps_dpb_mgr , ai4_poc_st_foll [ i ] ) ; if ( NULL != ps_pic_buf ) ps_pic_buf -> u1_used_as_ref = SHORT_TERM_REF ; as_ref_pic_st_foll [ i ] = ps_pic_buf ; } u4_num_rps_curr_temp_list0 = ( WORD32 ) u4_num_total_curr > ps_slice_hdr -> i1_num_ref_idx_l0_active ? ( WORD32 ) u4_num_total_curr : ps_slice_hdr -> i1_num_ref_idx_l0_active ; r_idx = 0 ; if ( ( PSLICE == ps_slice_hdr -> i1_slice_type ) || ( BSLICE == ps_slice_hdr -> i1_slice_type ) ) { while ( r_idx < u4_num_rps_curr_temp_list0 ) { for ( i = 0 ; ( i < ( WORD32 ) u4_num_st_curr_before ) && ( r_idx < u4_num_rps_curr_temp_list0 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_st_curr_before [ i ] ) { as_ref_pic_st_curr_before [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_st_curr_before [ i ] ) ; } as_ref_pic_list_temp0 [ r_idx ] = as_ref_pic_st_curr_before [ i ] ; } for ( i = 0 ; ( i < ( WORD32 ) u4_num_st_curr_after ) && ( r_idx < u4_num_rps_curr_temp_list0 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_st_curr_after [ i ] ) { as_ref_pic_st_curr_after [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_st_curr_after [ i ] ) ; } as_ref_pic_list_temp0 [ r_idx ] = as_ref_pic_st_curr_after [ i ] ; } for ( i = 0 ; ( i < ( WORD32 ) u4_num_lt_curr ) && ( r_idx < u4_num_rps_curr_temp_list0 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_lt_curr [ i ] ) { as_ref_pic_lt_curr [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_lt_curr [ i ] ) ; } as_ref_pic_list_temp0 [ r_idx ] = as_ref_pic_lt_curr [ i ] ; } } for ( r_idx = 0 ; ( WORD32 ) r_idx < ps_slice_hdr -> i1_num_ref_idx_l0_active ; r_idx ++ ) { pic_buf_t * ps_pic_buf ; ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf = ps_slice_hdr -> s_rplm . i1_ref_pic_list_modification_flag_l0 ? ( void * ) as_ref_pic_list_temp0 [ ps_slice_hdr -> s_rplm . i1_list_entry_l0 [ r_idx ] ] : ( void * ) as_ref_pic_list_temp0 [ r_idx ] ; ps_pic_buf = ( pic_buf_t * ) ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_pic_buf ; if ( ps_pic_buf == NULL ) return IHEVCD_REF_PIC_NOT_FOUND ; ps_mv_buf = ihevcd_mv_mgr_get_poc ( ps_mv_buf_mgr , ps_pic_buf -> i4_abs_poc ) ; ps_slice_hdr -> as_ref_pic_list0 [ r_idx ] . pv_mv_buf = ps_mv_buf ; } if ( ps_slice_hdr -> i1_slice_type == BSLICE ) { u4_num_rps_curr_temp_list1 = ( WORD32 ) u4_num_total_curr > ps_slice_hdr -> i1_num_ref_idx_l1_active ? ( WORD32 ) u4_num_total_curr : ps_slice_hdr -> i1_num_ref_idx_l1_active ; r_idx = 0 ; while ( r_idx < u4_num_rps_curr_temp_list1 ) { for ( i = 0 ; ( i < ( WORD32 ) u4_num_st_curr_after ) && ( r_idx < u4_num_rps_curr_temp_list1 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_st_curr_after [ i ] ) { as_ref_pic_st_curr_after [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_st_curr_after [ i ] ) ; } as_ref_pic_list_temp1 [ r_idx ] = as_ref_pic_st_curr_after [ i ] ; } for ( i = 0 ; ( i < ( WORD32 ) u4_num_st_curr_before ) && ( r_idx < u4_num_rps_curr_temp_list1 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_st_curr_before [ i ] ) { as_ref_pic_st_curr_before [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_st_curr_before [ i ] ) ; } as_ref_pic_list_temp1 [ r_idx ] = as_ref_pic_st_curr_before [ i ] ; } for ( i = 0 ; ( i < ( WORD32 ) u4_num_lt_curr ) && ( r_idx < u4_num_rps_curr_temp_list1 ) ; r_idx ++ , i ++ ) { if ( NULL == as_ref_pic_lt_curr [ i ] ) { as_ref_pic_lt_curr [ i ] = ihevc_dpb_mgr_get_ref_by_nearest_poc ( ps_dpb_mgr , ai4_poc_lt_curr [ i ] ) ; } as_ref_pic_list_temp1 [ r_idx ] = as_ref_pic_lt_curr [ i ] ; } } for ( r_idx = 0 ; ( WORD32 ) r_idx < ps_slice_hdr -> i1_num_ref_idx_l1_active ; r_idx ++ ) { pic_buf_t * ps_pic_buf ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf = ps_slice_hdr -> s_rplm . i1_ref_pic_list_modification_flag_l1 ? ( void * ) as_ref_pic_list_temp1 [ ps_slice_hdr -> s_rplm . i1_list_entry_l1 [ r_idx ] ] : ( void * ) as_ref_pic_list_temp1 [ r_idx ] ; ps_pic_buf = ( pic_buf_t * ) ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_pic_buf ; if ( ps_pic_buf == NULL ) return IHEVCD_REF_PIC_NOT_FOUND ; ps_mv_buf = ihevcd_mv_mgr_get_poc ( ps_mv_buf_mgr , ps_pic_buf -> i4_abs_poc ) ; ps_slice_hdr -> as_ref_pic_list1 [ r_idx ] . pv_mv_buf = ps_mv_buf ; } } } DEBUG_PRINT_REF_LIST_POCS ( i4_pic_order_cnt_val , ps_slice_hdr , ps_dpb_mgr , u4_num_st_curr_before , u4_num_st_curr_after , u4_num_st_foll , u4_num_lt_curr , u4_num_lt_foll , ai4_poc_st_curr_before , ai4_poc_st_curr_after , ai4_poc_st_foll , ai4_poc_lt_curr , ai4_poc_lt_foll ) ; for ( i = 0 ; i < MAX_DPB_BUFS ; i ++ ) { if ( ( ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf ) && ( UNUSED_FOR_REF == ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf -> u1_used_as_ref ) ) { pic_buf_t * ps_pic_buf = ps_dpb_mgr -> as_dpb_info [ i ] . ps_pic_buf ; mv_buf_t * ps_mv_buf ; ihevc_dpb_mgr_del_ref ( ps_dpb_mgr , ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_pic_buf -> i4_abs_poc ) ; ps_mv_buf = ( mv_buf_t * ) ps_codec -> ps_mv_buf ; <S2SV_StartBug> for ( i = 0 ; i < BUF_MGR_MAX_CNT ; i ++ ) <S2SV_EndBug> { if ( ps_mv_buf && ps_mv_buf -> i4_abs_poc == ps_pic_buf -> i4_abs_poc ) { <S2SV_StartBug> ihevc_buf_mgr_release ( ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr , i , BUF_MGR_REF ) ; <S2SV_EndBug> break ; } ps_mv_buf ++ ; } } } return IHEVCD_SUCCESS ; }
CWE-000 IHEVCD_ERROR_T ihevcd_mv_buf_mgr_add_bufs ( codec_t * ps_codec ) { IHEVCD_ERROR_T ret = ( IHEVCD_ERROR_T ) IHEVCD_SUCCESS ; WORD32 i ; WORD32 max_dpb_size ; WORD32 mv_bank_size_allocated ; WORD32 pic_mv_bank_size ; sps_t * ps_sps ; UWORD8 * pu1_buf ; mv_buf_t * ps_mv_buf ; ps_sps = ps_codec -> s_parse . ps_sps ; max_dpb_size = ps_sps -> ai1_sps_max_dec_pic_buffering [ ps_sps -> i1_sps_max_sub_layers - 1 ] ; max_dpb_size ++ ; <S2SV_StartBug> pu1_buf = ( UWORD8 * ) ps_codec -> pv_mv_bank_buf_base ; <S2SV_EndBug> ps_mv_buf = ( mv_buf_t * ) pu1_buf ; pu1_buf += max_dpb_size * sizeof ( mv_buf_t ) ; ps_codec -> ps_mv_buf = ps_mv_buf ; mv_bank_size_allocated = ps_codec -> i4_total_mv_bank_size - max_dpb_size * sizeof ( mv_buf_t ) ; pic_mv_bank_size = ihevcd_get_pic_mv_bank_size ( ALIGN64 ( ps_sps -> i2_pic_width_in_luma_samples ) * ALIGN64 ( ps_sps -> i2_pic_height_in_luma_samples ) ) ; for ( i = 0 ; i < max_dpb_size ; i ++ ) { WORD32 buf_ret ; WORD32 num_pu ; WORD32 num_ctb ; WORD32 pic_size ; pic_size = ALIGN64 ( ps_sps -> i2_pic_width_in_luma_samples ) * ALIGN64 ( ps_sps -> i2_pic_height_in_luma_samples ) ; num_pu = pic_size / ( MIN_PU_SIZE * MIN_PU_SIZE ) ; num_ctb = pic_size / ( MIN_CTB_SIZE * MIN_CTB_SIZE ) ; mv_bank_size_allocated -= pic_mv_bank_size ; if ( mv_bank_size_allocated < 0 ) { ps_codec -> s_parse . i4_error_code = IHEVCD_INSUFFICIENT_MEM_MVBANK ; return IHEVCD_INSUFFICIENT_MEM_MVBANK ; } ps_mv_buf -> pu4_pic_pu_idx = ( UWORD32 * ) pu1_buf ; pu1_buf += ( num_ctb + 1 ) * sizeof ( WORD32 ) ; ps_mv_buf -> pu1_pic_pu_map = pu1_buf ; pu1_buf += num_pu ; ps_mv_buf -> pu1_pic_slice_map = ( UWORD16 * ) pu1_buf ; pu1_buf += ALIGN4 ( num_ctb * sizeof ( UWORD16 ) ) ; ps_mv_buf -> ps_pic_pu = ( pu_t * ) pu1_buf ; pu1_buf += num_pu * sizeof ( pu_t ) ; buf_ret = ihevc_buf_mgr_add ( ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr , ps_mv_buf , i ) ; if ( 0 != buf_ret ) { ps_codec -> s_parse . i4_error_code = IHEVCD_BUF_MGR_ERROR ; return IHEVCD_BUF_MGR_ERROR ; } ps_mv_buf ++ ; } return ret ; }
CWE-000 WORD32 ihevcd_decode ( iv_obj_t * ps_codec_obj , void * pv_api_ip , void * pv_api_op ) { WORD32 ret = IV_SUCCESS ; codec_t * ps_codec = ( codec_t * ) ( ps_codec_obj -> pv_codec_handle ) ; ivd_video_decode_ip_t * ps_dec_ip ; ivd_video_decode_op_t * ps_dec_op ; WORD32 proc_idx = 0 ; WORD32 prev_proc_idx = 0 ; ps_codec -> i4_error_code = 0 ; ps_dec_ip = ( ivd_video_decode_ip_t * ) pv_api_ip ; ps_dec_op = ( ivd_video_decode_op_t * ) pv_api_op ; { UWORD32 u4_size = ps_dec_op -> u4_size ; memset ( ps_dec_op , 0 , sizeof ( ivd_video_decode_op_t ) ) ; ps_dec_op -> u4_size = u4_size ; } if ( ps_codec -> i4_init_done != 1 ) { ps_dec_op -> u4_error_code |= 1 << IVD_FATALERROR ; ps_dec_op -> u4_error_code |= IHEVCD_INIT_NOT_DONE ; return IV_FAIL ; } if ( ps_codec -> u4_pic_cnt >= NUM_FRAMES_LIMIT ) { ps_dec_op -> u4_error_code |= 1 << IVD_FATALERROR ; ps_dec_op -> u4_error_code |= IHEVCD_NUM_FRAMES_LIMIT_REACHED ; return IV_FAIL ; } if ( ps_codec -> i4_reset_flag ) { ps_codec -> i4_flush_mode = 1 ; } if ( 0 == ps_codec -> i4_flush_mode ) { if ( ps_dec_ip -> pv_stream_buffer == NULL ) { ps_dec_op -> u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM ; ps_dec_op -> u4_error_code |= IVD_DEC_FRM_BS_BUF_NULL ; return IV_FAIL ; } if ( ps_dec_ip -> u4_num_Bytes <= MIN_START_CODE_LEN ) { if ( ( WORD32 ) ps_dec_ip -> u4_num_Bytes > 0 ) ps_dec_op -> u4_num_bytes_consumed = ps_dec_ip -> u4_num_Bytes ; else ps_dec_op -> u4_num_bytes_consumed = 0 ; ps_dec_op -> u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM ; ps_dec_op -> u4_error_code |= IVD_DEC_NUMBYTES_INV ; return IV_FAIL ; } } # ifdef APPLY_CONCEALMENT { WORD32 num_mbs ; num_mbs = ( ps_codec -> i4_wd * ps_codec -> i4_ht + 255 ) >> 8 ; ps_codec -> mb_count = 0 ; memset ( ps_codec -> mb_map , 0 , ( ( num_mbs + 7 ) >> 3 ) ) ; } # endif if ( 0 == ps_codec -> i4_share_disp_buf && ps_codec -> i4_header_mode == 0 ) { UWORD32 i ; if ( ps_dec_ip -> s_out_buffer . u4_num_bufs == 0 ) { ps_dec_op -> u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM ; ps_dec_op -> u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS ; return IV_FAIL ; } for ( i = 0 ; i < ps_dec_ip -> s_out_buffer . u4_num_bufs ; i ++ ) { if ( ps_dec_ip -> s_out_buffer . pu1_bufs [ i ] == NULL ) { ps_dec_op -> u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM ; ps_dec_op -> u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL ; return IV_FAIL ; } if ( ps_dec_ip -> s_out_buffer . u4_min_out_buf_size [ i ] == 0 ) { ps_dec_op -> u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM ; ps_dec_op -> u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUF_SIZE ; return IV_FAIL ; } } } ps_codec -> ps_out_buffer = & ps_dec_ip -> s_out_buffer ; ps_codec -> u4_ts = ps_dec_ip -> u4_ts ; if ( ps_codec -> i4_flush_mode ) { ps_dec_op -> u4_pic_wd = ps_codec -> i4_disp_wd ; ps_dec_op -> u4_pic_ht = ps_codec -> i4_disp_ht ; ps_dec_op -> u4_new_seq = 0 ; ps_codec -> ps_disp_buf = ( pic_buf_t * ) ihevc_disp_mgr_get ( ( disp_mgr_t * ) ps_codec -> pv_disp_buf_mgr , & ps_codec -> i4_disp_buf_id ) ; if ( ( ps_codec -> ps_disp_buf ) && ( ( 0 == ps_codec -> i4_share_disp_buf ) || ( IV_YUV_420P == ps_codec -> e_chroma_fmt ) ) ) { process_ctxt_t * ps_proc = & ps_codec -> as_process [ prev_proc_idx ] ; if ( 0 == ps_proc -> i4_init_done ) { ihevcd_init_proc_ctxt ( ps_proc , 0 ) ; } ret = ihevcd_fmt_conv ( ps_codec , & ps_codec -> as_process [ prev_proc_idx ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 0 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 1 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 2 ] , 0 , ps_codec -> i4_disp_ht ) ; ihevc_buf_mgr_release ( ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_codec -> i4_disp_buf_id , BUF_MGR_DISP ) ; } ihevcd_fill_outargs ( ps_codec , ps_dec_ip , ps_dec_op ) ; if ( 1 == ps_dec_op -> u4_output_present ) { WORD32 xpos = ps_codec -> i4_disp_wd - 32 - LOGO_WD ; WORD32 ypos = ps_codec -> i4_disp_ht - 32 - LOGO_HT ; if ( ypos < 0 ) ypos = 0 ; if ( xpos < 0 ) xpos = 0 ; INSERT_LOGO ( ps_dec_ip -> s_out_buffer . pu1_bufs [ 0 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 1 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 2 ] , ps_codec -> i4_disp_strd , xpos , ypos , ps_codec -> e_chroma_fmt , ps_codec -> i4_disp_wd , ps_codec -> i4_disp_ht ) ; } if ( NULL == ps_codec -> ps_disp_buf ) { if ( ps_codec -> i4_reset_flag ) { ihevcd_init ( ps_codec ) ; } return ( IV_FAIL ) ; } return ( IV_SUCCESS ) ; } if ( ( 0 == ps_codec -> i4_header_mode ) && ( 1 == ps_codec -> i4_share_disp_buf ) ) { WORD32 buf_status ; buf_status = 1 ; if ( ps_codec -> pv_pic_buf_mgr ) buf_status = ihevc_buf_mgr_check_free ( ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr ) ; if ( 0 == buf_status ) { ps_dec_op -> u4_error_code = IVD_DEC_REF_BUF_NULL ; ps_dec_op -> u4_error_code |= ( 1 << IVD_UNSUPPORTEDPARAM ) ; return IV_FAIL ; } } ps_codec -> i4_bytes_remaining = ps_dec_ip -> u4_num_Bytes ; ps_codec -> pu1_inp_bitsbuf = ( UWORD8 * ) ps_dec_ip -> pv_stream_buffer ; ps_codec -> s_parse . i4_end_of_frame = 0 ; ps_codec -> i4_pic_present = 0 ; ps_codec -> i4_slice_error = 0 ; ps_codec -> ps_disp_buf = NULL ; if ( ps_codec -> i4_num_cores > 1 ) { ithread_set_affinity ( 0 ) ; } while ( MIN_START_CODE_LEN < ps_codec -> i4_bytes_remaining ) { WORD32 nal_len ; WORD32 nal_ofst ; WORD32 bits_len ; if ( ps_codec -> i4_slice_error ) { slice_header_t * ps_slice_hdr_next = ps_codec -> s_parse . ps_slice_hdr_base + ( ps_codec -> s_parse . i4_cur_slice_idx & ( MAX_SLICE_HDR_CNT - 1 ) ) ; WORD32 next_slice_addr = ps_slice_hdr_next -> i2_ctb_x + ps_slice_hdr_next -> i2_ctb_y * ps_codec -> s_parse . ps_sps -> i2_pic_wd_in_ctb ; if ( ps_codec -> s_parse . i4_next_ctb_indx == next_slice_addr ) ps_codec -> i4_slice_error = 0 ; } if ( ps_codec -> pu1_bitsbuf_dynamic ) { ps_codec -> pu1_bitsbuf = ps_codec -> pu1_bitsbuf_dynamic ; ps_codec -> u4_bitsbuf_size = ps_codec -> u4_bitsbuf_size_dynamic ; } else { ps_codec -> pu1_bitsbuf = ps_codec -> pu1_bitsbuf_static ; ps_codec -> u4_bitsbuf_size = ps_codec -> u4_bitsbuf_size_static ; } nal_ofst = ihevcd_nal_search_start_code ( ps_codec -> pu1_inp_bitsbuf , ps_codec -> i4_bytes_remaining ) ; ps_codec -> i4_nal_ofst = nal_ofst ; { WORD32 bytes_remaining = ps_codec -> i4_bytes_remaining - nal_ofst ; bytes_remaining = MIN ( ( UWORD32 ) bytes_remaining , ps_codec -> u4_bitsbuf_size ) ; ihevcd_nal_remv_emuln_bytes ( ps_codec -> pu1_inp_bitsbuf + nal_ofst , ps_codec -> pu1_bitsbuf , bytes_remaining , & nal_len , & bits_len ) ; if ( bits_len < ( WORD32 ) ( ps_codec -> u4_bitsbuf_size - 8 ) ) { memset ( ps_codec -> pu1_bitsbuf + bits_len , 0 , 2 * sizeof ( UWORD32 ) ) ; } } ps_codec -> i4_num_emln_bytes = nal_len - bits_len ; ps_codec -> i4_nal_len = nal_len ; ihevcd_bits_init ( & ps_codec -> s_parse . s_bitstrm , ps_codec -> pu1_bitsbuf , bits_len ) ; ret = ihevcd_nal_unit ( ps_codec ) ; if ( ps_codec -> i4_pic_present && ( ps_codec -> s_parse . i4_next_ctb_indx != ps_codec -> s_parse . ps_sps -> i4_pic_size_in_ctb ) ) { if ( ( ps_codec -> i4_bytes_remaining - ( nal_len + nal_ofst ) <= MIN_START_CODE_LEN ) || ( ps_codec -> i4_header_in_slice_mode ) ) { slice_header_t * ps_slice_hdr_next ; ps_codec -> s_parse . i4_cur_slice_idx -- ; if ( ps_codec -> s_parse . i4_cur_slice_idx < 0 ) ps_codec -> s_parse . i4_cur_slice_idx = 0 ; ps_slice_hdr_next = ps_codec -> s_parse . ps_slice_hdr_base + ( ( ps_codec -> s_parse . i4_cur_slice_idx + 1 ) & ( MAX_SLICE_HDR_CNT - 1 ) ) ; ps_slice_hdr_next -> i2_ctb_x = 0 ; ps_slice_hdr_next -> i2_ctb_y = ps_codec -> s_parse . ps_sps -> i2_pic_ht_in_ctb ; ps_codec -> i4_slice_error = 1 ; continue ; } } if ( IHEVCD_IGNORE_SLICE == ret ) { <S2SV_StartBug> ps_codec -> pu1_inp_bitsbuf += ( nal_ofst + nal_len ) ; <S2SV_EndBug> ps_codec -> i4_bytes_remaining -= ( nal_ofst + nal_len ) ; continue ; } if ( ( IVD_RES_CHANGED == ret ) || ( IHEVCD_UNSUPPORTED_DIMENSIONS == ret ) ) { break ; } if ( ret != IHEVCD_SLICE_IN_HEADER_MODE ) { if ( ( 0 == ps_codec -> i4_slice_error ) || ( ps_codec -> i4_bytes_remaining - ( nal_len + nal_ofst ) <= MIN_START_CODE_LEN ) ) { ps_codec -> pu1_inp_bitsbuf += ( nal_ofst + nal_len ) ; ps_codec -> i4_bytes_remaining -= ( nal_ofst + nal_len ) ; } if ( ret != IHEVCD_SUCCESS ) break ; if ( ps_codec -> s_parse . i4_end_of_frame ) break ; } else { ret = IHEVCD_SUCCESS ; break ; } if ( ( ps_codec -> u4_allocate_dynamic_done == 0 ) && ps_codec -> i4_sps_done ) { WORD32 ret ; ret = ihevcd_allocate_dynamic_bufs ( ps_codec ) ; if ( ret != IV_SUCCESS ) { ihevcd_free_dynamic_bufs ( ps_codec ) ; ps_codec -> i4_error_code = IVD_MEM_ALLOC_FAILED ; ps_dec_op -> u4_error_code |= 1 << IVD_FATALERROR ; ps_dec_op -> u4_error_code |= IVD_MEM_ALLOC_FAILED ; return IV_FAIL ; } } BREAK_AFTER_SLICE_NAL ( ) ; } if ( ( ps_codec -> u4_pic_cnt == 0 ) && ( ret != IHEVCD_SUCCESS ) ) { ps_codec -> i4_error_code = ret ; ihevcd_fill_outargs ( ps_codec , ps_dec_ip , ps_dec_op ) ; return IV_FAIL ; } if ( 1 == ps_codec -> i4_pic_present ) { WORD32 i ; sps_t * ps_sps = ps_codec -> s_parse . ps_sps ; ps_codec -> i4_first_pic_done = 1 ; if ( ps_codec -> i4_num_cores > 1 && ps_codec -> s_parse . i4_end_of_frame ) { process_ctxt_t * ps_proc ; ps_proc = & ps_codec -> as_process [ ps_codec -> i4_num_cores - 1 ] ; if ( ( ps_codec -> ps_disp_buf ) && ( ( 0 == ps_codec -> i4_share_disp_buf ) || ( IV_YUV_420P == ps_codec -> e_chroma_fmt ) ) ) { if ( ( 0 == ps_codec -> u4_enable_fmt_conv_ahead ) || ( ps_codec -> i4_disp_buf_id == ps_proc -> i4_cur_pic_buf_id ) ) for ( i = 0 ; i < ps_sps -> i2_pic_ht_in_ctb ; i ++ ) { proc_job_t s_job ; IHEVCD_ERROR_T ret ; s_job . i4_cmd = CMD_FMTCONV ; s_job . i2_ctb_cnt = 0 ; s_job . i2_ctb_x = 0 ; s_job . i2_ctb_y = i ; s_job . i2_slice_idx = 0 ; s_job . i4_tu_coeff_data_ofst = 0 ; ret = ihevcd_jobq_queue ( ( jobq_t * ) ps_codec -> s_parse . pv_proc_jobq , & s_job , sizeof ( proc_job_t ) , 1 ) ; if ( ret != ( IHEVCD_ERROR_T ) IHEVCD_SUCCESS ) return ( WORD32 ) ret ; } } ret = ihevcd_jobq_terminate ( ( jobq_t * ) ps_codec -> s_parse . pv_proc_jobq ) ; while ( 1 ) { IHEVCD_ERROR_T ret ; proc_job_t s_job ; process_ctxt_t * ps_proc ; ps_proc = & ps_codec -> as_process [ ps_codec -> i4_num_cores - 1 ] ; ret = ihevcd_jobq_dequeue ( ( jobq_t * ) ps_proc -> pv_proc_jobq , & s_job , sizeof ( proc_job_t ) , 1 ) ; if ( ( IHEVCD_ERROR_T ) IHEVCD_SUCCESS != ret ) break ; ps_proc -> i4_ctb_cnt = s_job . i2_ctb_cnt ; ps_proc -> i4_ctb_x = s_job . i2_ctb_x ; ps_proc -> i4_ctb_y = s_job . i2_ctb_y ; ps_proc -> i4_cur_slice_idx = s_job . i2_slice_idx ; if ( CMD_PROCESS == s_job . i4_cmd ) { ihevcd_init_proc_ctxt ( ps_proc , s_job . i4_tu_coeff_data_ofst ) ; ihevcd_process ( ps_proc ) ; } else if ( CMD_FMTCONV == s_job . i4_cmd ) { sps_t * ps_sps = ps_codec -> s_parse . ps_sps ; WORD32 num_rows = 1 << ps_sps -> i1_log2_ctb_size ; if ( 0 == ps_proc -> i4_init_done ) { ihevcd_init_proc_ctxt ( ps_proc , 0 ) ; } num_rows = MIN ( num_rows , ( ps_codec -> i4_disp_ht - ( s_job . i2_ctb_y << ps_sps -> i1_log2_ctb_size ) ) ) ; if ( num_rows < 0 ) num_rows = 0 ; ihevcd_fmt_conv ( ps_codec , ps_proc , ps_dec_ip -> s_out_buffer . pu1_bufs [ 0 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 1 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 2 ] , s_job . i2_ctb_y << ps_sps -> i1_log2_ctb_size , num_rows ) ; } } } else if ( ( ps_codec -> ps_disp_buf ) && ( ( 0 == ps_codec -> i4_share_disp_buf ) || ( IV_YUV_420P == ps_codec -> e_chroma_fmt ) ) && ( ps_codec -> s_parse . i4_end_of_frame ) ) { process_ctxt_t * ps_proc = & ps_codec -> as_process [ proc_idx ] ; ps_codec -> s_fmt_conv . i4_num_rows = ps_codec -> i4_disp_ht - ps_codec -> s_fmt_conv . i4_cur_row ; if ( 0 == ps_proc -> i4_init_done ) { ihevcd_init_proc_ctxt ( ps_proc , 0 ) ; } if ( ps_codec -> s_fmt_conv . i4_num_rows < 0 ) ps_codec -> s_fmt_conv . i4_num_rows = 0 ; ret = ihevcd_fmt_conv ( ps_codec , ps_proc , ps_dec_ip -> s_out_buffer . pu1_bufs [ 0 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 1 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 2 ] , ps_codec -> s_fmt_conv . i4_cur_row , ps_codec -> s_fmt_conv . i4_num_rows ) ; ps_codec -> s_fmt_conv . i4_cur_row += ps_codec -> s_fmt_conv . i4_num_rows ; } DEBUG_DUMP_MV_MAP ( ps_codec ) ; ihevc_buf_mgr_set_status ( ( buf_mgr_t * ) ps_codec -> pv_mv_buf_mgr , ps_codec -> as_process [ proc_idx ] . i4_cur_mv_bank_buf_id , BUF_MGR_REF ) ; ihevc_buf_mgr_set_status ( ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_codec -> as_process [ proc_idx ] . i4_cur_pic_buf_id , BUF_MGR_REF ) ; ihevc_buf_mgr_set_status ( ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_codec -> as_process [ proc_idx ] . i4_cur_pic_buf_id , BUF_MGR_DISP ) ; ihevc_dpb_mgr_insert_ref ( ( dpb_mgr_t * ) ps_codec -> pv_dpb_mgr , ps_codec -> as_process [ proc_idx ] . ps_cur_pic , ps_codec -> as_process [ proc_idx ] . i4_cur_pic_buf_id ) ; if ( ( 0 == ps_codec -> i4_share_disp_buf ) && ( ps_codec -> ps_disp_buf ) ) ihevc_buf_mgr_release ( ( buf_mgr_t * ) ps_codec -> pv_pic_buf_mgr , ps_codec -> i4_disp_buf_id , BUF_MGR_DISP ) ; for ( i = 0 ; i < ( ps_codec -> i4_num_cores - 1 ) ; i ++ ) { if ( ps_codec -> ai4_process_thread_created [ i ] ) { ithread_join ( ps_codec -> apv_process_thread_handle [ i ] , NULL ) ; ps_codec -> ai4_process_thread_created [ i ] = 0 ; } } DEBUG_VALIDATE_PADDED_REGION ( & ps_codec -> as_process [ proc_idx ] ) ; if ( ps_codec -> u4_pic_cnt > 0 ) { DEBUG_DUMP_PIC_PU ( ps_codec ) ; } DEBUG_DUMP_PIC_BUFFERS ( ps_codec ) ; ps_codec -> u4_pic_cnt ++ ; } ihevcd_fill_outargs ( ps_codec , ps_dec_ip , ps_dec_op ) ; if ( 1 == ps_dec_op -> u4_output_present ) { WORD32 xpos = ps_codec -> i4_disp_wd - 32 - LOGO_WD ; WORD32 ypos = ps_codec -> i4_disp_ht - 32 - LOGO_HT ; if ( ypos < 0 ) ypos = 0 ; if ( xpos < 0 ) xpos = 0 ; INSERT_LOGO ( ps_dec_ip -> s_out_buffer . pu1_bufs [ 0 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 1 ] , ps_dec_ip -> s_out_buffer . pu1_bufs [ 2 ] , ps_codec -> i4_disp_strd , xpos , ypos , ps_codec -> e_chroma_fmt , ps_codec -> i4_disp_wd , ps_codec -> i4_disp_ht ) ; } return ret ; }
CWE-000 static void setup_token_decoder ( VP8D_COMP * pbi , const unsigned char * token_part_sizes ) { vp8_reader * bool_decoder = & pbi -> mbc [ 0 ] ; unsigned int partition_idx ; unsigned int fragment_idx ; unsigned int num_token_partitions ; const unsigned char * first_fragment_end = pbi -> fragments . ptrs [ 0 ] + pbi -> fragments . sizes [ 0 ] ; TOKEN_PARTITION multi_token_partition = ( TOKEN_PARTITION ) vp8_read_literal ( & pbi -> mbc [ 8 ] , 2 ) ; if ( ! vp8dx_bool_error ( & pbi -> mbc [ 8 ] ) ) pbi -> common . multi_token_partition = multi_token_partition ; num_token_partitions = 1 << pbi -> common . multi_token_partition ; for ( fragment_idx = 0 ; fragment_idx < pbi -> fragments . count ; ++ fragment_idx ) { unsigned int fragment_size = pbi -> fragments . sizes [ fragment_idx ] ; const unsigned char * fragment_end = pbi -> fragments . ptrs [ fragment_idx ] + fragment_size ; if ( fragment_idx == 0 ) { ptrdiff_t ext_first_part_size = token_part_sizes - pbi -> fragments . ptrs [ 0 ] + 3 * ( num_token_partitions - 1 ) ; fragment_size -= ( unsigned int ) ext_first_part_size ; if ( fragment_size > 0 ) { pbi -> fragments . sizes [ 0 ] = ( unsigned int ) ext_first_part_size ; fragment_idx ++ ; pbi -> fragments . ptrs [ fragment_idx ] = pbi -> fragments . ptrs [ 0 ] + pbi -> fragments . sizes [ 0 ] ; } } while ( fragment_size > 0 ) { ptrdiff_t partition_size = read_available_partition_size ( pbi , token_part_sizes , pbi -> fragments . ptrs [ fragment_idx ] , first_fragment_end , fragment_end , fragment_idx - 1 , num_token_partitions ) ; pbi -> fragments . sizes [ fragment_idx ] = ( unsigned int ) partition_size ; fragment_size -= ( unsigned int ) partition_size ; assert ( fragment_idx <= num_token_partitions ) ; if ( fragment_size > 0 ) { fragment_idx ++ ; pbi -> fragments . ptrs [ fragment_idx ] = pbi -> fragments . ptrs [ fragment_idx - 1 ] + partition_size ; } } } pbi -> fragments . count = num_token_partitions + 1 ; for ( partition_idx = 1 ; partition_idx < pbi -> fragments . count ; ++ partition_idx ) { if ( vp8dx_start_decode ( bool_decoder , pbi -> fragments . ptrs [ partition_idx ] , pbi -> fragments . sizes [ partition_idx ] , pbi -> decrypt_cb , pbi -> decrypt_state ) ) vpx_internal_error ( & pbi -> common . error , VPX_CODEC_MEM_ERROR , "Failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>bool<S2SV_blank>decoder<S2SV_blank>%d" , partition_idx ) ; bool_decoder ++ ; } # if CONFIG_MULTITHREAD <S2SV_StartBug> if ( pbi -> decoding_thread_count > num_token_partitions - 1 ) <S2SV_EndBug> <S2SV_StartBug> pbi -> decoding_thread_count = num_token_partitions - 1 ; <S2SV_EndBug> # endif }
CWE-000 int vp8_remove_decoder_instances ( struct frame_buffers * fb ) { if ( ! fb -> use_frame_threads ) { VP8D_COMP * pbi = fb -> pbi [ 0 ] ; if ( ! pbi ) return VPX_CODEC_ERROR ; # if CONFIG_MULTITHREAD <S2SV_StartBug> if ( pbi -> b_multithreaded_rd ) <S2SV_EndBug> vp8mt_de_alloc_temp_buffers ( pbi , pbi -> common . mb_rows ) ; vp8_decoder_remove_threads ( pbi ) ; # endif remove_decompressor ( pbi ) ; } else { } return VPX_CODEC_OK ; }
CWE-000 void vp8_decoder_remove_threads ( VP8D_COMP * pbi ) { if ( pbi -> b_multithreaded_rd ) { int i ; pbi -> b_multithreaded_rd = 0 ; <S2SV_StartBug> for ( i = 0 ; i < pbi -> allocated_decoding_thread_count ; i ++ ) <S2SV_EndBug> { sem_post ( & pbi -> h_event_start_decoding [ i ] ) ; pthread_join ( pbi -> h_decoding_thread [ i ] , NULL ) ; } <S2SV_StartBug> for ( i = 0 ; i < pbi -> allocated_decoding_thread_count ; i ++ ) <S2SV_EndBug> { sem_destroy ( & pbi -> h_event_start_decoding [ i ] ) ; } sem_destroy ( & pbi -> h_event_end_decoding ) ; vpx_free ( pbi -> h_decoding_thread ) ; pbi -> h_decoding_thread = NULL ; vpx_free ( pbi -> h_event_start_decoding ) ; pbi -> h_event_start_decoding = NULL ; vpx_free ( pbi -> mb_row_di ) ; pbi -> mb_row_di = NULL ; vpx_free ( pbi -> de_thread_data ) ; pbi -> de_thread_data = NULL ; <S2SV_StartBug> } <S2SV_EndBug> }
CWE-000 void vp8mt_de_alloc_temp_buffers ( VP8D_COMP * pbi , int mb_rows ) { int i ; <S2SV_StartBug> if ( pbi -> b_multithreaded_rd ) <S2SV_EndBug> { vpx_free ( pbi -> mt_current_mb_col ) ; pbi -> mt_current_mb_col = NULL ; if ( pbi -> mt_yabove_row ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_yabove_row [ i ] ) ; pbi -> mt_yabove_row [ i ] = NULL ; } vpx_free ( pbi -> mt_yabove_row ) ; pbi -> mt_yabove_row = NULL ; } if ( pbi -> mt_uabove_row ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_uabove_row [ i ] ) ; pbi -> mt_uabove_row [ i ] = NULL ; } vpx_free ( pbi -> mt_uabove_row ) ; pbi -> mt_uabove_row = NULL ; } if ( pbi -> mt_vabove_row ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_vabove_row [ i ] ) ; pbi -> mt_vabove_row [ i ] = NULL ; } vpx_free ( pbi -> mt_vabove_row ) ; pbi -> mt_vabove_row = NULL ; } if ( pbi -> mt_yleft_col ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_yleft_col [ i ] ) ; pbi -> mt_yleft_col [ i ] = NULL ; } vpx_free ( pbi -> mt_yleft_col ) ; pbi -> mt_yleft_col = NULL ; } if ( pbi -> mt_uleft_col ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_uleft_col [ i ] ) ; pbi -> mt_uleft_col [ i ] = NULL ; } vpx_free ( pbi -> mt_uleft_col ) ; pbi -> mt_uleft_col = NULL ; } if ( pbi -> mt_vleft_col ) <S2SV_StartBug> { <S2SV_EndBug> for ( i = 0 ; i < mb_rows ; i ++ ) { vpx_free ( pbi -> mt_vleft_col [ i ] ) ; pbi -> mt_vleft_col [ i ] = NULL ; } vpx_free ( pbi -> mt_vleft_col ) ; pbi -> mt_vleft_col = NULL ; } } <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 <S2SV_StartBug> void close_connection ( h2o_http2_conn_t * conn ) <S2SV_EndBug> { conn -> state = H2O_HTTP2_CONN_STATE_IS_CLOSING ; if ( conn -> _write . buf_in_flight != NULL || h2o_timeout_is_linked ( & conn -> _write . timeout_entry ) ) { } else { close_connection_now ( conn ) ; <S2SV_StartBug> } <S2SV_EndBug> }
CWE-000 static void on_read ( h2o_socket_t * sock , int status ) { h2o_http2_conn_t * conn = sock -> data ; if ( status != 0 ) { h2o_socket_read_stop ( conn -> sock ) ; close_connection ( conn ) ; return ; } update_idle_timeout ( conn ) ; <S2SV_StartBug> parse_input ( conn ) ; <S2SV_EndBug> if ( h2o_timeout_is_linked ( & conn -> _write . timeout_entry ) ) { h2o_timeout_unlink ( & conn -> _write . timeout_entry ) ; do_emit_writereq ( conn ) ; } }
CWE-000 <S2SV_StartBug> static void parse_input ( h2o_http2_conn_t * conn ) <S2SV_EndBug> { size_t http2_max_concurrent_requests_per_connection = conn -> super . ctx -> globalconf -> http2 . max_concurrent_requests_per_connection ; int perform_early_exit = 0 ; if ( conn -> num_streams . pull . half_closed + conn -> num_streams . push . half_closed != http2_max_concurrent_requests_per_connection ) perform_early_exit = 1 ; while ( conn -> state < H2O_HTTP2_CONN_STATE_IS_CLOSING && conn -> sock -> input -> size != 0 ) { if ( perform_early_exit == 1 && conn -> num_streams . pull . half_closed + conn -> num_streams . push . half_closed == http2_max_concurrent_requests_per_connection ) goto EarlyExit ; const char * err_desc = NULL ; ssize_t ret = conn -> _read_expect ( conn , ( uint8_t * ) conn -> sock -> input -> bytes , conn -> sock -> input -> size , & err_desc ) ; if ( ret == H2O_HTTP2_ERROR_INCOMPLETE ) { break ; } else if ( ret < 0 ) { if ( ret != H2O_HTTP2_ERROR_PROTOCOL_CLOSE_IMMEDIATELY ) { enqueue_goaway ( conn , ( int ) ret , err_desc != NULL ? ( h2o_iovec_t ) { ( char * ) err_desc , strlen ( err_desc ) } : ( h2o_iovec_t ) { } ) ; } <S2SV_StartBug> close_connection ( conn ) ; <S2SV_EndBug> return ; } h2o_buffer_consume ( & conn -> sock -> input , ret ) ; } if ( ! h2o_socket_is_reading ( conn -> sock ) ) h2o_socket_read_start ( conn -> sock , on_read ) ; <S2SV_StartBug> return ; <S2SV_EndBug> EarlyExit : if ( h2o_socket_is_reading ( conn -> sock ) ) h2o_socket_read_stop ( conn -> sock ) ; <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 static int devzvol_readdir ( struct vnode * dvp , struct uio * uiop , struct cred * cred , int * eofp , caller_context_t * ct_unused , int flags_unused ) { struct sdev_node * sdvp = VTOSDEV ( dvp ) ; char * ptr ; sdcmn_err13 ( ( "zv<S2SV_blank>readdir<S2SV_blank>of<S2SV_blank>\'%s\'<S2SV_blank>%s\'" , sdvp -> sdev_path , sdvp -> sdev_name ) ) ; if ( strcmp ( sdvp -> sdev_path , ZVOL_DIR ) == 0 ) { struct vnode * vp ; rw_exit ( & sdvp -> sdev_contents ) ; ( void ) devname_lookup_func ( sdvp , "dsk" , & vp , cred , devzvol_create_dir , SDEV_VATTR ) ; VN_RELE ( vp ) ; ( void ) devname_lookup_func ( sdvp , "rdsk" , & vp , cred , devzvol_create_dir , SDEV_VATTR ) ; VN_RELE ( vp ) ; rw_enter ( & sdvp -> sdev_contents , RW_READER ) ; return ( devname_readdir_func ( dvp , uiop , cred , eofp , 0 ) ) ; } if ( uiop -> uio_offset == 0 ) devzvol_prunedir ( sdvp ) ; ptr = sdvp -> sdev_path + strlen ( ZVOL_DIR ) ; if ( ( strcmp ( ptr , "/dsk" ) == 0 ) || ( strcmp ( ptr , "/rdsk" ) == 0 ) ) { rw_exit ( & sdvp -> sdev_contents ) ; devzvol_create_pool_dirs ( dvp ) ; rw_enter ( & sdvp -> sdev_contents , RW_READER ) ; return ( devname_readdir_func ( dvp , uiop , cred , eofp , 0 ) ) ; } <S2SV_StartBug> ptr = strchr ( ptr + 1 , '/' ) + 1 ; <S2SV_EndBug> rw_exit ( & sdvp -> sdev_contents ) ; sdev_iter_datasets ( dvp , ZFS_IOC_DATASET_LIST_NEXT , ptr ) ; rw_enter ( & sdvp -> sdev_contents , RW_READER ) ; return ( devname_readdir_func ( dvp , uiop , cred , eofp , 0 ) ) ; }
CWE-000 static void dispatch_cmd ( conn c ) { int r , i , timeout = - 1 ; size_t z ; unsigned int count ; job j ; unsigned char type ; char * size_buf , * delay_buf , * ttr_buf , * pri_buf , * end_buf , * name ; unsigned int pri , body_size ; usec delay , ttr ; uint64_t id ; tube t = NULL ; c -> cmd [ c -> cmd_len - 2 ] = '\\0' ; if ( strlen ( c -> cmd ) != c -> cmd_len - 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } type = which_cmd ( c ) ; dprintf ( "got<S2SV_blank>%s<S2SV_blank>command:<S2SV_blank>\\"%s\\"\\n" , op_names [ ( int ) type ] , c -> cmd ) ; switch ( type ) { case OP_PUT : r = read_pri ( & pri , c -> cmd + 4 , & delay_buf ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_delay ( & delay , delay_buf , & ttr_buf ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_ttr ( & ttr , ttr_buf , & size_buf ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; errno = 0 ; body_size = strtoul ( size_buf , & end_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; if ( body_size > job_data_size_limit ) { <S2SV_StartBug> return reply_msg ( c , MSG_JOB_TOO_BIG ) ; <S2SV_EndBug> } if ( end_buf [ 0 ] != '\\0' ) return reply_msg ( c , MSG_BAD_FORMAT ) ; conn_set_producer ( c ) ; c -> in_job = make_job ( pri , delay , ttr ? : 1 , body_size + 2 , c -> use ) ; if ( ! c -> in_job ) { twarnx ( "server<S2SV_blank>error:<S2SV_blank>" MSG_OUT_OF_MEMORY ) ; return skip ( c , body_size + 2 , MSG_OUT_OF_MEMORY ) ; } fill_extra_data ( c ) ; maybe_enqueue_incoming_job ( c ) ; break ; case OP_PEEK_READY : if ( c -> cmd_len != CMD_PEEK_READY_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; j = job_copy ( pq_peek ( & c -> use -> ready ) ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; reply_job ( c , j , MSG_FOUND ) ; break ; case OP_PEEK_DELAYED : if ( c -> cmd_len != CMD_PEEK_DELAYED_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; j = job_copy ( pq_peek ( & c -> use -> delay ) ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; reply_job ( c , j , MSG_FOUND ) ; break ; case OP_PEEK_BURIED : if ( c -> cmd_len != CMD_PEEK_BURIED_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; j = job_copy ( buried_job_p ( c -> use ) ? j = c -> use -> buried . next : NULL ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; reply_job ( c , j , MSG_FOUND ) ; break ; case OP_PEEKJOB : errno = 0 ; id = strtoull ( c -> cmd + CMD_PEEKJOB_LEN , & end_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = job_copy ( peek_job ( id ) ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; reply_job ( c , j , MSG_FOUND ) ; break ; case OP_RESERVE_TIMEOUT : errno = 0 ; timeout = strtol ( c -> cmd + CMD_RESERVE_TIMEOUT_LEN , & end_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; case OP_RESERVE : if ( type == OP_RESERVE && c -> cmd_len != CMD_RESERVE_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; conn_set_worker ( c ) ; if ( conn_has_close_deadline ( c ) && ! conn_ready ( c ) ) { return reply_msg ( c , MSG_DEADLINE_SOON ) ; } wait_for_job ( c , timeout ) ; process_queue ( ) ; break ; case OP_DELETE : errno = 0 ; id = strtoull ( c -> cmd + CMD_DELETE_LEN , & end_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = job_find ( id ) ; j = remove_reserved_job ( c , j ) ? : remove_ready_job ( j ) ? : remove_buried_job ( j ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; j -> state = JOB_STATE_INVALID ; r = binlog_write_job ( j ) ; job_free ( j ) ; if ( ! r ) return reply_serr ( c , MSG_INTERNAL_ERROR ) ; reply ( c , MSG_DELETED , MSG_DELETED_LEN , STATE_SENDWORD ) ; break ; case OP_RELEASE : errno = 0 ; id = strtoull ( c -> cmd + CMD_RELEASE_LEN , & pri_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_pri ( & pri , pri_buf , & delay_buf ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_delay ( & delay , delay_buf , NULL ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = remove_reserved_job ( c , job_find ( id ) ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; if ( delay ) { z = binlog_reserve_space_update ( j ) ; if ( ! z ) return reply_serr ( c , MSG_OUT_OF_MEMORY ) ; j -> reserved_binlog_space += z ; } j -> pri = pri ; j -> delay = delay ; j -> release_ct ++ ; r = enqueue_job ( j , delay , ! ! delay ) ; if ( r < 0 ) return reply_serr ( c , MSG_INTERNAL_ERROR ) ; if ( r == 1 ) { return reply ( c , MSG_RELEASED , MSG_RELEASED_LEN , STATE_SENDWORD ) ; } bury_job ( j , 0 ) ; reply ( c , MSG_BURIED , MSG_BURIED_LEN , STATE_SENDWORD ) ; break ; case OP_BURY : errno = 0 ; id = strtoull ( c -> cmd + CMD_BURY_LEN , & pri_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_pri ( & pri , pri_buf , NULL ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = remove_reserved_job ( c , job_find ( id ) ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; j -> pri = pri ; r = bury_job ( j , 1 ) ; if ( ! r ) return reply_serr ( c , MSG_INTERNAL_ERROR ) ; reply ( c , MSG_BURIED , MSG_BURIED_LEN , STATE_SENDWORD ) ; break ; case OP_KICK : errno = 0 ; count = strtoul ( c -> cmd + CMD_KICK_LEN , & end_buf , 10 ) ; if ( end_buf == c -> cmd + CMD_KICK_LEN ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; i = kick_jobs ( c -> use , count ) ; return reply_line ( c , STATE_SENDWORD , "KICKED<S2SV_blank>%u\\r\\n" , i ) ; case OP_TOUCH : errno = 0 ; id = strtoull ( c -> cmd + CMD_TOUCH_LEN , & end_buf , 10 ) ; if ( errno ) return twarn ( "strtoull" ) , reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = touch_job ( c , job_find ( id ) ) ; if ( j ) { reply ( c , MSG_TOUCHED , MSG_TOUCHED_LEN , STATE_SENDWORD ) ; } else { return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; } break ; case OP_STATS : if ( c -> cmd_len != CMD_STATS_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; do_stats ( c , fmt_stats , NULL ) ; break ; case OP_JOBSTATS : errno = 0 ; id = strtoull ( c -> cmd + CMD_JOBSTATS_LEN , & end_buf , 10 ) ; if ( errno ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; j = peek_job ( id ) ; if ( ! j ) return reply ( c , MSG_NOTFOUND , MSG_NOTFOUND_LEN , STATE_SENDWORD ) ; if ( ! j -> tube ) return reply_serr ( c , MSG_INTERNAL_ERROR ) ; do_stats ( c , ( fmt_fn ) fmt_job_stats , j ) ; break ; case OP_STATS_TUBE : name = c -> cmd + CMD_STATS_TUBE_LEN ; if ( ! name_is_ok ( name , 200 ) ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; t = tube_find ( name ) ; if ( ! t ) return reply_msg ( c , MSG_NOTFOUND ) ; do_stats ( c , ( fmt_fn ) fmt_stats_tube , t ) ; t = NULL ; break ; case OP_LIST_TUBES : if ( c -> cmd_len != CMD_LIST_TUBES_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; do_list_tubes ( c , & tubes ) ; break ; case OP_LIST_TUBE_USED : if ( c -> cmd_len != CMD_LIST_TUBE_USED_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; reply_line ( c , STATE_SENDWORD , "USING<S2SV_blank>%s\\r\\n" , c -> use -> name ) ; break ; case OP_LIST_TUBES_WATCHED : if ( c -> cmd_len != CMD_LIST_TUBES_WATCHED_LEN + 2 ) { return reply_msg ( c , MSG_BAD_FORMAT ) ; } op_ct [ type ] ++ ; do_list_tubes ( c , & c -> watch ) ; break ; case OP_USE : name = c -> cmd + CMD_USE_LEN ; if ( ! name_is_ok ( name , 200 ) ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; TUBE_ASSIGN ( t , tube_find_or_make ( name ) ) ; if ( ! t ) return reply_serr ( c , MSG_OUT_OF_MEMORY ) ; c -> use -> using_ct -- ; TUBE_ASSIGN ( c -> use , t ) ; TUBE_ASSIGN ( t , NULL ) ; c -> use -> using_ct ++ ; reply_line ( c , STATE_SENDWORD , "USING<S2SV_blank>%s\\r\\n" , c -> use -> name ) ; break ; case OP_WATCH : name = c -> cmd + CMD_WATCH_LEN ; if ( ! name_is_ok ( name , 200 ) ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; TUBE_ASSIGN ( t , tube_find_or_make ( name ) ) ; if ( ! t ) return reply_serr ( c , MSG_OUT_OF_MEMORY ) ; r = 1 ; if ( ! ms_contains ( & c -> watch , t ) ) r = ms_append ( & c -> watch , t ) ; TUBE_ASSIGN ( t , NULL ) ; if ( ! r ) return reply_serr ( c , MSG_OUT_OF_MEMORY ) ; reply_line ( c , STATE_SENDWORD , "WATCHING<S2SV_blank>%d\\r\\n" , c -> watch . used ) ; break ; case OP_IGNORE : name = c -> cmd + CMD_IGNORE_LEN ; if ( ! name_is_ok ( name , 200 ) ) return reply_msg ( c , MSG_BAD_FORMAT ) ; op_ct [ type ] ++ ; t = NULL ; for ( i = 0 ; i < c -> watch . used ; i ++ ) { t = c -> watch . items [ i ] ; if ( strncmp ( t -> name , name , MAX_TUBE_NAME_LEN ) == 0 ) break ; t = NULL ; } if ( t && c -> watch . used < 2 ) return reply_msg ( c , MSG_NOT_IGNORED ) ; if ( t ) ms_remove ( & c -> watch , t ) ; t = NULL ; reply_line ( c , STATE_SENDWORD , "WATCHING<S2SV_blank>%d\\r\\n" , c -> watch . used ) ; break ; case OP_QUIT : conn_close ( c ) ; break ; case OP_PAUSE_TUBE : op_ct [ type ] ++ ; r = read_tube_name ( & name , c -> cmd + CMD_PAUSE_TUBE_LEN , & delay_buf ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; r = read_delay ( & delay , delay_buf , NULL ) ; if ( r ) return reply_msg ( c , MSG_BAD_FORMAT ) ; * delay_buf = '\\0' ; t = tube_find ( name ) ; if ( ! t ) return reply_msg ( c , MSG_NOTFOUND ) ; t -> deadline_at = now_usec ( ) + delay ; t -> pause = delay ; t -> stat . pause_ct ++ ; set_main_delay_timeout ( ) ; reply_line ( c , STATE_SENDWORD , "PAUSED\\r\\n" ) ; break ; default : return reply_msg ( c , MSG_UNKNOWN_COMMAND ) ; } }
CWE-000 static struct berval * * krb5_encode_krbsecretkey ( krb5_key_data * key_data_in , int n_key_data , krb5_kvno mkvno ) { struct berval * * ret = NULL ; int currkvno ; int num_versions = 1 ; int i , j , last ; krb5_error_code err = 0 ; <S2SV_StartBug> krb5_key_data * key_data ; <S2SV_EndBug> if ( n_key_data <= 0 ) return NULL ; key_data = k5calloc ( n_key_data , sizeof ( * key_data ) , & err ) ; <S2SV_StartBug> if ( key_data_in == NULL ) <S2SV_EndBug> goto cleanup ; memcpy ( key_data , key_data_in , n_key_data * sizeof ( * key_data ) ) ; for ( i = 0 ; i < n_key_data ; i ++ ) { if ( key_data [ i ] . key_data_ver == 1 ) { key_data [ i ] . key_data_ver = 2 ; key_data [ i ] . key_data_type [ 1 ] = KRB5_KDB_SALTTYPE_NORMAL ; key_data [ i ] . key_data_length [ 1 ] = 0 ; key_data [ i ] . key_data_contents [ 1 ] = NULL ; } } for ( i = 0 ; i < n_key_data - 1 ; i ++ ) if ( key_data [ i ] . key_data_kvno != key_data [ i + 1 ] . key_data_kvno ) num_versions ++ ; ret = ( struct berval * * ) calloc ( num_versions + 1 , sizeof ( struct berval * ) ) ; if ( ret == NULL ) { err = ENOMEM ; goto cleanup ; } for ( i = 0 , last = 0 , j = 0 , currkvno = key_data [ 0 ] . key_data_kvno ; i < n_key_data ; i ++ ) { krb5_data * code ; if ( i == n_key_data - 1 || key_data [ i + 1 ] . key_data_kvno != currkvno ) { ret [ j ] = k5alloc ( sizeof ( struct berval ) , & err ) ; if ( ret [ j ] == NULL ) goto cleanup ; err = asn1_encode_sequence_of_keys ( key_data + last , ( krb5_int16 ) i - last + 1 , mkvno , & code ) ; if ( err ) goto cleanup ; ret [ j ] -> bv_len = code -> length ; ret [ j ] -> bv_val = code -> data ; free ( code ) ; j ++ ; last = i + 1 ; if ( i < n_key_data - 1 ) currkvno = key_data [ i + 1 ] . key_data_kvno ; } } ret [ num_versions ] = NULL ; cleanup : free ( key_data ) ; if ( err != 0 ) { if ( ret != NULL ) { <S2SV_StartBug> for ( i = 0 ; i <= num_versions ; i ++ ) <S2SV_EndBug> <S2SV_StartBug> if ( ret [ i ] != NULL ) <S2SV_EndBug> free ( ret [ i ] ) ; free ( ret ) ; ret = NULL ; } } return ret ; }
CWE-000 krb5_error_code krb5_ldap_put_principal ( krb5_context context , krb5_db_entry * entry , char * * db_args ) { int l = 0 , kerberos_principal_object_type = 0 ; unsigned int ntrees = 0 , tre = 0 ; krb5_error_code st = 0 , tempst = 0 ; LDAP * ld = NULL ; LDAPMessage * result = NULL , * ent = NULL ; char * * subtreelist = NULL ; char * user = NULL , * subtree = NULL , * principal_dn = NULL ; char * * values = NULL , * strval [ 10 ] = { NULL } , errbuf [ 1024 ] ; char * filtuser = NULL ; struct berval * * bersecretkey = NULL ; LDAPMod * * mods = NULL ; krb5_boolean create_standalone_prinicipal = FALSE ; krb5_boolean krb_identity_exists = FALSE , establish_links = FALSE ; char * standalone_principal_dn = NULL ; krb5_tl_data * tl_data = NULL ; krb5_key_data * * keys = NULL ; kdb5_dal_handle * dal_handle = NULL ; krb5_ldap_context * ldap_context = NULL ; krb5_ldap_server_handle * ldap_server_handle = NULL ; osa_princ_ent_rec princ_ent = { 0 } ; xargs_t xargs = { 0 } ; char * polname = NULL ; OPERATION optype ; krb5_boolean found_entry = FALSE ; krb5_clear_error_message ( context ) ; SETUP_CONTEXT ( ) ; if ( ldap_context -> lrparams == NULL || ldap_context -> container_dn == NULL ) return EINVAL ; GET_HANDLE ( ) ; if ( ! is_principal_in_realm ( ldap_context , entry -> princ ) ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "Principal<S2SV_blank>does<S2SV_blank>not<S2SV_blank>belong<S2SV_blank>to<S2SV_blank>the<S2SV_blank>default<S2SV_blank>realm" ) ) ; goto cleanup ; } if ( ( ( st = krb5_unparse_name ( context , entry -> princ , & user ) ) != 0 ) || ( ( st = krb5_ldap_unparse_principal_name ( user ) ) != 0 ) ) goto cleanup ; filtuser = ldap_filter_correct ( user ) ; if ( filtuser == NULL ) { st = ENOMEM ; goto cleanup ; } if ( entry -> mask & KADM5_PRINCIPAL ) optype = ADD_PRINCIPAL ; else optype = MODIFY_PRINCIPAL ; if ( ( ( st = krb5_get_princ_type ( context , entry , & kerberos_principal_object_type ) ) != 0 ) || ( ( st = krb5_get_userdn ( context , entry , & principal_dn ) ) != 0 ) ) goto cleanup ; if ( ( st = process_db_args ( context , db_args , & xargs , optype ) ) != 0 ) goto cleanup ; if ( entry -> mask & KADM5_LOAD ) { unsigned int tree = 0 ; int numlentries = 0 ; char * filter = NULL ; if ( asprintf ( & filter , FILTER "%s))" , filtuser ) < 0 ) { filter = NULL ; st = ENOMEM ; goto cleanup ; } if ( ( st = krb5_get_subtree_info ( ldap_context , & subtreelist , & ntrees ) ) != 0 ) goto cleanup ; found_entry = FALSE ; for ( tree = 0 ; found_entry == FALSE && tree < ntrees ; ++ tree ) { if ( principal_dn == NULL ) { LDAP_SEARCH_1 ( subtreelist [ tree ] , ldap_context -> lrparams -> search_scope , filter , principal_attributes , IGNORE_STATUS ) ; } else { LDAP_SEARCH_1 ( principal_dn , LDAP_SCOPE_BASE , filter , principal_attributes , IGNORE_STATUS ) ; } if ( st == LDAP_SUCCESS ) { numlentries = ldap_count_entries ( ld , result ) ; if ( numlentries > 1 ) { free ( filter ) ; st = EINVAL ; k5_setmsg ( context , st , _ ( "operation<S2SV_blank>can<S2SV_blank>not<S2SV_blank>continue,<S2SV_blank>more<S2SV_blank>than<S2SV_blank>one<S2SV_blank>" "entry<S2SV_blank>with<S2SV_blank>principal<S2SV_blank>name<S2SV_blank>\\"%s\\"<S2SV_blank>found" ) , user ) ; goto cleanup ; } else if ( numlentries == 1 ) { found_entry = TRUE ; if ( principal_dn == NULL ) { ent = ldap_first_entry ( ld , result ) ; if ( ent != NULL ) { if ( ( principal_dn = ldap_get_dn ( ld , ent ) ) == NULL ) { ldap_get_option ( ld , LDAP_OPT_RESULT_CODE , & st ) ; st = set_ldap_error ( context , st , 0 ) ; free ( filter ) ; goto cleanup ; } } } } } else if ( st != LDAP_NO_SUCH_OBJECT ) { st = set_ldap_error ( context , st , 0 ) ; free ( filter ) ; goto cleanup ; } ldap_msgfree ( result ) ; result = NULL ; } free ( filter ) ; if ( found_entry == FALSE && principal_dn != NULL ) { create_standalone_prinicipal = TRUE ; standalone_principal_dn = strdup ( principal_dn ) ; CHECK_NULL ( standalone_principal_dn ) ; } } if ( principal_dn == NULL && xargs . dn == NULL ) { if ( entry -> princ -> length == 2 && entry -> princ -> data [ 0 ] . length == strlen ( "krbtgt" ) && strncmp ( entry -> princ -> data [ 0 ] . data , "krbtgt" , entry -> princ -> data [ 0 ] . length ) == 0 ) { subtree = strdup ( ldap_context -> lrparams -> realmdn ) ; } else if ( xargs . containerdn ) { if ( ( st = checkattributevalue ( ld , xargs . containerdn , NULL , NULL , NULL ) ) != 0 ) { if ( st == KRB5_KDB_NOENTRY || st == KRB5_KDB_CONSTRAINT_VIOLATION ) { int ost = st ; st = EINVAL ; k5_prependmsg ( context , ost , st , _ ( "\'%s\'<S2SV_blank>not<S2SV_blank>found" ) , xargs . containerdn ) ; } goto cleanup ; } subtree = strdup ( xargs . containerdn ) ; } else if ( ldap_context -> lrparams -> containerref && strlen ( ldap_context -> lrparams -> containerref ) != 0 ) { subtree = strdup ( ldap_context -> lrparams -> containerref ) ; } else { subtree = strdup ( ldap_context -> lrparams -> realmdn ) ; } CHECK_NULL ( subtree ) ; if ( asprintf ( & standalone_principal_dn , "krbprincipalname=%s,%s" , filtuser , subtree ) < 0 ) standalone_principal_dn = NULL ; CHECK_NULL ( standalone_principal_dn ) ; create_standalone_prinicipal = TRUE ; free ( subtree ) ; subtree = NULL ; } if ( xargs . dn_from_kbd == TRUE ) { int dnlen = 0 , subtreelen = 0 ; char * dn = NULL ; krb5_boolean outofsubtree = TRUE ; if ( xargs . dn != NULL ) { dn = xargs . dn ; } else if ( xargs . linkdn != NULL ) { dn = xargs . linkdn ; } else if ( standalone_principal_dn != NULL ) { dn = standalone_principal_dn ; } if ( subtreelist == NULL ) { st = krb5_get_subtree_info ( ldap_context , & subtreelist , & ntrees ) ; if ( st ) goto cleanup ; } for ( tre = 0 ; tre < ntrees ; ++ tre ) { if ( subtreelist [ tre ] == NULL || strlen ( subtreelist [ tre ] ) == 0 ) { outofsubtree = FALSE ; break ; } else { dnlen = strlen ( dn ) ; subtreelen = strlen ( subtreelist [ tre ] ) ; if ( ( dnlen >= subtreelen ) && ( strcasecmp ( ( dn + dnlen - subtreelen ) , subtreelist [ tre ] ) == 0 ) ) { outofsubtree = FALSE ; break ; } } } if ( outofsubtree == TRUE ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "DN<S2SV_blank>is<S2SV_blank>out<S2SV_blank>of<S2SV_blank>the<S2SV_blank>realm<S2SV_blank>subtree" ) ) ; goto cleanup ; } if ( standalone_principal_dn == NULL ) { char * attributes [ ] = { "krbticketpolicyreference" , "krbprincipalname" , NULL } ; ldap_msgfree ( result ) ; result = NULL ; LDAP_SEARCH_1 ( dn , LDAP_SCOPE_BASE , 0 , attributes , IGNORE_STATUS ) ; if ( st == LDAP_SUCCESS ) { ent = ldap_first_entry ( ld , result ) ; if ( ent != NULL ) { if ( ( values = ldap_get_values ( ld , ent , "krbticketpolicyreference" ) ) != NULL ) { ldap_value_free ( values ) ; } if ( ( values = ldap_get_values ( ld , ent , "krbprincipalname" ) ) != NULL ) { krb_identity_exists = TRUE ; ldap_value_free ( values ) ; } } } else { st = set_ldap_error ( context , st , OP_SEARCH ) ; goto cleanup ; } } } if ( xargs . dn != NULL && krb_identity_exists == TRUE ) { st = EINVAL ; snprintf ( errbuf , sizeof ( errbuf ) , _ ( "ldap<S2SV_blank>object<S2SV_blank>is<S2SV_blank>already<S2SV_blank>kerberized" ) ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } if ( xargs . linkdn != NULL ) { if ( optype == MODIFY_PRINCIPAL && kerberos_principal_object_type != KDB_STANDALONE_PRINCIPAL_OBJECT ) { st = EINVAL ; snprintf ( errbuf , sizeof ( errbuf ) , _ ( "link<S2SV_blank>information<S2SV_blank>can<S2SV_blank>not<S2SV_blank>be<S2SV_blank>set/updated<S2SV_blank>as<S2SV_blank>the<S2SV_blank>" "kerberos<S2SV_blank>principal<S2SV_blank>belongs<S2SV_blank>to<S2SV_blank>an<S2SV_blank>ldap<S2SV_blank>object" ) ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } { char * * linkdns = NULL ; int j = 0 ; if ( ( st = krb5_get_linkdn ( context , entry , & linkdns ) ) != 0 ) { snprintf ( errbuf , sizeof ( errbuf ) , _ ( "Failed<S2SV_blank>getting<S2SV_blank>object<S2SV_blank>references" ) ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } if ( linkdns != NULL ) { st = EINVAL ; snprintf ( errbuf , sizeof ( errbuf ) , _ ( "kerberos<S2SV_blank>principal<S2SV_blank>is<S2SV_blank>already<S2SV_blank>linked<S2SV_blank>to<S2SV_blank>a<S2SV_blank>ldap<S2SV_blank>" "object" ) ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; for ( j = 0 ; linkdns [ j ] != NULL ; ++ j ) free ( linkdns [ j ] ) ; free ( linkdns ) ; goto cleanup ; } } establish_links = TRUE ; } if ( entry -> mask & KADM5_LAST_SUCCESS ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( entry -> last_success ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbLastSuccessfulAuth" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } if ( entry -> mask & KADM5_LAST_FAILED ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( entry -> last_failed ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbLastFailedAuth" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } if ( entry -> mask & KADM5_FAIL_AUTH_COUNT ) { krb5_kvno fail_auth_count ; fail_auth_count = entry -> fail_auth_count ; if ( entry -> mask & KADM5_FAIL_AUTH_COUNT_INCREMENT ) fail_auth_count ++ ; st = krb5_add_int_mem_ldap_mod ( & mods , "krbLoginFailedCount" , LDAP_MOD_REPLACE , fail_auth_count ) ; if ( st != 0 ) goto cleanup ; } else if ( entry -> mask & KADM5_FAIL_AUTH_COUNT_INCREMENT ) { int attr_mask = 0 ; krb5_boolean has_fail_count ; st = krb5_get_attributes_mask ( context , entry , & attr_mask ) ; if ( st != 0 ) goto cleanup ; has_fail_count = ( ( attr_mask & KDB_FAIL_AUTH_COUNT_ATTR ) != 0 ) ; # ifdef LDAP_MOD_INCREMENT if ( ldap_server_handle -> server_info -> modify_increment && has_fail_count ) { st = krb5_add_int_mem_ldap_mod ( & mods , "krbLoginFailedCount" , LDAP_MOD_INCREMENT , 1 ) ; if ( st != 0 ) goto cleanup ; } else { # endif if ( has_fail_count ) { st = krb5_add_int_mem_ldap_mod ( & mods , "krbLoginFailedCount" , LDAP_MOD_DELETE , entry -> fail_auth_count ) ; if ( st != 0 ) goto cleanup ; } st = krb5_add_int_mem_ldap_mod ( & mods , "krbLoginFailedCount" , LDAP_MOD_ADD , entry -> fail_auth_count + 1 ) ; if ( st != 0 ) goto cleanup ; # ifdef LDAP_MOD_INCREMENT } # endif } else if ( optype == ADD_PRINCIPAL ) { st = krb5_add_int_mem_ldap_mod ( & mods , "krbLoginFailedCount" , LDAP_MOD_ADD , 0 ) ; } if ( entry -> mask & KADM5_MAX_LIFE ) { if ( ( st = krb5_add_int_mem_ldap_mod ( & mods , "krbmaxticketlife" , LDAP_MOD_REPLACE , entry -> max_life ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_MAX_RLIFE ) { if ( ( st = krb5_add_int_mem_ldap_mod ( & mods , "krbmaxrenewableage" , LDAP_MOD_REPLACE , entry -> max_renewable_life ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_ATTRIBUTES ) { if ( ( st = krb5_add_int_mem_ldap_mod ( & mods , "krbticketflags" , LDAP_MOD_REPLACE , entry -> attributes ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_PRINCIPAL ) { memset ( strval , 0 , sizeof ( strval ) ) ; strval [ 0 ] = user ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbprincipalname" , LDAP_MOD_REPLACE , strval ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_PRINC_EXPIRE_TIME ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( entry -> expiration ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbprincipalexpiration" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } if ( entry -> mask & KADM5_PW_EXPIRATION ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( entry -> pw_expiration ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbpasswordexpiration" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } if ( entry -> mask & KADM5_POLICY ) { memset ( & princ_ent , 0 , sizeof ( princ_ent ) ) ; for ( tl_data = entry -> tl_data ; tl_data ; tl_data = tl_data -> tl_data_next ) { if ( tl_data -> tl_data_type == KRB5_TL_KADM_DATA ) { if ( ( st = krb5_lookup_tl_kadm_data ( tl_data , & princ_ent ) ) != 0 ) { goto cleanup ; } break ; } } if ( princ_ent . aux_attributes & KADM5_POLICY ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( st = krb5_ldap_name_to_policydn ( context , princ_ent . policy , & polname ) ) != 0 ) goto cleanup ; strval [ 0 ] = polname ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbpwdpolicyreference" , LDAP_MOD_REPLACE , strval ) ) != 0 ) goto cleanup ; } else { st = EINVAL ; k5_setmsg ( context , st , "Password<S2SV_blank>policy<S2SV_blank>value<S2SV_blank>null" ) ; goto cleanup ; } } else if ( entry -> mask & KADM5_LOAD && found_entry == TRUE ) { if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbpwdpolicyreference" , LDAP_MOD_REPLACE , NULL ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_POLICY_CLR ) { if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbpwdpolicyreference" , LDAP_MOD_DELETE , NULL ) ) != 0 ) goto cleanup ; } if ( entry -> mask & KADM5_KEY_DATA || entry -> mask & KADM5_KVNO ) { krb5_kvno mkvno ; if ( ( st = krb5_dbe_lookup_mkvno ( context , entry , & mkvno ) ) != 0 ) goto cleanup ; bersecretkey = krb5_encode_krbsecretkey ( entry -> key_data , entry -> n_key_data , mkvno ) ; <S2SV_StartBug> if ( ( st = krb5_add_ber_mem_ldap_mod ( & mods , "krbprincipalkey" , <S2SV_EndBug> <S2SV_StartBug> LDAP_MOD_REPLACE | LDAP_MOD_BVALUES , bersecretkey ) ) != 0 ) <S2SV_EndBug> goto cleanup ; if ( ! ( entry -> mask & KADM5_PRINCIPAL ) ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( entry -> pw_expiration ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbpasswordexpiration" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } { krb5_timestamp last_pw_changed ; if ( ( st = krb5_dbe_lookup_last_pwd_change ( context , entry , & last_pw_changed ) ) != 0 ) goto cleanup ; memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( last_pw_changed ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbLastPwdChange" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } } if ( entry -> tl_data != NULL ) { int count = 0 ; struct berval * * ber_tl_data = NULL ; krb5_tl_data * ptr ; krb5_timestamp unlock_time ; for ( ptr = entry -> tl_data ; ptr != NULL ; ptr = ptr -> tl_data_next ) { if ( ptr -> tl_data_type == KRB5_TL_LAST_PWD_CHANGE # ifdef SECURID || ptr -> tl_data_type == KRB5_TL_DB_ARGS # endif || ptr -> tl_data_type == KRB5_TL_KADM_DATA || ptr -> tl_data_type == KDB_TL_USER_INFO || ptr -> tl_data_type == KRB5_TL_CONSTRAINED_DELEGATION_ACL || ptr -> tl_data_type == KRB5_TL_LAST_ADMIN_UNLOCK ) continue ; count ++ ; } if ( count != 0 ) { int j ; ber_tl_data = ( struct berval * * ) calloc ( count + 1 , sizeof ( struct berval * ) ) ; if ( ber_tl_data == NULL ) { st = ENOMEM ; goto cleanup ; } for ( j = 0 , ptr = entry -> tl_data ; ptr != NULL ; ptr = ptr -> tl_data_next ) { if ( ptr -> tl_data_type == KRB5_TL_LAST_PWD_CHANGE # ifdef SECURID || ptr -> tl_data_type == KRB5_TL_DB_ARGS # endif || ptr -> tl_data_type == KRB5_TL_KADM_DATA || ptr -> tl_data_type == KDB_TL_USER_INFO || ptr -> tl_data_type == KRB5_TL_CONSTRAINED_DELEGATION_ACL || ptr -> tl_data_type == KRB5_TL_LAST_ADMIN_UNLOCK ) continue ; if ( ( st = tl_data2berval ( ptr , & ber_tl_data [ j ] ) ) != 0 ) break ; j ++ ; } if ( st == 0 ) { ber_tl_data [ count ] = NULL ; st = krb5_add_ber_mem_ldap_mod ( & mods , "krbExtraData" , LDAP_MOD_REPLACE | LDAP_MOD_BVALUES , ber_tl_data ) ; } for ( j = 0 ; ber_tl_data [ j ] != NULL ; j ++ ) { free ( ber_tl_data [ j ] -> bv_val ) ; free ( ber_tl_data [ j ] ) ; } free ( ber_tl_data ) ; if ( st != 0 ) goto cleanup ; } if ( ( st = krb5_dbe_lookup_last_admin_unlock ( context , entry , & unlock_time ) ) != 0 ) goto cleanup ; if ( unlock_time != 0 ) { memset ( strval , 0 , sizeof ( strval ) ) ; if ( ( strval [ 0 ] = getstringtime ( unlock_time ) ) == NULL ) goto cleanup ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbLastAdminUnlock" , LDAP_MOD_REPLACE , strval ) ) != 0 ) { free ( strval [ 0 ] ) ; goto cleanup ; } free ( strval [ 0 ] ) ; } } if ( xargs . tktpolicydn != NULL ) { int tmask = 0 ; if ( strlen ( xargs . tktpolicydn ) != 0 ) { st = checkattributevalue ( ld , xargs . tktpolicydn , "objectclass" , policyclass , & tmask ) ; CHECK_CLASS_VALIDITY ( st , tmask , _ ( "ticket<S2SV_blank>policy<S2SV_blank>object<S2SV_blank>value:<S2SV_blank>" ) ) ; strval [ 0 ] = xargs . tktpolicydn ; strval [ 1 ] = NULL ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbticketpolicyreference" , LDAP_MOD_REPLACE , strval ) ) != 0 ) goto cleanup ; } else { if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbticketpolicyreference" , LDAP_MOD_DELETE , NULL ) ) != 0 ) goto cleanup ; } } if ( establish_links == TRUE ) { memset ( strval , 0 , sizeof ( strval ) ) ; strval [ 0 ] = xargs . linkdn ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "krbObjectReferences" , LDAP_MOD_REPLACE , strval ) ) != 0 ) goto cleanup ; } if ( mods == NULL ) goto cleanup ; if ( create_standalone_prinicipal == TRUE ) { memset ( strval , 0 , sizeof ( strval ) ) ; strval [ 0 ] = "krbprincipal" ; strval [ 1 ] = "krbprincipalaux" ; strval [ 2 ] = "krbTicketPolicyAux" ; if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "objectclass" , LDAP_MOD_ADD , strval ) ) != 0 ) goto cleanup ; st = ldap_add_ext_s ( ld , standalone_principal_dn , mods , NULL , NULL ) ; if ( st == LDAP_ALREADY_EXISTS && entry -> mask & KADM5_LOAD ) { st = ldap_delete_ext_s ( ld , standalone_principal_dn , NULL , NULL ) ; if ( st != LDAP_SUCCESS ) { snprintf ( errbuf , sizeof ( errbuf ) , _ ( "Principal<S2SV_blank>delete<S2SV_blank>failed<S2SV_blank>(trying<S2SV_blank>to<S2SV_blank>replace<S2SV_blank>" "entry):<S2SV_blank>%s" ) , ldap_err2string ( st ) ) ; st = translate_ldap_error ( st , OP_ADD ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } else { st = ldap_add_ext_s ( ld , standalone_principal_dn , mods , NULL , NULL ) ; } } if ( st != LDAP_SUCCESS ) { snprintf ( errbuf , sizeof ( errbuf ) , _ ( "Principal<S2SV_blank>add<S2SV_blank>failed:<S2SV_blank>%s" ) , ldap_err2string ( st ) ) ; st = translate_ldap_error ( st , OP_ADD ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } } else { { char * attrvalues [ ] = { "krbprincipalaux" , "krbTicketPolicyAux" , NULL } ; int p , q , r = 0 , amask = 0 ; if ( ( st = checkattributevalue ( ld , ( xargs . dn ) ? xargs . dn : principal_dn , "objectclass" , attrvalues , & amask ) ) != 0 ) goto cleanup ; memset ( strval , 0 , sizeof ( strval ) ) ; for ( p = 1 , q = 0 ; p <= 2 ; p <<= 1 , ++ q ) { if ( ( p & amask ) == 0 ) strval [ r ++ ] = attrvalues [ q ] ; } if ( r != 0 ) { if ( ( st = krb5_add_str_mem_ldap_mod ( & mods , "objectclass" , LDAP_MOD_ADD , strval ) ) != 0 ) goto cleanup ; } } if ( xargs . dn != NULL ) st = ldap_modify_ext_s ( ld , xargs . dn , mods , NULL , NULL ) ; else st = ldap_modify_ext_s ( ld , principal_dn , mods , NULL , NULL ) ; if ( st != LDAP_SUCCESS ) { snprintf ( errbuf , sizeof ( errbuf ) , _ ( "User<S2SV_blank>modification<S2SV_blank>failed:<S2SV_blank>%s" ) , ldap_err2string ( st ) ) ; st = translate_ldap_error ( st , OP_MOD ) ; k5_setmsg ( context , st , "%s" , errbuf ) ; goto cleanup ; } if ( entry -> mask & KADM5_FAIL_AUTH_COUNT_INCREMENT ) entry -> fail_auth_count ++ ; } cleanup : if ( user ) free ( user ) ; if ( filtuser ) free ( filtuser ) ; free_xargs ( xargs ) ; if ( standalone_principal_dn ) free ( standalone_principal_dn ) ; if ( principal_dn ) free ( principal_dn ) ; if ( polname != NULL ) free ( polname ) ; for ( tre = 0 ; tre < ntrees ; tre ++ ) free ( subtreelist [ tre ] ) ; free ( subtreelist ) ; if ( subtree ) free ( subtree ) ; if ( bersecretkey ) { for ( l = 0 ; bersecretkey [ l ] ; ++ l ) { if ( bersecretkey [ l ] -> bv_val ) free ( bersecretkey [ l ] -> bv_val ) ; free ( bersecretkey [ l ] ) ; } free ( bersecretkey ) ; } if ( keys ) free ( keys ) ; ldap_mods_free ( mods , 1 ) ; ldap_osa_free_princ_ent ( & princ_ent ) ; ldap_msgfree ( result ) ; krb5_ldap_put_handle_to_pool ( ldap_context , ldap_server_handle ) ; return ( st ) ; }
CWE-000 static krb5_error_code process_db_args ( krb5_context context , char * * db_args , xargs_t * xargs , OPERATION optype ) { int i = 0 ; krb5_error_code st = 0 ; char * arg = NULL , * arg_val = NULL ; char * * dptr = NULL ; unsigned int arg_val_len = 0 ; if ( db_args ) { for ( i = 0 ; db_args [ i ] ; ++ i ) { arg = strtok_r ( db_args [ i ] , "=" , & arg_val ) ; <S2SV_StartBug> if ( strcmp ( arg , TKTPOLICY_ARG ) == 0 ) { <S2SV_EndBug> dptr = & xargs -> tktpolicydn ; } else { if ( strcmp ( arg , USERDN_ARG ) == 0 ) { if ( optype == MODIFY_PRINCIPAL || xargs -> dn != NULL || xargs -> containerdn != NULL || xargs -> linkdn != NULL ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "%s<S2SV_blank>option<S2SV_blank>not<S2SV_blank>supported" ) , arg ) ; goto cleanup ; } dptr = & xargs -> dn ; } else if ( strcmp ( arg , CONTAINERDN_ARG ) == 0 ) { if ( optype == MODIFY_PRINCIPAL || xargs -> dn != NULL || xargs -> containerdn != NULL ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "%s<S2SV_blank>option<S2SV_blank>not<S2SV_blank>supported" ) , arg ) ; goto cleanup ; } dptr = & xargs -> containerdn ; } else if ( strcmp ( arg , LINKDN_ARG ) == 0 ) { if ( xargs -> dn != NULL || xargs -> linkdn != NULL ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "%s<S2SV_blank>option<S2SV_blank>not<S2SV_blank>supported" ) , arg ) ; goto cleanup ; } dptr = & xargs -> linkdn ; } else { st = EINVAL ; k5_setmsg ( context , st , _ ( "unknown<S2SV_blank>option:<S2SV_blank>%s" ) , arg ) ; goto cleanup ; } xargs -> dn_from_kbd = TRUE ; if ( arg_val == NULL || strlen ( arg_val ) == 0 ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "%s<S2SV_blank>option<S2SV_blank>value<S2SV_blank>missing" ) , arg ) ; goto cleanup ; } } if ( arg_val == NULL ) { st = EINVAL ; k5_setmsg ( context , st , _ ( "%s<S2SV_blank>option<S2SV_blank>value<S2SV_blank>missing" ) , arg ) ; goto cleanup ; } arg_val_len = strlen ( arg_val ) + 1 ; if ( strcmp ( arg , TKTPOLICY_ARG ) == 0 ) { if ( ( st = krb5_ldap_name_to_policydn ( context , arg_val , dptr ) ) != 0 ) goto cleanup ; } else { * dptr = k5memdup ( arg_val , arg_val_len , & st ) ; if ( * dptr == NULL ) goto cleanup ; } } } cleanup : return st ; }
CWE-000 int main ( argc , argv ) int argc ; char * argv [ ] ; { krb5_data pname_data , tkt_data ; int sock = 0 ; socklen_t l ; int retval ; struct sockaddr_in l_inaddr , f_inaddr ; krb5_creds creds , * new_creds ; krb5_ccache cc ; krb5_data msgtext , msg ; krb5_context context ; krb5_auth_context auth_context = NULL ; # ifndef DEBUG freopen ( "/tmp/uu-server.log" , "w" , stderr ) ; # endif retval = krb5_init_context ( & context ) ; if ( retval ) { com_err ( argv [ 0 ] , retval , "while<S2SV_blank>initializing<S2SV_blank>krb5" ) ; exit ( 1 ) ; } # ifdef DEBUG { int one = 1 ; int acc ; struct servent * sp ; socklen_t namelen = sizeof ( f_inaddr ) ; if ( ( sock = socket ( PF_INET , SOCK_STREAM , 0 ) ) < 0 ) { com_err ( "uu-server" , errno , "creating<S2SV_blank>socket" ) ; exit ( 3 ) ; } l_inaddr . sin_family = AF_INET ; l_inaddr . sin_addr . s_addr = 0 ; if ( argc == 2 ) { l_inaddr . sin_port = htons ( atoi ( argv [ 1 ] ) ) ; } else { if ( ! ( sp = getservbyname ( "uu-sample" , "tcp" ) ) ) { com_err ( "uu-server" , 0 , "can\'t<S2SV_blank>find<S2SV_blank>uu-sample/tcp<S2SV_blank>service" ) ; exit ( 3 ) ; } l_inaddr . sin_port = sp -> s_port ; } ( void ) setsockopt ( sock , SOL_SOCKET , SO_REUSEADDR , ( char * ) & one , sizeof ( one ) ) ; if ( bind ( sock , ( struct sockaddr * ) & l_inaddr , sizeof ( l_inaddr ) ) ) { com_err ( "uu-server" , errno , "binding<S2SV_blank>socket" ) ; exit ( 3 ) ; } if ( listen ( sock , 1 ) == - 1 ) { com_err ( "uu-server" , errno , "listening" ) ; exit ( 3 ) ; } printf ( "Server<S2SV_blank>started\\n" ) ; fflush ( stdout ) ; if ( ( acc = accept ( sock , ( struct sockaddr * ) & f_inaddr , & namelen ) ) == - 1 ) { com_err ( "uu-server" , errno , "accepting" ) ; exit ( 3 ) ; } dup2 ( acc , 0 ) ; close ( sock ) ; sock = 0 ; } # endif retval = krb5_read_message ( context , ( krb5_pointer ) & sock , & pname_data ) ; <S2SV_StartBug> if ( retval ) { <S2SV_EndBug> com_err ( "uu-server" , retval , "reading<S2SV_blank>pname" ) ; return 2 ; } retval = krb5_read_message ( context , ( krb5_pointer ) & sock , & tkt_data ) ; if ( retval ) { com_err ( "uu-server" , retval , "reading<S2SV_blank>ticket<S2SV_blank>data" ) ; return 2 ; } retval = krb5_cc_default ( context , & cc ) ; if ( retval ) { com_err ( "uu-server" , retval , "getting<S2SV_blank>credentials<S2SV_blank>cache" ) ; return 4 ; } memset ( & creds , 0 , sizeof ( creds ) ) ; retval = krb5_cc_get_principal ( context , cc , & creds . client ) ; if ( retval ) { com_err ( "uu-client" , retval , "getting<S2SV_blank>principal<S2SV_blank>name" ) ; return 6 ; } printf ( "uu-server:<S2SV_blank>client<S2SV_blank>principal<S2SV_blank>is<S2SV_blank>\\"%s\\".\\n" , pname_data . data ) ; retval = krb5_parse_name ( context , pname_data . data , & creds . server ) ; if ( retval ) { com_err ( "uu-server" , retval , "parsing<S2SV_blank>client<S2SV_blank>name" ) ; return 3 ; } creds . second_ticket = tkt_data ; printf ( "uu-server:<S2SV_blank>client<S2SV_blank>ticket<S2SV_blank>is<S2SV_blank>%d<S2SV_blank>bytes.\\n" , creds . second_ticket . length ) ; retval = krb5_get_credentials ( context , KRB5_GC_USER_USER , cc , & creds , & new_creds ) ; if ( retval ) { com_err ( "uu-server" , retval , "getting<S2SV_blank>user-user<S2SV_blank>ticket" ) ; return 5 ; } # ifndef DEBUG l = sizeof ( f_inaddr ) ; if ( getpeername ( 0 , ( struct sockaddr * ) & f_inaddr , & l ) == - 1 ) { com_err ( "uu-server" , errno , "getting<S2SV_blank>client<S2SV_blank>address" ) ; return 6 ; } # endif l = sizeof ( l_inaddr ) ; if ( getsockname ( 0 , ( struct sockaddr * ) & l_inaddr , & l ) == - 1 ) { com_err ( "uu-server" , errno , "getting<S2SV_blank>local<S2SV_blank>address" ) ; return 6 ; } retval = krb5_auth_con_init ( context , & auth_context ) ; if ( retval ) { com_err ( "uu-server" , retval , "making<S2SV_blank>auth_context" ) ; return 8 ; } retval = krb5_auth_con_setflags ( context , auth_context , KRB5_AUTH_CONTEXT_DO_SEQUENCE ) ; if ( retval ) { com_err ( "uu-server" , retval , "initializing<S2SV_blank>the<S2SV_blank>auth_context<S2SV_blank>flags" ) ; return 8 ; } retval = krb5_auth_con_genaddrs ( context , auth_context , sock , KRB5_AUTH_CONTEXT_GENERATE_LOCAL_FULL_ADDR | KRB5_AUTH_CONTEXT_GENERATE_REMOTE_FULL_ADDR ) ; if ( retval ) { com_err ( "uu-server" , retval , "generating<S2SV_blank>addrs<S2SV_blank>for<S2SV_blank>auth_context" ) ; return 9 ; } # if 1 retval = krb5_mk_req_extended ( context , & auth_context , AP_OPTS_USE_SESSION_KEY , NULL , new_creds , & msg ) ; if ( retval ) { com_err ( "uu-server" , retval , "making<S2SV_blank>AP_REQ" ) ; return 8 ; } retval = krb5_write_message ( context , ( krb5_pointer ) & sock , & msg ) ; # else retval = krb5_sendauth ( context , & auth_context , ( krb5_pointer ) & sock , "???" , 0 , 0 , AP_OPTS_MUTUAL_REQUIRED | AP_OPTS_USE_SESSION_KEY , NULL , & creds , cc , NULL , NULL , NULL ) ; # endif if ( retval ) goto cl_short_wrt ; free ( msg . data ) ; msgtext . length = 32 ; msgtext . data = "Hello,<S2SV_blank>other<S2SV_blank>end<S2SV_blank>of<S2SV_blank>connection." ; retval = krb5_mk_safe ( context , auth_context , & msgtext , & msg , NULL ) ; if ( retval ) { com_err ( "uu-server" , retval , "encoding<S2SV_blank>message<S2SV_blank>to<S2SV_blank>client" ) ; return 6 ; } retval = krb5_write_message ( context , ( krb5_pointer ) & sock , & msg ) ; if ( retval ) { cl_short_wrt : com_err ( "uu-server" , retval , "writing<S2SV_blank>message<S2SV_blank>to<S2SV_blank>client" ) ; return 7 ; } krb5_free_data_contents ( context , & msg ) ; krb5_free_data_contents ( context , & pname_data ) ; krb5_free_cred_contents ( context , & creds ) ; krb5_free_creds ( context , new_creds ) ; krb5_cc_close ( context , cc ) ; krb5_auth_con_free ( context , auth_context ) ; krb5_free_context ( context ) ; return 0 ; }
CWE-000 static krb5_error_code recvauth_common ( krb5_context context , krb5_auth_context * auth_context , krb5_pointer fd , char * appl_version , krb5_principal server , krb5_int32 flags , krb5_keytab keytab , krb5_ticket * * ticket , krb5_data * version ) { krb5_auth_context new_auth_context ; krb5_flags ap_option = 0 ; krb5_error_code retval , problem ; krb5_data inbuf ; krb5_data outbuf ; krb5_rcache rcache = 0 ; krb5_octet response ; krb5_data null_server ; <S2SV_StartBug> int need_error_free = 0 ; <S2SV_EndBug> int local_rcache = 0 , local_authcon = 0 ; problem = 0 ; response = 0 ; if ( ! ( flags & KRB5_RECVAUTH_SKIP_VERSION ) ) { if ( ( retval = krb5_read_message ( context , fd , & inbuf ) ) ) return ( retval ) ; <S2SV_StartBug> if ( strcmp ( inbuf . data , sendauth_version ) ) { <S2SV_EndBug> problem = KRB5_SENDAUTH_BADAUTHVERS ; response = 1 ; } free ( inbuf . data ) ; } if ( flags & KRB5_RECVAUTH_BADAUTHVERS ) { problem = KRB5_SENDAUTH_BADAUTHVERS ; response = 1 ; } if ( ( retval = krb5_read_message ( context , fd , & inbuf ) ) ) return ( retval ) ; <S2SV_StartBug> if ( appl_version && strcmp ( inbuf . data , appl_version ) ) { <S2SV_EndBug> if ( ! problem ) { problem = KRB5_SENDAUTH_BADAPPLVERS ; response = 2 ; } } if ( version && ! problem ) * version = inbuf ; else free ( inbuf . data ) ; if ( ( krb5_net_write ( context , * ( ( int * ) fd ) , ( char * ) & response , 1 ) ) < 0 ) { return ( problem ) ; } if ( problem ) return ( problem ) ; if ( ( retval = krb5_read_message ( context , fd , & inbuf ) ) ) return retval ; if ( * auth_context == NULL ) { problem = krb5_auth_con_init ( context , & new_auth_context ) ; * auth_context = new_auth_context ; local_authcon = 1 ; } krb5_auth_con_getrcache ( context , * auth_context , & rcache ) ; if ( ( ! problem ) && rcache == NULL ) { if ( server != NULL && server -> length > 0 ) { problem = krb5_get_server_rcache ( context , & server -> data [ 0 ] , & rcache ) ; } else { null_server . length = 7 ; null_server . data = "default" ; problem = krb5_get_server_rcache ( context , & null_server , & rcache ) ; } if ( ! problem ) problem = krb5_auth_con_setrcache ( context , * auth_context , rcache ) ; local_rcache = 1 ; } if ( ! problem ) { problem = krb5_rd_req ( context , auth_context , & inbuf , server , keytab , & ap_option , ticket ) ; free ( inbuf . data ) ; } if ( problem ) { krb5_error error ; const char * message ; memset ( & error , 0 , sizeof ( error ) ) ; krb5_us_timeofday ( context , & error . stime , & error . susec ) ; if ( server ) error . server = server ; else { ( void ) krb5_parse_name ( context , "????" , & error . server ) ; need_error_free = 1 ; } error . error = problem - ERROR_TABLE_BASE_krb5 ; if ( error . error > 127 ) error . error = KRB_ERR_GENERIC ; message = error_message ( problem ) ; error . text . length = strlen ( message ) + 1 ; error . text . data = strdup ( message ) ; if ( ! error . text . data ) { retval = ENOMEM ; goto cleanup ; } if ( ( retval = krb5_mk_error ( context , & error , & outbuf ) ) ) { free ( error . text . data ) ; goto cleanup ; } free ( error . text . data ) ; if ( need_error_free ) krb5_free_principal ( context , error . server ) ; } else { outbuf . length = 0 ; outbuf . data = 0 ; } retval = krb5_write_message ( context , fd , & outbuf ) ; if ( outbuf . data ) { free ( outbuf . data ) ; retval = problem ; goto cleanup ; } if ( retval ) goto cleanup ; if ( ( ap_option & AP_OPTS_MUTUAL_REQUIRED ) ) { if ( ( retval = krb5_mk_rep ( context , * auth_context , & outbuf ) ) ) { return ( retval ) ; } retval = krb5_write_message ( context , fd , & outbuf ) ; free ( outbuf . data ) ; } cleanup : ; if ( retval ) { if ( local_authcon ) { krb5_auth_con_free ( context , * auth_context ) ; } else if ( local_rcache && rcache != NULL ) { krb5_rc_close ( context , rcache ) ; krb5_auth_con_setrcache ( context , * auth_context , NULL ) ; } } return retval ; }
CWE-000 OM_uint32 kg_seal_iov ( OM_uint32 * minor_status , gss_ctx_id_t context_handle , int conf_req_flag , gss_qop_t qop_req , int * conf_state , gss_iov_buffer_desc * iov , int iov_count , int toktype ) { krb5_gss_ctx_id_rec * ctx ; krb5_error_code code ; krb5_context context ; if ( qop_req != 0 ) { * minor_status = ( OM_uint32 ) G_UNKNOWN_QOP ; return GSS_S_FAILURE ; } ctx = ( krb5_gss_ctx_id_rec * ) context_handle ; <S2SV_StartBug> if ( ! ctx -> established ) { <S2SV_EndBug> * minor_status = KG_CTX_INCOMPLETE ; return GSS_S_NO_CONTEXT ; } if ( conf_req_flag && kg_integ_only_iov ( iov , iov_count ) ) { conf_req_flag = FALSE ; } context = ctx -> k5_context ; switch ( ctx -> proto ) { case 0 : code = make_seal_token_v1_iov ( context , ctx , conf_req_flag , conf_state , iov , iov_count , toktype ) ; break ; case 1 : code = gss_krb5int_make_seal_token_v3_iov ( context , ctx , conf_req_flag , conf_state , iov , iov_count , toktype ) ; break ; default : code = G_UNKNOWN_QOP ; break ; } if ( code != 0 ) { * minor_status = code ; save_error_info ( * minor_status , context ) ; return GSS_S_FAILURE ; } * minor_status = 0 ; return GSS_S_COMPLETE ; }
CWE-000 OM_uint32 kg_unseal_iov ( OM_uint32 * minor_status , gss_ctx_id_t context_handle , int * conf_state , gss_qop_t * qop_state , gss_iov_buffer_desc * iov , int iov_count , int toktype ) { krb5_gss_ctx_id_rec * ctx ; OM_uint32 code ; ctx = ( krb5_gss_ctx_id_rec * ) context_handle ; <S2SV_StartBug> if ( ! ctx -> established ) { <S2SV_EndBug> * minor_status = KG_CTX_INCOMPLETE ; return GSS_S_NO_CONTEXT ; } if ( kg_locate_iov ( iov , iov_count , GSS_IOV_BUFFER_TYPE_STREAM ) != NULL ) { code = kg_unseal_stream_iov ( minor_status , ctx , conf_state , qop_state , iov , iov_count , toktype ) ; } else { code = kg_unseal_iov_token ( minor_status , ctx , conf_state , qop_state , iov , iov_count , toktype ) ; } return code ; }
CWE-000 OM_uint32 gss_krb5int_export_lucid_sec_context ( OM_uint32 * minor_status , const gss_ctx_id_t context_handle , const gss_OID desired_object , gss_buffer_set_t * data_set ) { krb5_error_code kret = 0 ; OM_uint32 retval ; krb5_gss_ctx_id_t ctx = ( krb5_gss_ctx_id_t ) context_handle ; void * lctx = NULL ; int version = 0 ; gss_buffer_desc rep ; retval = GSS_S_FAILURE ; * minor_status = 0 ; * data_set = GSS_C_NO_BUFFER_SET ; <S2SV_StartBug> retval = generic_gss_oid_decompose ( minor_status , <S2SV_EndBug> GSS_KRB5_EXPORT_LUCID_SEC_CONTEXT_OID , GSS_KRB5_EXPORT_LUCID_SEC_CONTEXT_OID_LENGTH , desired_object , & version ) ; if ( GSS_ERROR ( retval ) ) return retval ; switch ( version ) { case 1 : kret = make_external_lucid_ctx_v1 ( ( krb5_pointer ) ctx , version , & lctx ) ; break ; default : kret = ( OM_uint32 ) KG_LUCID_VERSION ; break ; } if ( kret ) goto error_out ; rep . value = & lctx ; rep . length = sizeof ( lctx ) ; retval = generic_gss_add_buffer_set_member ( minor_status , & rep , data_set ) ; if ( GSS_ERROR ( retval ) ) goto error_out ; error_out : if ( * minor_status == 0 ) * minor_status = ( OM_uint32 ) kret ; return ( retval ) ; }
CWE-000 int main ( int argc , char * argv [ ] ) { OM_uint32 minor , major ; gss_ctx_id_t context ; gss_union_ctx_id_desc uctx ; krb5_gss_ctx_id_rec kgctx ; krb5_key k1 , k2 ; krb5_keyblock kb1 , kb2 ; gss_buffer_desc in , out ; unsigned char k1buf [ 32 ] , k2buf [ 32 ] , outbuf [ 44 ] ; size_t i ; context = ( gss_ctx_id_t ) & uctx ; uctx . mech_type = & mech_krb5 ; uctx . internal_ctx_id = ( gss_ctx_id_t ) & kgctx ; kgctx . k5_context = NULL ; <S2SV_StartBug> kgctx . have_acceptor_subkey = 1 ; <S2SV_EndBug> kb1 . contents = k1buf ; kb2 . contents = k2buf ; for ( i = 0 ; i < sizeof ( tests ) / sizeof ( * tests ) ; i ++ ) { kb1 . enctype = tests [ i ] . enctype ; kb1 . length = fromhex ( tests [ i ] . key1 , k1buf ) ; check_k5err ( NULL , "create_key" , krb5_k_create_key ( NULL , & kb1 , & k1 ) ) ; kgctx . subkey = k1 ; kb2 . enctype = tests [ i ] . enctype ; kb2 . length = fromhex ( tests [ i ] . key2 , k2buf ) ; check_k5err ( NULL , "create_key" , krb5_k_create_key ( NULL , & kb2 , & k2 ) ) ; kgctx . acceptor_subkey = k2 ; in . length = 0 ; in . value = NULL ; major = gss_pseudo_random ( & minor , context , GSS_C_PRF_KEY_PARTIAL , & in , 44 , & out ) ; check_gsserr ( "gss_pseudo_random" , major , minor ) ; ( void ) fromhex ( tests [ i ] . out1 , outbuf ) ; assert ( out . length == 44 && memcmp ( out . value , outbuf , 44 ) == 0 ) ; ( void ) gss_release_buffer ( & minor , & out ) ; in . length = strlen ( inputstr ) ; in . value = ( char * ) inputstr ; major = gss_pseudo_random ( & minor , context , GSS_C_PRF_KEY_FULL , & in , 44 , & out ) ; check_gsserr ( "gss_pseudo_random" , major , minor ) ; ( void ) fromhex ( tests [ i ] . out2 , outbuf ) ; assert ( out . length == 44 && memcmp ( out . value , outbuf , 44 ) == 0 ) ; ( void ) gss_release_buffer ( & minor , & out ) ; major = gss_pseudo_random ( & minor , context , GSS_C_PRF_KEY_FULL , & in , 0 , & out ) ; check_gsserr ( "gss_pseudo_random" , major , minor ) ; assert ( out . length == 0 ) ; ( void ) gss_release_buffer ( & minor , & out ) ; krb5_k_free_key ( NULL , k1 ) ; krb5_k_free_key ( NULL , k2 ) ; } return 0 ; }
CWE-000 bool_t xdr_krb5_principal ( XDR * xdrs , krb5_principal * objp ) { int ret ; char * p = NULL ; krb5_principal pr = NULL ; static krb5_context context = NULL ; if ( ! context && kadm5_init_krb5_context ( & context ) ) return ( FALSE ) ; switch ( xdrs -> x_op ) { case XDR_ENCODE : if ( * objp ) { if ( ( ret = krb5_unparse_name ( context , * objp , & p ) ) != 0 ) return FALSE ; } if ( ! xdr_nullstring ( xdrs , & p ) ) return FALSE ; if ( p ) free ( p ) ; break ; case XDR_DECODE : if ( ! xdr_nullstring ( xdrs , & p ) ) return FALSE ; if ( p ) { ret = krb5_parse_name ( context , p , & pr ) ; if ( ret != 0 ) return FALSE ; * objp = pr ; free ( p ) ; } else * objp = NULL ; break ; case XDR_FREE : if ( * objp != NULL ) krb5_free_principal ( context , * objp ) ; <S2SV_StartBug> break ; <S2SV_EndBug> } return TRUE ; }
CWE-000 bool_t xdr_krb5_tl_data ( XDR * xdrs , krb5_tl_data * * tl_data_head ) { krb5_tl_data * tl , * tl2 ; bool_t more ; unsigned int len ; switch ( xdrs -> x_op ) { case XDR_FREE : tl = tl2 = * tl_data_head ; while ( tl ) { tl2 = tl -> tl_data_next ; free ( tl -> tl_data_contents ) ; free ( tl ) ; tl = tl2 ; } <S2SV_StartBug> break ; <S2SV_EndBug> case XDR_ENCODE : tl = * tl_data_head ; while ( 1 ) { more = ( tl != NULL ) ; if ( ! xdr_bool ( xdrs , & more ) ) return FALSE ; if ( tl == NULL ) break ; if ( ! xdr_krb5_int16 ( xdrs , & tl -> tl_data_type ) ) return FALSE ; len = tl -> tl_data_length ; if ( ! xdr_bytes ( xdrs , ( char * * ) & tl -> tl_data_contents , & len , ~ 0 ) ) return FALSE ; tl = tl -> tl_data_next ; } break ; case XDR_DECODE : tl = NULL ; while ( 1 ) { if ( ! xdr_bool ( xdrs , & more ) ) return FALSE ; if ( more == FALSE ) break ; tl2 = ( krb5_tl_data * ) malloc ( sizeof ( krb5_tl_data ) ) ; if ( tl2 == NULL ) return FALSE ; memset ( tl2 , 0 , sizeof ( krb5_tl_data ) ) ; if ( ! xdr_krb5_int16 ( xdrs , & tl2 -> tl_data_type ) ) return FALSE ; if ( ! xdr_bytes ( xdrs , ( char * * ) & tl2 -> tl_data_contents , & len , ~ 0 ) ) return FALSE ; tl2 -> tl_data_length = len ; tl2 -> tl_data_next = tl ; tl = tl2 ; } * tl_data_head = tl ; break ; } return TRUE ; }
CWE-000 bool_t auth_gssapi_unwrap_data ( OM_uint32 * major , OM_uint32 * minor , gss_ctx_id_t context , uint32_t seq_num , XDR * in_xdrs , bool_t ( * xdr_func ) ( ) , caddr_t xdr_ptr ) { gss_buffer_desc in_buf , out_buf ; XDR temp_xdrs ; uint32_t verf_seq_num ; int conf , qop ; unsigned int length ; PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>starting\\n" ) ) ; * major = GSS_S_COMPLETE ; * minor = 0 ; in_buf . value = NULL ; out_buf . value = NULL ; if ( ! xdr_bytes ( in_xdrs , ( char * * ) & in_buf . value , & length , ( unsigned int ) - 1 ) ) { PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>deserializing<S2SV_blank>encrypted<S2SV_blank>data<S2SV_blank>failed\\n" ) ) ; temp_xdrs . x_op = XDR_FREE ; ( void ) xdr_bytes ( & temp_xdrs , ( char * * ) & in_buf . value , & length , ( unsigned int ) - 1 ) ; return FALSE ; } in_buf . length = length ; * major = gss_unseal ( minor , context , & in_buf , & out_buf , & conf , & qop ) ; free ( in_buf . value ) ; if ( * major != GSS_S_COMPLETE ) return FALSE ; PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>%llu<S2SV_blank>bytes<S2SV_blank>data,<S2SV_blank>%llu<S2SV_blank>bytes<S2SV_blank>sealed\\n" , ( unsigned long long ) out_buf . length , ( unsigned long long ) in_buf . length ) ) ; xdrmem_create ( & temp_xdrs , out_buf . value , out_buf . length , XDR_DECODE ) ; if ( ! xdr_u_int32 ( & temp_xdrs , & verf_seq_num ) ) { PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>deserializing<S2SV_blank>verf_seq_num<S2SV_blank>failed\\n" ) ) ; gss_release_buffer ( minor , & out_buf ) ; XDR_DESTROY ( & temp_xdrs ) ; return FALSE ; } if ( verf_seq_num != seq_num ) { PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>seq<S2SV_blank>%d<S2SV_blank>specified,<S2SV_blank>read<S2SV_blank>%d\\n" , seq_num , verf_seq_num ) ) ; gss_release_buffer ( minor , & out_buf ) ; XDR_DESTROY ( & temp_xdrs ) ; return FALSE ; } PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>unwrap<S2SV_blank>seq_num<S2SV_blank>%d<S2SV_blank>okay\\n" , verf_seq_num ) ) ; if ( ! ( * xdr_func ) ( & temp_xdrs , xdr_ptr ) ) { PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>deserializing<S2SV_blank>arguments<S2SV_blank>failed\\n" ) ) ; gss_release_buffer ( minor , & out_buf ) ; <S2SV_StartBug> xdr_free ( xdr_func , xdr_ptr ) ; <S2SV_EndBug> XDR_DESTROY ( & temp_xdrs ) ; return FALSE ; } PRINTF ( ( "gssapi_unwrap_data:<S2SV_blank>succeeding\\n\\n" ) ) ; gss_release_buffer ( minor , & out_buf ) ; XDR_DESTROY ( & temp_xdrs ) ; return TRUE ; }
CWE-000 kadm5_ret_t kadm5_create_principal_3 ( void * server_handle , kadm5_principal_ent_t entry , long mask , int n_ks_tuple , krb5_key_salt_tuple * ks_tuple , char * password ) { krb5_db_entry * kdb ; osa_princ_ent_rec adb ; kadm5_policy_ent_rec polent ; krb5_boolean have_polent = FALSE ; krb5_int32 now ; krb5_tl_data * tl_data_tail ; unsigned int ret ; kadm5_server_handle_t handle = server_handle ; krb5_keyblock * act_mkey ; krb5_kvno act_kvno ; int new_n_ks_tuple = 0 ; krb5_key_salt_tuple * new_ks_tuple = NULL ; CHECK_HANDLE ( server_handle ) ; krb5_clear_error_message ( handle -> context ) ; check_1_6_dummy ( entry , mask , n_ks_tuple , ks_tuple , & password ) ; <S2SV_StartBug> if ( ! ( mask & KADM5_PRINCIPAL ) || ( mask & KADM5_MOD_NAME ) || <S2SV_EndBug> ( mask & KADM5_MOD_TIME ) || ( mask & KADM5_LAST_PWD_CHANGE ) || ( mask & KADM5_MKVNO ) || ( mask & KADM5_AUX_ATTRIBUTES ) || ( mask & KADM5_LAST_SUCCESS ) || ( mask & KADM5_LAST_FAILED ) || ( mask & KADM5_FAIL_AUTH_COUNT ) ) return KADM5_BAD_MASK ; if ( ( mask & KADM5_KEY_DATA ) && entry -> n_key_data != 0 ) return KADM5_BAD_MASK ; <S2SV_StartBug> if ( ( mask & KADM5_POLICY ) && ( mask & KADM5_POLICY_CLR ) ) <S2SV_EndBug> return KADM5_BAD_MASK ; <S2SV_StartBug> if ( ( mask & ~ ALL_PRINC_MASK ) ) <S2SV_EndBug> <S2SV_StartBug> return KADM5_BAD_MASK ; <S2SV_EndBug> if ( entry == NULL ) return EINVAL ; ret = kdb_get_entry ( handle , entry -> principal , & kdb , & adb ) ; switch ( ret ) { case KADM5_UNK_PRINC : break ; case 0 : kdb_free_entry ( handle , kdb , & adb ) ; return KADM5_DUP ; default : return ret ; } kdb = krb5_db_alloc ( handle -> context , NULL , sizeof ( * kdb ) ) ; if ( kdb == NULL ) return ENOMEM ; memset ( kdb , 0 , sizeof ( * kdb ) ) ; memset ( & adb , 0 , sizeof ( osa_princ_ent_rec ) ) ; if ( ( mask & KADM5_POLICY ) ) { ret = get_policy ( handle , entry -> policy , & polent , & have_polent ) ; if ( ret ) goto cleanup ; } if ( password ) { ret = passwd_check ( handle , password , have_polent ? & polent : NULL , entry -> principal ) ; if ( ret ) goto cleanup ; } if ( ( ret = krb5_timeofday ( handle -> context , & now ) ) ) goto cleanup ; kdb -> magic = KRB5_KDB_MAGIC_NUMBER ; kdb -> len = KRB5_KDB_V1_BASE_LENGTH ; if ( ( mask & KADM5_ATTRIBUTES ) ) kdb -> attributes = entry -> attributes ; else kdb -> attributes = handle -> params . flags ; if ( ( mask & KADM5_MAX_LIFE ) ) kdb -> max_life = entry -> max_life ; else kdb -> max_life = handle -> params . max_life ; if ( mask & KADM5_MAX_RLIFE ) kdb -> max_renewable_life = entry -> max_renewable_life ; else kdb -> max_renewable_life = handle -> params . max_rlife ; if ( ( mask & KADM5_PRINC_EXPIRE_TIME ) ) kdb -> expiration = entry -> princ_expire_time ; else kdb -> expiration = handle -> params . expiration ; kdb -> pw_expiration = 0 ; if ( have_polent ) { if ( polent . pw_max_life ) kdb -> pw_expiration = now + polent . pw_max_life ; else kdb -> pw_expiration = 0 ; } if ( ( mask & KADM5_PW_EXPIRATION ) ) kdb -> pw_expiration = entry -> pw_expiration ; kdb -> last_success = 0 ; kdb -> last_failed = 0 ; kdb -> fail_auth_count = 0 ; if ( ( ret = kadm5_copy_principal ( handle -> context , entry -> principal , & ( kdb -> princ ) ) ) ) goto cleanup ; if ( ( ret = krb5_dbe_update_last_pwd_change ( handle -> context , kdb , now ) ) ) goto cleanup ; if ( mask & KADM5_TL_DATA ) { for ( tl_data_tail = entry -> tl_data ; tl_data_tail ; tl_data_tail = tl_data_tail -> tl_data_next ) { ret = krb5_dbe_update_tl_data ( handle -> context , kdb , tl_data_tail ) ; if ( ret ) goto cleanup ; } } ret = apply_keysalt_policy ( handle , entry -> policy , n_ks_tuple , ks_tuple , & new_n_ks_tuple , & new_ks_tuple ) ; if ( ret ) goto cleanup ; ret = kdb_get_active_mkey ( handle , & act_kvno , & act_mkey ) ; if ( ret ) goto cleanup ; if ( mask & KADM5_KEY_DATA ) { assert ( entry -> n_key_data == 0 ) ; } else if ( password ) { ret = krb5_dbe_cpw ( handle -> context , act_mkey , new_ks_tuple , new_n_ks_tuple , password , ( mask & KADM5_KVNO ) ? entry -> kvno : 1 , FALSE , kdb ) ; } else { ret = krb5_dbe_crk ( handle -> context , & master_keyblock , new_ks_tuple , new_n_ks_tuple , FALSE , kdb ) ; } if ( ret ) goto cleanup ; ret = krb5_dbe_update_mkvno ( handle -> context , kdb , act_kvno ) ; if ( ret ) goto cleanup ; ret = k5_kadm5_hook_create ( handle -> context , handle -> hook_handles , KADM5_HOOK_STAGE_PRECOMMIT , entry , mask , new_n_ks_tuple , new_ks_tuple , password ) ; if ( ret ) goto cleanup ; adb . admin_history_kvno = INITIAL_HIST_KVNO ; if ( mask & KADM5_POLICY ) { adb . aux_attributes = KADM5_POLICY ; adb . policy = entry -> policy ; } kdb -> mask = mask | KADM5_KEY_DATA | KADM5_PRINCIPAL ; ret = kdb_put_entry ( handle , kdb , & adb ) ; ( void ) k5_kadm5_hook_create ( handle -> context , handle -> hook_handles , KADM5_HOOK_STAGE_POSTCOMMIT , entry , mask , new_n_ks_tuple , new_ks_tuple , password ) ; cleanup : free ( new_ks_tuple ) ; krb5_db_free_principal ( handle -> context , kdb ) ; if ( have_polent ) ( void ) kadm5_free_policy_ent ( handle -> lhandle , & polent ) ; return ret ; }
CWE-000 kadm5_ret_t kadm5_modify_principal ( void * server_handle , kadm5_principal_ent_t entry , long mask ) { int ret , ret2 , i ; kadm5_policy_ent_rec pol ; krb5_boolean have_pol = FALSE ; krb5_db_entry * kdb ; krb5_tl_data * tl_data_orig ; osa_princ_ent_rec adb ; kadm5_server_handle_t handle = server_handle ; CHECK_HANDLE ( server_handle ) ; krb5_clear_error_message ( handle -> context ) ; <S2SV_StartBug> if ( ( mask & KADM5_PRINCIPAL ) || ( mask & KADM5_LAST_PWD_CHANGE ) || <S2SV_EndBug> ( mask & KADM5_MOD_TIME ) || ( mask & KADM5_MOD_NAME ) || ( mask & KADM5_MKVNO ) || ( mask & KADM5_AUX_ATTRIBUTES ) || ( mask & KADM5_KEY_DATA ) || ( mask & KADM5_LAST_SUCCESS ) || ( mask & KADM5_LAST_FAILED ) ) return KADM5_BAD_MASK ; if ( ( mask & ~ ALL_PRINC_MASK ) ) return KADM5_BAD_MASK ; <S2SV_StartBug> if ( ( mask & KADM5_POLICY ) && ( mask & KADM5_POLICY_CLR ) ) <S2SV_EndBug> return KADM5_BAD_MASK ; <S2SV_StartBug> if ( entry == ( kadm5_principal_ent_t ) NULL ) <S2SV_EndBug> return EINVAL ; if ( mask & KADM5_TL_DATA ) { tl_data_orig = entry -> tl_data ; while ( tl_data_orig ) { if ( tl_data_orig -> tl_data_type < 256 ) return KADM5_BAD_TL_TYPE ; tl_data_orig = tl_data_orig -> tl_data_next ; } } ret = kdb_get_entry ( handle , entry -> principal , & kdb , & adb ) ; if ( ret ) return ( ret ) ; if ( ( mask & KADM5_POLICY ) ) { ret = get_policy ( handle , entry -> policy , & pol , & have_pol ) ; if ( ret ) goto done ; adb . aux_attributes |= KADM5_POLICY ; if ( adb . policy ) free ( adb . policy ) ; adb . policy = strdup ( entry -> policy ) ; } if ( have_pol ) { if ( pol . pw_max_life ) { ret = krb5_dbe_lookup_last_pwd_change ( handle -> context , kdb , & ( kdb -> pw_expiration ) ) ; if ( ret ) goto done ; kdb -> pw_expiration += pol . pw_max_life ; } else { kdb -> pw_expiration = 0 ; } } if ( ( mask & KADM5_POLICY_CLR ) && ( adb . aux_attributes & KADM5_POLICY ) ) { free ( adb . policy ) ; adb . policy = NULL ; adb . aux_attributes &= ~ KADM5_POLICY ; kdb -> pw_expiration = 0 ; } if ( ( mask & KADM5_ATTRIBUTES ) ) kdb -> attributes = entry -> attributes ; if ( ( mask & KADM5_MAX_LIFE ) ) kdb -> max_life = entry -> max_life ; if ( ( mask & KADM5_PRINC_EXPIRE_TIME ) ) kdb -> expiration = entry -> princ_expire_time ; if ( mask & KADM5_PW_EXPIRATION ) kdb -> pw_expiration = entry -> pw_expiration ; if ( mask & KADM5_MAX_RLIFE ) kdb -> max_renewable_life = entry -> max_renewable_life ; if ( ( mask & KADM5_KVNO ) ) { for ( i = 0 ; i < kdb -> n_key_data ; i ++ ) kdb -> key_data [ i ] . key_data_kvno = entry -> kvno ; } if ( mask & KADM5_TL_DATA ) { krb5_tl_data * tl ; for ( tl = entry -> tl_data ; tl ; tl = tl -> tl_data_next ) { ret = krb5_dbe_update_tl_data ( handle -> context , kdb , tl ) ; if ( ret ) { goto done ; } } } if ( mask & KADM5_FAIL_AUTH_COUNT ) { if ( entry -> fail_auth_count != 0 ) { ret = KADM5_BAD_SERVER_PARAMS ; goto done ; } kdb -> fail_auth_count = 0 ; } kdb -> mask = mask ; ret = k5_kadm5_hook_modify ( handle -> context , handle -> hook_handles , KADM5_HOOK_STAGE_PRECOMMIT , entry , mask ) ; if ( ret ) goto done ; ret = kdb_put_entry ( handle , kdb , & adb ) ; if ( ret ) goto done ; ( void ) k5_kadm5_hook_modify ( handle -> context , handle -> hook_handles , KADM5_HOOK_STAGE_POSTCOMMIT , entry , mask ) ; ret = KADM5_OK ; done : if ( have_pol ) { ret2 = kadm5_free_policy_ent ( handle -> lhandle , & pol ) ; ret = ret ? ret : ret2 ; } kdb_free_entry ( handle , kdb , & adb ) ; return ret ; }
CWE-000 krb5_error_code setup_server_realm ( krb5_principal sprinc ) { krb5_error_code kret ; kdc_realm_t * newrealm ; <S2SV_StartBug> kret = 0 ; <S2SV_EndBug> if ( kdc_numrealms > 1 ) { if ( ! ( newrealm = find_realm_data ( sprinc -> realm . data , ( krb5_ui_4 ) sprinc -> realm . length ) ) ) kret = ENOENT ; else kdc_active_realm = newrealm ; } else kdc_active_realm = kdc_realmlist [ 0 ] ; return ( kret ) ; }
CWE-000 static void check_1_6_dummy ( kadm5_principal_ent_t entry , long mask , int n_ks_tuple , krb5_key_salt_tuple * ks_tuple , char * * passptr ) { int i ; char * password = * passptr ; <S2SV_StartBug> if ( ! ( mask & KADM5_ATTRIBUTES ) || <S2SV_EndBug> ! ( entry -> attributes & KRB5_KDB_DISALLOW_ALL_TIX ) ) return ; for ( i = 0 ; ( unsigned char ) password [ i ] == i + 1 ; i ++ ) ; if ( password [ i ] != '\\0' || i != 255 ) return ; * passptr = NULL ; }
CWE-000 static krb5_error_code krb5_ldap_get_password_policy_from_dn ( krb5_context context , char * pol_name , char * pol_dn , osa_policy_ent_t * policy ) { krb5_error_code st = 0 , tempst = 0 ; LDAP * ld = NULL ; LDAPMessage * result = NULL , * ent = NULL ; kdb5_dal_handle * dal_handle = NULL ; krb5_ldap_context * ldap_context = NULL ; krb5_ldap_server_handle * ldap_server_handle = NULL ; krb5_clear_error_message ( context ) ; if ( pol_dn == NULL ) return EINVAL ; * policy = NULL ; SETUP_CONTEXT ( ) ; GET_HANDLE ( ) ; * ( policy ) = ( osa_policy_ent_t ) malloc ( sizeof ( osa_policy_ent_rec ) ) ; if ( * policy == NULL ) { st = ENOMEM ; goto cleanup ; } memset ( * policy , 0 , sizeof ( osa_policy_ent_rec ) ) ; LDAP_SEARCH ( pol_dn , LDAP_SCOPE_BASE , "(objectclass=krbPwdPolicy)" , password_policy_attributes ) ; ent = ldap_first_entry ( ld , result ) ; <S2SV_StartBug> if ( ent != NULL ) { <S2SV_EndBug> if ( ( st = populate_policy ( context , ld , ent , pol_name , * policy ) ) != 0 ) goto cleanup ; } <S2SV_StartBug> cleanup : <S2SV_EndBug> ldap_msgfree ( result ) ; if ( st != 0 ) { if ( * policy != NULL ) { krb5_ldap_free_password_policy ( context , * policy ) ; * policy = NULL ; } } krb5_ldap_put_handle_to_pool ( ldap_context , ldap_server_handle ) ; return st ; }
CWE-000 static krb5_error_code pkinit_server_return_padata ( krb5_context context , krb5_pa_data * padata , krb5_data * req_pkt , krb5_kdc_req * request , krb5_kdc_rep * reply , krb5_keyblock * encrypting_key , krb5_pa_data * * send_pa , krb5_kdcpreauth_callbacks cb , krb5_kdcpreauth_rock rock , krb5_kdcpreauth_moddata moddata , krb5_kdcpreauth_modreq modreq ) { krb5_error_code retval = 0 ; krb5_data scratch = { 0 , 0 , NULL } ; krb5_pa_pk_as_req * reqp = NULL ; krb5_pa_pk_as_req_draft9 * reqp9 = NULL ; int i = 0 ; unsigned char * subjectPublicKey = NULL ; unsigned char * dh_pubkey = NULL , * server_key = NULL ; unsigned int subjectPublicKey_len = 0 ; unsigned int server_key_len = 0 , dh_pubkey_len = 0 ; krb5_kdc_dh_key_info dhkey_info ; krb5_data * encoded_dhkey_info = NULL ; krb5_pa_pk_as_rep * rep = NULL ; krb5_pa_pk_as_rep_draft9 * rep9 = NULL ; krb5_data * out_data = NULL ; krb5_octet_data secret ; krb5_enctype enctype = - 1 ; krb5_reply_key_pack * key_pack = NULL ; krb5_reply_key_pack_draft9 * key_pack9 = NULL ; krb5_data * encoded_key_pack = NULL ; pkinit_kdc_context plgctx ; pkinit_kdc_req_context reqctx ; int fixed_keypack = 0 ; * send_pa = NULL ; if ( padata -> pa_type == KRB5_PADATA_PKINIT_KX ) { return return_pkinit_kx ( context , request , reply , encrypting_key , send_pa ) ; } if ( padata -> length <= 0 || padata -> contents == NULL ) return 0 ; if ( modreq == NULL ) { pkiDebug ( "missing<S2SV_blank>request<S2SV_blank>context<S2SV_blank>\\n" ) ; return EINVAL ; } plgctx = pkinit_find_realm_context ( context , moddata , request -> server ) ; if ( plgctx == NULL ) { pkiDebug ( "Unable<S2SV_blank>to<S2SV_blank>locate<S2SV_blank>correct<S2SV_blank>realm<S2SV_blank>context\\n" ) ; return ENOENT ; } pkiDebug ( "pkinit_return_padata:<S2SV_blank>entered!\\n" ) ; reqctx = ( pkinit_kdc_req_context ) modreq ; if ( encrypting_key -> contents ) { free ( encrypting_key -> contents ) ; encrypting_key -> length = 0 ; encrypting_key -> contents = NULL ; } for ( i = 0 ; i < request -> nktypes ; i ++ ) { enctype = request -> ktype [ i ] ; if ( ! krb5_c_valid_enctype ( enctype ) ) continue ; else { pkiDebug ( "KDC<S2SV_blank>picked<S2SV_blank>etype<S2SV_blank>=<S2SV_blank>%d\\n" , enctype ) ; break ; } } if ( i == request -> nktypes ) { retval = KRB5KDC_ERR_ETYPE_NOSUPP ; goto cleanup ; } switch ( ( int ) reqctx -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : init_krb5_pa_pk_as_rep ( & rep ) ; if ( rep == NULL ) { retval = ENOMEM ; goto cleanup ; } rep -> choice = choice_pa_pk_as_rep_encKeyPack ; break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : init_krb5_pa_pk_as_rep_draft9 ( & rep9 ) ; if ( rep9 == NULL ) { retval = ENOMEM ; goto cleanup ; } rep9 -> choice = choice_pa_pk_as_rep_draft9_encKeyPack ; break ; default : retval = KRB5KDC_ERR_PREAUTH_FAILED ; goto cleanup ; } if ( reqctx -> rcv_auth_pack != NULL && reqctx -> rcv_auth_pack -> clientPublicValue != NULL ) { subjectPublicKey = reqctx -> rcv_auth_pack -> clientPublicValue -> subjectPublicKey . data ; subjectPublicKey_len = reqctx -> rcv_auth_pack -> clientPublicValue -> subjectPublicKey . length ; rep -> choice = choice_pa_pk_as_rep_dhInfo ; } else if ( reqctx -> rcv_auth_pack9 != NULL && reqctx -> rcv_auth_pack9 -> clientPublicValue != NULL ) { subjectPublicKey = reqctx -> rcv_auth_pack9 -> clientPublicValue -> subjectPublicKey . data ; subjectPublicKey_len = reqctx -> rcv_auth_pack9 -> clientPublicValue -> subjectPublicKey . length ; rep9 -> choice = choice_pa_pk_as_rep_draft9_dhSignedData ; } if ( rep != NULL && ( rep -> choice == choice_pa_pk_as_rep_dhInfo || rep -> choice == choice_pa_pk_as_rep_draft9_dhSignedData ) ) { pkiDebug ( "received<S2SV_blank>DH<S2SV_blank>key<S2SV_blank>delivery<S2SV_blank>AS<S2SV_blank>REQ\\n" ) ; retval = server_process_dh ( context , plgctx -> cryptoctx , reqctx -> cryptoctx , plgctx -> idctx , subjectPublicKey , subjectPublicKey_len , & dh_pubkey , & dh_pubkey_len , & server_key , & server_key_len ) ; if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>process/create<S2SV_blank>dh<S2SV_blank>paramters\\n" ) ; goto cleanup ; } } if ( ( rep9 != NULL && rep9 -> choice == choice_pa_pk_as_rep_draft9_dhSignedData ) || ( rep != NULL && rep -> choice == choice_pa_pk_as_rep_dhInfo ) ) { dhkey_info . subjectPublicKey . length = dh_pubkey_len ; dhkey_info . subjectPublicKey . data = dh_pubkey ; dhkey_info . nonce = request -> nonce ; dhkey_info . dhKeyExpiration = 0 ; retval = k5int_encode_krb5_kdc_dh_key_info ( & dhkey_info , & encoded_dhkey_info ) ; if ( retval ) { pkiDebug ( "encode_krb5_kdc_dh_key_info<S2SV_blank>failed\\n" ) ; goto cleanup ; } # ifdef DEBUG_ASN1 print_buffer_bin ( ( unsigned char * ) encoded_dhkey_info -> data , encoded_dhkey_info -> length , "/tmp/kdc_dh_key_info" ) ; # endif switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : retval = cms_signeddata_create ( context , plgctx -> cryptoctx , reqctx -> cryptoctx , plgctx -> idctx , CMS_SIGN_SERVER , 1 , ( unsigned char * ) encoded_dhkey_info -> data , encoded_dhkey_info -> length , & rep -> u . dh_Info . dhSignedData . data , & rep -> u . dh_Info . dhSignedData . length ) ; if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>create<S2SV_blank>pkcs7<S2SV_blank>signed<S2SV_blank>data\\n" ) ; goto cleanup ; } break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : retval = cms_signeddata_create ( context , plgctx -> cryptoctx , reqctx -> cryptoctx , plgctx -> idctx , CMS_SIGN_DRAFT9 , 1 , ( unsigned char * ) encoded_dhkey_info -> data , encoded_dhkey_info -> length , & rep9 -> u . dhSignedData . data , & rep9 -> u . dhSignedData . length ) ; if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>create<S2SV_blank>pkcs7<S2SV_blank>signed<S2SV_blank>data\\n" ) ; goto cleanup ; } break ; } } else { pkiDebug ( "received<S2SV_blank>RSA<S2SV_blank>key<S2SV_blank>delivery<S2SV_blank>AS<S2SV_blank>REQ\\n" ) ; retval = krb5_c_make_random_key ( context , enctype , encrypting_key ) ; if ( retval ) { pkiDebug ( "unable<S2SV_blank>to<S2SV_blank>make<S2SV_blank>a<S2SV_blank>session<S2SV_blank>key\\n" ) ; goto cleanup ; } for ( i = 0 ; request -> padata [ i ] != NULL ; i ++ ) { pkiDebug ( "%s:<S2SV_blank>Checking<S2SV_blank>pa_type<S2SV_blank>0x%08x\\n" , __FUNCTION__ , request -> padata [ i ] -> pa_type ) ; if ( request -> padata [ i ] -> pa_type == 132 ) fixed_keypack = 1 ; } pkiDebug ( "%s:<S2SV_blank>return<S2SV_blank>checksum<S2SV_blank>instead<S2SV_blank>of<S2SV_blank>nonce<S2SV_blank>=<S2SV_blank>%d\\n" , __FUNCTION__ , fixed_keypack ) ; if ( ( int ) padata -> pa_type == KRB5_PADATA_PK_AS_REQ || fixed_keypack ) { init_krb5_reply_key_pack ( & key_pack ) ; if ( key_pack == NULL ) { retval = ENOMEM ; goto cleanup ; } retval = krb5_c_make_checksum ( context , 0 , encrypting_key , KRB5_KEYUSAGE_TGS_REQ_AUTH_CKSUM , req_pkt , & key_pack -> asChecksum ) ; if ( retval ) { pkiDebug ( "unable<S2SV_blank>to<S2SV_blank>calculate<S2SV_blank>AS<S2SV_blank>REQ<S2SV_blank>checksum\\n" ) ; goto cleanup ; } # ifdef DEBUG_CKSUM pkiDebug ( "calculating<S2SV_blank>checksum<S2SV_blank>on<S2SV_blank>buf<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d\\n" , req_pkt -> length ) ; print_buffer ( req_pkt -> data , req_pkt -> length ) ; pkiDebug ( "checksum<S2SV_blank>size<S2SV_blank>=<S2SV_blank>%d\\n" , key_pack -> asChecksum . length ) ; print_buffer ( key_pack -> asChecksum . contents , key_pack -> asChecksum . length ) ; pkiDebug ( "encrypting<S2SV_blank>key<S2SV_blank>(%d)\\n" , encrypting_key -> length ) ; print_buffer ( encrypting_key -> contents , encrypting_key -> length ) ; # endif krb5_copy_keyblock_contents ( context , encrypting_key , & key_pack -> replyKey ) ; retval = k5int_encode_krb5_reply_key_pack ( key_pack , & encoded_key_pack ) ; if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>encode<S2SV_blank>reply_key_pack\\n" ) ; goto cleanup ; } } switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : rep -> choice = choice_pa_pk_as_rep_encKeyPack ; retval = cms_envelopeddata_create ( context , plgctx -> cryptoctx , reqctx -> cryptoctx , plgctx -> idctx , padata -> pa_type , 1 , ( unsigned char * ) encoded_key_pack -> data , encoded_key_pack -> length , & rep -> u . encKeyPack . data , & rep -> u . encKeyPack . length ) ; break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : if ( ! fixed_keypack ) { init_krb5_reply_key_pack_draft9 ( & key_pack9 ) ; if ( key_pack9 == NULL ) { retval = ENOMEM ; goto cleanup ; } key_pack9 -> nonce = reqctx -> rcv_auth_pack9 -> pkAuthenticator . nonce ; krb5_copy_keyblock_contents ( context , encrypting_key , & key_pack9 -> replyKey ) ; retval = k5int_encode_krb5_reply_key_pack_draft9 ( key_pack9 , & encoded_key_pack ) ; if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>encode<S2SV_blank>reply_key_pack\\n" ) ; goto cleanup ; } } rep9 -> choice = choice_pa_pk_as_rep_draft9_encKeyPack ; retval = cms_envelopeddata_create ( context , plgctx -> cryptoctx , reqctx -> cryptoctx , plgctx -> idctx , padata -> pa_type , 1 , ( unsigned char * ) encoded_key_pack -> data , encoded_key_pack -> length , & rep9 -> u . encKeyPack . data , & rep9 -> u . encKeyPack . length ) ; break ; } if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>create<S2SV_blank>pkcs7<S2SV_blank>enveloped<S2SV_blank>data:<S2SV_blank>%s\\n" , error_message ( retval ) ) ; goto cleanup ; } # ifdef DEBUG_ASN1 print_buffer_bin ( ( unsigned char * ) encoded_key_pack -> data , encoded_key_pack -> length , "/tmp/kdc_key_pack" ) ; switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : print_buffer_bin ( rep -> u . encKeyPack . data , rep -> u . encKeyPack . length , "/tmp/kdc_enc_key_pack" ) ; break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : print_buffer_bin ( rep9 -> u . encKeyPack . data , rep9 -> u . encKeyPack . length , "/tmp/kdc_enc_key_pack" ) ; break ; } # endif } if ( ( rep != NULL && rep -> choice == choice_pa_pk_as_rep_dhInfo ) && ( ( reqctx -> rcv_auth_pack != NULL && reqctx -> rcv_auth_pack -> supportedKDFs != NULL ) ) ) { if ( reqctx -> rcv_auth_pack != NULL && reqctx -> rcv_auth_pack -> supportedKDFs != NULL ) { retval = pkinit_pick_kdf_alg ( context , reqctx -> rcv_auth_pack -> supportedKDFs , & ( rep -> u . dh_Info . kdfID ) ) ; if ( retval ) { pkiDebug ( "pkinit_pick_kdf_alg<S2SV_blank>failed:<S2SV_blank>%s\\n" , error_message ( retval ) ) ; goto cleanup ; } } } switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : retval = k5int_encode_krb5_pa_pk_as_rep ( rep , & out_data ) ; break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : retval = k5int_encode_krb5_pa_pk_as_rep_draft9 ( rep9 , & out_data ) ; break ; } if ( retval ) { pkiDebug ( "failed<S2SV_blank>to<S2SV_blank>encode<S2SV_blank>AS_REP\\n" ) ; goto cleanup ; } # ifdef DEBUG_ASN1 if ( out_data != NULL ) print_buffer_bin ( ( unsigned char * ) out_data -> data , out_data -> length , "/tmp/kdc_as_rep" ) ; # endif if ( ( rep9 != NULL && rep9 -> choice == choice_pa_pk_as_rep_draft9_dhSignedData ) || ( rep != NULL && rep -> choice == choice_pa_pk_as_rep_dhInfo ) ) { <S2SV_StartBug> if ( rep -> u . dh_Info . kdfID ) { <S2SV_EndBug> <S2SV_StartBug> secret . data = server_key ; <S2SV_EndBug> secret . length = server_key_len ; retval = pkinit_alg_agility_kdf ( context , & secret , rep -> u . dh_Info . kdfID , request -> client , request -> server , enctype , ( krb5_octet_data * ) req_pkt , ( krb5_octet_data * ) out_data , encrypting_key ) ; if ( retval ) { pkiDebug ( "pkinit_alg_agility_kdf<S2SV_blank>failed:<S2SV_blank>%s\\n" , error_message ( retval ) ) ; goto cleanup ; } } else { retval = pkinit_octetstring2key ( context , enctype , server_key , server_key_len , encrypting_key ) ; if ( retval ) { pkiDebug ( "pkinit_octetstring2key<S2SV_blank>failed:<S2SV_blank>%s\\n" , error_message ( retval ) ) ; goto cleanup ; } } } * send_pa = malloc ( sizeof ( krb5_pa_data ) ) ; if ( * send_pa == NULL ) { retval = ENOMEM ; free ( out_data -> data ) ; free ( out_data ) ; out_data = NULL ; goto cleanup ; } ( * send_pa ) -> magic = KV5M_PA_DATA ; switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : ( * send_pa ) -> pa_type = KRB5_PADATA_PK_AS_REP ; break ; case KRB5_PADATA_PK_AS_REQ_OLD : case KRB5_PADATA_PK_AS_REP_OLD : ( * send_pa ) -> pa_type = KRB5_PADATA_PK_AS_REP_OLD ; break ; } ( * send_pa ) -> length = out_data -> length ; ( * send_pa ) -> contents = ( krb5_octet * ) out_data -> data ; cleanup : pkinit_fini_kdc_req_context ( context , reqctx ) ; free ( scratch . data ) ; free ( out_data ) ; if ( encoded_dhkey_info != NULL ) krb5_free_data ( context , encoded_dhkey_info ) ; if ( encoded_key_pack != NULL ) krb5_free_data ( context , encoded_key_pack ) ; free ( dh_pubkey ) ; free ( server_key ) ; switch ( ( int ) padata -> pa_type ) { case KRB5_PADATA_PK_AS_REQ : free_krb5_pa_pk_as_req ( & reqp ) ; free_krb5_pa_pk_as_rep ( & rep ) ; free_krb5_reply_key_pack ( & key_pack ) ; break ; case KRB5_PADATA_PK_AS_REP_OLD : case KRB5_PADATA_PK_AS_REQ_OLD : free_krb5_pa_pk_as_req_draft9 ( & reqp9 ) ; free_krb5_pa_pk_as_rep_draft9 ( & rep9 ) ; if ( ! fixed_keypack ) free_krb5_reply_key_pack_draft9 ( & key_pack9 ) ; else free_krb5_reply_key_pack ( & key_pack ) ; break ; } if ( retval ) pkiDebug ( "pkinit_verify_padata<S2SV_blank>failure" ) ; return retval ; }
CWE-000 krb5_error_code pkinit_check_kdc_pkid ( krb5_context context , pkinit_plg_crypto_context plg_cryptoctx , pkinit_req_crypto_context req_cryptoctx , pkinit_identity_crypto_context id_cryptoctx , unsigned char * pdid_buf , unsigned int pkid_len , int * valid_kdcPkId ) { krb5_error_code retval = KRB5KDC_ERR_PREAUTH_FAILED ; PKCS7_ISSUER_AND_SERIAL * is = NULL ; const unsigned char * p = pdid_buf ; int status = 1 ; X509 * kdc_cert = sk_X509_value ( id_cryptoctx -> my_certs , id_cryptoctx -> cert_index ) ; * valid_kdcPkId = 0 ; pkiDebug ( "found<S2SV_blank>kdcPkId<S2SV_blank>in<S2SV_blank>AS<S2SV_blank>REQ\\n" ) ; is = d2i_PKCS7_ISSUER_AND_SERIAL ( NULL , & p , ( int ) pkid_len ) ; if ( is == NULL ) <S2SV_StartBug> goto cleanup ; <S2SV_EndBug> status = X509_NAME_cmp ( X509_get_issuer_name ( kdc_cert ) , is -> issuer ) ; if ( ! status ) { status = ASN1_INTEGER_cmp ( X509_get_serialNumber ( kdc_cert ) , is -> serial ) ; if ( ! status ) * valid_kdcPkId = 1 ; } retval = 0 ; <S2SV_StartBug> cleanup : <S2SV_EndBug> X509_NAME_free ( is -> issuer ) ; ASN1_INTEGER_free ( is -> serial ) ; free ( is ) ; return retval ; }
CWE-000 PHYSICALPATH_FUNC ( mod_alias_physical_handler ) { plugin_data * p = p_d ; int uri_len , basedir_len ; char * uri_ptr ; size_t k ; if ( buffer_is_empty ( con -> physical . path ) ) return HANDLER_GO_ON ; mod_alias_patch_connection ( srv , con , p ) ; basedir_len = buffer_string_length ( con -> physical . basedir ) ; if ( '/' == con -> physical . basedir -> ptr [ basedir_len - 1 ] ) -- basedir_len ; uri_len = buffer_string_length ( con -> physical . path ) - basedir_len ; uri_ptr = con -> physical . path -> ptr + basedir_len ; for ( k = 0 ; k < p -> conf . alias -> used ; k ++ ) { data_string * ds = ( data_string * ) p -> conf . alias -> data [ k ] ; int alias_len = buffer_string_length ( ds -> key ) ; if ( alias_len > uri_len ) continue ; if ( buffer_is_empty ( ds -> key ) ) continue ; if ( 0 == ( con -> conf . force_lowercase_filenames ? strncasecmp ( uri_ptr , ds -> key -> ptr , alias_len ) : strncmp ( uri_ptr , ds -> key -> ptr , alias_len ) ) ) { <S2SV_StartBug> buffer_copy_buffer ( con -> physical . basedir , ds -> value ) ; <S2SV_EndBug> buffer_copy_buffer ( srv -> tmp_buf , ds -> value ) ; buffer_append_string ( srv -> tmp_buf , uri_ptr + alias_len ) ; buffer_copy_buffer ( con -> physical . path , srv -> tmp_buf ) ; return HANDLER_GO_ON ; } } return HANDLER_GO_ON ; }
CWE-000 long jpc_bitstream_getbits ( jpc_bitstream_t * bitstream , int n ) { long v ; int u ; <S2SV_StartBug> assert ( n >= 0 && n < 32 ) ; <S2SV_EndBug> v = 0 ; while ( -- n >= 0 ) { if ( ( u = jpc_bitstream_getbit ( bitstream ) ) < 0 ) { return - 1 ; } v = ( v << 1 ) | u ; } return v ; }
CWE-000 int jpc_bitstream_putbits ( jpc_bitstream_t * bitstream , int n , long v ) { int m ; <S2SV_StartBug> assert ( n >= 0 && n < 32 ) ; <S2SV_EndBug> assert ( ! ( v & ( ~ JAS_ONES ( n ) ) ) ) ; m = n - 1 ; while ( -- n >= 0 ) { if ( jpc_bitstream_putbit ( bitstream , ( v >> m ) & 1 ) == EOF ) { return EOF ; } v <<= 1 ; } return 0 ; }
CWE-000 static int jpc_qcd_dumpparms ( jpc_ms_t * ms , FILE * out ) { jpc_qcd_t * qcd = & ms -> parms . qcd ; int i ; fprintf ( out , "qntsty<S2SV_blank>=<S2SV_blank>%d;<S2SV_blank>numguard<S2SV_blank>=<S2SV_blank>%d;<S2SV_blank>numstepsizes<S2SV_blank>=<S2SV_blank>%d\\n" , ( int ) qcd -> compparms . qntsty , qcd -> compparms . numguard , qcd -> compparms . numstepsizes ) ; for ( i = 0 ; i < qcd -> compparms . numstepsizes ; ++ i ) { fprintf ( out , "expn[%d]<S2SV_blank>=<S2SV_blank>0x%04x;<S2SV_blank>mant[%d]<S2SV_blank>=<S2SV_blank>0x%04x;\\n" , <S2SV_StartBug> i , ( unsigned ) JPC_QCX_GETEXPN ( qcd -> compparms . stepsizes [ i ] ) , <S2SV_EndBug> <S2SV_StartBug> i , ( unsigned ) JPC_QCX_GETMANT ( qcd -> compparms . stepsizes [ i ] ) ) ; <S2SV_EndBug> } return 0 ; }
CWE-000 static int ras_getcmap ( jas_stream_t * in , ras_hdr_t * hdr , ras_cmap_t * cmap ) { int i ; int j ; int x ; int c ; int numcolors ; int actualnumcolors ; switch ( hdr -> maptype ) { case RAS_MT_NONE : break ; case RAS_MT_EQUALRGB : { jas_eprintf ( "warning:<S2SV_blank>palettized<S2SV_blank>images<S2SV_blank>not<S2SV_blank>fully<S2SV_blank>supported\\n" ) ; numcolors = 1 << hdr -> depth ; <S2SV_StartBug> assert ( numcolors <= RAS_CMAP_MAXSIZ ) ; <S2SV_EndBug> actualnumcolors = hdr -> maplength / 3 ; for ( i = 0 ; i < numcolors ; i ++ ) { cmap -> data [ i ] = 0 ; } if ( ( hdr -> maplength % 3 ) || hdr -> maplength < 0 || hdr -> maplength > 3 * numcolors ) { return - 1 ; } for ( i = 0 ; i < 3 ; i ++ ) { for ( j = 0 ; j < actualnumcolors ; j ++ ) { if ( ( c = jas_stream_getc ( in ) ) == EOF ) { return - 1 ; } x = 0 ; switch ( i ) { case 0 : x = RAS_RED ( c ) ; break ; case 1 : x = RAS_GREEN ( c ) ; break ; case 2 : x = RAS_BLUE ( c ) ; break ; } cmap -> data [ j ] |= x ; } } } break ; default : return - 1 ; break ; } return 0 ; }
CWE-000 static int ras_getdatastd ( jas_stream_t * in , ras_hdr_t * hdr , ras_cmap_t * cmap , jas_image_t * image ) { int pad ; int nz ; int z ; int c ; int y ; int x ; int v ; int i ; jas_matrix_t * data [ 3 ] ; cmap = 0 ; <S2SV_StartBug> for ( i = 0 ; i < jas_image_numcmpts ( image ) ; ++ i ) { <S2SV_EndBug> <S2SV_StartBug> data [ i ] = jas_matrix_create ( 1 , jas_image_width ( image ) ) ; <S2SV_EndBug> assert ( data [ i ] ) ; } pad = RAS_ROWSIZE ( hdr ) - ( hdr -> width * hdr -> depth + 7 ) / 8 ; for ( y = 0 ; y < hdr -> height ; y ++ ) { nz = 0 ; z = 0 ; for ( x = 0 ; x < hdr -> width ; x ++ ) { while ( nz < hdr -> depth ) { if ( ( c = jas_stream_getc ( in ) ) == EOF ) { <S2SV_StartBug> return - 1 ; <S2SV_EndBug> } <S2SV_StartBug> z = ( z << 8 ) | c ; <S2SV_EndBug> nz += 8 ; } v = ( z >> ( nz - hdr -> depth ) ) & RAS_ONES ( hdr -> depth ) ; z &= RAS_ONES ( nz - hdr -> depth ) ; nz -= hdr -> depth ; if ( jas_image_numcmpts ( image ) == 3 ) { jas_matrix_setv ( data [ 0 ] , x , ( RAS_GETRED ( v ) ) ) ; jas_matrix_setv ( data [ 1 ] , x , ( RAS_GETGREEN ( v ) ) ) ; jas_matrix_setv ( data [ 2 ] , x , ( RAS_GETBLUE ( v ) ) ) ; } else { jas_matrix_setv ( data [ 0 ] , x , ( v ) ) ; } } if ( pad ) { if ( ( c = jas_stream_getc ( in ) ) == EOF ) { return - 1 ; } } for ( i = 0 ; i < jas_image_numcmpts ( image ) ; ++ i ) { if ( jas_image_writecmpt ( image , i , 0 , y , hdr -> width , 1 , data [ i ] ) ) { return - 1 ; } } } for ( i = 0 ; i < jas_image_numcmpts ( image ) ; ++ i ) { jas_matrix_destroy ( data [ i ] ) ; } return 0 ; }
CWE-000 static int ras_putdatastd ( jas_stream_t * out , ras_hdr_t * hdr , jas_image_t * image , int numcmpts , int * cmpts ) { int rowsize ; int pad ; unsigned int z ; int nz ; int c ; int x ; int y ; int v ; jas_matrix_t * data [ 3 ] ; int i ; <S2SV_StartBug> for ( i = 0 ; i < numcmpts ; ++ i ) { <S2SV_EndBug> <S2SV_StartBug> data [ i ] = jas_matrix_create ( jas_image_height ( image ) , jas_image_width ( image ) ) ; <S2SV_EndBug> assert ( data [ i ] ) ; } rowsize = RAS_ROWSIZE ( hdr ) ; pad = rowsize - ( hdr -> width * hdr -> depth + 7 ) / 8 ; hdr -> length = hdr -> height * rowsize ; for ( y = 0 ; y < hdr -> height ; y ++ ) { for ( i = 0 ; i < numcmpts ; ++ i ) { if ( jas_image_readcmpt ( image , cmpts [ i ] , 0 , y , jas_image_width ( image ) , 1 , data [ i ] ) ) { <S2SV_StartBug> return - 1 ; <S2SV_EndBug> } } z = 0 ; nz = 0 ; for ( x = 0 ; x < hdr -> width ; x ++ ) { z <<= hdr -> depth ; if ( RAS_ISRGB ( hdr ) ) { v = RAS_RED ( ( jas_matrix_getv ( data [ 0 ] , x ) ) ) | RAS_GREEN ( ( jas_matrix_getv ( data [ 1 ] , x ) ) ) | RAS_BLUE ( ( jas_matrix_getv ( data [ 2 ] , x ) ) ) ; } else { v = ( jas_matrix_getv ( data [ 0 ] , x ) ) ; } z |= v & RAS_ONES ( hdr -> depth ) ; nz += hdr -> depth ; while ( nz >= 8 ) { c = ( z >> ( nz - 8 ) ) & 0xff ; if ( jas_stream_putc ( out , c ) == EOF ) { <S2SV_StartBug> return - 1 ; <S2SV_EndBug> } <S2SV_StartBug> nz -= 8 ; <S2SV_EndBug> z &= RAS_ONES ( nz ) ; } } if ( nz > 0 ) { c = ( z >> ( 8 - nz ) ) & RAS_ONES ( nz ) ; if ( jas_stream_putc ( out , c ) == EOF ) { return - 1 ; } } if ( pad % 2 ) { if ( jas_stream_putc ( out , 0 ) == EOF ) { return - 1 ; } } } for ( i = 0 ; i < numcmpts ; ++ i ) { jas_matrix_destroy ( data [ i ] ) ; } return 0 ; }
CWE-000 static int jpc_dec_tiledecode ( jpc_dec_t * dec , jpc_dec_tile_t * tile ) { int i ; int j ; jpc_dec_tcomp_t * tcomp ; jpc_dec_rlvl_t * rlvl ; jpc_dec_band_t * band ; int compno ; int rlvlno ; int bandno ; int adjust ; int v ; jpc_dec_ccp_t * ccp ; jpc_dec_cmpt_t * cmpt ; if ( jpc_dec_decodecblks ( dec , tile ) ) { jas_eprintf ( "jpc_dec_decodecblks<S2SV_blank>failed\\n" ) ; return - 1 ; } for ( compno = 0 , tcomp = tile -> tcomps ; compno < dec -> numcomps ; ++ compno , ++ tcomp ) { ccp = & tile -> cp -> ccps [ compno ] ; for ( rlvlno = 0 , rlvl = tcomp -> rlvls ; rlvlno < tcomp -> numrlvls ; ++ rlvlno , ++ rlvl ) { if ( ! rlvl -> bands ) { continue ; } for ( bandno = 0 , band = rlvl -> bands ; bandno < rlvl -> numbands ; ++ bandno , ++ band ) { if ( ! band -> data ) { continue ; } jpc_undo_roi ( band -> data , band -> roishift , ccp -> roishift - band -> roishift , band -> numbps ) ; if ( tile -> realmode ) { jas_matrix_asl ( band -> data , JPC_FIX_FRACBITS ) ; jpc_dequantize ( band -> data , band -> absstepsize ) ; } } } } for ( compno = 0 , tcomp = tile -> tcomps ; compno < dec -> numcomps ; ++ compno , ++ tcomp ) { ccp = & tile -> cp -> ccps [ compno ] ; jpc_tsfb_synthesize ( tcomp -> tsfb , tcomp -> data ) ; } switch ( tile -> cp -> mctid ) { case JPC_MCT_RCT : if ( dec -> numcomps < 3 ) { <S2SV_StartBug> jas_eprintf ( "RCT<S2SV_blank>requires<S2SV_blank>at<S2SV_blank>least<S2SV_blank>three<S2SV_blank>components\\n" ) ; <S2SV_EndBug> return - 1 ; } jpc_irct ( tile -> tcomps [ 0 ] . data , tile -> tcomps [ 1 ] . data , tile -> tcomps [ 2 ] . data ) ; break ; case JPC_MCT_ICT : if ( dec -> numcomps < 3 ) { jas_eprintf ( "ICT<S2SV_blank>requires<S2SV_blank>at<S2SV_blank>least<S2SV_blank>three<S2SV_blank>components\\n" ) ; return - 1 ; } <S2SV_StartBug> jpc_iict ( tile -> tcomps [ 0 ] . data , tile -> tcomps [ 1 ] . data , <S2SV_EndBug> tile -> tcomps [ 2 ] . data ) ; break ; } if ( tile -> realmode ) { for ( compno = 0 , tcomp = tile -> tcomps ; compno < dec -> numcomps ; ++ compno , ++ tcomp ) { for ( i = 0 ; i < jas_matrix_numrows ( tcomp -> data ) ; ++ i ) { for ( j = 0 ; j < jas_matrix_numcols ( tcomp -> data ) ; ++ j ) { v = jas_matrix_get ( tcomp -> data , i , j ) ; v = jpc_fix_round ( v ) ; jas_matrix_set ( tcomp -> data , i , j , jpc_fixtoint ( v ) ) ; } } } } for ( compno = 0 , tcomp = tile -> tcomps , cmpt = dec -> cmpts ; compno < dec -> numcomps ; ++ compno , ++ tcomp , ++ cmpt ) { adjust = cmpt -> sgnd ? 0 : ( 1 << ( cmpt -> prec - 1 ) ) ; for ( i = 0 ; i < jas_matrix_numrows ( tcomp -> data ) ; ++ i ) { for ( j = 0 ; j < jas_matrix_numcols ( tcomp -> data ) ; ++ j ) { * jas_matrix_getref ( tcomp -> data , i , j ) += adjust ; } } } for ( compno = 0 , tcomp = tile -> tcomps , cmpt = dec -> cmpts ; compno < dec -> numcomps ; ++ compno , ++ tcomp , ++ cmpt ) { jpc_fix_t mn ; jpc_fix_t mx ; mn = cmpt -> sgnd ? ( - ( 1 << ( cmpt -> prec - 1 ) ) ) : ( 0 ) ; mx = cmpt -> sgnd ? ( ( 1 << ( cmpt -> prec - 1 ) ) - 1 ) : ( ( 1 << cmpt -> prec ) - 1 ) ; jas_matrix_clip ( tcomp -> data , mn , mx ) ; } for ( compno = 0 , tcomp = tile -> tcomps , cmpt = dec -> cmpts ; compno < dec -> numcomps ; ++ compno , ++ tcomp , ++ cmpt ) { if ( jas_image_writecmpt ( dec -> image , compno , tcomp -> xstart - JPC_CEILDIV ( dec -> xstart , cmpt -> hstep ) , tcomp -> ystart - JPC_CEILDIV ( dec -> ystart , cmpt -> vstep ) , jas_matrix_numcols ( tcomp -> data ) , jas_matrix_numrows ( tcomp -> data ) , tcomp -> data ) ) { jas_eprintf ( "write<S2SV_blank>component<S2SV_blank>failed\\n" ) ; return - 1 ; } } return 0 ; }
CWE-000 static Curves16Data * CurvesAlloc ( cmsContext ContextID , int nCurves , int nElements , cmsToneCurve * * G ) { int i , j ; Curves16Data * c16 ; c16 = _cmsMallocZero ( ContextID , sizeof ( Curves16Data ) ) ; if ( c16 == NULL ) return NULL ; c16 -> nCurves = nCurves ; c16 -> nElements = nElements ; c16 -> Curves = _cmsCalloc ( ContextID , nCurves , sizeof ( cmsUInt16Number * ) ) ; if ( c16 -> Curves == NULL ) return NULL ; for ( i = 0 ; i < nCurves ; i ++ ) { <S2SV_StartBug> c16 -> Curves [ i ] = _cmsCalloc ( ContextID , nElements , sizeof ( cmsUInt16Number ) ) ; <S2SV_EndBug> if ( nElements == 256 ) { for ( j = 0 ; j < nElements ; j ++ ) { c16 -> Curves [ i ] [ j ] = cmsEvalToneCurve16 ( G [ i ] , FROM_8_TO_16 ( j ) ) ; } } else { for ( j = 0 ; j < nElements ; j ++ ) { c16 -> Curves [ i ] [ j ] = cmsEvalToneCurve16 ( G [ i ] , ( cmsUInt16Number ) j ) ; } } } return c16 ; }
CWE-000 static cmsPipeline * DefaultICCintents ( cmsContext ContextID , cmsUInt32Number nProfiles , cmsUInt32Number TheIntents [ ] , cmsHPROFILE hProfiles [ ] , cmsBool BPC [ ] , cmsFloat64Number AdaptationStates [ ] , cmsUInt32Number dwFlags ) { cmsPipeline * Lut = NULL ; cmsPipeline * Result ; cmsHPROFILE hProfile ; cmsMAT3 m ; cmsVEC3 off ; cmsColorSpaceSignature ColorSpaceIn , ColorSpaceOut , CurrentColorSpace ; cmsProfileClassSignature ClassSig ; cmsUInt32Number i , Intent ; if ( nProfiles == 0 ) return NULL ; Result = cmsPipelineAlloc ( ContextID , 0 , 0 ) ; if ( Result == NULL ) return NULL ; CurrentColorSpace = cmsGetColorSpace ( hProfiles [ 0 ] ) ; for ( i = 0 ; i < nProfiles ; i ++ ) { cmsBool lIsDeviceLink , lIsInput ; hProfile = hProfiles [ i ] ; ClassSig = cmsGetDeviceClass ( hProfile ) ; lIsDeviceLink = ( ClassSig == cmsSigLinkClass || ClassSig == cmsSigAbstractClass ) ; if ( ( i == 0 ) && ! lIsDeviceLink ) { lIsInput = TRUE ; } else { lIsInput = ( CurrentColorSpace != cmsSigXYZData ) && ( CurrentColorSpace != cmsSigLabData ) ; } Intent = TheIntents [ i ] ; if ( lIsInput || lIsDeviceLink ) { ColorSpaceIn = cmsGetColorSpace ( hProfile ) ; ColorSpaceOut = cmsGetPCS ( hProfile ) ; } else { ColorSpaceIn = cmsGetPCS ( hProfile ) ; ColorSpaceOut = cmsGetColorSpace ( hProfile ) ; } if ( ! ColorSpaceIsCompatible ( ColorSpaceIn , CurrentColorSpace ) ) { cmsSignalError ( ContextID , cmsERROR_COLORSPACE_CHECK , "ColorSpace<S2SV_blank>mismatch" ) ; goto Error ; } if ( lIsDeviceLink || ( ( ClassSig == cmsSigNamedColorClass ) && ( nProfiles == 1 ) ) ) { Lut = _cmsReadDevicelinkLUT ( hProfile , Intent ) ; if ( Lut == NULL ) goto Error ; if ( ClassSig == cmsSigAbstractClass && i > 0 ) { if ( ! ComputeConversion ( i , hProfiles , Intent , BPC [ i ] , AdaptationStates [ i ] , & m , & off ) ) goto Error ; } else { _cmsMAT3identity ( & m ) ; _cmsVEC3init ( & off , 0 , 0 , 0 ) ; } if ( ! AddConversion ( Result , CurrentColorSpace , ColorSpaceIn , & m , & off ) ) goto Error ; } else { if ( lIsInput ) { Lut = _cmsReadInputLUT ( hProfile , Intent ) ; if ( Lut == NULL ) goto Error ; } else { Lut = _cmsReadOutputLUT ( hProfile , Intent ) ; if ( Lut == NULL ) goto Error ; if ( ! ComputeConversion ( i , hProfiles , Intent , BPC [ i ] , AdaptationStates [ i ] , & m , & off ) ) goto Error ; if ( ! AddConversion ( Result , CurrentColorSpace , ColorSpaceIn , & m , & off ) ) goto Error ; } } if ( ! cmsPipelineCat ( Result , Lut ) ) goto Error ; cmsPipelineFree ( Lut ) ; <S2SV_StartBug> CurrentColorSpace = ColorSpaceOut ; <S2SV_EndBug> } return Result ; Error : <S2SV_StartBug> cmsPipelineFree ( Lut ) ; <S2SV_EndBug> if ( Result != NULL ) cmsPipelineFree ( Result ) ; return NULL ; cmsUNUSED_PARAMETER ( dwFlags ) ; }
CWE-000 static void detect_allow_debuggers ( int argc , char * * argv ) { int i ; for ( i = 1 ; i < argc ; i ++ ) { if ( strcmp ( argv [ i ] , "--allow-debuggers" ) == 0 ) { <S2SV_StartBug> arg_allow_debuggers = 1 ; <S2SV_EndBug> break ; } if ( strcmp ( argv [ i ] , "--" ) == 0 ) break ; if ( strncmp ( argv [ i ] , "--" , 2 ) != 0 ) break ; } }
CWE-000 int dtls1_get_record ( SSL * s ) { int ssl_major , ssl_minor ; int i , n ; SSL3_RECORD * rr ; unsigned char * p = NULL ; unsigned short version ; DTLS1_BITMAP * bitmap ; unsigned int is_next_epoch ; rr = & ( s -> s3 -> rrec ) ; dtls1_process_buffered_records ( s ) ; if ( dtls1_get_processed_record ( s ) ) return 1 ; again : if ( ( s -> rstate != SSL_ST_READ_BODY ) || ( s -> packet_length < DTLS1_RT_HEADER_LENGTH ) ) { n = ssl3_read_n ( s , DTLS1_RT_HEADER_LENGTH , s -> s3 -> rbuf . len , 0 ) ; if ( n <= 0 ) return ( n ) ; if ( s -> packet_length != DTLS1_RT_HEADER_LENGTH ) { s -> packet_length = 0 ; goto again ; } s -> rstate = SSL_ST_READ_BODY ; p = s -> packet ; if ( s -> msg_callback ) s -> msg_callback ( 0 , 0 , SSL3_RT_HEADER , p , DTLS1_RT_HEADER_LENGTH , s , s -> msg_callback_arg ) ; rr -> type = * ( p ++ ) ; ssl_major = * ( p ++ ) ; ssl_minor = * ( p ++ ) ; version = ( ssl_major << 8 ) | ssl_minor ; n2s ( p , rr -> epoch ) ; memcpy ( & ( s -> s3 -> read_sequence [ 2 ] ) , p , 6 ) ; p += 6 ; n2s ( p , rr -> length ) ; if ( ! s -> first_packet ) { if ( version != s -> version ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } if ( ( version & 0xff00 ) != ( s -> version & 0xff00 ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } if ( rr -> length > SSL3_RT_MAX_ENCRYPTED_LENGTH ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } if ( rr -> length > s -> packet_length - DTLS1_RT_HEADER_LENGTH ) { i = rr -> length ; n = ssl3_read_n ( s , i , i , 1 ) ; if ( n != i ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } s -> rstate = SSL_ST_READ_HEADER ; bitmap = dtls1_get_bitmap ( s , rr , & is_next_epoch ) ; if ( bitmap == NULL ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } # ifndef OPENSSL_NO_SCTP if ( ! BIO_dgram_is_sctp ( SSL_get_rbio ( s ) ) ) { # endif if ( ! ( s -> d1 -> listen && rr -> type == SSL3_RT_HANDSHAKE && <S2SV_StartBug> * p == SSL3_MT_CLIENT_HELLO ) && <S2SV_EndBug> ! dtls1_record_replay_check ( s , bitmap ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } # ifndef OPENSSL_NO_SCTP } # endif if ( rr -> length == 0 ) goto again ; if ( is_next_epoch ) { if ( ( SSL_in_init ( s ) || s -> in_handshake ) && ! s -> d1 -> listen ) { dtls1_buffer_record ( s , & ( s -> d1 -> unprocessed_rcds ) , rr -> seq_num ) ; } rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } if ( ! dtls1_process_record ( s ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } return ( 1 ) ; }
CWE-000 BIO * PKCS7_dataDecode ( PKCS7 * p7 , EVP_PKEY * pkey , BIO * in_bio , X509 * pcert ) { int i , j ; BIO * out = NULL , * btmp = NULL , * etmp = NULL , * bio = NULL ; X509_ALGOR * xa ; ASN1_OCTET_STRING * data_body = NULL ; const EVP_MD * evp_md ; const EVP_CIPHER * evp_cipher = NULL ; EVP_CIPHER_CTX * evp_ctx = NULL ; X509_ALGOR * enc_alg = NULL ; STACK_OF ( X509_ALGOR ) * md_sk = NULL ; STACK_OF ( PKCS7_RECIP_INFO ) * rsk = NULL ; PKCS7_RECIP_INFO * ri = NULL ; unsigned char * ek = NULL , * tkey = NULL ; int eklen = 0 , tkeylen = 0 ; if ( p7 == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_INVALID_NULL_POINTER ) ; return NULL ; } if ( p7 -> d . ptr == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_NO_CONTENT ) ; return NULL ; } i = OBJ_obj2nid ( p7 -> type ) ; p7 -> state = PKCS7_S_HEADER ; switch ( i ) { case NID_pkcs7_signed : data_body = PKCS7_get_octet_string ( p7 -> d . sign -> contents ) ; if ( ! PKCS7_is_detached ( p7 ) && data_body == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_INVALID_SIGNED_DATA_TYPE ) ; goto err ; } md_sk = p7 -> d . sign -> md_algs ; break ; case NID_pkcs7_signedAndEnveloped : rsk = p7 -> d . signed_and_enveloped -> recipientinfo ; md_sk = p7 -> d . signed_and_enveloped -> md_algs ; data_body = p7 -> d . signed_and_enveloped -> enc_data -> enc_data ; enc_alg = p7 -> d . signed_and_enveloped -> enc_data -> algorithm ; evp_cipher = EVP_get_cipherbyobj ( enc_alg -> algorithm ) ; if ( evp_cipher == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_UNSUPPORTED_CIPHER_TYPE ) ; goto err ; } break ; case NID_pkcs7_enveloped : rsk = p7 -> d . enveloped -> recipientinfo ; enc_alg = p7 -> d . enveloped -> enc_data -> algorithm ; data_body = p7 -> d . enveloped -> enc_data -> enc_data ; evp_cipher = EVP_get_cipherbyobj ( enc_alg -> algorithm ) ; if ( evp_cipher == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_UNSUPPORTED_CIPHER_TYPE ) ; goto err ; } break ; default : PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_UNSUPPORTED_CONTENT_TYPE ) ; goto err ; } <S2SV_StartBug> if ( md_sk != NULL ) { <S2SV_EndBug> for ( i = 0 ; i < sk_X509_ALGOR_num ( md_sk ) ; i ++ ) { xa = sk_X509_ALGOR_value ( md_sk , i ) ; if ( ( btmp = BIO_new ( BIO_f_md ( ) ) ) == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , ERR_R_BIO_LIB ) ; goto err ; } j = OBJ_obj2nid ( xa -> algorithm ) ; evp_md = EVP_get_digestbynid ( j ) ; if ( evp_md == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_UNKNOWN_DIGEST_TYPE ) ; goto err ; } BIO_set_md ( btmp , evp_md ) ; if ( out == NULL ) out = btmp ; else BIO_push ( out , btmp ) ; btmp = NULL ; } } if ( evp_cipher != NULL ) { if ( ( etmp = BIO_new ( BIO_f_cipher ( ) ) ) == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , ERR_R_BIO_LIB ) ; goto err ; } if ( pcert ) { for ( i = 0 ; i < sk_PKCS7_RECIP_INFO_num ( rsk ) ; i ++ ) { ri = sk_PKCS7_RECIP_INFO_value ( rsk , i ) ; if ( ! pkcs7_cmp_ri ( ri , pcert ) ) break ; ri = NULL ; } if ( ri == NULL ) { PKCS7err ( PKCS7_F_PKCS7_DATADECODE , PKCS7_R_NO_RECIPIENT_MATCHES_CERTIFICATE ) ; goto err ; } } if ( pcert == NULL ) { for ( i = 0 ; i < sk_PKCS7_RECIP_INFO_num ( rsk ) ; i ++ ) { ri = sk_PKCS7_RECIP_INFO_value ( rsk , i ) ; if ( pkcs7_decrypt_rinfo ( & ek , & eklen , ri , pkey ) < 0 ) goto err ; ERR_clear_error ( ) ; } } else { if ( pkcs7_decrypt_rinfo ( & ek , & eklen , ri , pkey ) < 0 ) goto err ; ERR_clear_error ( ) ; } evp_ctx = NULL ; BIO_get_cipher_ctx ( etmp , & evp_ctx ) ; if ( EVP_CipherInit_ex ( evp_ctx , evp_cipher , NULL , NULL , NULL , 0 ) <= 0 ) goto err ; if ( EVP_CIPHER_asn1_to_param ( evp_ctx , enc_alg -> parameter ) < 0 ) goto err ; tkeylen = EVP_CIPHER_CTX_key_length ( evp_ctx ) ; tkey = OPENSSL_malloc ( tkeylen ) ; if ( ! tkey ) goto err ; if ( EVP_CIPHER_CTX_rand_key ( evp_ctx , tkey ) <= 0 ) goto err ; if ( ek == NULL ) { ek = tkey ; eklen = tkeylen ; tkey = NULL ; } if ( eklen != EVP_CIPHER_CTX_key_length ( evp_ctx ) ) { if ( ! EVP_CIPHER_CTX_set_key_length ( evp_ctx , eklen ) ) { OPENSSL_clear_free ( ek , eklen ) ; ek = tkey ; eklen = tkeylen ; tkey = NULL ; } } ERR_clear_error ( ) ; if ( EVP_CipherInit_ex ( evp_ctx , NULL , NULL , ek , NULL , 0 ) <= 0 ) goto err ; OPENSSL_clear_free ( ek , eklen ) ; ek = NULL ; OPENSSL_clear_free ( tkey , tkeylen ) ; tkey = NULL ; if ( out == NULL ) out = etmp ; else BIO_push ( out , etmp ) ; etmp = NULL ; } <S2SV_StartBug> if ( PKCS7_is_detached ( p7 ) || ( in_bio != NULL ) ) { <S2SV_EndBug> bio = in_bio ; } else { if ( data_body -> length > 0 ) bio = BIO_new_mem_buf ( data_body -> data , data_body -> length ) ; else { bio = BIO_new ( BIO_s_mem ( ) ) ; BIO_set_mem_eof_return ( bio , 0 ) ; } if ( bio == NULL ) goto err ; } BIO_push ( out , bio ) ; bio = NULL ; return out ; err : OPENSSL_clear_free ( ek , eklen ) ; OPENSSL_clear_free ( tkey , tkeylen ) ; BIO_free_all ( out ) ; BIO_free_all ( btmp ) ; BIO_free_all ( etmp ) ; BIO_free_all ( bio ) ; return NULL ; }
CWE-000 int dtls1_get_record ( SSL * s ) { int ssl_major , ssl_minor ; int i , n ; SSL3_RECORD * rr ; unsigned char * p = NULL ; unsigned short version ; DTLS1_BITMAP * bitmap ; unsigned int is_next_epoch ; rr = & ( s -> s3 -> rrec ) ; dtls1_process_buffered_records ( s ) ; if ( dtls1_get_processed_record ( s ) ) return 1 ; again : if ( ( s -> rstate != SSL_ST_READ_BODY ) || ( s -> packet_length < DTLS1_RT_HEADER_LENGTH ) ) { n = ssl3_read_n ( s , DTLS1_RT_HEADER_LENGTH , s -> s3 -> rbuf . len , 0 ) ; if ( n <= 0 ) return ( n ) ; if ( s -> packet_length != DTLS1_RT_HEADER_LENGTH ) { s -> packet_length = 0 ; goto again ; } s -> rstate = SSL_ST_READ_BODY ; p = s -> packet ; if ( s -> msg_callback ) s -> msg_callback ( 0 , 0 , SSL3_RT_HEADER , p , DTLS1_RT_HEADER_LENGTH , s , s -> msg_callback_arg ) ; rr -> type = * ( p ++ ) ; ssl_major = * ( p ++ ) ; ssl_minor = * ( p ++ ) ; version = ( ssl_major << 8 ) | ssl_minor ; n2s ( p , rr -> epoch ) ; memcpy ( & ( s -> s3 -> read_sequence [ 2 ] ) , p , 6 ) ; p += 6 ; n2s ( p , rr -> length ) ; if ( ! s -> first_packet ) { if ( version != s -> version ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } if ( ( version & 0xff00 ) != ( s -> version & 0xff00 ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } if ( rr -> length > SSL3_RT_MAX_ENCRYPTED_LENGTH ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } if ( rr -> length > s -> packet_length - DTLS1_RT_HEADER_LENGTH ) { i = rr -> length ; n = ssl3_read_n ( s , i , i , 1 ) ; <S2SV_StartBug> if ( n <= 0 ) return ( n ) ; <S2SV_EndBug> if ( n != i ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } } s -> rstate = SSL_ST_READ_HEADER ; bitmap = dtls1_get_bitmap ( s , rr , & is_next_epoch ) ; if ( bitmap == NULL ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } # ifndef OPENSSL_NO_SCTP if ( ! BIO_dgram_is_sctp ( SSL_get_rbio ( s ) ) ) { # endif if ( ! ( s -> d1 -> listen && rr -> type == SSL3_RT_HANDSHAKE && * p == SSL3_MT_CLIENT_HELLO ) && ! dtls1_record_replay_check ( s , bitmap ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } # ifndef OPENSSL_NO_SCTP } # endif if ( rr -> length == 0 ) goto again ; if ( is_next_epoch ) { if ( ( SSL_in_init ( s ) || s -> in_handshake ) && ! s -> d1 -> listen ) { dtls1_buffer_record ( s , & ( s -> d1 -> unprocessed_rcds ) , rr -> seq_num ) ; } rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } if ( ! dtls1_process_record ( s ) ) { rr -> length = 0 ; s -> packet_length = 0 ; goto again ; } return ( 1 ) ; }
CWE-000 int ssl3_read_n ( SSL * s , int n , int max , int extend ) { int i , len , left ; long align = 0 ; unsigned char * pkt ; SSL3_BUFFER * rb ; if ( n <= 0 ) return n ; rb = & ( s -> s3 -> rbuf ) ; if ( rb -> buf == NULL ) if ( ! ssl3_setup_read_buffer ( s ) ) return - 1 ; left = rb -> left ; # if defined ( SSL3_ALIGN_PAYLOAD ) && SSL3_ALIGN_PAYLOAD != 0 align = ( long ) rb -> buf + SSL3_RT_HEADER_LENGTH ; align = ( - align ) & ( SSL3_ALIGN_PAYLOAD - 1 ) ; # endif if ( ! extend ) { if ( left == 0 ) rb -> offset = align ; else if ( align != 0 && left >= SSL3_RT_HEADER_LENGTH ) { pkt = rb -> buf + rb -> offset ; if ( pkt [ 0 ] == SSL3_RT_APPLICATION_DATA && ( pkt [ 3 ] << 8 | pkt [ 4 ] ) >= 128 ) { memmove ( rb -> buf + align , pkt , left ) ; rb -> offset = align ; } } s -> packet = rb -> buf + rb -> offset ; s -> packet_length = 0 ; } if ( SSL_IS_DTLS ( s ) ) { <S2SV_StartBug> if ( left > 0 && n > left ) <S2SV_EndBug> n = left ; } if ( left >= n ) { s -> packet_length += n ; rb -> left = left - n ; rb -> offset += n ; return ( n ) ; } len = s -> packet_length ; pkt = rb -> buf + align ; if ( s -> packet != pkt ) { memmove ( pkt , s -> packet , len + left ) ; s -> packet = pkt ; rb -> offset = len + align ; } if ( n > ( int ) ( rb -> len - rb -> offset ) ) { SSLerr ( SSL_F_SSL3_READ_N , ERR_R_INTERNAL_ERROR ) ; return - 1 ; } if ( ! s -> read_ahead ) max = n ; else { if ( max < n ) max = n ; if ( max > ( int ) ( rb -> len - rb -> offset ) ) max = rb -> len - rb -> offset ; } while ( left < n ) { clear_sys_error ( ) ; if ( s -> rbio != NULL ) { s -> rwstate = SSL_READING ; i = BIO_read ( s -> rbio , pkt + len + left , max - left ) ; } else { SSLerr ( SSL_F_SSL3_READ_N , SSL_R_READ_BIO_NOT_SET ) ; i = - 1 ; } if ( i <= 0 ) { rb -> left = left ; if ( s -> mode & SSL_MODE_RELEASE_BUFFERS && ! SSL_IS_DTLS ( s ) ) if ( len + left == 0 ) ssl3_release_read_buffer ( s ) ; return ( i ) ; } left += i ; if ( SSL_IS_DTLS ( s ) ) { if ( n > left ) n = left ; } } rb -> offset += n ; rb -> left = left - n ; s -> packet_length += n ; s -> rwstate = SSL_NOTHING ; return ( n ) ; }
CWE-000 static enum ofperr decode_bundle ( bool load , const struct nx_action_bundle * nab , const struct vl_mff_map * vl_mff_map , uint64_t * tlv_bitmap , struct ofpbuf * ofpacts ) { static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT ( 1 , 5 ) ; struct ofpact_bundle * bundle ; uint32_t slave_type ; size_t slaves_size , i ; enum ofperr error ; bundle = ofpact_put_BUNDLE ( ofpacts ) ; bundle -> n_slaves = ntohs ( nab -> n_slaves ) ; bundle -> basis = ntohs ( nab -> basis ) ; bundle -> fields = ntohs ( nab -> fields ) ; bundle -> algorithm = ntohs ( nab -> algorithm ) ; slave_type = ntohl ( nab -> slave_type ) ; slaves_size = ntohs ( nab -> len ) - sizeof * nab ; error = OFPERR_OFPBAC_BAD_ARGUMENT ; if ( ! flow_hash_fields_valid ( bundle -> fields ) ) { VLOG_WARN_RL ( & rl , "unsupported<S2SV_blank>fields<S2SV_blank>%d" , ( int ) bundle -> fields ) ; } else if ( bundle -> n_slaves > BUNDLE_MAX_SLAVES ) { VLOG_WARN_RL ( & rl , "too<S2SV_blank>many<S2SV_blank>slaves" ) ; } else if ( bundle -> algorithm != NX_BD_ALG_HRW && bundle -> algorithm != NX_BD_ALG_ACTIVE_BACKUP ) { VLOG_WARN_RL ( & rl , "unsupported<S2SV_blank>algorithm<S2SV_blank>%d" , ( int ) bundle -> algorithm ) ; } else if ( slave_type != mf_nxm_header ( MFF_IN_PORT ) ) { VLOG_WARN_RL ( & rl , "unsupported<S2SV_blank>slave<S2SV_blank>type<S2SV_blank>%" PRIu16 , slave_type ) ; } else { error = 0 ; } if ( ! is_all_zeros ( nab -> zero , sizeof nab -> zero ) ) { VLOG_WARN_RL ( & rl , "reserved<S2SV_blank>field<S2SV_blank>is<S2SV_blank>nonzero" ) ; error = OFPERR_OFPBAC_BAD_ARGUMENT ; } if ( load ) { bundle -> dst . ofs = nxm_decode_ofs ( nab -> ofs_nbits ) ; bundle -> dst . n_bits = nxm_decode_n_bits ( nab -> ofs_nbits ) ; error = mf_vl_mff_mf_from_nxm_header ( ntohl ( nab -> dst ) , vl_mff_map , & bundle -> dst . field , tlv_bitmap ) ; if ( error ) { return error ; } if ( bundle -> dst . n_bits < 16 ) { VLOG_WARN_RL ( & rl , "bundle_load<S2SV_blank>action<S2SV_blank>requires<S2SV_blank>at<S2SV_blank>least<S2SV_blank>16<S2SV_blank>bit<S2SV_blank>" "destination." ) ; error = OFPERR_OFPBAC_BAD_ARGUMENT ; } } else { if ( nab -> ofs_nbits || nab -> dst ) { VLOG_WARN_RL ( & rl , "bundle<S2SV_blank>action<S2SV_blank>has<S2SV_blank>nonzero<S2SV_blank>reserved<S2SV_blank>fields" ) ; error = OFPERR_OFPBAC_BAD_ARGUMENT ; } } if ( slaves_size < bundle -> n_slaves * sizeof ( ovs_be16 ) ) { VLOG_WARN_RL ( & rl , "Nicira<S2SV_blank>action<S2SV_blank>%s<S2SV_blank>only<S2SV_blank>has<S2SV_blank>%" PRIuSIZE "<S2SV_blank>bytes<S2SV_blank>" "allocated<S2SV_blank>for<S2SV_blank>slaves.<S2SV_blank><S2SV_blank>%" PRIuSIZE "<S2SV_blank>bytes<S2SV_blank>are<S2SV_blank>required<S2SV_blank>" "for<S2SV_blank>%" PRIu16 "<S2SV_blank>slaves." , load ? "bundle_load" : "bundle" , slaves_size , bundle -> n_slaves * sizeof ( ovs_be16 ) , bundle -> n_slaves ) ; error = OFPERR_OFPBAC_BAD_LEN ; <S2SV_StartBug> } <S2SV_EndBug> for ( i = 0 ; i < bundle -> n_slaves ; i ++ ) { ofp_port_t ofp_port = u16_to_ofp ( ntohs ( ( ( ovs_be16 * ) ( nab + 1 ) ) [ i ] ) ) ; ofpbuf_put ( ofpacts , & ofp_port , sizeof ofp_port ) ; bundle = ofpacts -> header ; } <S2SV_StartBug> ofpact_finish_BUNDLE ( ofpacts , & bundle ) ; <S2SV_EndBug> if ( ! error ) { error = bundle_check ( bundle , OFPP_MAX , NULL ) ; } return error ; }
CWE-000 static inline int process_nested_data ( UNSERIALIZE_PARAMETER , HashTable * ht , long elements , int objprops ) { while ( elements -- > 0 ) { zval * key , * data , * * old_data ; ALLOC_INIT_ZVAL ( key ) ; if ( ! php_var_unserialize ( & key , p , max , NULL TSRMLS_CC ) ) { zval_dtor ( key ) ; FREE_ZVAL ( key ) ; return 0 ; } if ( Z_TYPE_P ( key ) != IS_LONG && Z_TYPE_P ( key ) != IS_STRING ) { zval_dtor ( key ) ; FREE_ZVAL ( key ) ; return 0 ; } ALLOC_INIT_ZVAL ( data ) ; if ( ! php_var_unserialize ( & data , p , max , var_hash TSRMLS_CC ) ) { zval_dtor ( key ) ; FREE_ZVAL ( key ) ; zval_dtor ( data ) ; FREE_ZVAL ( data ) ; return 0 ; } if ( ! objprops ) { switch ( Z_TYPE_P ( key ) ) { case IS_LONG : if ( zend_hash_index_find ( ht , Z_LVAL_P ( key ) , ( void * * ) & old_data ) == SUCCESS ) { var_push_dtor ( var_hash , old_data ) ; } zend_hash_index_update ( ht , Z_LVAL_P ( key ) , & data , sizeof ( data ) , NULL ) ; break ; case IS_STRING : if ( zend_symtable_find ( ht , Z_STRVAL_P ( key ) , Z_STRLEN_P ( key ) + 1 , ( void * * ) & old_data ) == SUCCESS ) { var_push_dtor ( var_hash , old_data ) ; } zend_symtable_update ( ht , Z_STRVAL_P ( key ) , Z_STRLEN_P ( key ) + 1 , & data , sizeof ( data ) , NULL ) ; break ; } } else { convert_to_string ( key ) ; <S2SV_StartBug> if ( zend_symtable_find ( ht , Z_STRVAL_P ( key ) , Z_STRLEN_P ( key ) + 1 , ( void * * ) & old_data ) == SUCCESS ) { <S2SV_EndBug> var_push_dtor ( var_hash , old_data ) ; } zend_hash_update ( ht , Z_STRVAL_P ( key ) , Z_STRLEN_P ( key ) + 1 , & data , sizeof data , NULL ) ; } zval_dtor ( key ) ; FREE_ZVAL ( key ) ; if ( elements && * ( * p - 1 ) != ';' && * ( * p - 1 ) != '}' ) { ( * p ) -- ; return 0 ; } } return 1 ; }
CWE-000 matvar_t * Mat_VarReadNextInfo4 ( mat_t * mat ) { int M , O , data_type , class_type ; mat_int32_t tmp ; long nBytes ; size_t readresult ; matvar_t * matvar = NULL ; union { mat_uint32_t u ; mat_uint8_t c [ 4 ] ; } endian ; if ( mat == NULL || mat -> fp == NULL ) return NULL ; else if ( NULL == ( matvar = Mat_VarCalloc ( ) ) ) return NULL ; readresult = fread ( & tmp , sizeof ( int ) , 1 , ( FILE * ) mat -> fp ) ; if ( 1 != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; } endian . u = 0x01020304 ; if ( tmp < 0 || tmp > 4052 ) { if ( Mat_int32Swap ( & tmp ) > 4052 ) { Mat_VarFree ( matvar ) ; return NULL ; } } M = ( int ) floor ( tmp / 1000.0 ) ; switch ( M ) { case 0 : mat -> byteswap = endian . c [ 0 ] != 4 ; break ; case 1 : mat -> byteswap = endian . c [ 0 ] != 1 ; break ; default : Mat_VarFree ( matvar ) ; return NULL ; } tmp -= M * 1000 ; O = ( int ) floor ( tmp / 100.0 ) ; if ( 0 != O ) { Mat_VarFree ( matvar ) ; return NULL ; } tmp -= O * 100 ; data_type = ( int ) floor ( tmp / 10.0 ) ; switch ( data_type ) { case 0 : matvar -> data_type = MAT_T_DOUBLE ; break ; case 1 : matvar -> data_type = MAT_T_SINGLE ; break ; case 2 : matvar -> data_type = MAT_T_INT32 ; break ; case 3 : matvar -> data_type = MAT_T_INT16 ; break ; case 4 : matvar -> data_type = MAT_T_UINT16 ; break ; case 5 : matvar -> data_type = MAT_T_UINT8 ; break ; default : Mat_VarFree ( matvar ) ; return NULL ; } tmp -= data_type * 10 ; class_type = ( int ) floor ( tmp / 1.0 ) ; switch ( class_type ) { case 0 : matvar -> class_type = MAT_C_DOUBLE ; break ; case 1 : matvar -> class_type = MAT_C_CHAR ; break ; case 2 : matvar -> class_type = MAT_C_SPARSE ; break ; default : Mat_VarFree ( matvar ) ; return NULL ; } matvar -> rank = 2 ; matvar -> dims = ( size_t * ) calloc ( 2 , sizeof ( * matvar -> dims ) ) ; if ( NULL == matvar -> dims ) { Mat_VarFree ( matvar ) ; return NULL ; } readresult = fread ( & tmp , sizeof ( int ) , 1 , ( FILE * ) mat -> fp ) ; if ( mat -> byteswap ) Mat_int32Swap ( & tmp ) ; matvar -> dims [ 0 ] = tmp ; if ( 1 != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; } readresult = fread ( & tmp , sizeof ( int ) , 1 , ( FILE * ) mat -> fp ) ; if ( mat -> byteswap ) Mat_int32Swap ( & tmp ) ; matvar -> dims [ 1 ] = tmp ; if ( 1 != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; } readresult = fread ( & ( matvar -> isComplex ) , sizeof ( int ) , 1 , ( FILE * ) mat -> fp ) ; if ( 1 != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; } if ( matvar -> isComplex && MAT_C_CHAR == matvar -> class_type ) { Mat_VarFree ( matvar ) ; return NULL ; } readresult = fread ( & tmp , sizeof ( int ) , 1 , ( FILE * ) mat -> fp ) ; if ( 1 != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; } if ( mat -> byteswap ) Mat_int32Swap ( & tmp ) ; if ( tmp < 1 ) { Mat_VarFree ( matvar ) ; return NULL ; } matvar -> name = ( char * ) malloc ( tmp ) ; if ( NULL == matvar -> name ) { Mat_VarFree ( matvar ) ; return NULL ; } readresult = fread ( matvar -> name , 1 , tmp , ( FILE * ) mat -> fp ) ; if ( tmp != readresult ) { Mat_VarFree ( matvar ) ; return NULL ; <S2SV_StartBug> } <S2SV_EndBug> matvar -> internal -> datapos = ftell ( ( FILE * ) mat -> fp ) ; if ( matvar -> internal -> datapos == - 1L ) { Mat_VarFree ( matvar ) ; Mat_Critical ( "Couldn\'t<S2SV_blank>determine<S2SV_blank>file<S2SV_blank>position" ) ; return NULL ; } { int err ; size_t tmp2 = Mat_SizeOf ( matvar -> data_type ) ; if ( matvar -> isComplex ) tmp2 *= 2 ; err = SafeMulDims ( matvar , & tmp2 ) ; if ( err ) { Mat_VarFree ( matvar ) ; Mat_Critical ( "Integer<S2SV_blank>multiplication<S2SV_blank>overflow" ) ; return NULL ; } nBytes = ( long ) tmp2 ; } ( void ) fseek ( ( FILE * ) mat -> fp , nBytes , SEEK_CUR ) ; return matvar ; }
CWE-000 static int kvm_vm_ioctl_set_pit2 ( struct kvm * kvm , struct kvm_pit_state2 * ps ) { <S2SV_StartBug> int start = 0 ; <S2SV_EndBug> u32 prev_legacy , cur_legacy ; mutex_lock ( & kvm -> arch . vpit -> pit_state . lock ) ; prev_legacy = kvm -> arch . vpit -> pit_state . flags & KVM_PIT_FLAGS_HPET_LEGACY ; cur_legacy = ps -> flags & KVM_PIT_FLAGS_HPET_LEGACY ; if ( ! prev_legacy && cur_legacy ) start = 1 ; memcpy ( & kvm -> arch . vpit -> pit_state . channels , & ps -> channels , sizeof ( kvm -> arch . vpit -> pit_state . channels ) ) ; kvm -> arch . vpit -> pit_state . flags = ps -> flags ; <S2SV_StartBug> kvm_pit_load_count ( kvm , 0 , kvm -> arch . vpit -> pit_state . channels [ 0 ] . count , start ) ; <S2SV_EndBug> mutex_unlock ( & kvm -> arch . vpit -> pit_state . lock ) ; return 0 ; }
CWE-000 static int kvm_vm_ioctl_set_pit ( struct kvm * kvm , struct kvm_pit_state * ps ) <S2SV_StartBug> { <S2SV_EndBug> mutex_lock ( & kvm -> arch . vpit -> pit_state . lock ) ; memcpy ( & kvm -> arch . vpit -> pit_state , ps , sizeof ( struct kvm_pit_state ) ) ; <S2SV_StartBug> kvm_pit_load_count ( kvm , 0 , ps -> channels [ 0 ] . count , 0 ) ; <S2SV_EndBug> mutex_unlock ( & kvm -> arch . vpit -> pit_state . lock ) ; return 0 ; }
CWE-000 static int snd_seq_ioctl_remove_events ( struct snd_seq_client * client , void __user * arg ) { struct snd_seq_remove_events info ; if ( copy_from_user ( & info , arg , sizeof ( info ) ) ) return - EFAULT ; if ( info . remove_mode & SNDRV_SEQ_REMOVE_INPUT ) { <S2SV_StartBug> if ( client -> type == USER_CLIENT ) <S2SV_EndBug> snd_seq_fifo_clear ( client -> data . user . fifo ) ; } if ( info . remove_mode & SNDRV_SEQ_REMOVE_OUTPUT ) snd_seq_queue_remove_cells ( client -> number , & info ) ; return 0 ; }
CWE-000 int sas_discover_sata ( struct domain_device * dev ) { int res ; if ( dev -> dev_type == SAS_SATA_PM ) return - ENODEV ; dev -> sata_dev . class = sas_get_ata_command_set ( dev ) ; sas_fill_in_rphy ( dev , dev -> rphy ) ; res = sas_notify_lldd_dev_found ( dev ) ; if ( res ) return res ; <S2SV_StartBug> sas_discover_event ( dev -> port , DISCE_PROBE ) ; <S2SV_EndBug> return 0 ; }
CWE-000 <S2SV_StartBug> static void sas_destruct_devices ( struct work_struct * work ) <S2SV_EndBug> { <S2SV_StartBug> struct domain_device * dev , * n ; <S2SV_EndBug> struct sas_discovery_event * ev = to_sas_discovery_event ( work ) ; struct asd_sas_port * port = ev -> port ; clear_bit ( DISCE_DESTRUCT , & port -> disc . pending ) ; list_for_each_entry_safe ( dev , n , & port -> destroy_list , disco_list_node ) { list_del_init ( & dev -> disco_list_node ) ; sas_remove_children ( & dev -> rphy -> dev ) ; sas_rphy_delete ( dev -> rphy ) ; sas_unregister_common_dev ( port , dev ) ; } }
CWE-000 static void sas_discover_domain ( struct work_struct * work ) { struct domain_device * dev ; int error = 0 ; struct sas_discovery_event * ev = to_sas_discovery_event ( work ) ; struct asd_sas_port * port = ev -> port ; clear_bit ( DISCE_DISCOVER_DOMAIN , & port -> disc . pending ) ; if ( port -> port_dev ) return ; error = sas_get_port_device ( port ) ; if ( error ) return ; dev = port -> port_dev ; SAS_DPRINTK ( "DOING<S2SV_blank>DISCOVERY<S2SV_blank>on<S2SV_blank>port<S2SV_blank>%d,<S2SV_blank>pid:%d\\n" , port -> id , task_pid_nr ( current ) ) ; switch ( dev -> dev_type ) { case SAS_END_DEVICE : error = sas_discover_end_dev ( dev ) ; break ; case SAS_EDGE_EXPANDER_DEVICE : case SAS_FANOUT_EXPANDER_DEVICE : error = sas_discover_root_expander ( dev ) ; break ; case SAS_SATA_DEV : case SAS_SATA_PM : # ifdef CONFIG_SCSI_SAS_ATA error = sas_discover_sata ( dev ) ; break ; # else SAS_DPRINTK ( "ATA<S2SV_blank>device<S2SV_blank>seen<S2SV_blank>but<S2SV_blank>CONFIG_SCSI_SAS_ATA=N<S2SV_blank>so<S2SV_blank>cannot<S2SV_blank>attach\\n" ) ; # endif default : error = - ENXIO ; SAS_DPRINTK ( "unhandled<S2SV_blank>device<S2SV_blank>%d\\n" , dev -> dev_type ) ; break ; } if ( error ) { sas_rphy_free ( dev -> rphy ) ; list_del_init ( & dev -> disco_list_node ) ; spin_lock_irq ( & port -> dev_list_lock ) ; list_del_init ( & dev -> dev_list_node ) ; spin_unlock_irq ( & port -> dev_list_lock ) ; sas_put_device ( dev ) ; port -> port_dev = NULL ; } <S2SV_StartBug> SAS_DPRINTK ( "DONE<S2SV_blank>DISCOVERY<S2SV_blank>on<S2SV_blank>port<S2SV_blank>%d,<S2SV_blank>pid:%d,<S2SV_blank>result:%d\\n" , port -> id , <S2SV_EndBug> task_pid_nr ( current ) , error ) ; }
CWE-000 int sas_discover_end_dev ( struct domain_device * dev ) { int res ; res = sas_notify_lldd_dev_found ( dev ) ; if ( res ) return res ; <S2SV_StartBug> sas_discover_event ( dev -> port , DISCE_PROBE ) ; <S2SV_EndBug> return 0 ; }
CWE-000 void sas_init_disc ( struct sas_discovery * disc , struct asd_sas_port * port ) { int i ; static const work_func_t sas_event_fns [ DISC_NUM_EVENTS ] = { [ DISCE_DISCOVER_DOMAIN ] = sas_discover_domain , [ DISCE_REVALIDATE_DOMAIN ] = sas_revalidate_domain , <S2SV_StartBug> [ DISCE_PROBE ] = sas_probe_devices , <S2SV_EndBug> [ DISCE_SUSPEND ] = sas_suspend_devices , <S2SV_StartBug> [ DISCE_RESUME ] = sas_resume_devices , <S2SV_EndBug> [ DISCE_DESTRUCT ] = sas_destruct_devices , } ; disc -> pending = 0 ; for ( i = 0 ; i < DISC_NUM_EVENTS ; i ++ ) { INIT_SAS_WORK ( & disc -> disc_work [ i ] . work , sas_event_fns [ i ] ) ; disc -> disc_work [ i ] . port = port ; } }
CWE-000 <S2SV_StartBug> static void sas_probe_devices ( struct work_struct * work ) <S2SV_EndBug> { <S2SV_StartBug> struct domain_device * dev , * n ; <S2SV_EndBug> struct sas_discovery_event * ev = to_sas_discovery_event ( work ) ; struct asd_sas_port * port = ev -> port ; clear_bit ( DISCE_PROBE , & port -> disc . pending ) ; list_for_each_entry ( dev , & port -> disco_list , disco_list_node ) { spin_lock_irq ( & port -> dev_list_lock ) ; list_add_tail ( & dev -> dev_list_node , & port -> dev_list ) ; spin_unlock_irq ( & port -> dev_list_lock ) ; } sas_probe_sata ( port ) ; list_for_each_entry_safe ( dev , n , & port -> disco_list , disco_list_node ) { int err ; err = sas_rphy_add ( dev -> rphy ) ; if ( err ) sas_fail_probe ( dev , __func__ , err ) ; else list_del_init ( & dev -> disco_list_node ) ; } }
CWE-000 static void sas_revalidate_domain ( struct work_struct * work ) { int res = 0 ; struct sas_discovery_event * ev = to_sas_discovery_event ( work ) ; struct asd_sas_port * port = ev -> port ; struct sas_ha_struct * ha = port -> ha ; struct domain_device * ddev = port -> port_dev ; mutex_lock ( & ha -> disco_mutex ) ; if ( test_bit ( SAS_HA_ATA_EH_ACTIVE , & ha -> state ) ) { SAS_DPRINTK ( "REVALIDATION<S2SV_blank>DEFERRED<S2SV_blank>on<S2SV_blank>port<S2SV_blank>%d,<S2SV_blank>pid:%d\\n" , port -> id , task_pid_nr ( current ) ) ; goto out ; } clear_bit ( DISCE_REVALIDATE_DOMAIN , & port -> disc . pending ) ; SAS_DPRINTK ( "REVALIDATING<S2SV_blank>DOMAIN<S2SV_blank>on<S2SV_blank>port<S2SV_blank>%d,<S2SV_blank>pid:%d\\n" , port -> id , task_pid_nr ( current ) ) ; if ( ddev && ( ddev -> dev_type == SAS_FANOUT_EXPANDER_DEVICE || ddev -> dev_type == SAS_EDGE_EXPANDER_DEVICE ) ) res = sas_ex_revalidate_domain ( ddev ) ; SAS_DPRINTK ( "done<S2SV_blank>REVALIDATING<S2SV_blank>DOMAIN<S2SV_blank>on<S2SV_blank>port<S2SV_blank>%d,<S2SV_blank>pid:%d,<S2SV_blank>res<S2SV_blank>0x%x\\n" , port -> id , task_pid_nr ( current ) , res ) ; out : mutex_unlock ( & ha -> disco_mutex ) ; <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 void sas_unregister_dev ( struct asd_sas_port * port , struct domain_device * dev ) { if ( ! test_bit ( SAS_DEV_DESTROY , & dev -> state ) && ! list_empty ( & dev -> disco_list_node ) ) { list_del_init ( & dev -> disco_list_node ) ; sas_rphy_free ( dev -> rphy ) ; sas_unregister_common_dev ( port , dev ) ; return ; } if ( ! test_and_set_bit ( SAS_DEV_DESTROY , & dev -> state ) ) { sas_rphy_unlink ( dev -> rphy ) ; list_move_tail ( & dev -> disco_list_node , & port -> destroy_list ) ; <S2SV_StartBug> sas_discover_event ( dev -> port , DISCE_DESTRUCT ) ; <S2SV_EndBug> } }
CWE-000 int sas_ex_revalidate_domain ( struct domain_device * port_dev ) { int res ; struct domain_device * dev = NULL ; res = sas_find_bcast_dev ( port_dev , & dev ) ; <S2SV_StartBug> while ( res == 0 && dev ) { <S2SV_EndBug> struct expander_device * ex = & dev -> ex_dev ; int i = 0 , phy_id ; do { phy_id = - 1 ; res = sas_find_bcast_phy ( dev , & phy_id , i , true ) ; if ( phy_id == - 1 ) break ; res = sas_rediscover ( dev , phy_id ) ; i = phy_id + 1 ; } while ( i < ex -> num_phys ) ; <S2SV_StartBug> dev = NULL ; <S2SV_EndBug> res = sas_find_bcast_dev ( port_dev , & dev ) ; } return res ; }
CWE-000 static void sas_unregister_devs_sas_addr ( struct domain_device * parent , int phy_id , bool last ) { struct expander_device * ex_dev = & parent -> ex_dev ; struct ex_phy * phy = & ex_dev -> ex_phy [ phy_id ] ; struct domain_device * child , * n , * found = NULL ; if ( last ) { list_for_each_entry_safe ( child , n , & ex_dev -> children , siblings ) { if ( SAS_ADDR ( child -> sas_addr ) == SAS_ADDR ( phy -> attached_sas_addr ) ) { set_bit ( SAS_DEV_GONE , & child -> state ) ; if ( child -> dev_type == SAS_EDGE_EXPANDER_DEVICE || child -> dev_type == SAS_FANOUT_EXPANDER_DEVICE ) sas_unregister_ex_tree ( parent -> port , child ) ; else sas_unregister_dev ( parent -> port , child ) ; found = child ; break ; } } sas_disable_routing ( parent , phy -> attached_sas_addr ) ; } memset ( phy -> attached_sas_addr , 0 , SAS_ADDR_SIZE ) ; if ( phy -> port ) { sas_port_delete_phy ( phy -> port , phy -> phy ) ; sas_device_set_phy ( found , phy -> port ) ; if ( phy -> port -> num_phys == 0 ) <S2SV_StartBug> sas_port_delete ( phy -> port ) ; <S2SV_EndBug> phy -> port = NULL ; } }
CWE-000 void sas_deform_port ( struct asd_sas_phy * phy , int gone ) { struct sas_ha_struct * sas_ha = phy -> ha ; struct asd_sas_port * port = phy -> port ; struct sas_internal * si = to_sas_internal ( sas_ha -> core . shost -> transportt ) ; struct domain_device * dev ; unsigned long flags ; if ( ! port ) return ; dev = port -> port_dev ; if ( dev ) dev -> pathways -- ; if ( port -> num_phys == 1 ) { sas_unregister_domain_devices ( port , gone ) ; <S2SV_StartBug> sas_port_delete ( port -> port ) ; <S2SV_EndBug> port -> port = NULL ; } else { sas_port_delete_phy ( port -> port , phy -> phy ) ; sas_device_set_phy ( dev , port -> port ) ; } if ( si -> dft -> lldd_port_deformed ) si -> dft -> lldd_port_deformed ( phy ) ; spin_lock_irqsave ( & sas_ha -> phy_port_lock , flags ) ; spin_lock ( & port -> phy_list_lock ) ; list_del_init ( & phy -> port_phy_el ) ; sas_phy_set_target ( phy , NULL ) ; phy -> port = NULL ; port -> num_phys -- ; port -> phy_mask &= ~ ( 1U << phy -> id ) ; if ( port -> num_phys == 0 ) { INIT_LIST_HEAD ( & port -> phy_list ) ; memset ( port -> sas_addr , 0 , SAS_ADDR_SIZE ) ; memset ( port -> attached_sas_addr , 0 , SAS_ADDR_SIZE ) ; port -> class = 0 ; port -> iproto = 0 ; port -> tproto = 0 ; port -> oob_mode = 0 ; port -> phy_mask = 0 ; } spin_unlock ( & port -> phy_list_lock ) ; spin_unlock_irqrestore ( & sas_ha -> phy_port_lock , flags ) ; return ; }
CWE-000 static void sas_init_port ( struct asd_sas_port * port , struct sas_ha_struct * sas_ha , int i ) { memset ( port , 0 , sizeof ( * port ) ) ; port -> id = i ; INIT_LIST_HEAD ( & port -> dev_list ) ; INIT_LIST_HEAD ( & port -> disco_list ) ; INIT_LIST_HEAD ( & port -> destroy_list ) ; <S2SV_StartBug> spin_lock_init ( & port -> phy_list_lock ) ; <S2SV_EndBug> INIT_LIST_HEAD ( & port -> phy_list ) ; port -> ha = sas_ha ; spin_lock_init ( & port -> dev_list_lock ) ; }
CWE-000 static void sas_resume_port ( struct asd_sas_phy * phy ) { struct domain_device * dev ; struct asd_sas_port * port = phy -> port ; struct sas_ha_struct * sas_ha = phy -> ha ; struct sas_internal * si = to_sas_internal ( sas_ha -> core . shost -> transportt ) ; if ( si -> dft -> lldd_port_formed ) si -> dft -> lldd_port_formed ( phy ) ; if ( port -> suspended ) port -> suspended = 0 ; else { return ; } list_for_each_entry ( dev , & port -> dev_list , dev_list_node ) { int i , rc ; rc = sas_notify_lldd_dev_found ( dev ) ; if ( rc ) { <S2SV_StartBug> sas_unregister_dev ( port , dev ) ; <S2SV_EndBug> continue ; } if ( dev -> dev_type == SAS_EDGE_EXPANDER_DEVICE || dev -> dev_type == SAS_FANOUT_EXPANDER_DEVICE ) { dev -> ex_dev . ex_change_count = - 1 ; for ( i = 0 ; i < dev -> ex_dev . num_phys ; i ++ ) { struct ex_phy * phy = & dev -> ex_dev . ex_phy [ i ] ; phy -> phy_change_count = - 1 ; } } } sas_discover_event ( port , DISCE_RESUME ) ; }
CWE-000 int snd_usbmidi_create ( struct snd_card * card , struct usb_interface * iface , struct list_head * midi_list , const struct snd_usb_audio_quirk * quirk ) { struct snd_usb_midi * umidi ; struct snd_usb_midi_endpoint_info endpoints [ MIDI_MAX_ENDPOINTS ] ; int out_ports , in_ports ; int i , err ; umidi = kzalloc ( sizeof ( * umidi ) , GFP_KERNEL ) ; if ( ! umidi ) return - ENOMEM ; umidi -> dev = interface_to_usbdev ( iface ) ; umidi -> card = card ; umidi -> iface = iface ; umidi -> quirk = quirk ; umidi -> usb_protocol_ops = & snd_usbmidi_standard_ops ; spin_lock_init ( & umidi -> disc_lock ) ; init_rwsem ( & umidi -> disc_rwsem ) ; mutex_init ( & umidi -> mutex ) ; umidi -> usb_id = USB_ID ( le16_to_cpu ( umidi -> dev -> descriptor . idVendor ) , le16_to_cpu ( umidi -> dev -> descriptor . idProduct ) ) ; setup_timer ( & umidi -> error_timer , snd_usbmidi_error_timer , ( unsigned long ) umidi ) ; memset ( endpoints , 0 , sizeof ( endpoints ) ) ; switch ( quirk ? quirk -> type : QUIRK_MIDI_STANDARD_INTERFACE ) { case QUIRK_MIDI_STANDARD_INTERFACE : err = snd_usbmidi_get_ms_info ( umidi , endpoints ) ; if ( umidi -> usb_id == USB_ID ( 0x0763 , 0x0150 ) ) umidi -> usb_protocol_ops = & snd_usbmidi_maudio_broken_running_status_ops ; break ; case QUIRK_MIDI_US122L : umidi -> usb_protocol_ops = & snd_usbmidi_122l_ops ; case QUIRK_MIDI_FIXED_ENDPOINT : memcpy ( & endpoints [ 0 ] , quirk -> data , sizeof ( struct snd_usb_midi_endpoint_info ) ) ; err = snd_usbmidi_detect_endpoints ( umidi , & endpoints [ 0 ] , 1 ) ; break ; case QUIRK_MIDI_YAMAHA : err = snd_usbmidi_detect_yamaha ( umidi , & endpoints [ 0 ] ) ; break ; case QUIRK_MIDI_ROLAND : err = snd_usbmidi_detect_roland ( umidi , & endpoints [ 0 ] ) ; break ; case QUIRK_MIDI_MIDIMAN : umidi -> usb_protocol_ops = & snd_usbmidi_midiman_ops ; memcpy ( & endpoints [ 0 ] , quirk -> data , sizeof ( struct snd_usb_midi_endpoint_info ) ) ; err = 0 ; break ; case QUIRK_MIDI_NOVATION : umidi -> usb_protocol_ops = & snd_usbmidi_novation_ops ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; break ; case QUIRK_MIDI_RAW_BYTES : umidi -> usb_protocol_ops = & snd_usbmidi_raw_ops ; if ( umidi -> usb_id == USB_ID ( 0x07fd , 0x0001 ) ) usb_set_interface ( umidi -> dev , 0 , 0 ) ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; break ; case QUIRK_MIDI_EMAGIC : umidi -> usb_protocol_ops = & snd_usbmidi_emagic_ops ; memcpy ( & endpoints [ 0 ] , quirk -> data , sizeof ( struct snd_usb_midi_endpoint_info ) ) ; err = snd_usbmidi_detect_endpoints ( umidi , & endpoints [ 0 ] , 1 ) ; break ; case QUIRK_MIDI_CME : umidi -> usb_protocol_ops = & snd_usbmidi_cme_ops ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; break ; case QUIRK_MIDI_AKAI : umidi -> usb_protocol_ops = & snd_usbmidi_akai_ops ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; endpoints [ 1 ] . out_cables = 0 ; break ; case QUIRK_MIDI_FTDI : umidi -> usb_protocol_ops = & snd_usbmidi_ftdi_ops ; err = usb_control_msg ( umidi -> dev , usb_sndctrlpipe ( umidi -> dev , 0 ) , 3 , 0x40 , 0x60 , 0 , NULL , 0 , 1000 ) ; if ( err < 0 ) break ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; break ; case QUIRK_MIDI_CH345 : umidi -> usb_protocol_ops = & snd_usbmidi_ch345_broken_sysex_ops ; err = snd_usbmidi_detect_per_port_endpoints ( umidi , endpoints ) ; break ; default : dev_err ( & umidi -> dev -> dev , "invalid<S2SV_blank>quirk<S2SV_blank>type<S2SV_blank>%d\\n" , quirk -> type ) ; err = - ENXIO ; break ; } if ( err < 0 ) { kfree ( umidi ) ; return err ; } out_ports = 0 ; in_ports = 0 ; for ( i = 0 ; i < MIDI_MAX_ENDPOINTS ; ++ i ) { out_ports += hweight16 ( endpoints [ i ] . out_cables ) ; in_ports += hweight16 ( endpoints [ i ] . in_cables ) ; } err = snd_usbmidi_create_rawmidi ( umidi , out_ports , in_ports ) ; if ( err < 0 ) { kfree ( umidi ) ; return err ; } if ( quirk && quirk -> type == QUIRK_MIDI_MIDIMAN ) err = snd_usbmidi_create_endpoints_midiman ( umidi , & endpoints [ 0 ] ) ; else err = snd_usbmidi_create_endpoints ( umidi , endpoints ) ; if ( err < 0 ) { <S2SV_StartBug> snd_usbmidi_free ( umidi ) ; <S2SV_EndBug> return err ; } usb_autopm_get_interface_no_resume ( umidi -> iface ) ; list_add_tail ( & umidi -> list , midi_list ) ; return 0 ; }
CWE-000 static int orinoco_ioctl_set_auth ( struct net_device * dev , struct iw_request_info * info , union iwreq_data * wrqu , char * extra ) { struct orinoco_private * priv = ndev_priv ( dev ) ; hermes_t * hw = & priv -> hw ; struct iw_param * param = & wrqu -> param ; unsigned long flags ; int ret = - EINPROGRESS ; if ( orinoco_lock ( priv , & flags ) != 0 ) return - EBUSY ; switch ( param -> flags & IW_AUTH_INDEX ) { case IW_AUTH_WPA_VERSION : case IW_AUTH_CIPHER_PAIRWISE : case IW_AUTH_CIPHER_GROUP : case IW_AUTH_RX_UNENCRYPTED_EAPOL : case IW_AUTH_PRIVACY_INVOKED : case IW_AUTH_DROP_UNENCRYPTED : break ; case IW_AUTH_KEY_MGMT : priv -> key_mgmt = param -> value ; break ; case IW_AUTH_TKIP_COUNTERMEASURES : if ( param -> value ) { priv -> tkip_cm_active = 1 ; <S2SV_StartBug> ret = hermes_enable_port ( hw , 0 ) ; <S2SV_EndBug> } else { priv -> tkip_cm_active = 0 ; ret = hermes_disable_port ( hw , 0 ) ; } break ; case IW_AUTH_80211_AUTH_ALG : if ( param -> value & IW_AUTH_ALG_SHARED_KEY ) priv -> wep_restrict = 1 ; else if ( param -> value & IW_AUTH_ALG_OPEN_SYSTEM ) priv -> wep_restrict = 0 ; else ret = - EINVAL ; break ; case IW_AUTH_WPA_ENABLED : if ( priv -> has_wpa ) { priv -> wpa_enabled = param -> value ? 1 : 0 ; } else { if ( param -> value ) ret = - EOPNOTSUPP ; priv -> wpa_enabled = 0 ; } break ; default : ret = - EOPNOTSUPP ; } orinoco_unlock ( priv , & flags ) ; return ret ; }
CWE-000 static int create_fixed_stream_quirk ( struct snd_usb_audio * chip , struct usb_interface * iface , struct usb_driver * driver , const struct snd_usb_audio_quirk * quirk ) { struct audioformat * fp ; struct usb_host_interface * alts ; struct usb_interface_descriptor * altsd ; int stream , err ; unsigned * rate_table = NULL ; fp = kmemdup ( quirk -> data , sizeof ( * fp ) , GFP_KERNEL ) ; if ( ! fp ) { usb_audio_err ( chip , "cannot<S2SV_blank>memdup\\n" ) ; return - ENOMEM ; } if ( fp -> nr_rates > MAX_NR_RATES ) { kfree ( fp ) ; return - EINVAL ; } if ( fp -> nr_rates > 0 ) { rate_table = kmemdup ( fp -> rate_table , sizeof ( int ) * fp -> nr_rates , GFP_KERNEL ) ; if ( ! rate_table ) { kfree ( fp ) ; return - ENOMEM ; } fp -> rate_table = rate_table ; } stream = ( fp -> endpoint & USB_DIR_IN ) ? SNDRV_PCM_STREAM_CAPTURE : SNDRV_PCM_STREAM_PLAYBACK ; err = snd_usb_add_audio_stream ( chip , stream , fp ) ; if ( err < 0 ) { kfree ( fp ) ; kfree ( rate_table ) ; return err ; } if ( fp -> iface != get_iface_desc ( & iface -> altsetting [ 0 ] ) -> bInterfaceNumber || fp -> altset_idx >= iface -> num_altsetting ) { kfree ( fp ) ; kfree ( rate_table ) ; return - EINVAL ; } alts = & iface -> altsetting [ fp -> altset_idx ] ; altsd = get_iface_desc ( alts ) ; <S2SV_StartBug> fp -> protocol = altsd -> bInterfaceProtocol ; <S2SV_EndBug> if ( fp -> datainterval == 0 ) fp -> datainterval = snd_usb_parse_datainterval ( chip , alts ) ; if ( fp -> maxpacksize == 0 ) fp -> maxpacksize = le16_to_cpu ( get_endpoint ( alts , 0 ) -> wMaxPacketSize ) ; usb_set_interface ( chip -> dev , fp -> iface , 0 ) ; snd_usb_init_pitch ( chip , fp -> iface , alts , fp ) ; snd_usb_init_sample_rate ( chip , fp -> iface , alts , fp , fp -> rate_max ) ; return 0 ; }
CWE-000 SYSCALL_DEFINE4 ( epoll_ctl , int , epfd , int , op , int , fd , struct epoll_event __user * , event ) { int error ; int did_lock_epmutex = 0 ; struct file * file , * tfile ; struct eventpoll * ep ; struct epitem * epi ; struct epoll_event epds ; error = - EFAULT ; if ( ep_op_has_event ( op ) && copy_from_user ( & epds , event , sizeof ( struct epoll_event ) ) ) goto error_return ; error = - EBADF ; file = fget ( epfd ) ; if ( ! file ) goto error_return ; tfile = fget ( fd ) ; if ( ! tfile ) goto error_fput ; error = - EPERM ; if ( ! tfile -> f_op || ! tfile -> f_op -> poll ) goto error_tgt_fput ; error = - EINVAL ; if ( file == tfile || ! is_file_epoll ( file ) ) goto error_tgt_fput ; ep = file -> private_data ; if ( op == EPOLL_CTL_ADD || op == EPOLL_CTL_DEL ) { mutex_lock ( & epmutex ) ; did_lock_epmutex = 1 ; } if ( op == EPOLL_CTL_ADD ) { if ( is_file_epoll ( tfile ) ) { error = - ELOOP ; <S2SV_StartBug> if ( ep_loop_check ( ep , tfile ) != 0 ) <S2SV_EndBug> <S2SV_StartBug> goto error_tgt_fput ; <S2SV_EndBug> } else list_add ( & tfile -> f_tfile_llink , & tfile_check_list ) ; } mutex_lock_nested ( & ep -> mtx , 0 ) ; epi = ep_find ( ep , tfile , fd ) ; error = - EINVAL ; switch ( op ) { case EPOLL_CTL_ADD : if ( ! epi ) { epds . events |= POLLERR | POLLHUP ; error = ep_insert ( ep , & epds , tfile , fd ) ; } else error = - EEXIST ; clear_tfile_check_list ( ) ; break ; case EPOLL_CTL_DEL : if ( epi ) error = ep_remove ( ep , epi ) ; else error = - ENOENT ; break ; case EPOLL_CTL_MOD : if ( epi ) { epds . events |= POLLERR | POLLHUP ; error = ep_modify ( ep , epi , & epds ) ; } else error = - ENOENT ; break ; } mutex_unlock ( & ep -> mtx ) ; error_tgt_fput : if ( did_lock_epmutex ) mutex_unlock ( & epmutex ) ; fput ( tfile ) ; error_fput : fput ( file ) ; error_return : return error ; }
CWE-000 static int gtco_probe ( struct usb_interface * usbinterface , const struct usb_device_id * id ) { struct gtco * gtco ; struct input_dev * input_dev ; struct hid_descriptor * hid_desc ; char * report ; int result = 0 , retry ; int error ; struct usb_endpoint_descriptor * endpoint ; gtco = kzalloc ( sizeof ( struct gtco ) , GFP_KERNEL ) ; input_dev = input_allocate_device ( ) ; if ( ! gtco || ! input_dev ) { dev_err ( & usbinterface -> dev , "No<S2SV_blank>more<S2SV_blank>memory\\n" ) ; error = - ENOMEM ; goto err_free_devs ; } gtco -> inputdevice = input_dev ; gtco -> usbdev = interface_to_usbdev ( usbinterface ) ; gtco -> intf = usbinterface ; gtco -> buffer = usb_alloc_coherent ( gtco -> usbdev , REPORT_MAX_SIZE , GFP_KERNEL , & gtco -> buf_dma ) ; if ( ! gtco -> buffer ) { dev_err ( & usbinterface -> dev , "No<S2SV_blank>more<S2SV_blank>memory<S2SV_blank>for<S2SV_blank>us<S2SV_blank>buffers\\n" ) ; error = - ENOMEM ; goto err_free_devs ; } gtco -> urbinfo = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! gtco -> urbinfo ) { dev_err ( & usbinterface -> dev , "Failed<S2SV_blank>to<S2SV_blank>allocate<S2SV_blank>URB\\n" ) ; error = - ENOMEM ; goto err_free_buf ; } <S2SV_StartBug> endpoint = & usbinterface -> altsetting [ 0 ] . endpoint [ 0 ] . desc ; <S2SV_EndBug> dev_dbg ( & usbinterface -> dev , "gtco<S2SV_blank>#<S2SV_blank>interfaces:<S2SV_blank>%d\\n" , usbinterface -> num_altsetting ) ; dev_dbg ( & usbinterface -> dev , "num<S2SV_blank>endpoints:<S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank><S2SV_blank>%d\\n" , usbinterface -> cur_altsetting -> desc . bNumEndpoints ) ; dev_dbg ( & usbinterface -> dev , "interface<S2SV_blank>class:<S2SV_blank><S2SV_blank><S2SV_blank>%d\\n" , usbinterface -> cur_altsetting -> desc . bInterfaceClass ) ; dev_dbg ( & usbinterface -> dev , "endpoint:<S2SV_blank>attribute:0x%x<S2SV_blank>type:0x%x\\n" , endpoint -> bmAttributes , endpoint -> bDescriptorType ) ; if ( usb_endpoint_xfer_int ( endpoint ) ) dev_dbg ( & usbinterface -> dev , "endpoint:<S2SV_blank>we<S2SV_blank>have<S2SV_blank>interrupt<S2SV_blank>endpoint\\n" ) ; dev_dbg ( & usbinterface -> dev , "endpoint<S2SV_blank>extra<S2SV_blank>len:%d\\n" , usbinterface -> altsetting [ 0 ] . extralen ) ; if ( usb_get_extra_descriptor ( usbinterface -> cur_altsetting , HID_DEVICE_TYPE , & hid_desc ) != 0 ) { dev_err ( & usbinterface -> dev , "Can\'t<S2SV_blank>retrieve<S2SV_blank>exta<S2SV_blank>USB<S2SV_blank>descriptor<S2SV_blank>to<S2SV_blank>get<S2SV_blank>hid<S2SV_blank>report<S2SV_blank>descriptor<S2SV_blank>length\\n" ) ; error = - EIO ; goto err_free_urb ; } dev_dbg ( & usbinterface -> dev , "Extra<S2SV_blank>descriptor<S2SV_blank>success:<S2SV_blank>type:%d<S2SV_blank><S2SV_blank>len:%d\\n" , hid_desc -> bDescriptorType , hid_desc -> wDescriptorLength ) ; report = kzalloc ( le16_to_cpu ( hid_desc -> wDescriptorLength ) , GFP_KERNEL ) ; if ( ! report ) { dev_err ( & usbinterface -> dev , "No<S2SV_blank>more<S2SV_blank>memory<S2SV_blank>for<S2SV_blank>report\\n" ) ; error = - ENOMEM ; goto err_free_urb ; } for ( retry = 0 ; retry < 3 ; retry ++ ) { result = usb_control_msg ( gtco -> usbdev , usb_rcvctrlpipe ( gtco -> usbdev , 0 ) , USB_REQ_GET_DESCRIPTOR , USB_RECIP_INTERFACE | USB_DIR_IN , REPORT_DEVICE_TYPE << 8 , 0 , report , le16_to_cpu ( hid_desc -> wDescriptorLength ) , 5000 ) ; dev_dbg ( & usbinterface -> dev , "usb_control_msg<S2SV_blank>result:<S2SV_blank>%d\\n" , result ) ; if ( result == le16_to_cpu ( hid_desc -> wDescriptorLength ) ) { parse_hid_report_descriptor ( gtco , report , result ) ; break ; } } kfree ( report ) ; if ( result != le16_to_cpu ( hid_desc -> wDescriptorLength ) ) { dev_err ( & usbinterface -> dev , "Failed<S2SV_blank>to<S2SV_blank>get<S2SV_blank>HID<S2SV_blank>Report<S2SV_blank>Descriptor<S2SV_blank>of<S2SV_blank>size:<S2SV_blank>%d\\n" , hid_desc -> wDescriptorLength ) ; error = - EIO ; goto err_free_urb ; } usb_make_path ( gtco -> usbdev , gtco -> usbpath , sizeof ( gtco -> usbpath ) ) ; strlcat ( gtco -> usbpath , "/input0" , sizeof ( gtco -> usbpath ) ) ; input_dev -> open = gtco_input_open ; input_dev -> close = gtco_input_close ; input_dev -> name = "GTCO_CalComp" ; input_dev -> phys = gtco -> usbpath ; input_set_drvdata ( input_dev , gtco ) ; gtco_setup_caps ( input_dev ) ; usb_to_input_id ( gtco -> usbdev , & input_dev -> id ) ; input_dev -> dev . parent = & usbinterface -> dev ; endpoint = & usbinterface -> altsetting [ 0 ] . endpoint [ 0 ] . desc ; usb_fill_int_urb ( gtco -> urbinfo , gtco -> usbdev , usb_rcvintpipe ( gtco -> usbdev , endpoint -> bEndpointAddress ) , gtco -> buffer , REPORT_MAX_SIZE , gtco_urb_callback , gtco , endpoint -> bInterval ) ; gtco -> urbinfo -> transfer_dma = gtco -> buf_dma ; gtco -> urbinfo -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; usb_set_intfdata ( usbinterface , gtco ) ; error = input_register_device ( input_dev ) ; if ( error ) goto err_free_urb ; return 0 ; err_free_urb : usb_free_urb ( gtco -> urbinfo ) ; err_free_buf : usb_free_coherent ( gtco -> usbdev , REPORT_MAX_SIZE , gtco -> buffer , gtco -> buf_dma ) ; err_free_devs : input_free_device ( input_dev ) ; kfree ( gtco ) ; return error ; }
CWE-000 int usbnet_probe ( struct usb_interface * udev , const struct usb_device_id * prod ) { struct usbnet * dev ; struct net_device * net ; struct usb_host_interface * interface ; struct driver_info * info ; struct usb_device * xdev ; int status ; const char * name ; struct usb_driver * driver = to_usb_driver ( udev -> dev . driver ) ; if ( ! driver -> supports_autosuspend ) { driver -> supports_autosuspend = 1 ; pm_runtime_enable ( & udev -> dev ) ; } name = udev -> dev . driver -> name ; info = ( struct driver_info * ) prod -> driver_info ; if ( ! info ) { dev_dbg ( & udev -> dev , "blacklisted<S2SV_blank>by<S2SV_blank>%s\\n" , name ) ; return - ENODEV ; } xdev = interface_to_usbdev ( udev ) ; interface = udev -> cur_altsetting ; status = - ENOMEM ; net = alloc_etherdev ( sizeof ( * dev ) ) ; if ( ! net ) goto out ; SET_NETDEV_DEV ( net , & udev -> dev ) ; dev = netdev_priv ( net ) ; dev -> udev = xdev ; dev -> intf = udev ; dev -> driver_info = info ; dev -> driver_name = name ; dev -> msg_enable = netif_msg_init ( msg_level , NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK ) ; init_waitqueue_head ( & dev -> wait ) ; skb_queue_head_init ( & dev -> rxq ) ; skb_queue_head_init ( & dev -> txq ) ; skb_queue_head_init ( & dev -> done ) ; skb_queue_head_init ( & dev -> rxq_pause ) ; dev -> bh . func = usbnet_bh ; dev -> bh . data = ( unsigned long ) dev ; INIT_WORK ( & dev -> kevent , usbnet_deferred_kevent ) ; init_usb_anchor ( & dev -> deferred ) ; dev -> delay . function = usbnet_bh ; dev -> delay . data = ( unsigned long ) dev ; init_timer ( & dev -> delay ) ; mutex_init ( & dev -> phy_mutex ) ; mutex_init ( & dev -> interrupt_mutex ) ; dev -> interrupt_count = 0 ; dev -> net = net ; strcpy ( net -> name , "usb%d" ) ; memcpy ( net -> dev_addr , node_id , sizeof node_id ) ; dev -> hard_mtu = net -> mtu + net -> hard_header_len ; net -> netdev_ops = & usbnet_netdev_ops ; net -> watchdog_timeo = TX_TIMEOUT_JIFFIES ; net -> ethtool_ops = & usbnet_ethtool_ops ; if ( info -> bind ) { status = info -> bind ( dev , udev ) ; if ( status < 0 ) goto out1 ; if ( ( dev -> driver_info -> flags & FLAG_ETHER ) != 0 && ( ( dev -> driver_info -> flags & FLAG_POINTTOPOINT ) == 0 || ( net -> dev_addr [ 0 ] & 0x02 ) == 0 ) ) strcpy ( net -> name , "eth%d" ) ; if ( ( dev -> driver_info -> flags & FLAG_WLAN ) != 0 ) strcpy ( net -> name , "wlan%d" ) ; if ( ( dev -> driver_info -> flags & FLAG_WWAN ) != 0 ) strcpy ( net -> name , "wwan%d" ) ; if ( ( dev -> driver_info -> flags & FLAG_NOARP ) != 0 ) net -> flags |= IFF_NOARP ; if ( net -> mtu > ( dev -> hard_mtu - net -> hard_header_len ) ) net -> mtu = dev -> hard_mtu - net -> hard_header_len ; } else if ( ! info -> in || ! info -> out ) status = usbnet_get_endpoints ( dev , udev ) ; else { dev -> in = usb_rcvbulkpipe ( xdev , info -> in ) ; dev -> out = usb_sndbulkpipe ( xdev , info -> out ) ; if ( ! ( info -> flags & FLAG_NO_SETINT ) ) status = usb_set_interface ( xdev , interface -> desc . bInterfaceNumber , interface -> desc . bAlternateSetting ) ; else status = 0 ; } if ( status >= 0 && dev -> status ) status = init_status ( dev , udev ) ; if ( status < 0 ) goto out3 ; if ( ! dev -> rx_urb_size ) dev -> rx_urb_size = dev -> hard_mtu ; dev -> maxpacket = usb_maxpacket ( dev -> udev , dev -> out , 1 ) ; if ( ether_addr_equal ( net -> dev_addr , node_id ) ) net -> addr_assign_type = NET_ADDR_RANDOM ; if ( ( dev -> driver_info -> flags & FLAG_WLAN ) != 0 ) SET_NETDEV_DEVTYPE ( net , & wlan_type ) ; if ( ( dev -> driver_info -> flags & FLAG_WWAN ) != 0 ) SET_NETDEV_DEVTYPE ( net , & wwan_type ) ; usbnet_update_max_qlen ( dev ) ; if ( dev -> can_dma_sg && ! ( info -> flags & FLAG_SEND_ZLP ) && ! ( info -> flags & FLAG_MULTI_PACKET ) ) { dev -> padding_pkt = kzalloc ( 1 , GFP_KERNEL ) ; if ( ! dev -> padding_pkt ) { status = - ENOMEM ; goto out4 ; } } status = register_netdev ( net ) ; if ( status ) goto out5 ; netif_info ( dev , probe , dev -> net , "register<S2SV_blank>\'%s\'<S2SV_blank>at<S2SV_blank>usb-%s-%s,<S2SV_blank>%s,<S2SV_blank>%pM\\n" , udev -> dev . driver -> name , xdev -> bus -> bus_name , xdev -> devpath , dev -> driver_info -> description , net -> dev_addr ) ; usb_set_intfdata ( udev , dev ) ; netif_device_attach ( net ) ; if ( dev -> driver_info -> flags & FLAG_LINK_INTR ) usbnet_link_change ( dev , 0 , 0 ) ; return 0 ; out5 : kfree ( dev -> padding_pkt ) ; out4 : usb_free_urb ( dev -> interrupt ) ; out3 : if ( info -> unbind ) info -> unbind ( dev , udev ) ; out1 : <S2SV_StartBug> free_netdev ( net ) ; <S2SV_EndBug> out : return status ; }
CWE-000 void sctp_assoc_update ( struct sctp_association * asoc , struct sctp_association * new ) { struct sctp_transport * trans ; struct list_head * pos , * temp ; asoc -> c = new -> c ; asoc -> peer . rwnd = new -> peer . rwnd ; asoc -> peer . sack_needed = new -> peer . sack_needed ; <S2SV_StartBug> asoc -> peer . i = new -> peer . i ; <S2SV_EndBug> sctp_tsnmap_init ( & asoc -> peer . tsn_map , SCTP_TSN_MAP_INITIAL , asoc -> peer . i . initial_tsn , GFP_ATOMIC ) ; list_for_each_safe ( pos , temp , & asoc -> peer . transport_addr_list ) { trans = list_entry ( pos , struct sctp_transport , transports ) ; if ( ! sctp_assoc_lookup_paddr ( new , & trans -> ipaddr ) ) { sctp_assoc_rm_peer ( asoc , trans ) ; continue ; } if ( asoc -> state >= SCTP_STATE_ESTABLISHED ) sctp_transport_reset ( trans ) ; } if ( asoc -> state >= SCTP_STATE_ESTABLISHED ) { asoc -> next_tsn = new -> next_tsn ; asoc -> ctsn_ack_point = new -> ctsn_ack_point ; asoc -> adv_peer_ack_point = new -> adv_peer_ack_point ; sctp_ssnmap_clear ( asoc -> ssnmap ) ; sctp_ulpq_flush ( & asoc -> ulpq ) ; asoc -> overall_error_count = 0 ; } else { list_for_each_entry ( trans , & new -> peer . transport_addr_list , transports ) { if ( ! sctp_assoc_lookup_paddr ( asoc , & trans -> ipaddr ) ) sctp_assoc_add_peer ( asoc , & trans -> ipaddr , GFP_ATOMIC , trans -> state ) ; } asoc -> ctsn_ack_point = asoc -> next_tsn - 1 ; asoc -> adv_peer_ack_point = asoc -> ctsn_ack_point ; if ( ! asoc -> ssnmap ) { asoc -> ssnmap = new -> ssnmap ; new -> ssnmap = NULL ; } if ( ! asoc -> assoc_id ) { sctp_assoc_set_id ( asoc , GFP_ATOMIC ) ; } } kfree ( asoc -> peer . peer_random ) ; asoc -> peer . peer_random = new -> peer . peer_random ; new -> peer . peer_random = NULL ; kfree ( asoc -> peer . peer_chunks ) ; asoc -> peer . peer_chunks = new -> peer . peer_chunks ; new -> peer . peer_chunks = NULL ; kfree ( asoc -> peer . peer_hmacs ) ; asoc -> peer . peer_hmacs = new -> peer . peer_hmacs ; new -> peer . peer_hmacs = NULL ; sctp_auth_key_put ( asoc -> asoc_shared_key ) ; sctp_auth_asoc_init_active_key ( asoc , GFP_ATOMIC ) ; }
CWE-000 static __u8 * cp_report_fixup ( struct hid_device * hdev , __u8 * rdesc , unsigned int * rsize ) { unsigned long quirks = ( unsigned long ) hid_get_drvdata ( hdev ) ; unsigned int i ; <S2SV_StartBug> if ( ! ( quirks & CP_RDESC_SWAPPED_MIN_MAX ) ) <S2SV_EndBug> return rdesc ; for ( i = 0 ; i < * rsize - 4 ; i ++ ) if ( rdesc [ i ] == 0x29 && rdesc [ i + 2 ] == 0x19 ) { rdesc [ i ] = 0x19 ; rdesc [ i + 2 ] = 0x29 ; swap ( rdesc [ i + 3 ] , rdesc [ i + 1 ] ) ; } return rdesc ; }
CWE-000 long join_session_keyring ( const char * name ) { const struct cred * old ; struct cred * new ; struct key * keyring ; long ret , serial ; new = prepare_creds ( ) ; if ( ! new ) return - ENOMEM ; old = current_cred ( ) ; if ( ! name ) { ret = install_session_keyring_to_cred ( new , NULL ) ; if ( ret < 0 ) goto error ; serial = new -> session_keyring -> serial ; ret = commit_creds ( new ) ; if ( ret == 0 ) ret = serial ; goto okay ; } mutex_lock ( & key_session_mutex ) ; keyring = find_keyring_by_name ( name , false ) ; if ( PTR_ERR ( keyring ) == - ENOKEY ) { keyring = keyring_alloc ( name , old -> uid , old -> gid , old , KEY_POS_ALL | KEY_USR_VIEW | KEY_USR_READ | KEY_USR_LINK , KEY_ALLOC_IN_QUOTA , NULL ) ; if ( IS_ERR ( keyring ) ) { ret = PTR_ERR ( keyring ) ; goto error2 ; } } else if ( IS_ERR ( keyring ) ) { ret = PTR_ERR ( keyring ) ; goto error2 ; } else if ( keyring == new -> session_keyring ) { <S2SV_StartBug> ret = 0 ; <S2SV_EndBug> goto error2 ; } ret = install_session_keyring_to_cred ( new , keyring ) ; if ( ret < 0 ) goto error2 ; commit_creds ( new ) ; mutex_unlock ( & key_session_mutex ) ; ret = keyring -> serial ; key_put ( keyring ) ; okay : return ret ; error2 : mutex_unlock ( & key_session_mutex ) ; error : abort_creds ( new ) ; return ret ; }
CWE-000 struct key * key_alloc ( struct key_type * type , const char * desc , kuid_t uid , kgid_t gid , const struct cred * cred , key_perm_t perm , unsigned long flags , struct key_restriction * restrict_link ) { struct key_user * user = NULL ; struct key * key ; size_t desclen , quotalen ; int ret ; key = ERR_PTR ( - EINVAL ) ; if ( ! desc || ! * desc ) goto error ; if ( type -> vet_description ) { ret = type -> vet_description ( desc ) ; if ( ret < 0 ) { key = ERR_PTR ( ret ) ; goto error ; } } desclen = strlen ( desc ) ; quotalen = desclen + 1 + type -> def_datalen ; user = key_user_lookup ( uid ) ; if ( ! user ) goto no_memory_1 ; if ( ! ( flags & KEY_ALLOC_NOT_IN_QUOTA ) ) { unsigned maxkeys = uid_eq ( uid , GLOBAL_ROOT_UID ) ? key_quota_root_maxkeys : key_quota_maxkeys ; unsigned maxbytes = uid_eq ( uid , GLOBAL_ROOT_UID ) ? key_quota_root_maxbytes : key_quota_maxbytes ; spin_lock ( & user -> lock ) ; if ( ! ( flags & KEY_ALLOC_QUOTA_OVERRUN ) ) { if ( user -> qnkeys + 1 >= maxkeys || user -> qnbytes + quotalen >= maxbytes || user -> qnbytes + quotalen < user -> qnbytes ) goto no_quota ; } user -> qnkeys ++ ; user -> qnbytes += quotalen ; spin_unlock ( & user -> lock ) ; } key = kmem_cache_zalloc ( key_jar , GFP_KERNEL ) ; if ( ! key ) goto no_memory_2 ; key -> index_key . desc_len = desclen ; key -> index_key . description = kmemdup ( desc , desclen + 1 , GFP_KERNEL ) ; if ( ! key -> index_key . description ) goto no_memory_3 ; refcount_set ( & key -> usage , 1 ) ; init_rwsem ( & key -> sem ) ; lockdep_set_class ( & key -> sem , & type -> lock_class ) ; key -> index_key . type = type ; key -> user = user ; key -> quotalen = quotalen ; key -> datalen = type -> def_datalen ; key -> uid = uid ; key -> gid = gid ; key -> perm = perm ; key -> restrict_link = restrict_link ; if ( ! ( flags & KEY_ALLOC_NOT_IN_QUOTA ) ) key -> flags |= 1 << KEY_FLAG_IN_QUOTA ; if ( flags & KEY_ALLOC_BUILT_IN ) key -> flags |= 1 << KEY_FLAG_BUILTIN ; <S2SV_StartBug> # ifdef KEY_DEBUGGING <S2SV_EndBug> key -> magic = KEY_DEBUG_MAGIC ; # endif ret = security_key_alloc ( key , cred , flags ) ; if ( ret < 0 ) goto security_error ; atomic_inc ( & user -> nkeys ) ; key_alloc_serial ( key ) ; error : return key ; security_error : kfree ( key -> description ) ; kmem_cache_free ( key_jar , key ) ; if ( ! ( flags & KEY_ALLOC_NOT_IN_QUOTA ) ) { spin_lock ( & user -> lock ) ; user -> qnkeys -- ; user -> qnbytes -= quotalen ; spin_unlock ( & user -> lock ) ; } key_user_put ( user ) ; key = ERR_PTR ( ret ) ; goto error ; no_memory_3 : kmem_cache_free ( key_jar , key ) ; no_memory_2 : if ( ! ( flags & KEY_ALLOC_NOT_IN_QUOTA ) ) { spin_lock ( & user -> lock ) ; user -> qnkeys -- ; user -> qnbytes -= quotalen ; spin_unlock ( & user -> lock ) ; } key_user_put ( user ) ; no_memory_1 : key = ERR_PTR ( - ENOMEM ) ; goto error ; no_quota : spin_unlock ( & user -> lock ) ; key_user_put ( user ) ; key = ERR_PTR ( - EDQUOT ) ; goto error ; }
CWE-000 <S2SV_StartBug> struct key * find_keyring_by_name ( const char * name , bool skip_perm_check ) <S2SV_EndBug> { struct key * keyring ; int bucket ; if ( ! name ) return ERR_PTR ( - EINVAL ) ; bucket = keyring_hash ( name ) ; read_lock ( & keyring_name_lock ) ; if ( keyring_name_hash [ bucket ] . next ) { list_for_each_entry ( keyring , & keyring_name_hash [ bucket ] , name_link ) { if ( ! kuid_has_mapping ( current_user_ns ( ) , keyring -> user -> uid ) ) continue ; if ( test_bit ( KEY_FLAG_REVOKED , & keyring -> flags ) ) continue ; if ( strcmp ( keyring -> description , name ) != 0 ) continue ; <S2SV_StartBug> if ( ! skip_perm_check && <S2SV_EndBug> key_permission ( make_key_ref ( keyring , 0 ) , KEY_NEED_SEARCH ) < 0 ) <S2SV_StartBug> continue ; <S2SV_EndBug> if ( ! refcount_inc_not_zero ( & keyring -> usage ) ) continue ; keyring -> last_used_at = current_kernel_time ( ) . tv_sec ; goto out ; } } keyring = ERR_PTR ( - ENOKEY ) ; out : read_unlock ( & keyring_name_lock ) ; return keyring ; }
CWE-000 int install_user_keyrings ( void ) { struct user_struct * user ; const struct cred * cred ; struct key * uid_keyring , * session_keyring ; key_perm_t user_keyring_perm ; char buf [ 20 ] ; int ret ; uid_t uid ; user_keyring_perm = ( KEY_POS_ALL & ~ KEY_POS_SETATTR ) | KEY_USR_ALL ; cred = current_cred ( ) ; user = cred -> user ; uid = from_kuid ( cred -> user_ns , user -> uid ) ; kenter ( "%p{%u}" , user , uid ) ; if ( user -> uid_keyring && user -> session_keyring ) { kleave ( "<S2SV_blank>=<S2SV_blank>0<S2SV_blank>[exist]" ) ; return 0 ; } mutex_lock ( & key_user_keyring_mutex ) ; ret = 0 ; if ( ! user -> uid_keyring ) { sprintf ( buf , "_uid.%u" , uid ) ; uid_keyring = find_keyring_by_name ( buf , true ) ; if ( IS_ERR ( uid_keyring ) ) { uid_keyring = keyring_alloc ( buf , user -> uid , INVALID_GID , cred , user_keyring_perm , <S2SV_StartBug> KEY_ALLOC_IN_QUOTA , <S2SV_EndBug> NULL , NULL ) ; if ( IS_ERR ( uid_keyring ) ) { ret = PTR_ERR ( uid_keyring ) ; goto error ; } } sprintf ( buf , "_uid_ses.%u" , uid ) ; session_keyring = find_keyring_by_name ( buf , true ) ; if ( IS_ERR ( session_keyring ) ) { session_keyring = keyring_alloc ( buf , user -> uid , INVALID_GID , cred , user_keyring_perm , <S2SV_StartBug> KEY_ALLOC_IN_QUOTA , <S2SV_EndBug> NULL , NULL ) ; if ( IS_ERR ( session_keyring ) ) { ret = PTR_ERR ( session_keyring ) ; goto error_release ; } ret = key_link ( session_keyring , uid_keyring ) ; if ( ret < 0 ) goto error_release_both ; } user -> uid_keyring = uid_keyring ; user -> session_keyring = session_keyring ; } mutex_unlock ( & key_user_keyring_mutex ) ; kleave ( "<S2SV_blank>=<S2SV_blank>0" ) ; return 0 ; error_release_both : key_put ( session_keyring ) ; error_release : key_put ( uid_keyring ) ; error : mutex_unlock ( & key_user_keyring_mutex ) ; kleave ( "<S2SV_blank>=<S2SV_blank>%d" , ret ) ; return ret ; }
CWE-000 static int asn1_find_indefinite_length ( const unsigned char * data , size_t datalen , size_t * _dp , size_t * _len , const char * * _errmsg ) { unsigned char tag , tmp ; size_t dp = * _dp , len , n ; int indef_level = 1 ; next_tag : if ( unlikely ( datalen - dp < 2 ) ) { if ( datalen == dp ) goto missing_eoc ; goto data_overrun_error ; } tag = data [ dp ++ ] ; <S2SV_StartBug> if ( tag == 0 ) { <S2SV_EndBug> if ( data [ dp ++ ] != 0 ) goto invalid_eoc ; if ( -- indef_level <= 0 ) { * _len = dp - * _dp ; * _dp = dp ; return 0 ; } goto next_tag ; } if ( unlikely ( ( tag & 0x1f ) == ASN1_LONG_TAG ) ) { do { if ( unlikely ( datalen - dp < 2 ) ) goto data_overrun_error ; tmp = data [ dp ++ ] ; } while ( tmp & 0x80 ) ; } len = data [ dp ++ ] ; <S2SV_StartBug> if ( len <= 0x7f ) { <S2SV_EndBug> dp += len ; goto next_tag ; } if ( unlikely ( len == ASN1_INDEFINITE_LENGTH ) ) { if ( unlikely ( ( tag & ASN1_CONS_BIT ) == ASN1_PRIM << 5 ) ) goto indefinite_len_primitive ; indef_level ++ ; goto next_tag ; } n = len - 0x80 ; <S2SV_StartBug> if ( unlikely ( n > sizeof ( size_t ) - 1 ) ) <S2SV_EndBug> goto length_too_long ; if ( unlikely ( n > datalen - dp ) ) goto data_overrun_error ; <S2SV_StartBug> for ( len = 0 ; n > 0 ; n -- ) { <S2SV_EndBug> len <<= 8 ; len |= data [ dp ++ ] ; } <S2SV_StartBug> dp += len ; <S2SV_EndBug> goto next_tag ; length_too_long : * _errmsg = "Unsupported<S2SV_blank>length" ; goto error ; indefinite_len_primitive : * _errmsg = "Indefinite<S2SV_blank>len<S2SV_blank>primitive<S2SV_blank>not<S2SV_blank>permitted" ; goto error ; invalid_eoc : * _errmsg = "Invalid<S2SV_blank>length<S2SV_blank>EOC" ; goto error ; data_overrun_error : * _errmsg = "Data<S2SV_blank>overrun<S2SV_blank>error" ; goto error ; missing_eoc : * _errmsg = "Missing<S2SV_blank>EOC<S2SV_blank>in<S2SV_blank>indefinite<S2SV_blank>len<S2SV_blank>cons" ; error : * _dp = dp ; return - 1 ; }
CWE-000 int ocfs2_setattr ( struct dentry * dentry , struct iattr * attr ) { int status = 0 , size_change ; int inode_locked = 0 ; struct inode * inode = d_inode ( dentry ) ; struct super_block * sb = inode -> i_sb ; struct ocfs2_super * osb = OCFS2_SB ( sb ) ; struct buffer_head * bh = NULL ; handle_t * handle = NULL ; struct dquot * transfer_to [ MAXQUOTAS ] = { } ; int qtype ; int had_lock ; struct ocfs2_lock_holder oh ; trace_ocfs2_setattr ( inode , dentry , ( unsigned long long ) OCFS2_I ( inode ) -> ip_blkno , dentry -> d_name . len , dentry -> d_name . name , attr -> ia_valid , attr -> ia_mode , from_kuid ( & init_user_ns , attr -> ia_uid ) , from_kgid ( & init_user_ns , attr -> ia_gid ) ) ; if ( S_ISLNK ( inode -> i_mode ) ) attr -> ia_valid &= ~ ATTR_SIZE ; # define OCFS2_VALID_ATTRS ( ATTR_ATIME | ATTR_MTIME | ATTR_CTIME | ATTR_SIZE | ATTR_GID | ATTR_UID | ATTR_MODE ) if ( ! ( attr -> ia_valid & OCFS2_VALID_ATTRS ) ) return 0 ; status = setattr_prepare ( dentry , attr ) ; if ( status ) return status ; if ( is_quota_modification ( inode , attr ) ) { status = dquot_initialize ( inode ) ; if ( status ) return status ; } size_change = S_ISREG ( inode -> i_mode ) && attr -> ia_valid & ATTR_SIZE ; if ( size_change ) { <S2SV_StartBug> status = ocfs2_rw_lock ( inode , 1 ) ; <S2SV_EndBug> if ( status < 0 ) { mlog_errno ( status ) ; goto bail ; } } had_lock = ocfs2_inode_lock_tracker ( inode , & bh , 1 , & oh ) ; if ( had_lock < 0 ) { status = had_lock ; goto bail_unlock_rw ; } else if ( had_lock ) { mlog ( ML_ERROR , "Another<S2SV_blank>case<S2SV_blank>of<S2SV_blank>recursive<S2SV_blank>locking:\\n" ) ; dump_stack ( ) ; } inode_locked = 1 ; if ( size_change ) { status = inode_newsize_ok ( inode , attr -> ia_size ) ; if ( status ) <S2SV_StartBug> goto bail_unlock ; <S2SV_EndBug> inode_dio_wait ( inode ) ; if ( i_size_read ( inode ) >= attr -> ia_size ) { if ( ocfs2_should_order_data ( inode ) ) { status = ocfs2_begin_ordered_truncate ( inode , attr -> ia_size ) ; if ( status ) goto bail_unlock ; } status = ocfs2_truncate_file ( inode , bh , attr -> ia_size ) ; } else status = ocfs2_extend_file ( inode , bh , attr -> ia_size ) ; if ( status < 0 ) { if ( status != - ENOSPC ) mlog_errno ( status ) ; status = - ENOSPC ; goto bail_unlock ; } } if ( ( attr -> ia_valid & ATTR_UID && ! uid_eq ( attr -> ia_uid , inode -> i_uid ) ) || ( attr -> ia_valid & ATTR_GID && ! gid_eq ( attr -> ia_gid , inode -> i_gid ) ) ) { if ( attr -> ia_valid & ATTR_UID && ! uid_eq ( attr -> ia_uid , inode -> i_uid ) && OCFS2_HAS_RO_COMPAT_FEATURE ( sb , OCFS2_FEATURE_RO_COMPAT_USRQUOTA ) ) { transfer_to [ USRQUOTA ] = dqget ( sb , make_kqid_uid ( attr -> ia_uid ) ) ; if ( IS_ERR ( transfer_to [ USRQUOTA ] ) ) { status = PTR_ERR ( transfer_to [ USRQUOTA ] ) ; goto bail_unlock ; } } if ( attr -> ia_valid & ATTR_GID && ! gid_eq ( attr -> ia_gid , inode -> i_gid ) && OCFS2_HAS_RO_COMPAT_FEATURE ( sb , OCFS2_FEATURE_RO_COMPAT_GRPQUOTA ) ) { transfer_to [ GRPQUOTA ] = dqget ( sb , make_kqid_gid ( attr -> ia_gid ) ) ; if ( IS_ERR ( transfer_to [ GRPQUOTA ] ) ) { status = PTR_ERR ( transfer_to [ GRPQUOTA ] ) ; goto bail_unlock ; } } handle = ocfs2_start_trans ( osb , OCFS2_INODE_UPDATE_CREDITS + 2 * ocfs2_quota_trans_credits ( sb ) ) ; if ( IS_ERR ( handle ) ) { status = PTR_ERR ( handle ) ; mlog_errno ( status ) ; goto bail_unlock ; } status = __dquot_transfer ( inode , transfer_to ) ; if ( status < 0 ) goto bail_commit ; } else { handle = ocfs2_start_trans ( osb , OCFS2_INODE_UPDATE_CREDITS ) ; if ( IS_ERR ( handle ) ) { status = PTR_ERR ( handle ) ; mlog_errno ( status ) ; goto bail_unlock ; } } setattr_copy ( inode , attr ) ; mark_inode_dirty ( inode ) ; status = ocfs2_mark_inode_dirty ( handle , inode , bh ) ; if ( status < 0 ) mlog_errno ( status ) ; bail_commit : ocfs2_commit_trans ( osb , handle ) ; bail_unlock : if ( status && inode_locked ) { ocfs2_inode_unlock_tracker ( inode , 1 , & oh , had_lock ) ; inode_locked = 0 ; } bail_unlock_rw : if ( size_change ) ocfs2_rw_unlock ( inode , 1 ) ; bail : for ( qtype = 0 ; qtype < OCFS2_MAXQUOTAS ; qtype ++ ) dqput ( transfer_to [ qtype ] ) ; if ( ! status && attr -> ia_valid & ATTR_MODE ) { status = ocfs2_acl_chmod ( inode , bh ) ; if ( status < 0 ) mlog_errno ( status ) ; } if ( inode_locked ) ocfs2_inode_unlock_tracker ( inode , 1 , & oh , had_lock ) ; brelse ( bh ) ; return status ; }
CWE-000 static int userfaultfd_register ( struct userfaultfd_ctx * ctx , unsigned long arg ) { struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev , * cur ; int ret ; struct uffdio_register uffdio_register ; struct uffdio_register __user * user_uffdio_register ; unsigned long vm_flags , new_flags ; bool found ; bool basic_ioctls ; unsigned long start , end , vma_end ; user_uffdio_register = ( struct uffdio_register __user * ) arg ; ret = - EFAULT ; if ( copy_from_user ( & uffdio_register , user_uffdio_register , sizeof ( uffdio_register ) - sizeof ( __u64 ) ) ) goto out ; ret = - EINVAL ; if ( ! uffdio_register . mode ) goto out ; if ( uffdio_register . mode & ~ ( UFFDIO_REGISTER_MODE_MISSING | UFFDIO_REGISTER_MODE_WP ) ) goto out ; vm_flags = 0 ; if ( uffdio_register . mode & UFFDIO_REGISTER_MODE_MISSING ) vm_flags |= VM_UFFD_MISSING ; if ( uffdio_register . mode & UFFDIO_REGISTER_MODE_WP ) { vm_flags |= VM_UFFD_WP ; ret = - EINVAL ; goto out ; } ret = validate_range ( mm , uffdio_register . range . start , uffdio_register . range . len ) ; if ( ret ) goto out ; start = uffdio_register . range . start ; end = start + uffdio_register . range . len ; ret = - ENOMEM ; if ( ! mmget_not_zero ( mm ) ) goto out ; down_write ( & mm -> mmap_sem ) ; vma = find_vma_prev ( mm , start , & prev ) ; if ( ! vma ) goto out_unlock ; ret = - EINVAL ; if ( vma -> vm_start >= end ) goto out_unlock ; if ( is_vm_hugetlb_page ( vma ) ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; if ( start & ( vma_hpagesize - 1 ) ) goto out_unlock ; } found = false ; basic_ioctls = false ; for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; ret = - EINVAL ; if ( ! vma_can_userfault ( cur ) ) goto out_unlock ; <S2SV_StartBug> if ( is_vm_hugetlb_page ( cur ) && end <= cur -> vm_end && <S2SV_EndBug> end > cur -> vm_start ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( cur ) ; ret = - EINVAL ; if ( end & ( vma_hpagesize - 1 ) ) goto out_unlock ; } ret = - EBUSY ; if ( cur -> vm_userfaultfd_ctx . ctx && cur -> vm_userfaultfd_ctx . ctx != ctx ) goto out_unlock ; if ( is_vm_hugetlb_page ( cur ) ) basic_ioctls = true ; found = true ; } BUG_ON ( ! found ) ; if ( vma -> vm_start < start ) prev = vma ; ret = 0 ; do { cond_resched ( ) ; BUG_ON ( ! vma_can_userfault ( vma ) ) ; BUG_ON ( vma -> vm_userfaultfd_ctx . ctx && <S2SV_StartBug> vma -> vm_userfaultfd_ctx . ctx != ctx ) ; <S2SV_EndBug> if ( vma -> vm_userfaultfd_ctx . ctx == ctx && ( vma -> vm_flags & vm_flags ) == vm_flags ) goto skip ; if ( vma -> vm_start > start ) start = vma -> vm_start ; vma_end = min ( end , vma -> vm_end ) ; new_flags = ( vma -> vm_flags & ~ vm_flags ) | vm_flags ; prev = vma_merge ( mm , prev , start , vma_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , ( ( struct vm_userfaultfd_ctx ) { ctx } ) ) ; if ( prev ) { vma = prev ; goto next ; } if ( vma -> vm_start < start ) { ret = split_vma ( mm , vma , start , 1 ) ; if ( ret ) break ; } if ( vma -> vm_end > end ) { ret = split_vma ( mm , vma , end , 0 ) ; if ( ret ) break ; } next : vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx . ctx = ctx ; skip : prev = vma ; start = vma -> vm_end ; vma = vma -> vm_next ; } while ( vma && vma -> vm_start < end ) ; out_unlock : up_write ( & mm -> mmap_sem ) ; mmput ( mm ) ; if ( ! ret ) { if ( put_user ( basic_ioctls ? UFFD_API_RANGE_IOCTLS_BASIC : UFFD_API_RANGE_IOCTLS , & user_uffdio_register -> ioctls ) ) ret = - EFAULT ; } out : return ret ; }
CWE-000 static int userfaultfd_unregister ( struct userfaultfd_ctx * ctx , unsigned long arg ) { struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev , * cur ; int ret ; struct uffdio_range uffdio_unregister ; unsigned long new_flags ; bool found ; unsigned long start , end , vma_end ; const void __user * buf = ( void __user * ) arg ; ret = - EFAULT ; if ( copy_from_user ( & uffdio_unregister , buf , sizeof ( uffdio_unregister ) ) ) goto out ; ret = validate_range ( mm , uffdio_unregister . start , uffdio_unregister . len ) ; if ( ret ) goto out ; start = uffdio_unregister . start ; end = start + uffdio_unregister . len ; ret = - ENOMEM ; if ( ! mmget_not_zero ( mm ) ) goto out ; down_write ( & mm -> mmap_sem ) ; vma = find_vma_prev ( mm , start , & prev ) ; if ( ! vma ) goto out_unlock ; ret = - EINVAL ; if ( vma -> vm_start >= end ) goto out_unlock ; if ( is_vm_hugetlb_page ( vma ) ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; if ( start & ( vma_hpagesize - 1 ) ) goto out_unlock ; } found = false ; ret = - EINVAL ; for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; if ( ! vma_can_userfault ( cur ) ) goto out_unlock ; found = true ; } BUG_ON ( ! found ) ; if ( vma -> vm_start < start ) prev = vma ; ret = 0 ; do { cond_resched ( ) ; BUG_ON ( ! vma_can_userfault ( vma ) ) ; <S2SV_StartBug> if ( ! vma -> vm_userfaultfd_ctx . ctx ) <S2SV_EndBug> goto skip ; if ( vma -> vm_start > start ) start = vma -> vm_start ; vma_end = min ( end , vma -> vm_end ) ; if ( userfaultfd_missing ( vma ) ) { struct userfaultfd_wake_range range ; range . start = start ; range . len = vma_end - start ; wake_userfault ( vma -> vm_userfaultfd_ctx . ctx , & range ) ; } new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; prev = vma_merge ( mm , prev , start , vma_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , NULL_VM_UFFD_CTX ) ; if ( prev ) { vma = prev ; goto next ; } if ( vma -> vm_start < start ) { ret = split_vma ( mm , vma , start , 1 ) ; if ( ret ) break ; } if ( vma -> vm_end > end ) { ret = split_vma ( mm , vma , end , 0 ) ; if ( ret ) break ; } next : vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; skip : prev = vma ; start = vma -> vm_end ; vma = vma -> vm_next ; } while ( vma && vma -> vm_start < end ) ; out_unlock : up_write ( & mm -> mmap_sem ) ; mmput ( mm ) ; out : return ret ; }
CWE-000 static void sas_eh_finish_cmd ( struct scsi_cmnd * cmd ) { struct sas_ha_struct * sas_ha = SHOST_TO_SAS_HA ( cmd -> device -> host ) ; <S2SV_StartBug> struct sas_task * task = TO_SAS_TASK ( cmd ) ; <S2SV_EndBug> sas_end_task ( cmd , task ) ; <S2SV_StartBug> scsi_eh_finish_cmd ( cmd , & sas_ha -> eh_done_q ) ; <S2SV_EndBug> }
CWE-000 static void sas_eh_handle_sas_errors ( struct Scsi_Host * shost , struct list_head * work_q ) { struct scsi_cmnd * cmd , * n ; enum task_disposition res = TASK_IS_DONE ; int tmf_resp , need_reset ; struct sas_internal * i = to_sas_internal ( shost -> transportt ) ; unsigned long flags ; struct sas_ha_struct * ha = SHOST_TO_SAS_HA ( shost ) ; LIST_HEAD ( done ) ; list_for_each_entry_safe ( cmd , n , work_q , eh_entry ) { struct domain_device * dev = cmd_to_domain_dev ( cmd ) ; struct sas_task * task ; spin_lock_irqsave ( & dev -> done_lock , flags ) ; task = TO_SAS_TASK ( cmd ) ; spin_unlock_irqrestore ( & dev -> done_lock , flags ) ; if ( ! task ) list_move_tail ( & cmd -> eh_entry , & done ) ; } Again : list_for_each_entry_safe ( cmd , n , work_q , eh_entry ) { struct sas_task * task = TO_SAS_TASK ( cmd ) ; list_del_init ( & cmd -> eh_entry ) ; spin_lock_irqsave ( & task -> task_state_lock , flags ) ; need_reset = task -> task_state_flags & SAS_TASK_NEED_DEV_RESET ; spin_unlock_irqrestore ( & task -> task_state_lock , flags ) ; if ( need_reset ) { SAS_DPRINTK ( "%s:<S2SV_blank>task<S2SV_blank>0x%p<S2SV_blank>requests<S2SV_blank>reset\\n" , __func__ , task ) ; goto reset ; } SAS_DPRINTK ( "trying<S2SV_blank>to<S2SV_blank>find<S2SV_blank>task<S2SV_blank>0x%p\\n" , task ) ; res = sas_scsi_find_task ( task ) ; switch ( res ) { case TASK_IS_DONE : SAS_DPRINTK ( "%s:<S2SV_blank>task<S2SV_blank>0x%p<S2SV_blank>is<S2SV_blank>done\\n" , __func__ , task ) ; <S2SV_StartBug> sas_eh_defer_cmd ( cmd ) ; <S2SV_EndBug> continue ; case TASK_IS_ABORTED : SAS_DPRINTK ( "%s:<S2SV_blank>task<S2SV_blank>0x%p<S2SV_blank>is<S2SV_blank>aborted\\n" , __func__ , task ) ; <S2SV_StartBug> sas_eh_defer_cmd ( cmd ) ; <S2SV_EndBug> continue ; case TASK_IS_AT_LU : SAS_DPRINTK ( "task<S2SV_blank>0x%p<S2SV_blank>is<S2SV_blank>at<S2SV_blank>LU:<S2SV_blank>lu<S2SV_blank>recover\\n" , task ) ; reset : tmf_resp = sas_recover_lu ( task -> dev , cmd ) ; if ( tmf_resp == TMF_RESP_FUNC_COMPLETE ) { SAS_DPRINTK ( "dev<S2SV_blank>%016llx<S2SV_blank>LU<S2SV_blank>%llx<S2SV_blank>is<S2SV_blank>" "recovered\\n" , SAS_ADDR ( task -> dev ) , cmd -> device -> lun ) ; <S2SV_StartBug> sas_eh_defer_cmd ( cmd ) ; <S2SV_EndBug> sas_scsi_clear_queue_lu ( work_q , cmd ) ; goto Again ; } case TASK_IS_NOT_AT_LU : case TASK_ABORT_FAILED : SAS_DPRINTK ( "task<S2SV_blank>0x%p<S2SV_blank>is<S2SV_blank>not<S2SV_blank>at<S2SV_blank>LU:<S2SV_blank>I_T<S2SV_blank>recover\\n" , task ) ; tmf_resp = sas_recover_I_T ( task -> dev ) ; if ( tmf_resp == TMF_RESP_FUNC_COMPLETE || tmf_resp == - ENODEV ) { struct domain_device * dev = task -> dev ; SAS_DPRINTK ( "I_T<S2SV_blank>%016llx<S2SV_blank>recovered\\n" , SAS_ADDR ( task -> dev -> sas_addr ) ) ; sas_eh_finish_cmd ( cmd ) ; sas_scsi_clear_queue_I_T ( work_q , dev ) ; goto Again ; } try_to_reset_cmd_device ( cmd ) ; if ( i -> dft -> lldd_clear_nexus_port ) { struct asd_sas_port * port = task -> dev -> port ; SAS_DPRINTK ( "clearing<S2SV_blank>nexus<S2SV_blank>for<S2SV_blank>port:%d\\n" , port -> id ) ; res = i -> dft -> lldd_clear_nexus_port ( port ) ; if ( res == TMF_RESP_FUNC_COMPLETE ) { SAS_DPRINTK ( "clear<S2SV_blank>nexus<S2SV_blank>port:%d<S2SV_blank>" "succeeded\\n" , port -> id ) ; sas_eh_finish_cmd ( cmd ) ; sas_scsi_clear_queue_port ( work_q , port ) ; goto Again ; } } if ( i -> dft -> lldd_clear_nexus_ha ) { SAS_DPRINTK ( "clear<S2SV_blank>nexus<S2SV_blank>ha\\n" ) ; res = i -> dft -> lldd_clear_nexus_ha ( ha ) ; if ( res == TMF_RESP_FUNC_COMPLETE ) { SAS_DPRINTK ( "clear<S2SV_blank>nexus<S2SV_blank>ha<S2SV_blank>" "succeeded\\n" ) ; sas_eh_finish_cmd ( cmd ) ; goto clear_q ; } } SAS_DPRINTK ( "error<S2SV_blank>from<S2SV_blank><S2SV_blank>device<S2SV_blank>%llx,<S2SV_blank>LUN<S2SV_blank>%llx<S2SV_blank>" "couldn\'t<S2SV_blank>be<S2SV_blank>recovered<S2SV_blank>in<S2SV_blank>any<S2SV_blank>way\\n" , SAS_ADDR ( task -> dev -> sas_addr ) , cmd -> device -> lun ) ; sas_eh_finish_cmd ( cmd ) ; goto clear_q ; } } out : list_splice_tail ( & done , work_q ) ; list_splice_tail_init ( & ha -> eh_ata_q , work_q ) ; return ; clear_q : SAS_DPRINTK ( "---<S2SV_blank>Exit<S2SV_blank>%s<S2SV_blank>--<S2SV_blank>clear_q\\n" , __func__ ) ; list_for_each_entry_safe ( cmd , n , work_q , eh_entry ) sas_eh_finish_cmd ( cmd ) ; goto out ; }
CWE-000 static void sas_scsi_clear_queue_lu ( struct list_head * error_q , struct scsi_cmnd * my_cmd ) { struct scsi_cmnd * cmd , * n ; list_for_each_entry_safe ( cmd , n , error_q , eh_entry ) { if ( cmd -> device -> sdev_target == my_cmd -> device -> sdev_target && cmd -> device -> lun == my_cmd -> device -> lun ) <S2SV_StartBug> sas_eh_defer_cmd ( cmd ) ; <S2SV_EndBug> } }
CWE-000 static void mem_cgroup_usage_unregister_event ( struct cgroup * cgrp , struct cftype * cft , struct eventfd_ctx * eventfd ) { struct mem_cgroup * memcg = mem_cgroup_from_cont ( cgrp ) ; struct mem_cgroup_thresholds * thresholds ; struct mem_cgroup_threshold_ary * new ; int type = MEMFILE_TYPE ( cft -> private ) ; u64 usage ; int i , j , size ; mutex_lock ( & memcg -> thresholds_lock ) ; if ( type == _MEM ) thresholds = & memcg -> thresholds ; else if ( type == _MEMSWAP ) thresholds = & memcg -> memsw_thresholds ; else BUG ( ) ; <S2SV_StartBug> BUG_ON ( ! thresholds ) ; <S2SV_EndBug> usage = mem_cgroup_usage ( memcg , type == _MEMSWAP ) ; __mem_cgroup_threshold ( memcg , type == _MEMSWAP ) ; size = 0 ; for ( i = 0 ; i < thresholds -> primary -> size ; i ++ ) { if ( thresholds -> primary -> entries [ i ] . eventfd != eventfd ) size ++ ; } new = thresholds -> spare ; if ( ! size ) { kfree ( new ) ; new = NULL ; goto swap_buffers ; } new -> size = size ; new -> current_threshold = - 1 ; for ( i = 0 , j = 0 ; i < thresholds -> primary -> size ; i ++ ) { if ( thresholds -> primary -> entries [ i ] . eventfd == eventfd ) continue ; new -> entries [ j ] = thresholds -> primary -> entries [ i ] ; if ( new -> entries [ j ] . threshold < usage ) { ++ new -> current_threshold ; } j ++ ; } swap_buffers : thresholds -> spare = thresholds -> primary ; rcu_assign_pointer ( thresholds -> primary , new ) ; synchronize_rcu ( ) ; <S2SV_StartBug> mutex_unlock ( & memcg -> thresholds_lock ) ; <S2SV_EndBug> }
CWE-000 int key_reject_and_link ( struct key * key , unsigned timeout , unsigned error , struct key * keyring , struct key * authkey ) { struct assoc_array_edit * edit ; struct timespec now ; int ret , awaken , link_ret = 0 ; key_check ( key ) ; key_check ( keyring ) ; awaken = 0 ; ret = - EBUSY ; if ( keyring ) { if ( keyring -> restrict_link ) return - EPERM ; link_ret = __key_link_begin ( keyring , & key -> index_key , & edit ) ; } mutex_lock ( & key_construction_mutex ) ; if ( ! test_bit ( KEY_FLAG_INSTANTIATED , & key -> flags ) ) { atomic_inc ( & key -> user -> nikeys ) ; key -> reject_error = - error ; smp_wmb ( ) ; set_bit ( KEY_FLAG_NEGATIVE , & key -> flags ) ; set_bit ( KEY_FLAG_INSTANTIATED , & key -> flags ) ; now = current_kernel_time ( ) ; key -> expiry = now . tv_sec + timeout ; key_schedule_gc ( key -> expiry + key_gc_delay ) ; if ( test_and_clear_bit ( KEY_FLAG_USER_CONSTRUCT , & key -> flags ) ) awaken = 1 ; ret = 0 ; if ( keyring && link_ret == 0 ) __key_link ( key , & edit ) ; if ( authkey ) key_revoke ( authkey ) ; } mutex_unlock ( & key_construction_mutex ) ; <S2SV_StartBug> if ( keyring ) <S2SV_EndBug> __key_link_end ( keyring , & key -> index_key , edit ) ; if ( awaken ) wake_up_bit ( & key -> flags , KEY_FLAG_USER_CONSTRUCT ) ; return ret == 0 ? link_ret : ret ; }
CWE-000 void ping_unhash ( struct sock * sk ) { struct inet_sock * isk = inet_sk ( sk ) ; pr_debug ( "ping_unhash(isk=%p,isk->num=%u)\\n" , isk , isk -> inet_num ) ; <S2SV_StartBug> if ( sk_hashed ( sk ) ) { <S2SV_EndBug> <S2SV_StartBug> write_lock_bh ( & ping_table . lock ) ; <S2SV_EndBug> hlist_nulls_del ( & sk -> sk_nulls_node ) ; sk_nulls_node_init ( & sk -> sk_nulls_node ) ; sock_put ( sk ) ; isk -> inet_num = 0 ; isk -> inet_sport = 0 ; sock_prot_inuse_add ( sock_net ( sk ) , sk -> sk_prot , - 1 ) ; <S2SV_StartBug> write_unlock_bh ( & ping_table . lock ) ; <S2SV_EndBug> } <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 int tipc_nl_publ_dump ( struct sk_buff * skb , struct netlink_callback * cb ) { int err ; u32 tsk_portid = cb -> args [ 0 ] ; u32 last_publ = cb -> args [ 1 ] ; u32 done = cb -> args [ 2 ] ; struct net * net = sock_net ( skb -> sk ) ; struct tipc_sock * tsk ; if ( ! tsk_portid ) { struct nlattr * * attrs ; struct nlattr * sock [ TIPC_NLA_SOCK_MAX + 1 ] ; err = tipc_nlmsg_parse ( cb -> nlh , & attrs ) ; if ( err ) return err ; <S2SV_StartBug> err = nla_parse_nested ( sock , TIPC_NLA_SOCK_MAX , <S2SV_EndBug> <S2SV_StartBug> attrs [ TIPC_NLA_SOCK ] , <S2SV_EndBug> tipc_nl_sock_policy ) ; if ( err ) return err ; if ( ! sock [ TIPC_NLA_SOCK_REF ] ) return - EINVAL ; <S2SV_StartBug> tsk_portid = nla_get_u32 ( sock [ TIPC_NLA_SOCK_REF ] ) ; <S2SV_EndBug> } if ( done ) return 0 ; tsk = tipc_sk_lookup ( net , tsk_portid ) ; if ( ! tsk ) return - EINVAL ; <S2SV_StartBug> lock_sock ( & tsk -> sk ) ; <S2SV_EndBug> err = __tipc_nl_list_sk_publ ( skb , cb , tsk , & last_publ ) ; if ( ! err ) done = 1 ; release_sock ( & tsk -> sk ) ; sock_put ( & tsk -> sk ) ; cb -> args [ 0 ] = tsk_portid ; cb -> args [ 1 ] = last_publ ; cb -> args [ 2 ] = done ; return skb -> len ; }
CWE-000 int simple_set_acl ( struct inode * inode , struct posix_acl * acl , int type ) { int error ; if ( type == ACL_TYPE_ACCESS ) { <S2SV_StartBug> error = posix_acl_equiv_mode ( acl , & inode -> i_mode ) ; <S2SV_EndBug> <S2SV_StartBug> if ( error < 0 ) <S2SV_EndBug> return 0 ; if ( error == 0 ) acl = NULL ; } inode -> i_ctime = current_time ( inode ) ; set_cached_acl ( inode , type , acl ) ; return 0 ; }
CWE-000 int hashbin_delete ( hashbin_t * hashbin , FREE_FUNC free_func ) { irda_queue_t * queue ; unsigned long flags = 0 ; int i ; IRDA_ASSERT ( hashbin != NULL , return - 1 ; ) ; IRDA_ASSERT ( hashbin -> magic == HB_MAGIC , return - 1 ; ) ; <S2SV_StartBug> if ( hashbin -> hb_type & HB_LOCK ) { <S2SV_EndBug> spin_lock_irqsave_nested ( & hashbin -> hb_spinlock , flags , hashbin_lock_depth ++ ) ; } for ( i = 0 ; i < HASHBIN_SIZE ; i ++ ) { <S2SV_StartBug> queue = dequeue_first ( ( irda_queue_t * * ) & hashbin -> hb_queue [ i ] ) ; <S2SV_EndBug> <S2SV_StartBug> while ( queue ) { <S2SV_EndBug> if ( free_func ) <S2SV_StartBug> ( * free_func ) ( queue ) ; <S2SV_EndBug> queue = dequeue_first ( ( irda_queue_t * * ) & hashbin -> hb_queue [ i ] ) ; } } hashbin -> hb_current = NULL ; hashbin -> magic = ~ HB_MAGIC ; <S2SV_StartBug> if ( hashbin -> hb_type & HB_LOCK ) { <S2SV_EndBug> spin_unlock_irqrestore ( & hashbin -> hb_spinlock , flags ) ; <S2SV_StartBug> # ifdef CONFIG_LOCKDEP <S2SV_EndBug> hashbin_lock_depth -- ; # endif } kfree ( hashbin ) ; return 0 ; }
CWE-000 static ssize_t aio_run_iocb ( struct kiocb * req , unsigned opcode , char __user * buf , size_t len , bool compat ) { struct file * file = req -> ki_filp ; ssize_t ret ; unsigned long nr_segs ; int rw ; fmode_t mode ; aio_rw_op * rw_op ; rw_iter_op * iter_op ; struct iovec inline_vecs [ UIO_FASTIOV ] , * iovec = inline_vecs ; struct iov_iter iter ; switch ( opcode ) { case IOCB_CMD_PREAD : case IOCB_CMD_PREADV : mode = FMODE_READ ; rw = READ ; rw_op = file -> f_op -> aio_read ; iter_op = file -> f_op -> read_iter ; goto rw_common ; case IOCB_CMD_PWRITE : case IOCB_CMD_PWRITEV : mode = FMODE_WRITE ; rw = WRITE ; rw_op = file -> f_op -> aio_write ; iter_op = file -> f_op -> write_iter ; goto rw_common ; rw_common : if ( unlikely ( ! ( file -> f_mode & mode ) ) ) return - EBADF ; if ( ! rw_op && ! iter_op ) return - EINVAL ; if ( opcode == IOCB_CMD_PREADV || opcode == IOCB_CMD_PWRITEV ) ret = aio_setup_vectored_rw ( req , rw , buf , & nr_segs , <S2SV_StartBug> & len , & iovec , compat ) ; <S2SV_EndBug> else ret = aio_setup_single_vector ( req , rw , buf , & nr_segs , <S2SV_StartBug> len , iovec ) ; <S2SV_EndBug> if ( ! ret ) ret = rw_verify_area ( rw , file , & req -> ki_pos , len ) ; if ( ret < 0 ) { if ( iovec != inline_vecs ) kfree ( iovec ) ; return ret ; } len = ret ; if ( req -> ki_pos < 0 ) { ret = - EINVAL ; break ; } if ( rw == WRITE ) file_start_write ( file ) ; if ( iter_op ) { <S2SV_StartBug> iov_iter_init ( & iter , rw , iovec , nr_segs , len ) ; <S2SV_EndBug> ret = iter_op ( req , & iter ) ; } else { ret = rw_op ( req , iovec , nr_segs , req -> ki_pos ) ; } if ( rw == WRITE ) file_end_write ( file ) ; break ; case IOCB_CMD_FDSYNC : if ( ! file -> f_op -> aio_fsync ) return - EINVAL ; ret = file -> f_op -> aio_fsync ( req , 1 ) ; break ; case IOCB_CMD_FSYNC : if ( ! file -> f_op -> aio_fsync ) return - EINVAL ; ret = file -> f_op -> aio_fsync ( req , 0 ) ; break ; default : pr_debug ( "EINVAL:<S2SV_blank>no<S2SV_blank>operation<S2SV_blank>provided\\n" ) ; return - EINVAL ; } if ( iovec != inline_vecs ) kfree ( iovec ) ; if ( ret != - EIOCBQUEUED ) { if ( unlikely ( ret == - ERESTARTSYS || ret == - ERESTARTNOINTR || ret == - ERESTARTNOHAND || ret == - ERESTART_RESTARTBLOCK ) ) ret = - EINTR ; aio_complete ( req , ret , 0 ) ; } return 0 ; }
CWE-000 static ssize_t aio_setup_single_vector ( struct kiocb * kiocb , int rw , char __user * buf , unsigned long * nr_segs , size_t len , <S2SV_StartBug> struct iovec * iovec ) <S2SV_EndBug> { if ( unlikely ( ! access_ok ( ! rw , buf , len ) ) ) return - EFAULT ; iovec -> iov_base = buf ; iovec -> iov_len = len ; * nr_segs = 1 ; <S2SV_StartBug> return 0 ; <S2SV_EndBug> }
CWE-000 static ssize_t aio_setup_vectored_rw ( struct kiocb * kiocb , int rw , char __user * buf , unsigned long * nr_segs , size_t * len , struct iovec * * iovec , <S2SV_StartBug> bool compat ) <S2SV_EndBug> { ssize_t ret ; * nr_segs = * len ; # ifdef CONFIG_COMPAT if ( compat ) ret = compat_rw_copy_check_uvector ( rw , ( struct compat_iovec __user * ) buf , * nr_segs , UIO_FASTIOV , * iovec , iovec ) ; else # endif ret = rw_copy_check_uvector ( rw , ( struct iovec __user * ) buf , * nr_segs , UIO_FASTIOV , * iovec , iovec ) ; if ( ret < 0 ) return ret ; * len = ret ; <S2SV_StartBug> return 0 ; <S2SV_EndBug> }
CWE-000 static int cdc_ncm_bind ( struct usbnet * dev , struct usb_interface * intf ) { <S2SV_StartBug> int ret ; <S2SV_EndBug> if ( cdc_ncm_select_altsetting ( intf ) != CDC_NCM_COMM_ALTSETTING_NCM ) return - ENODEV ; <S2SV_StartBug> ret = cdc_ncm_bind_common ( dev , intf , CDC_NCM_DATA_ALTSETTING_NCM , 0 ) ; <S2SV_EndBug> <S2SV_StartBug> usbnet_link_change ( dev , 0 , 0 ) ; <S2SV_EndBug> return ret ; }
CWE-000 static int mct_u232_port_probe ( struct usb_serial_port * port ) { <S2SV_StartBug> struct mct_u232_private * priv ; <S2SV_EndBug> priv = kzalloc ( sizeof ( * priv ) , GFP_KERNEL ) ; if ( ! priv ) return - ENOMEM ; <S2SV_StartBug> priv -> read_urb = port -> serial -> port [ 1 ] -> interrupt_in_urb ; <S2SV_EndBug> priv -> read_urb -> context = port ; spin_lock_init ( & priv -> lock ) ; usb_set_serial_port_data ( port , priv ) ; return 0 ; }
CWE-000 static int iowarrior_probe ( struct usb_interface * interface , const struct usb_device_id * id ) { struct usb_device * udev = interface_to_usbdev ( interface ) ; struct iowarrior * dev = NULL ; struct usb_host_interface * iface_desc ; struct usb_endpoint_descriptor * endpoint ; int i ; int retval = - ENOMEM ; dev = kzalloc ( sizeof ( struct iowarrior ) , GFP_KERNEL ) ; if ( dev == NULL ) { dev_err ( & interface -> dev , "Out<S2SV_blank>of<S2SV_blank>memory\\n" ) ; return retval ; } mutex_init ( & dev -> mutex ) ; atomic_set ( & dev -> intr_idx , 0 ) ; atomic_set ( & dev -> read_idx , 0 ) ; spin_lock_init ( & dev -> intr_idx_lock ) ; atomic_set ( & dev -> overflow_flag , 0 ) ; init_waitqueue_head ( & dev -> read_wait ) ; atomic_set ( & dev -> write_busy , 0 ) ; init_waitqueue_head ( & dev -> write_wait ) ; dev -> udev = udev ; dev -> interface = interface ; iface_desc = interface -> cur_altsetting ; <S2SV_StartBug> dev -> product_id = le16_to_cpu ( udev -> descriptor . idProduct ) ; <S2SV_EndBug> for ( i = 0 ; i < iface_desc -> desc . bNumEndpoints ; ++ i ) { endpoint = & iface_desc -> endpoint [ i ] . desc ; if ( usb_endpoint_is_int_in ( endpoint ) ) dev -> int_in_endpoint = endpoint ; if ( usb_endpoint_is_int_out ( endpoint ) ) dev -> int_out_endpoint = endpoint ; } dev -> report_size = usb_endpoint_maxp ( dev -> int_in_endpoint ) ; if ( ( dev -> interface -> cur_altsetting -> desc . bInterfaceNumber == 0 ) && ( dev -> product_id == USB_DEVICE_ID_CODEMERCS_IOW56 ) ) dev -> report_size = 7 ; dev -> int_in_urb = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! dev -> int_in_urb ) { dev_err ( & interface -> dev , "Couldn\'t<S2SV_blank>allocate<S2SV_blank>interrupt_in_urb\\n" ) ; goto error ; } dev -> int_in_buffer = kmalloc ( dev -> report_size , GFP_KERNEL ) ; if ( ! dev -> int_in_buffer ) { dev_err ( & interface -> dev , "Couldn\'t<S2SV_blank>allocate<S2SV_blank>int_in_buffer\\n" ) ; goto error ; } usb_fill_int_urb ( dev -> int_in_urb , dev -> udev , usb_rcvintpipe ( dev -> udev , dev -> int_in_endpoint -> bEndpointAddress ) , dev -> int_in_buffer , dev -> report_size , iowarrior_callback , dev , dev -> int_in_endpoint -> bInterval ) ; dev -> read_queue = kmalloc ( ( ( dev -> report_size + 1 ) * MAX_INTERRUPT_BUFFER ) , GFP_KERNEL ) ; if ( ! dev -> read_queue ) { dev_err ( & interface -> dev , "Couldn\'t<S2SV_blank>allocate<S2SV_blank>read_queue\\n" ) ; goto error ; } memset ( dev -> chip_serial , 0x00 , sizeof ( dev -> chip_serial ) ) ; usb_string ( udev , udev -> descriptor . iSerialNumber , dev -> chip_serial , sizeof ( dev -> chip_serial ) ) ; if ( strlen ( dev -> chip_serial ) != 8 ) memset ( dev -> chip_serial , 0x00 , sizeof ( dev -> chip_serial ) ) ; if ( dev -> interface -> cur_altsetting -> desc . bInterfaceNumber == 0 ) { usb_control_msg ( udev , usb_sndctrlpipe ( udev , 0 ) , 0x0A , USB_TYPE_CLASS | USB_RECIP_INTERFACE , 0 , 0 , NULL , 0 , USB_CTRL_SET_TIMEOUT ) ; } dev -> present = 1 ; usb_set_intfdata ( interface , dev ) ; retval = usb_register_dev ( interface , & iowarrior_class ) ; if ( retval ) { dev_err ( & interface -> dev , "Not<S2SV_blank>able<S2SV_blank>to<S2SV_blank>get<S2SV_blank>a<S2SV_blank>minor<S2SV_blank>for<S2SV_blank>this<S2SV_blank>device.\\n" ) ; usb_set_intfdata ( interface , NULL ) ; goto error ; } dev -> minor = interface -> minor ; dev_info ( & interface -> dev , "IOWarrior<S2SV_blank>product=0x%x,<S2SV_blank>serial=%s<S2SV_blank>interface=%d<S2SV_blank>" "now<S2SV_blank>attached<S2SV_blank>to<S2SV_blank>iowarrior%d\\n" , dev -> product_id , dev -> chip_serial , iface_desc -> desc . bInterfaceNumber , dev -> minor - IOWARRIOR_MINOR_BASE ) ; return retval ; error : iowarrior_delete ( dev ) ; return retval ; }
CWE-000 static int prepare_vmcs02 ( struct kvm_vcpu * vcpu , struct vmcs12 * vmcs12 , bool from_vmentry , u32 * entry_failure_code ) { struct vcpu_vmx * vmx = to_vmx ( vcpu ) ; u32 exec_control , vmcs12_exec_ctrl ; vmcs_write16 ( GUEST_ES_SELECTOR , vmcs12 -> guest_es_selector ) ; vmcs_write16 ( GUEST_CS_SELECTOR , vmcs12 -> guest_cs_selector ) ; vmcs_write16 ( GUEST_SS_SELECTOR , vmcs12 -> guest_ss_selector ) ; vmcs_write16 ( GUEST_DS_SELECTOR , vmcs12 -> guest_ds_selector ) ; vmcs_write16 ( GUEST_FS_SELECTOR , vmcs12 -> guest_fs_selector ) ; vmcs_write16 ( GUEST_GS_SELECTOR , vmcs12 -> guest_gs_selector ) ; vmcs_write16 ( GUEST_LDTR_SELECTOR , vmcs12 -> guest_ldtr_selector ) ; vmcs_write16 ( GUEST_TR_SELECTOR , vmcs12 -> guest_tr_selector ) ; vmcs_write32 ( GUEST_ES_LIMIT , vmcs12 -> guest_es_limit ) ; vmcs_write32 ( GUEST_CS_LIMIT , vmcs12 -> guest_cs_limit ) ; vmcs_write32 ( GUEST_SS_LIMIT , vmcs12 -> guest_ss_limit ) ; vmcs_write32 ( GUEST_DS_LIMIT , vmcs12 -> guest_ds_limit ) ; vmcs_write32 ( GUEST_FS_LIMIT , vmcs12 -> guest_fs_limit ) ; vmcs_write32 ( GUEST_GS_LIMIT , vmcs12 -> guest_gs_limit ) ; vmcs_write32 ( GUEST_LDTR_LIMIT , vmcs12 -> guest_ldtr_limit ) ; vmcs_write32 ( GUEST_TR_LIMIT , vmcs12 -> guest_tr_limit ) ; vmcs_write32 ( GUEST_GDTR_LIMIT , vmcs12 -> guest_gdtr_limit ) ; vmcs_write32 ( GUEST_IDTR_LIMIT , vmcs12 -> guest_idtr_limit ) ; vmcs_write32 ( GUEST_ES_AR_BYTES , vmcs12 -> guest_es_ar_bytes ) ; vmcs_write32 ( GUEST_CS_AR_BYTES , vmcs12 -> guest_cs_ar_bytes ) ; vmcs_write32 ( GUEST_SS_AR_BYTES , vmcs12 -> guest_ss_ar_bytes ) ; vmcs_write32 ( GUEST_DS_AR_BYTES , vmcs12 -> guest_ds_ar_bytes ) ; vmcs_write32 ( GUEST_FS_AR_BYTES , vmcs12 -> guest_fs_ar_bytes ) ; vmcs_write32 ( GUEST_GS_AR_BYTES , vmcs12 -> guest_gs_ar_bytes ) ; vmcs_write32 ( GUEST_LDTR_AR_BYTES , vmcs12 -> guest_ldtr_ar_bytes ) ; vmcs_write32 ( GUEST_TR_AR_BYTES , vmcs12 -> guest_tr_ar_bytes ) ; vmcs_writel ( GUEST_ES_BASE , vmcs12 -> guest_es_base ) ; vmcs_writel ( GUEST_CS_BASE , vmcs12 -> guest_cs_base ) ; vmcs_writel ( GUEST_SS_BASE , vmcs12 -> guest_ss_base ) ; vmcs_writel ( GUEST_DS_BASE , vmcs12 -> guest_ds_base ) ; vmcs_writel ( GUEST_FS_BASE , vmcs12 -> guest_fs_base ) ; vmcs_writel ( GUEST_GS_BASE , vmcs12 -> guest_gs_base ) ; vmcs_writel ( GUEST_LDTR_BASE , vmcs12 -> guest_ldtr_base ) ; vmcs_writel ( GUEST_TR_BASE , vmcs12 -> guest_tr_base ) ; vmcs_writel ( GUEST_GDTR_BASE , vmcs12 -> guest_gdtr_base ) ; vmcs_writel ( GUEST_IDTR_BASE , vmcs12 -> guest_idtr_base ) ; if ( from_vmentry && ( vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS ) ) { kvm_set_dr ( vcpu , 7 , vmcs12 -> guest_dr7 ) ; vmcs_write64 ( GUEST_IA32_DEBUGCTL , vmcs12 -> guest_ia32_debugctl ) ; } else { kvm_set_dr ( vcpu , 7 , vcpu -> arch . dr7 ) ; vmcs_write64 ( GUEST_IA32_DEBUGCTL , vmx -> nested . vmcs01_debugctl ) ; } if ( from_vmentry ) { vmcs_write32 ( VM_ENTRY_INTR_INFO_FIELD , vmcs12 -> vm_entry_intr_info_field ) ; vmcs_write32 ( VM_ENTRY_EXCEPTION_ERROR_CODE , vmcs12 -> vm_entry_exception_error_code ) ; vmcs_write32 ( VM_ENTRY_INSTRUCTION_LEN , vmcs12 -> vm_entry_instruction_len ) ; vmcs_write32 ( GUEST_INTERRUPTIBILITY_INFO , vmcs12 -> guest_interruptibility_info ) ; vmx -> loaded_vmcs -> nmi_known_unmasked = ! ( vmcs12 -> guest_interruptibility_info & GUEST_INTR_STATE_NMI ) ; } else { vmcs_write32 ( VM_ENTRY_INTR_INFO_FIELD , 0 ) ; } vmcs_write32 ( GUEST_SYSENTER_CS , vmcs12 -> guest_sysenter_cs ) ; vmx_set_rflags ( vcpu , vmcs12 -> guest_rflags ) ; vmcs_writel ( GUEST_PENDING_DBG_EXCEPTIONS , vmcs12 -> guest_pending_dbg_exceptions ) ; vmcs_writel ( GUEST_SYSENTER_ESP , vmcs12 -> guest_sysenter_esp ) ; vmcs_writel ( GUEST_SYSENTER_EIP , vmcs12 -> guest_sysenter_eip ) ; if ( nested_cpu_has_xsaves ( vmcs12 ) ) vmcs_write64 ( XSS_EXIT_BITMAP , vmcs12 -> xss_exit_bitmap ) ; vmcs_write64 ( VMCS_LINK_POINTER , - 1ull ) ; exec_control = vmcs12 -> pin_based_vm_exec_control ; exec_control &= ~ PIN_BASED_VMX_PREEMPTION_TIMER ; exec_control |= vmcs_config . pin_based_exec_ctrl ; if ( vmx -> hv_deadline_tsc == - 1 ) exec_control &= ~ PIN_BASED_VMX_PREEMPTION_TIMER ; if ( nested_cpu_has_posted_intr ( vmcs12 ) ) { vmx -> nested . posted_intr_nv = vmcs12 -> posted_intr_nv ; vmx -> nested . pi_pending = false ; vmcs_write16 ( POSTED_INTR_NV , POSTED_INTR_NESTED_VECTOR ) ; } else { exec_control &= ~ PIN_BASED_POSTED_INTR ; } vmcs_write32 ( PIN_BASED_VM_EXEC_CONTROL , exec_control ) ; vmx -> nested . preemption_timer_expired = false ; if ( nested_cpu_has_preemption_timer ( vmcs12 ) ) vmx_start_preemption_timer ( vcpu ) ; vmcs_write32 ( PAGE_FAULT_ERROR_CODE_MASK , enable_ept ? vmcs12 -> page_fault_error_code_mask : 0 ) ; vmcs_write32 ( PAGE_FAULT_ERROR_CODE_MATCH , enable_ept ? vmcs12 -> page_fault_error_code_match : 0 ) ; if ( cpu_has_secondary_exec_ctrls ( ) ) { exec_control = vmx -> secondary_exec_control ; exec_control &= ~ ( SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES | SECONDARY_EXEC_ENABLE_INVPCID | SECONDARY_EXEC_RDTSCP | SECONDARY_EXEC_XSAVES | SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY | SECONDARY_EXEC_APIC_REGISTER_VIRT | SECONDARY_EXEC_ENABLE_VMFUNC ) ; if ( nested_cpu_has ( vmcs12 , CPU_BASED_ACTIVATE_SECONDARY_CONTROLS ) ) { vmcs12_exec_ctrl = vmcs12 -> secondary_vm_exec_control & ~ SECONDARY_EXEC_ENABLE_PML ; exec_control |= vmcs12_exec_ctrl ; } if ( exec_control & SECONDARY_EXEC_ENABLE_VMFUNC ) vmcs_write64 ( VM_FUNCTION_CONTROL , 0 ) ; if ( exec_control & SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY ) { vmcs_write64 ( EOI_EXIT_BITMAP0 , vmcs12 -> eoi_exit_bitmap0 ) ; vmcs_write64 ( EOI_EXIT_BITMAP1 , vmcs12 -> eoi_exit_bitmap1 ) ; vmcs_write64 ( EOI_EXIT_BITMAP2 , vmcs12 -> eoi_exit_bitmap2 ) ; vmcs_write64 ( EOI_EXIT_BITMAP3 , vmcs12 -> eoi_exit_bitmap3 ) ; vmcs_write16 ( GUEST_INTR_STATUS , vmcs12 -> guest_intr_status ) ; } if ( exec_control & SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES ) vmcs_write64 ( APIC_ACCESS_ADDR , - 1ull ) ; vmcs_write32 ( SECONDARY_VM_EXEC_CONTROL , exec_control ) ; } vmx_set_constant_host_state ( vmx ) ; vmcs_write32 ( VM_EXIT_MSR_STORE_COUNT , 0 ) ; vmcs_write32 ( VM_EXIT_MSR_LOAD_COUNT , vmx -> msr_autoload . nr ) ; vmcs_write64 ( VM_EXIT_MSR_LOAD_ADDR , __pa ( vmx -> msr_autoload . host ) ) ; vmcs_write32 ( VM_ENTRY_MSR_LOAD_COUNT , vmx -> msr_autoload . nr ) ; vmcs_write64 ( VM_ENTRY_MSR_LOAD_ADDR , __pa ( vmx -> msr_autoload . guest ) ) ; vmx -> host_rsp = 0 ; exec_control = vmx_exec_control ( vmx ) ; exec_control &= ~ CPU_BASED_VIRTUAL_INTR_PENDING ; exec_control &= ~ CPU_BASED_VIRTUAL_NMI_PENDING ; exec_control &= ~ CPU_BASED_TPR_SHADOW ; exec_control |= vmcs12 -> cpu_based_vm_exec_control ; if ( exec_control & CPU_BASED_TPR_SHADOW ) { vmcs_write64 ( VIRTUAL_APIC_PAGE_ADDR , - 1ull ) ; <S2SV_StartBug> vmcs_write32 ( TPR_THRESHOLD , vmcs12 -> tpr_threshold ) ; <S2SV_EndBug> } exec_control &= ~ CPU_BASED_USE_IO_BITMAPS ; exec_control |= CPU_BASED_UNCOND_IO_EXITING ; vmcs_write32 ( CPU_BASED_VM_EXEC_CONTROL , exec_control ) ; update_exception_bitmap ( vcpu ) ; vcpu -> arch . cr0_guest_owned_bits &= ~ vmcs12 -> cr0_guest_host_mask ; vmcs_writel ( CR0_GUEST_HOST_MASK , ~ vcpu -> arch . cr0_guest_owned_bits ) ; vmcs_write32 ( VM_EXIT_CONTROLS , vmcs_config . vmexit_ctrl ) ; vm_entry_controls_init ( vmx , ( vmcs12 -> vm_entry_controls & ~ VM_ENTRY_LOAD_IA32_EFER & ~ VM_ENTRY_IA32E_MODE ) | ( vmcs_config . vmentry_ctrl & ~ VM_ENTRY_IA32E_MODE ) ) ; if ( from_vmentry && ( vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_IA32_PAT ) ) { vmcs_write64 ( GUEST_IA32_PAT , vmcs12 -> guest_ia32_pat ) ; vcpu -> arch . pat = vmcs12 -> guest_ia32_pat ; } else if ( vmcs_config . vmentry_ctrl & VM_ENTRY_LOAD_IA32_PAT ) { vmcs_write64 ( GUEST_IA32_PAT , vmx -> vcpu . arch . pat ) ; } set_cr4_guest_host_mask ( vmx ) ; if ( from_vmentry && vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_BNDCFGS ) vmcs_write64 ( GUEST_BNDCFGS , vmcs12 -> guest_bndcfgs ) ; if ( vmcs12 -> cpu_based_vm_exec_control & CPU_BASED_USE_TSC_OFFSETING ) vmcs_write64 ( TSC_OFFSET , vcpu -> arch . tsc_offset + vmcs12 -> tsc_offset ) ; else vmcs_write64 ( TSC_OFFSET , vcpu -> arch . tsc_offset ) ; if ( kvm_has_tsc_control ) decache_tsc_multiplier ( vmx ) ; if ( enable_vpid ) { if ( nested_cpu_has_vpid ( vmcs12 ) && vmx -> nested . vpid02 ) { vmcs_write16 ( VIRTUAL_PROCESSOR_ID , vmx -> nested . vpid02 ) ; if ( vmcs12 -> virtual_processor_id != vmx -> nested . last_vpid ) { vmx -> nested . last_vpid = vmcs12 -> virtual_processor_id ; __vmx_flush_tlb ( vcpu , to_vmx ( vcpu ) -> nested . vpid02 ) ; } } else { vmcs_write16 ( VIRTUAL_PROCESSOR_ID , vmx -> vpid ) ; vmx_flush_tlb ( vcpu ) ; } } if ( enable_pml ) { ASSERT ( vmx -> pml_pg ) ; vmcs_write64 ( PML_ADDRESS , page_to_phys ( vmx -> pml_pg ) ) ; vmcs_write16 ( GUEST_PML_INDEX , PML_ENTITY_NUM - 1 ) ; } if ( nested_cpu_has_ept ( vmcs12 ) ) { if ( nested_ept_init_mmu_context ( vcpu ) ) { * entry_failure_code = ENTRY_FAIL_DEFAULT ; return 1 ; } } else if ( nested_cpu_has2 ( vmcs12 , SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES ) ) { vmx_flush_tlb_ept_only ( vcpu ) ; } vmx_set_cr0 ( vcpu , vmcs12 -> guest_cr0 ) ; vmcs_writel ( CR0_READ_SHADOW , nested_read_cr0 ( vmcs12 ) ) ; vmx_set_cr4 ( vcpu , vmcs12 -> guest_cr4 ) ; vmcs_writel ( CR4_READ_SHADOW , nested_read_cr4 ( vmcs12 ) ) ; if ( from_vmentry && ( vmcs12 -> vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER ) ) vcpu -> arch . efer = vmcs12 -> guest_ia32_efer ; else if ( vmcs12 -> vm_entry_controls & VM_ENTRY_IA32E_MODE ) vcpu -> arch . efer |= ( EFER_LMA | EFER_LME ) ; else vcpu -> arch . efer &= ~ ( EFER_LMA | EFER_LME ) ; vmx_set_efer ( vcpu , vcpu -> arch . efer ) ; if ( nested_vmx_load_cr3 ( vcpu , vmcs12 -> guest_cr3 , nested_cpu_has_ept ( vmcs12 ) , entry_failure_code ) ) return 1 ; if ( ! enable_ept ) vcpu -> arch . walk_mmu -> inject_page_fault = vmx_inject_page_fault_nested ; if ( enable_ept ) { vmcs_write64 ( GUEST_PDPTR0 , vmcs12 -> guest_pdptr0 ) ; vmcs_write64 ( GUEST_PDPTR1 , vmcs12 -> guest_pdptr1 ) ; vmcs_write64 ( GUEST_PDPTR2 , vmcs12 -> guest_pdptr2 ) ; vmcs_write64 ( GUEST_PDPTR3 , vmcs12 -> guest_pdptr3 ) ; } kvm_register_write ( vcpu , VCPU_REGS_RSP , vmcs12 -> guest_rsp ) ; kvm_register_write ( vcpu , VCPU_REGS_RIP , vmcs12 -> guest_rip ) ; return 0 ; }
CWE-000 int hugetlb_mcopy_atomic_pte ( struct mm_struct * dst_mm , pte_t * dst_pte , struct vm_area_struct * dst_vma , unsigned long dst_addr , unsigned long src_addr , struct page * * pagep ) { int vm_shared = dst_vma -> vm_flags & VM_SHARED ; struct hstate * h = hstate_vma ( dst_vma ) ; pte_t _dst_pte ; spinlock_t * ptl ; int ret ; struct page * page ; if ( ! * pagep ) { ret = - ENOMEM ; page = alloc_huge_page ( dst_vma , dst_addr , 0 ) ; if ( IS_ERR ( page ) ) goto out ; ret = copy_huge_page_from_user ( page , ( const void __user * ) src_addr , pages_per_huge_page ( h ) , false ) ; if ( unlikely ( ret ) ) { ret = - EFAULT ; * pagep = page ; goto out ; } } else { page = * pagep ; * pagep = NULL ; } __SetPageUptodate ( page ) ; set_page_huge_active ( page ) ; if ( vm_shared ) { struct address_space * mapping = dst_vma -> vm_file -> f_mapping ; pgoff_t idx = vma_hugecache_offset ( h , dst_vma , dst_addr ) ; ret = huge_add_to_page_cache ( page , mapping , idx ) ; if ( ret ) goto out_release_nounlock ; } ptl = huge_pte_lockptr ( h , dst_mm , dst_pte ) ; spin_lock ( ptl ) ; ret = - EEXIST ; if ( ! huge_pte_none ( huge_ptep_get ( dst_pte ) ) ) goto out_release_unlock ; if ( vm_shared ) { page_dup_rmap ( page , true ) ; } else { ClearPagePrivate ( page ) ; hugepage_add_new_anon_rmap ( page , dst_vma , dst_addr ) ; } _dst_pte = make_huge_pte ( dst_vma , page , dst_vma -> vm_flags & VM_WRITE ) ; if ( dst_vma -> vm_flags & VM_WRITE ) _dst_pte = huge_pte_mkdirty ( _dst_pte ) ; _dst_pte = pte_mkyoung ( _dst_pte ) ; set_huge_pte_at ( dst_mm , dst_addr , dst_pte , _dst_pte ) ; ( void ) huge_ptep_set_access_flags ( dst_vma , dst_addr , dst_pte , _dst_pte , dst_vma -> vm_flags & VM_WRITE ) ; hugetlb_count_add ( pages_per_huge_page ( h ) , dst_mm ) ; update_mmu_cache ( dst_vma , dst_addr , dst_pte ) ; spin_unlock ( ptl ) ; if ( vm_shared ) unlock_page ( page ) ; ret = 0 ; out : return ret ; out_release_unlock : spin_unlock ( ptl ) ; <S2SV_StartBug> out_release_nounlock : <S2SV_EndBug> if ( vm_shared ) unlock_page ( page ) ; put_page ( page ) ; goto out ; }
CWE-000 int propagate_mnt ( struct mount * dest_mnt , struct mountpoint * dest_mp , struct mount * source_mnt , struct hlist_head * tree_list ) { struct mount * m , * n ; int ret = 0 ; user_ns = current -> nsproxy -> mnt_ns -> user_ns ; last_dest = dest_mnt ; <S2SV_StartBug> last_source = source_mnt ; <S2SV_EndBug> mp = dest_mp ; list = tree_list ; dest_master = dest_mnt -> mnt_master ; for ( n = next_peer ( dest_mnt ) ; n != dest_mnt ; n = next_peer ( n ) ) { ret = propagate_one ( n ) ; if ( ret ) goto out ; } for ( m = next_group ( dest_mnt , dest_mnt ) ; m ; m = next_group ( m , dest_mnt ) ) { n = m ; do { ret = propagate_one ( n ) ; if ( ret ) goto out ; n = next_peer ( n ) ; } while ( n != m ) ; } out : read_seqlock_excl ( & mount_lock ) ; hlist_for_each_entry ( n , tree_list , mnt_hash ) { m = n -> mnt_parent ; if ( m -> mnt_master != dest_mnt -> mnt_master ) CLEAR_MNT_MARK ( m -> mnt_master ) ; } read_sequnlock_excl ( & mount_lock ) ; return ret ; }
CWE-000 static int propagate_one ( struct mount * m ) { struct mount * child ; int type ; if ( IS_MNT_NEW ( m ) ) return 0 ; if ( ! is_subdir ( mp -> m_dentry , m -> mnt . mnt_root ) ) return 0 ; if ( peers ( m , last_dest ) ) { type = CL_MAKE_SHARED ; } else { <S2SV_StartBug> struct mount * n , * p ; <S2SV_EndBug> for ( n = m ; ; n = p ) { p = n -> mnt_master ; <S2SV_StartBug> if ( p == dest_master || IS_MNT_MARKED ( p ) ) { <S2SV_EndBug> while ( last_dest -> mnt_master != p ) { last_source = last_source -> mnt_master ; last_dest = last_source -> mnt_parent ; } if ( ! peers ( n , last_dest ) ) { last_source = last_source -> mnt_master ; last_dest = last_source -> mnt_parent ; } break ; } } type = CL_SLAVE ; if ( IS_MNT_SHARED ( m ) ) type |= CL_MAKE_SHARED ; } if ( m -> mnt_ns -> user_ns != user_ns ) type |= CL_UNPRIVILEGED ; child = copy_tree ( last_source , last_source -> mnt . mnt_root , type ) ; if ( IS_ERR ( child ) ) return PTR_ERR ( child ) ; child -> mnt . mnt_flags &= ~ MNT_LOCKED ; mnt_set_mountpoint ( m , mp , child ) ; last_dest = m ; last_source = child ; if ( m -> mnt_master != dest_master ) { read_seqlock_excl ( & mount_lock ) ; SET_MNT_MARK ( m -> mnt_master ) ; read_sequnlock_excl ( & mount_lock ) ; } hlist_add_head ( & child -> mnt_hash , list ) ; return 0 ; }
CWE-000 void sctp_assoc_update ( struct sctp_association * asoc , struct sctp_association * new ) { struct sctp_transport * trans ; struct list_head * pos , * temp ; asoc -> c = new -> c ; asoc -> peer . rwnd = new -> peer . rwnd ; asoc -> peer . sack_needed = new -> peer . sack_needed ; asoc -> peer . auth_capable = new -> peer . auth_capable ; asoc -> peer . i = new -> peer . i ; sctp_tsnmap_init ( & asoc -> peer . tsn_map , SCTP_TSN_MAP_INITIAL , asoc -> peer . i . initial_tsn , GFP_ATOMIC ) ; list_for_each_safe ( pos , temp , & asoc -> peer . transport_addr_list ) { trans = list_entry ( pos , struct sctp_transport , transports ) ; if ( ! sctp_assoc_lookup_paddr ( new , & trans -> ipaddr ) ) { sctp_assoc_rm_peer ( asoc , trans ) ; continue ; } if ( asoc -> state >= SCTP_STATE_ESTABLISHED ) sctp_transport_reset ( trans ) ; } if ( asoc -> state >= SCTP_STATE_ESTABLISHED ) { asoc -> next_tsn = new -> next_tsn ; asoc -> ctsn_ack_point = new -> ctsn_ack_point ; asoc -> adv_peer_ack_point = new -> adv_peer_ack_point ; sctp_ssnmap_clear ( asoc -> ssnmap ) ; sctp_ulpq_flush ( & asoc -> ulpq ) ; asoc -> overall_error_count = 0 ; } else { list_for_each_entry ( trans , & new -> peer . transport_addr_list , transports ) { if ( ! sctp_assoc_lookup_paddr ( asoc , & trans -> ipaddr ) ) sctp_assoc_add_peer ( asoc , & trans -> ipaddr , GFP_ATOMIC , trans -> state ) ; } asoc -> ctsn_ack_point = asoc -> next_tsn - 1 ; asoc -> adv_peer_ack_point = asoc -> ctsn_ack_point ; if ( ! asoc -> ssnmap ) { asoc -> ssnmap = new -> ssnmap ; new -> ssnmap = NULL ; } if ( ! asoc -> assoc_id ) { sctp_assoc_set_id ( asoc , GFP_ATOMIC ) ; } } kfree ( asoc -> peer . peer_random ) ; asoc -> peer . peer_random = new -> peer . peer_random ; new -> peer . peer_random = NULL ; kfree ( asoc -> peer . peer_chunks ) ; asoc -> peer . peer_chunks = new -> peer . peer_chunks ; new -> peer . peer_chunks = NULL ; kfree ( asoc -> peer . peer_hmacs ) ; asoc -> peer . peer_hmacs = new -> peer . peer_hmacs ; new -> peer . peer_hmacs = NULL ; <S2SV_StartBug> sctp_auth_key_put ( asoc -> asoc_shared_key ) ; <S2SV_EndBug> sctp_auth_asoc_init_active_key ( asoc , GFP_ATOMIC ) ; }
CWE-000 int rds_ib_xmit ( struct rds_connection * conn , struct rds_message * rm , unsigned int hdr_off , unsigned int sg , unsigned int off ) { struct rds_ib_connection * ic = conn -> c_transport_data ; struct ib_device * dev = ic -> i_cm_id -> device ; struct rds_ib_send_work * send = NULL ; struct rds_ib_send_work * first ; struct rds_ib_send_work * prev ; struct ib_send_wr * failed_wr ; struct scatterlist * scat ; u32 pos ; u32 i ; u32 work_alloc ; u32 credit_alloc = 0 ; u32 posted ; u32 adv_credits = 0 ; int send_flags = 0 ; int bytes_sent = 0 ; int ret ; int flow_controlled = 0 ; int nr_sig = 0 ; BUG_ON ( off % RDS_FRAG_SIZE ) ; BUG_ON ( hdr_off != 0 && hdr_off != sizeof ( struct rds_header ) ) ; if ( conn -> c_loopback && rm -> m_inc . i_hdr . h_flags & RDS_FLAG_CONG_BITMAP ) { rds_cong_map_updated ( conn -> c_fcong , ~ ( u64 ) 0 ) ; <S2SV_StartBug> return sizeof ( struct rds_header ) + RDS_CONG_MAP_BYTES ; <S2SV_EndBug> } if ( be32_to_cpu ( rm -> m_inc . i_hdr . h_len ) == 0 ) i = 1 ; else i = ceil ( be32_to_cpu ( rm -> m_inc . i_hdr . h_len ) , RDS_FRAG_SIZE ) ; work_alloc = rds_ib_ring_alloc ( & ic -> i_send_ring , i , & pos ) ; if ( work_alloc == 0 ) { set_bit ( RDS_LL_SEND_FULL , & conn -> c_flags ) ; rds_ib_stats_inc ( s_ib_tx_ring_full ) ; ret = - ENOMEM ; goto out ; } if ( ic -> i_flowctl ) { credit_alloc = rds_ib_send_grab_credits ( ic , work_alloc , & posted , 0 , RDS_MAX_ADV_CREDIT ) ; adv_credits += posted ; if ( credit_alloc < work_alloc ) { rds_ib_ring_unalloc ( & ic -> i_send_ring , work_alloc - credit_alloc ) ; work_alloc = credit_alloc ; flow_controlled = 1 ; } if ( work_alloc == 0 ) { set_bit ( RDS_LL_SEND_FULL , & conn -> c_flags ) ; rds_ib_stats_inc ( s_ib_tx_throttle ) ; ret = - ENOMEM ; goto out ; } } if ( ! ic -> i_data_op ) { if ( rm -> data . op_nents ) { rm -> data . op_count = ib_dma_map_sg ( dev , rm -> data . op_sg , rm -> data . op_nents , DMA_TO_DEVICE ) ; rdsdebug ( "ic<S2SV_blank>%p<S2SV_blank>mapping<S2SV_blank>rm<S2SV_blank>%p:<S2SV_blank>%d\\n" , ic , rm , rm -> data . op_count ) ; if ( rm -> data . op_count == 0 ) { rds_ib_stats_inc ( s_ib_tx_sg_mapping_failure ) ; rds_ib_ring_unalloc ( & ic -> i_send_ring , work_alloc ) ; ret = - ENOMEM ; goto out ; } } else { rm -> data . op_count = 0 ; } rds_message_addref ( rm ) ; ic -> i_data_op = & rm -> data ; if ( test_bit ( RDS_MSG_ACK_REQUIRED , & rm -> m_flags ) ) rm -> m_inc . i_hdr . h_flags |= RDS_FLAG_ACK_REQUIRED ; if ( test_bit ( RDS_MSG_RETRANSMITTED , & rm -> m_flags ) ) rm -> m_inc . i_hdr . h_flags |= RDS_FLAG_RETRANSMITTED ; if ( rm -> rdma . op_active ) { struct rds_ext_header_rdma ext_hdr ; ext_hdr . h_rdma_rkey = cpu_to_be32 ( rm -> rdma . op_rkey ) ; rds_message_add_extension ( & rm -> m_inc . i_hdr , RDS_EXTHDR_RDMA , & ext_hdr , sizeof ( ext_hdr ) ) ; } if ( rm -> m_rdma_cookie ) { rds_message_add_rdma_dest_extension ( & rm -> m_inc . i_hdr , rds_rdma_cookie_key ( rm -> m_rdma_cookie ) , rds_rdma_cookie_offset ( rm -> m_rdma_cookie ) ) ; } rm -> m_inc . i_hdr . h_ack = cpu_to_be64 ( rds_ib_piggyb_ack ( ic ) ) ; rds_message_make_checksum ( & rm -> m_inc . i_hdr ) ; if ( ic -> i_flowctl ) { rds_ib_send_grab_credits ( ic , 0 , & posted , 1 , RDS_MAX_ADV_CREDIT - adv_credits ) ; adv_credits += posted ; BUG_ON ( adv_credits > 255 ) ; } } if ( rm -> rdma . op_active && rm -> rdma . op_fence ) send_flags = IB_SEND_FENCE ; send = & ic -> i_sends [ pos ] ; first = send ; prev = NULL ; scat = & ic -> i_data_op -> op_sg [ sg ] ; i = 0 ; do { unsigned int len = 0 ; send -> s_wr . send_flags = send_flags ; send -> s_wr . opcode = IB_WR_SEND ; send -> s_wr . num_sge = 1 ; send -> s_wr . next = NULL ; send -> s_queued = jiffies ; send -> s_op = NULL ; send -> s_sge [ 0 ] . addr = ic -> i_send_hdrs_dma + ( pos * sizeof ( struct rds_header ) ) ; send -> s_sge [ 0 ] . length = sizeof ( struct rds_header ) ; memcpy ( & ic -> i_send_hdrs [ pos ] , & rm -> m_inc . i_hdr , sizeof ( struct rds_header ) ) ; if ( i < work_alloc && scat != & rm -> data . op_sg [ rm -> data . op_count ] ) { len = min ( RDS_FRAG_SIZE , ib_sg_dma_len ( dev , scat ) - off ) ; send -> s_wr . num_sge = 2 ; send -> s_sge [ 1 ] . addr = ib_sg_dma_address ( dev , scat ) + off ; send -> s_sge [ 1 ] . length = len ; bytes_sent += len ; off += len ; if ( off == ib_sg_dma_len ( dev , scat ) ) { scat ++ ; off = 0 ; } } rds_ib_set_wr_signal_state ( ic , send , 0 ) ; if ( ic -> i_flowctl && flow_controlled && i == ( work_alloc - 1 ) ) send -> s_wr . send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED ; if ( send -> s_wr . send_flags & IB_SEND_SIGNALED ) nr_sig ++ ; rdsdebug ( "send<S2SV_blank>%p<S2SV_blank>wr<S2SV_blank>%p<S2SV_blank>num_sge<S2SV_blank>%u<S2SV_blank>next<S2SV_blank>%p\\n" , send , & send -> s_wr , send -> s_wr . num_sge , send -> s_wr . next ) ; if ( ic -> i_flowctl && adv_credits ) { struct rds_header * hdr = & ic -> i_send_hdrs [ pos ] ; hdr -> h_credit = adv_credits ; rds_message_make_checksum ( hdr ) ; adv_credits = 0 ; rds_ib_stats_inc ( s_ib_tx_credit_updates ) ; } if ( prev ) prev -> s_wr . next = & send -> s_wr ; prev = send ; pos = ( pos + 1 ) % ic -> i_send_ring . w_nr ; send = & ic -> i_sends [ pos ] ; i ++ ; } while ( i < work_alloc && scat != & rm -> data . op_sg [ rm -> data . op_count ] ) ; if ( hdr_off == 0 ) bytes_sent += sizeof ( struct rds_header ) ; if ( scat == & rm -> data . op_sg [ rm -> data . op_count ] ) { prev -> s_op = ic -> i_data_op ; prev -> s_wr . send_flags |= IB_SEND_SOLICITED ; ic -> i_data_op = NULL ; } if ( i < work_alloc ) { rds_ib_ring_unalloc ( & ic -> i_send_ring , work_alloc - i ) ; work_alloc = i ; } if ( ic -> i_flowctl && i < credit_alloc ) rds_ib_send_add_credits ( conn , credit_alloc - i ) ; if ( nr_sig ) atomic_add ( nr_sig , & ic -> i_signaled_sends ) ; failed_wr = & first -> s_wr ; ret = ib_post_send ( ic -> i_cm_id -> qp , & first -> s_wr , & failed_wr ) ; rdsdebug ( "ic<S2SV_blank>%p<S2SV_blank>first<S2SV_blank>%p<S2SV_blank>(wr<S2SV_blank>%p)<S2SV_blank>ret<S2SV_blank>%d<S2SV_blank>wr<S2SV_blank>%p\\n" , ic , first , & first -> s_wr , ret , failed_wr ) ; BUG_ON ( failed_wr != & first -> s_wr ) ; if ( ret ) { printk ( KERN_WARNING "RDS/IB:<S2SV_blank>ib_post_send<S2SV_blank>to<S2SV_blank>%pI4<S2SV_blank>" "returned<S2SV_blank>%d\\n" , & conn -> c_faddr , ret ) ; rds_ib_ring_unalloc ( & ic -> i_send_ring , work_alloc ) ; rds_ib_sub_signaled ( ic , nr_sig ) ; if ( prev -> s_op ) { ic -> i_data_op = prev -> s_op ; prev -> s_op = NULL ; } rds_ib_conn_error ( ic -> conn , "ib_post_send<S2SV_blank>failed\\n" ) ; goto out ; } ret = bytes_sent ; out : BUG_ON ( adv_credits ) ; return ret ; }
CWE-000 static int rds_loop_xmit ( struct rds_connection * conn , struct rds_message * rm , unsigned int hdr_off , unsigned int sg , unsigned int off ) { <S2SV_StartBug> if ( rm -> m_inc . i_hdr . h_flags & RDS_FLAG_CONG_BITMAP ) { <S2SV_EndBug> rds_cong_map_updated ( conn -> c_fcong , ~ ( u64 ) 0 ) ; <S2SV_StartBug> return sizeof ( struct rds_header ) + RDS_CONG_MAP_BYTES ; <S2SV_EndBug> } BUG_ON ( hdr_off || sg || off ) ; rds_inc_init ( & rm -> m_inc , conn , conn -> c_laddr ) ; rds_message_addref ( rm ) ; rds_recv_incoming ( conn , conn -> c_laddr , conn -> c_faddr , & rm -> m_inc , GFP_KERNEL , KM_USER0 ) ; rds_send_drop_acked ( conn , be64_to_cpu ( rm -> m_inc . i_hdr . h_sequence ) , NULL ) ; rds_inc_put ( & rm -> m_inc ) ; <S2SV_StartBug> return sizeof ( struct rds_header ) + be32_to_cpu ( rm -> m_inc . i_hdr . h_len ) ; <S2SV_EndBug> }
CWE-000 static int snd_compress_check_input ( struct snd_compr_params * params ) { if ( params -> buffer . fragment_size == 0 || <S2SV_StartBug> params -> buffer . fragments > SIZE_MAX / params -> buffer . fragment_size ) <S2SV_EndBug> return - EINVAL ; if ( params -> codec . id == 0 || params -> codec . id > SND_AUDIOCODEC_MAX ) return - EINVAL ; if ( params -> codec . ch_in == 0 || params -> codec . ch_out == 0 ) return - EINVAL ; return 0 ; }
CWE-000 static void ip_expire ( unsigned long arg ) { struct ipq * qp ; struct net * net ; qp = container_of ( ( struct inet_frag_queue * ) arg , struct ipq , q ) ; net = container_of ( qp -> q . net , struct net , ipv4 . frags ) ; spin_lock ( & qp -> q . lock ) ; if ( qp -> q . last_in & INET_FRAG_COMPLETE ) goto out ; ipq_kill ( qp ) ; IP_INC_STATS_BH ( net , IPSTATS_MIB_REASMTIMEOUT ) ; IP_INC_STATS_BH ( net , IPSTATS_MIB_REASMFAILS ) ; if ( ( qp -> q . last_in & INET_FRAG_FIRST_IN ) && qp -> q . fragments != NULL ) { struct sk_buff * head = qp -> q . fragments ; <S2SV_StartBug> rcu_read_lock ( ) ; <S2SV_EndBug> head -> dev = dev_get_by_index_rcu ( net , qp -> iif ) ; <S2SV_StartBug> if ( ! head -> dev ) <S2SV_EndBug> goto out_rcu_unlock ; <S2SV_StartBug> if ( qp -> user == IP_DEFRAG_CONNTRACK_IN && ! skb_dst ( head ) ) { <S2SV_EndBug> const struct iphdr * iph = ip_hdr ( head ) ; int err = ip_route_input ( head , iph -> daddr , iph -> saddr , iph -> tos , head -> dev ) ; if ( unlikely ( err ) ) goto out_rcu_unlock ; if ( skb_rtable ( head ) -> rt_type != RTN_LOCAL ) goto out_rcu_unlock ; <S2SV_StartBug> } <S2SV_EndBug> icmp_send ( head , ICMP_TIME_EXCEEDED , ICMP_EXC_FRAGTIME , 0 ) ; out_rcu_unlock : rcu_read_unlock ( ) ; } out : spin_unlock ( & qp -> q . lock ) ; ipq_put ( qp ) ; }
CWE-000 static inline int xfrm_replay_verify_len ( struct xfrm_replay_state_esn * replay_esn , struct nlattr * rp ) { struct xfrm_replay_state_esn * up ; int ulen ; if ( ! replay_esn || ! rp ) return 0 ; up = nla_data ( rp ) ; ulen = xfrm_replay_state_esn_len ( up ) ; if ( nla_len ( rp ) < ulen || xfrm_replay_state_esn_len ( replay_esn ) != ulen ) return - EINVAL ; <S2SV_StartBug> return 0 ; <S2SV_EndBug> }
CWE-000 int iwch_cxgb3_ofld_send ( struct t3cdev * tdev , struct sk_buff * skb ) { int error = 0 ; struct cxio_rdev * rdev ; rdev = ( struct cxio_rdev * ) tdev -> ulp ; if ( cxio_fatal_error ( rdev ) ) { kfree_skb ( skb ) ; return - EIO ; } error = cxgb3_ofld_send ( tdev , skb ) ; if ( error < 0 ) kfree_skb ( skb ) ; <S2SV_StartBug> return error ; <S2SV_EndBug> }
CWE-000 static int iwch_l2t_send ( struct t3cdev * tdev , struct sk_buff * skb , struct l2t_entry * l2e ) { int error = 0 ; struct cxio_rdev * rdev ; rdev = ( struct cxio_rdev * ) tdev -> ulp ; if ( cxio_fatal_error ( rdev ) ) { kfree_skb ( skb ) ; return - EIO ; } error = l2t_send ( tdev , skb , l2e ) ; if ( error < 0 ) kfree_skb ( skb ) ; <S2SV_StartBug> return error ; <S2SV_EndBug> }
CWE-000 unsigned int get_random_int ( void ) { <S2SV_StartBug> struct keydata * keyptr ; <S2SV_EndBug> __u32 * hash = get_cpu_var ( get_random_int_hash ) ; <S2SV_StartBug> int ret ; <S2SV_EndBug> keyptr = get_keyptr ( ) ; hash [ 0 ] += current -> pid + jiffies + get_cycles ( ) ; <S2SV_StartBug> ret = half_md4_transform ( hash , keyptr -> secret ) ; <S2SV_EndBug> put_cpu_var ( get_random_int_hash ) ; return ret ; }
CWE-000 static int ip6_frag_queue ( struct frag_queue * fq , struct sk_buff * skb , struct frag_hdr * fhdr , int nhoff ) { struct sk_buff * prev , * next ; struct net_device * dev ; int offset , end ; struct net * net = dev_net ( skb_dst ( skb ) -> dev ) ; if ( fq -> q . last_in & INET_FRAG_COMPLETE ) goto err ; offset = ntohs ( fhdr -> frag_off ) & ~ 0x7 ; end = offset + ( ntohs ( ipv6_hdr ( skb ) -> payload_len ) - ( ( u8 * ) ( fhdr + 1 ) - ( u8 * ) ( ipv6_hdr ( skb ) + 1 ) ) ) ; if ( ( unsigned int ) end > IPV6_MAXPLEN ) { IP6_INC_STATS_BH ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_INHDRERRORS ) ; icmpv6_param_prob ( skb , ICMPV6_HDR_FIELD , ( ( u8 * ) & fhdr -> frag_off - skb_network_header ( skb ) ) ) ; return - 1 ; } if ( skb -> ip_summed == CHECKSUM_COMPLETE ) { const unsigned char * nh = skb_network_header ( skb ) ; skb -> csum = csum_sub ( skb -> csum , csum_partial ( nh , ( u8 * ) ( fhdr + 1 ) - nh , 0 ) ) ; } if ( ! ( fhdr -> frag_off & htons ( IP6_MF ) ) ) { if ( end < fq -> q . len || ( ( fq -> q . last_in & INET_FRAG_LAST_IN ) && end != fq -> q . len ) ) goto err ; fq -> q . last_in |= INET_FRAG_LAST_IN ; fq -> q . len = end ; } else { if ( end & 0x7 ) { IP6_INC_STATS_BH ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_INHDRERRORS ) ; icmpv6_param_prob ( skb , ICMPV6_HDR_FIELD , offsetof ( struct ipv6hdr , payload_len ) ) ; return - 1 ; } if ( end > fq -> q . len ) { if ( fq -> q . last_in & INET_FRAG_LAST_IN ) goto err ; fq -> q . len = end ; } } if ( end == offset ) goto err ; if ( ! pskb_pull ( skb , ( u8 * ) ( fhdr + 1 ) - skb -> data ) ) goto err ; if ( pskb_trim_rcsum ( skb , end - offset ) ) goto err ; prev = fq -> q . fragments_tail ; if ( ! prev || FRAG6_CB ( prev ) -> offset < offset ) { next = NULL ; goto found ; } prev = NULL ; for ( next = fq -> q . fragments ; next != NULL ; next = next -> next ) { if ( FRAG6_CB ( next ) -> offset >= offset ) break ; prev = next ; } found : <S2SV_StartBug> if ( prev ) { <S2SV_EndBug> <S2SV_StartBug> int i = ( FRAG6_CB ( prev ) -> offset + prev -> len ) - offset ; <S2SV_EndBug> <S2SV_StartBug> if ( i > 0 ) { <S2SV_EndBug> offset += i ; if ( end <= offset ) goto err ; if ( ! pskb_pull ( skb , i ) ) goto err ; if ( skb -> ip_summed != CHECKSUM_UNNECESSARY ) skb -> ip_summed = CHECKSUM_NONE ; } } <S2SV_StartBug> while ( next && FRAG6_CB ( next ) -> offset < end ) { <S2SV_EndBug> int i = end - FRAG6_CB ( next ) -> offset ; if ( i < next -> len ) { if ( ! pskb_pull ( next , i ) ) goto err ; FRAG6_CB ( next ) -> offset += i ; fq -> q . meat -= i ; if ( next -> ip_summed != CHECKSUM_UNNECESSARY ) next -> ip_summed = CHECKSUM_NONE ; break ; } else { struct sk_buff * free_it = next ; next = next -> next ; if ( prev ) prev -> next = next ; else fq -> q . fragments = next ; fq -> q . meat -= free_it -> len ; frag_kfree_skb ( fq -> q . net , free_it ) ; } } FRAG6_CB ( skb ) -> offset = offset ; skb -> next = next ; if ( ! next ) fq -> q . fragments_tail = skb ; if ( prev ) prev -> next = skb ; else fq -> q . fragments = skb ; dev = skb -> dev ; if ( dev ) { fq -> iif = dev -> ifindex ; skb -> dev = NULL ; } fq -> q . stamp = skb -> tstamp ; fq -> q . meat += skb -> len ; atomic_add ( skb -> truesize , & fq -> q . net -> mem ) ; if ( offset == 0 ) { fq -> nhoffset = nhoff ; fq -> q . last_in |= INET_FRAG_FIRST_IN ; } if ( fq -> q . last_in == ( INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN ) && fq -> q . meat == fq -> q . len ) return ip6_frag_reasm ( fq , prev , dev ) ; write_lock ( & ip6_frags . lock ) ; list_move_tail ( & fq -> q . lru_list , & fq -> q . net -> lru_list ) ; write_unlock ( & ip6_frags . lock ) ; return - 1 ; <S2SV_StartBug> err : <S2SV_EndBug> IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_REASMFAILS ) ; kfree_skb ( skb ) ; return - 1 ; }
CWE-000 static int handle_vmon ( struct kvm_vcpu * vcpu ) { int ret ; gpa_t vmptr ; struct page * page ; struct vcpu_vmx * vmx = to_vmx ( vcpu ) ; const u64 VMXON_NEEDED_FEATURES = FEATURE_CONTROL_LOCKED | FEATURE_CONTROL_VMXON_ENABLED_OUTSIDE_SMX ; <S2SV_StartBug> if ( ! kvm_read_cr4_bits ( vcpu , X86_CR4_VMXE ) ) { <S2SV_EndBug> kvm_queue_exception ( vcpu , UD_VECTOR ) ; return 1 ; } if ( vmx -> nested . vmxon ) { nested_vmx_failValid ( vcpu , VMXERR_VMXON_IN_VMX_ROOT_OPERATION ) ; return kvm_skip_emulated_instruction ( vcpu ) ; } if ( ( vmx -> msr_ia32_feature_control & VMXON_NEEDED_FEATURES ) != VMXON_NEEDED_FEATURES ) { kvm_inject_gp ( vcpu , 0 ) ; return 1 ; } if ( nested_vmx_get_vmptr ( vcpu , & vmptr ) ) return 1 ; if ( ! PAGE_ALIGNED ( vmptr ) || ( vmptr >> cpuid_maxphyaddr ( vcpu ) ) ) { nested_vmx_failInvalid ( vcpu ) ; return kvm_skip_emulated_instruction ( vcpu ) ; } page = kvm_vcpu_gpa_to_page ( vcpu , vmptr ) ; if ( is_error_page ( page ) ) { nested_vmx_failInvalid ( vcpu ) ; return kvm_skip_emulated_instruction ( vcpu ) ; } if ( * ( u32 * ) kmap ( page ) != VMCS12_REVISION ) { kunmap ( page ) ; kvm_release_page_clean ( page ) ; nested_vmx_failInvalid ( vcpu ) ; return kvm_skip_emulated_instruction ( vcpu ) ; } kunmap ( page ) ; kvm_release_page_clean ( page ) ; vmx -> nested . vmxon_ptr = vmptr ; ret = enter_vmx_operation ( vcpu ) ; if ( ret ) return ret ; nested_vmx_succeed ( vcpu ) ; return kvm_skip_emulated_instruction ( vcpu ) ; }
CWE-000 static int nested_vmx_check_permission ( struct kvm_vcpu * vcpu ) <S2SV_StartBug> { <S2SV_EndBug> if ( ! to_vmx ( vcpu ) -> nested . vmxon ) { kvm_queue_exception ( vcpu , UD_VECTOR ) ; return 0 ; } return 1 ; }
CWE-000 int ext4_ext_get_blocks ( handle_t * handle , struct inode * inode , ext4_lblk_t iblock , unsigned int max_blocks , struct buffer_head * bh_result , int flags ) { struct ext4_ext_path * path = NULL ; struct ext4_extent_header * eh ; struct ext4_extent newex , * ex , * last_ex ; ext4_fsblk_t newblock ; int err = 0 , depth , ret , cache_type ; unsigned int allocated = 0 ; struct ext4_allocation_request ar ; ext4_io_end_t * io = EXT4_I ( inode ) -> cur_aio_dio ; __clear_bit ( BH_New , & bh_result -> b_state ) ; ext_debug ( "blocks<S2SV_blank>%u/%u<S2SV_blank>requested<S2SV_blank>for<S2SV_blank>inode<S2SV_blank>%lu\\n" , iblock , max_blocks , inode -> i_ino ) ; cache_type = ext4_ext_in_cache ( inode , iblock , & newex ) ; if ( cache_type ) { if ( cache_type == EXT4_EXT_CACHE_GAP ) { if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 ) { goto out2 ; } } else if ( cache_type == EXT4_EXT_CACHE_EXTENT ) { newblock = iblock - le32_to_cpu ( newex . ee_block ) + ext_pblock ( & newex ) ; allocated = ext4_ext_get_actual_len ( & newex ) - ( iblock - le32_to_cpu ( newex . ee_block ) ) ; goto out ; } else { BUG ( ) ; } } path = ext4_ext_find_extent ( inode , iblock , NULL ) ; if ( IS_ERR ( path ) ) { err = PTR_ERR ( path ) ; path = NULL ; goto out2 ; } depth = ext_depth ( inode ) ; if ( path [ depth ] . p_ext == NULL && depth != 0 ) { ext4_error ( inode -> i_sb , "bad<S2SV_blank>extent<S2SV_blank>address<S2SV_blank>" "inode:<S2SV_blank>%lu,<S2SV_blank>iblock:<S2SV_blank>%d,<S2SV_blank>depth:<S2SV_blank>%d" , inode -> i_ino , iblock , depth ) ; err = - EIO ; goto out2 ; } eh = path [ depth ] . p_hdr ; ex = path [ depth ] . p_ext ; if ( ex ) { ext4_lblk_t ee_block = le32_to_cpu ( ex -> ee_block ) ; ext4_fsblk_t ee_start = ext_pblock ( ex ) ; unsigned short ee_len ; ee_len = ext4_ext_get_actual_len ( ex ) ; if ( iblock >= ee_block && iblock < ee_block + ee_len ) { newblock = iblock - ee_block + ee_start ; allocated = ee_len - ( iblock - ee_block ) ; ext_debug ( "%u<S2SV_blank>fit<S2SV_blank>into<S2SV_blank>%u:%d<S2SV_blank>-><S2SV_blank>%llu\\n" , iblock , ee_block , ee_len , newblock ) ; if ( ! ext4_ext_is_uninitialized ( ex ) ) { ext4_ext_put_in_cache ( inode , ee_block , ee_len , ee_start , EXT4_EXT_CACHE_EXTENT ) ; goto out ; } ret = ext4_ext_handle_uninitialized_extents ( handle , inode , iblock , max_blocks , path , flags , allocated , bh_result , newblock ) ; return ret ; } } if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 ) { ext4_ext_put_gap_in_cache ( inode , path , iblock ) ; goto out2 ; } ar . lleft = iblock ; err = ext4_ext_search_left ( inode , path , & ar . lleft , & ar . pleft ) ; if ( err ) goto out2 ; ar . lright = iblock ; err = ext4_ext_search_right ( inode , path , & ar . lright , & ar . pright ) ; if ( err ) goto out2 ; if ( max_blocks > EXT_INIT_MAX_LEN && ! ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) ) max_blocks = EXT_INIT_MAX_LEN ; else if ( max_blocks > EXT_UNINIT_MAX_LEN && ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) ) max_blocks = EXT_UNINIT_MAX_LEN ; newex . ee_block = cpu_to_le32 ( iblock ) ; newex . ee_len = cpu_to_le16 ( max_blocks ) ; err = ext4_ext_check_overlap ( inode , & newex , path ) ; if ( err ) allocated = ext4_ext_get_actual_len ( & newex ) ; else allocated = max_blocks ; ar . inode = inode ; ar . goal = ext4_ext_find_goal ( inode , path , iblock ) ; ar . logical = iblock ; ar . len = allocated ; if ( S_ISREG ( inode -> i_mode ) ) ar . flags = EXT4_MB_HINT_DATA ; else ar . flags = 0 ; newblock = ext4_mb_new_blocks ( handle , & ar , & err ) ; if ( ! newblock ) goto out2 ; ext_debug ( "allocate<S2SV_blank>new<S2SV_blank>block:<S2SV_blank>goal<S2SV_blank>%llu,<S2SV_blank>found<S2SV_blank>%llu/%u\\n" , ar . goal , newblock , allocated ) ; ext4_ext_store_pblock ( & newex , newblock ) ; newex . ee_len = cpu_to_le16 ( ar . len ) ; if ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) { ext4_ext_mark_uninitialized ( & newex ) ; <S2SV_StartBug> if ( flags == EXT4_GET_BLOCKS_PRE_IO ) { <S2SV_EndBug> if ( io ) io -> flag = EXT4_IO_UNWRITTEN ; else ext4_set_inode_state ( inode , EXT4_STATE_DIO_UNWRITTEN ) ; <S2SV_StartBug> } <S2SV_EndBug> } if ( unlikely ( EXT4_I ( inode ) -> i_flags & EXT4_EOFBLOCKS_FL ) ) { if ( eh -> eh_entries ) { last_ex = EXT_LAST_EXTENT ( eh ) ; if ( iblock + ar . len > le32_to_cpu ( last_ex -> ee_block ) + ext4_ext_get_actual_len ( last_ex ) ) EXT4_I ( inode ) -> i_flags &= ~ EXT4_EOFBLOCKS_FL ; } else { WARN_ON ( eh -> eh_entries == 0 ) ; ext4_error ( inode -> i_sb , __func__ , "inode#%lu,<S2SV_blank>eh->eh_entries<S2SV_blank>=<S2SV_blank>0!" , inode -> i_ino ) ; } } err = ext4_ext_insert_extent ( handle , inode , path , & newex , flags ) ; if ( err ) { ext4_discard_preallocations ( inode ) ; ext4_free_blocks ( handle , inode , 0 , ext_pblock ( & newex ) , ext4_ext_get_actual_len ( & newex ) , 0 ) ; goto out2 ; } newblock = ext_pblock ( & newex ) ; allocated = ext4_ext_get_actual_len ( & newex ) ; if ( allocated > max_blocks ) allocated = max_blocks ; set_buffer_new ( bh_result ) ; if ( flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE ) ext4_da_update_reserve_space ( inode , allocated , 1 ) ; if ( ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) == 0 ) { ext4_ext_put_in_cache ( inode , iblock , allocated , newblock , EXT4_EXT_CACHE_EXTENT ) ; ext4_update_inode_fsync_trans ( handle , inode , 1 ) ; } else ext4_update_inode_fsync_trans ( handle , inode , 0 ) ; out : if ( allocated > max_blocks ) allocated = max_blocks ; ext4_ext_show_leaf ( inode , path ) ; set_buffer_mapped ( bh_result ) ; bh_result -> b_bdev = inode -> i_sb -> s_bdev ; bh_result -> b_blocknr = newblock ; out2 : if ( path ) { ext4_ext_drop_refs ( path ) ; kfree ( path ) ; } return err ? err : allocated ; }
CWE-000 static int ext4_ext_handle_uninitialized_extents ( handle_t * handle , struct inode * inode , ext4_lblk_t iblock , unsigned int max_blocks , struct ext4_ext_path * path , int flags , unsigned int allocated , struct buffer_head * bh_result , ext4_fsblk_t newblock ) { int ret = 0 ; int err = 0 ; ext4_io_end_t * io = EXT4_I ( inode ) -> cur_aio_dio ; ext_debug ( "ext4_ext_handle_uninitialized_extents:<S2SV_blank>inode<S2SV_blank>%lu,<S2SV_blank>logical" "block<S2SV_blank>%llu,<S2SV_blank>max_blocks<S2SV_blank>%u,<S2SV_blank>flags<S2SV_blank>%d,<S2SV_blank>allocated<S2SV_blank>%u" , inode -> i_ino , ( unsigned long long ) iblock , max_blocks , flags , allocated ) ; ext4_ext_show_leaf ( inode , path ) ; <S2SV_StartBug> if ( flags == EXT4_GET_BLOCKS_PRE_IO ) { <S2SV_EndBug> ret = ext4_split_unwritten_extents ( handle , inode , path , iblock , max_blocks , flags ) ; if ( io ) io -> flag = EXT4_IO_UNWRITTEN ; else <S2SV_StartBug> ext4_set_inode_state ( inode , EXT4_STATE_DIO_UNWRITTEN ) ; <S2SV_EndBug> goto out ; } <S2SV_StartBug> if ( flags == EXT4_GET_BLOCKS_CONVERT ) { <S2SV_EndBug> ret = ext4_convert_unwritten_extents_endio ( handle , inode , path ) ; if ( ret >= 0 ) ext4_update_inode_fsync_trans ( handle , inode , 1 ) ; goto out2 ; } if ( flags & EXT4_GET_BLOCKS_UNINIT_EXT ) goto map_out ; if ( ( flags & EXT4_GET_BLOCKS_CREATE ) == 0 ) { set_buffer_unwritten ( bh_result ) ; goto out1 ; } ret = ext4_ext_convert_to_initialized ( handle , inode , path , iblock , max_blocks ) ; if ( ret >= 0 ) ext4_update_inode_fsync_trans ( handle , inode , 1 ) ; out : if ( ret <= 0 ) { err = ret ; goto out2 ; } else allocated = ret ; set_buffer_new ( bh_result ) ; if ( allocated > max_blocks ) { unmap_underlying_metadata_blocks ( inode -> i_sb -> s_bdev , newblock + max_blocks , allocated - max_blocks ) ; allocated = max_blocks ; } if ( flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE ) ext4_da_update_reserve_space ( inode , allocated , 0 ) ; map_out : set_buffer_mapped ( bh_result ) ; out1 : if ( allocated > max_blocks ) allocated = max_blocks ; ext4_ext_show_leaf ( inode , path ) ; bh_result -> b_bdev = inode -> i_sb -> s_bdev ; bh_result -> b_blocknr = newblock ; out2 : if ( path ) { ext4_ext_drop_refs ( path ) ; kfree ( path ) ; } return err ? err : allocated ; }
CWE-000 int ext4_ext_insert_extent ( handle_t * handle , struct inode * inode , struct ext4_ext_path * path , struct ext4_extent * newext , int flag ) { struct ext4_extent_header * eh ; struct ext4_extent * ex , * fex ; struct ext4_extent * nearex ; struct ext4_ext_path * npath = NULL ; int depth , len , err ; ext4_lblk_t next ; unsigned uninitialized = 0 ; BUG_ON ( ext4_ext_get_actual_len ( newext ) == 0 ) ; depth = ext_depth ( inode ) ; ex = path [ depth ] . p_ext ; BUG_ON ( path [ depth ] . p_hdr == NULL ) ; <S2SV_StartBug> if ( ex && ( flag != EXT4_GET_BLOCKS_PRE_IO ) <S2SV_EndBug> && ext4_can_extents_be_merged ( inode , ex , newext ) ) { ext_debug ( "append<S2SV_blank>[%d]%d<S2SV_blank>block<S2SV_blank>to<S2SV_blank>%d:[%d]%d<S2SV_blank>(from<S2SV_blank>%llu)\\n" , ext4_ext_is_uninitialized ( newext ) , ext4_ext_get_actual_len ( newext ) , le32_to_cpu ( ex -> ee_block ) , ext4_ext_is_uninitialized ( ex ) , ext4_ext_get_actual_len ( ex ) , ext_pblock ( ex ) ) ; err = ext4_ext_get_access ( handle , inode , path + depth ) ; if ( err ) return err ; if ( ext4_ext_is_uninitialized ( ex ) ) uninitialized = 1 ; ex -> ee_len = cpu_to_le16 ( ext4_ext_get_actual_len ( ex ) + ext4_ext_get_actual_len ( newext ) ) ; if ( uninitialized ) ext4_ext_mark_uninitialized ( ex ) ; eh = path [ depth ] . p_hdr ; nearex = ex ; goto merge ; } repeat : depth = ext_depth ( inode ) ; eh = path [ depth ] . p_hdr ; if ( le16_to_cpu ( eh -> eh_entries ) < le16_to_cpu ( eh -> eh_max ) ) goto has_space ; fex = EXT_LAST_EXTENT ( eh ) ; next = ext4_ext_next_leaf_block ( inode , path ) ; if ( le32_to_cpu ( newext -> ee_block ) > le32_to_cpu ( fex -> ee_block ) && next != EXT_MAX_BLOCK ) { ext_debug ( "next<S2SV_blank>leaf<S2SV_blank>block<S2SV_blank>-<S2SV_blank>%d\\n" , next ) ; BUG_ON ( npath != NULL ) ; npath = ext4_ext_find_extent ( inode , next , NULL ) ; if ( IS_ERR ( npath ) ) return PTR_ERR ( npath ) ; BUG_ON ( npath -> p_depth != path -> p_depth ) ; eh = npath [ depth ] . p_hdr ; if ( le16_to_cpu ( eh -> eh_entries ) < le16_to_cpu ( eh -> eh_max ) ) { ext_debug ( "next<S2SV_blank>leaf<S2SV_blank>isnt<S2SV_blank>full(%d)\\n" , le16_to_cpu ( eh -> eh_entries ) ) ; path = npath ; goto repeat ; } ext_debug ( "next<S2SV_blank>leaf<S2SV_blank>has<S2SV_blank>no<S2SV_blank>free<S2SV_blank>space(%d,%d)\\n" , le16_to_cpu ( eh -> eh_entries ) , le16_to_cpu ( eh -> eh_max ) ) ; } err = ext4_ext_create_new_leaf ( handle , inode , path , newext ) ; if ( err ) goto cleanup ; depth = ext_depth ( inode ) ; eh = path [ depth ] . p_hdr ; has_space : nearex = path [ depth ] . p_ext ; err = ext4_ext_get_access ( handle , inode , path + depth ) ; if ( err ) goto cleanup ; if ( ! nearex ) { ext_debug ( "first<S2SV_blank>extent<S2SV_blank>in<S2SV_blank>the<S2SV_blank>leaf:<S2SV_blank>%d:%llu:[%d]%d\\n" , le32_to_cpu ( newext -> ee_block ) , ext_pblock ( newext ) , ext4_ext_is_uninitialized ( newext ) , ext4_ext_get_actual_len ( newext ) ) ; path [ depth ] . p_ext = EXT_FIRST_EXTENT ( eh ) ; } else if ( le32_to_cpu ( newext -> ee_block ) > le32_to_cpu ( nearex -> ee_block ) ) { if ( nearex != EXT_LAST_EXTENT ( eh ) ) { len = EXT_MAX_EXTENT ( eh ) - nearex ; len = ( len - 1 ) * sizeof ( struct ext4_extent ) ; len = len < 0 ? 0 : len ; ext_debug ( "insert<S2SV_blank>%d:%llu:[%d]%d<S2SV_blank>after:<S2SV_blank>nearest<S2SV_blank>0x%p,<S2SV_blank>" "move<S2SV_blank>%d<S2SV_blank>from<S2SV_blank>0x%p<S2SV_blank>to<S2SV_blank>0x%p\\n" , le32_to_cpu ( newext -> ee_block ) , ext_pblock ( newext ) , ext4_ext_is_uninitialized ( newext ) , ext4_ext_get_actual_len ( newext ) , nearex , len , nearex + 1 , nearex + 2 ) ; memmove ( nearex + 2 , nearex + 1 , len ) ; } path [ depth ] . p_ext = nearex + 1 ; } else { BUG_ON ( newext -> ee_block == nearex -> ee_block ) ; len = ( EXT_MAX_EXTENT ( eh ) - nearex ) * sizeof ( struct ext4_extent ) ; len = len < 0 ? 0 : len ; ext_debug ( "insert<S2SV_blank>%d:%llu:[%d]%d<S2SV_blank>before:<S2SV_blank>nearest<S2SV_blank>0x%p,<S2SV_blank>" "move<S2SV_blank>%d<S2SV_blank>from<S2SV_blank>0x%p<S2SV_blank>to<S2SV_blank>0x%p\\n" , le32_to_cpu ( newext -> ee_block ) , ext_pblock ( newext ) , ext4_ext_is_uninitialized ( newext ) , ext4_ext_get_actual_len ( newext ) , nearex , len , nearex + 1 , nearex + 2 ) ; memmove ( nearex + 1 , nearex , len ) ; path [ depth ] . p_ext = nearex ; } le16_add_cpu ( & eh -> eh_entries , 1 ) ; nearex = path [ depth ] . p_ext ; nearex -> ee_block = newext -> ee_block ; ext4_ext_store_pblock ( nearex , ext_pblock ( newext ) ) ; nearex -> ee_len = newext -> ee_len ; merge : <S2SV_StartBug> if ( flag != EXT4_GET_BLOCKS_PRE_IO ) <S2SV_EndBug> ext4_ext_try_to_merge ( inode , path , nearex ) ; err = ext4_ext_correct_indexes ( handle , inode , path ) ; if ( err ) goto cleanup ; err = ext4_ext_dirty ( handle , inode , path + depth ) ; cleanup : if ( npath ) { ext4_ext_drop_refs ( npath ) ; kfree ( npath ) ; } ext4_ext_invalidate_cache ( inode ) ; return err ; }
CWE-000 static struct rds_connection * __rds_conn_create ( struct net * net , __be32 laddr , __be32 faddr , struct rds_transport * trans , gfp_t gfp , int is_outgoing ) { struct rds_connection * conn , * parent = NULL ; struct hlist_head * head = rds_conn_bucket ( laddr , faddr ) ; struct rds_transport * loop_trans ; unsigned long flags ; int ret ; struct rds_transport * otrans = trans ; if ( ! is_outgoing && otrans -> t_type == RDS_TRANS_TCP ) goto new_conn ; rcu_read_lock ( ) ; conn = rds_conn_lookup ( net , head , laddr , faddr , trans ) ; if ( conn && conn -> c_loopback && conn -> c_trans != & rds_loop_transport && laddr == faddr && ! is_outgoing ) { parent = conn ; conn = parent -> c_passive ; } rcu_read_unlock ( ) ; if ( conn ) goto out ; new_conn : conn = kmem_cache_zalloc ( rds_conn_slab , gfp ) ; if ( ! conn ) { conn = ERR_PTR ( - ENOMEM ) ; goto out ; } INIT_HLIST_NODE ( & conn -> c_hash_node ) ; conn -> c_laddr = laddr ; conn -> c_faddr = faddr ; spin_lock_init ( & conn -> c_lock ) ; conn -> c_next_tx_seq = 1 ; rds_conn_net_set ( conn , net ) ; init_waitqueue_head ( & conn -> c_waitq ) ; INIT_LIST_HEAD ( & conn -> c_send_queue ) ; INIT_LIST_HEAD ( & conn -> c_retrans ) ; ret = rds_cong_get_maps ( conn ) ; if ( ret ) { kmem_cache_free ( rds_conn_slab , conn ) ; conn = ERR_PTR ( ret ) ; goto out ; } loop_trans = rds_trans_get_preferred ( net , faddr ) ; if ( loop_trans ) { rds_trans_put ( loop_trans ) ; conn -> c_loopback = 1 ; if ( is_outgoing && trans -> t_prefer_loopback ) { trans = & rds_loop_transport ; } } <S2SV_StartBug> conn -> c_trans = trans ; <S2SV_EndBug> ret = trans -> conn_alloc ( conn , gfp ) ; if ( ret ) { kmem_cache_free ( rds_conn_slab , conn ) ; conn = ERR_PTR ( ret ) ; goto out ; } atomic_set ( & conn -> c_state , RDS_CONN_DOWN ) ; conn -> c_send_gen = 0 ; conn -> c_reconnect_jiffies = 0 ; INIT_DELAYED_WORK ( & conn -> c_send_w , rds_send_worker ) ; INIT_DELAYED_WORK ( & conn -> c_recv_w , rds_recv_worker ) ; INIT_DELAYED_WORK ( & conn -> c_conn_w , rds_connect_worker ) ; INIT_WORK ( & conn -> c_down_w , rds_shutdown_worker ) ; mutex_init ( & conn -> c_cm_lock ) ; conn -> c_flags = 0 ; rdsdebug ( "allocated<S2SV_blank>conn<S2SV_blank>%p<S2SV_blank>for<S2SV_blank>%pI4<S2SV_blank>-><S2SV_blank>%pI4<S2SV_blank>over<S2SV_blank>%s<S2SV_blank>%s\\n" , conn , & laddr , & faddr , trans -> t_name ? trans -> t_name : "[unknown]" , is_outgoing ? "(outgoing)" : "" ) ; spin_lock_irqsave ( & rds_conn_lock , flags ) ; if ( parent ) { if ( parent -> c_passive ) { trans -> conn_free ( conn -> c_transport_data ) ; kmem_cache_free ( rds_conn_slab , conn ) ; conn = parent -> c_passive ; } else { parent -> c_passive = conn ; rds_cong_add_conn ( conn ) ; rds_conn_count ++ ; } } else { struct rds_connection * found ; if ( ! is_outgoing && otrans -> t_type == RDS_TRANS_TCP ) found = NULL ; else found = rds_conn_lookup ( net , head , laddr , faddr , trans ) ; if ( found ) { trans -> conn_free ( conn -> c_transport_data ) ; kmem_cache_free ( rds_conn_slab , conn ) ; conn = found ; } else { if ( ( is_outgoing && otrans -> t_type == RDS_TRANS_TCP ) || ( otrans -> t_type != RDS_TRANS_TCP ) ) { hlist_add_head_rcu ( & conn -> c_hash_node , head ) ; } rds_cong_add_conn ( conn ) ; rds_conn_count ++ ; } } spin_unlock_irqrestore ( & rds_conn_lock , flags ) ; out : return conn ; }
CWE-000 static int ax25_create ( struct net * net , struct socket * sock , int protocol , int kern ) { struct sock * sk ; ax25_cb * ax25 ; <S2SV_StartBug> if ( ! net_eq ( net , & init_net ) ) <S2SV_EndBug> return - EAFNOSUPPORT ; switch ( sock -> type ) { case SOCK_DGRAM : if ( protocol == 0 || protocol == PF_AX25 ) protocol = AX25_P_TEXT ; break ; case SOCK_SEQPACKET : switch ( protocol ) { case 0 : case PF_AX25 : protocol = AX25_P_TEXT ; break ; case AX25_P_SEGMENT : # ifdef CONFIG_INET case AX25_P_ARP : case AX25_P_IP : # endif # ifdef CONFIG_NETROM case AX25_P_NETROM : # endif # ifdef CONFIG_ROSE case AX25_P_ROSE : # endif return - ESOCKTNOSUPPORT ; # ifdef CONFIG_NETROM_MODULE case AX25_P_NETROM : if ( ax25_protocol_is_registered ( AX25_P_NETROM ) ) return - ESOCKTNOSUPPORT ; break ; # endif # ifdef CONFIG_ROSE_MODULE case AX25_P_ROSE : if ( ax25_protocol_is_registered ( AX25_P_ROSE ) ) return - ESOCKTNOSUPPORT ; # endif default : break ; } break ; case SOCK_RAW : break ; default : return - ESOCKTNOSUPPORT ; } sk = sk_alloc ( net , PF_AX25 , GFP_ATOMIC , & ax25_proto , kern ) ; if ( sk == NULL ) return - ENOMEM ; ax25 = ax25_sk ( sk ) -> cb = ax25_create_cb ( ) ; if ( ! ax25 ) { sk_free ( sk ) ; return - ENOMEM ; } sock_init_data ( sock , sk ) ; sk -> sk_destruct = ax25_free_sock ; sock -> ops = & ax25_proto_ops ; sk -> sk_protocol = protocol ; ax25 -> sk = sk ; return 0 ; }
CWE-000 static int dn_create ( struct net * net , struct socket * sock , int protocol , int kern ) { <S2SV_StartBug> struct sock * sk ; <S2SV_EndBug> if ( ! net_eq ( net , & init_net ) ) return - EAFNOSUPPORT ; switch ( sock -> type ) { case SOCK_SEQPACKET : if ( protocol != DNPROTO_NSP ) return - EPROTONOSUPPORT ; break ; case SOCK_STREAM : break ; default : return - ESOCKTNOSUPPORT ; } if ( ( sk = dn_alloc_sock ( net , sock , GFP_KERNEL , kern ) ) == NULL ) return - ENOBUFS ; sk -> sk_protocol = protocol ; return 0 ; }
CWE-000 static int inet_create ( struct net * net , struct socket * sock , int protocol , int kern ) { struct sock * sk ; struct inet_protosw * answer ; struct inet_sock * inet ; struct proto * answer_prot ; unsigned char answer_flags ; int try_loading_module = 0 ; <S2SV_StartBug> int err ; <S2SV_EndBug> sock -> state = SS_UNCONNECTED ; lookup_protocol : err = - ESOCKTNOSUPPORT ; rcu_read_lock ( ) ; list_for_each_entry_rcu ( answer , & inetsw [ sock -> type ] , list ) { err = 0 ; if ( protocol == answer -> protocol ) { if ( protocol != IPPROTO_IP ) break ; } else { if ( IPPROTO_IP == protocol ) { protocol = answer -> protocol ; break ; } if ( IPPROTO_IP == answer -> protocol ) break ; } err = - EPROTONOSUPPORT ; } if ( unlikely ( err ) ) { if ( try_loading_module < 2 ) { rcu_read_unlock ( ) ; if ( ++ try_loading_module == 1 ) request_module ( "net-pf-%d-proto-%d-type-%d" , PF_INET , protocol , sock -> type ) ; else request_module ( "net-pf-%d-proto-%d" , PF_INET , protocol ) ; goto lookup_protocol ; } else goto out_rcu_unlock ; } err = - EPERM ; if ( sock -> type == SOCK_RAW && ! kern && ! ns_capable ( net -> user_ns , CAP_NET_RAW ) ) goto out_rcu_unlock ; sock -> ops = answer -> ops ; answer_prot = answer -> prot ; answer_flags = answer -> flags ; rcu_read_unlock ( ) ; WARN_ON ( ! answer_prot -> slab ) ; err = - ENOBUFS ; sk = sk_alloc ( net , PF_INET , GFP_KERNEL , answer_prot , kern ) ; if ( ! sk ) goto out ; err = 0 ; if ( INET_PROTOSW_REUSE & answer_flags ) sk -> sk_reuse = SK_CAN_REUSE ; inet = inet_sk ( sk ) ; inet -> is_icsk = ( INET_PROTOSW_ICSK & answer_flags ) != 0 ; inet -> nodefrag = 0 ; if ( SOCK_RAW == sock -> type ) { inet -> inet_num = protocol ; if ( IPPROTO_RAW == protocol ) inet -> hdrincl = 1 ; } if ( net -> ipv4 . sysctl_ip_no_pmtu_disc ) inet -> pmtudisc = IP_PMTUDISC_DONT ; else inet -> pmtudisc = IP_PMTUDISC_WANT ; inet -> inet_id = 0 ; sock_init_data ( sock , sk ) ; sk -> sk_destruct = inet_sock_destruct ; sk -> sk_protocol = protocol ; sk -> sk_backlog_rcv = sk -> sk_prot -> backlog_rcv ; inet -> uc_ttl = - 1 ; inet -> mc_loop = 1 ; inet -> mc_ttl = 1 ; inet -> mc_all = 1 ; inet -> mc_index = 0 ; inet -> mc_list = NULL ; inet -> rcv_tos = 0 ; sk_refcnt_debug_inc ( sk ) ; if ( inet -> inet_num ) { inet -> inet_sport = htons ( inet -> inet_num ) ; sk -> sk_prot -> hash ( sk ) ; } if ( sk -> sk_prot -> init ) { err = sk -> sk_prot -> init ( sk ) ; if ( err ) sk_common_release ( sk ) ; } out : return err ; out_rcu_unlock : rcu_read_unlock ( ) ; goto out ; }
CWE-000 static int inet6_create ( struct net * net , struct socket * sock , int protocol , int kern ) { struct inet_sock * inet ; struct ipv6_pinfo * np ; struct sock * sk ; struct inet_protosw * answer ; struct proto * answer_prot ; unsigned char answer_flags ; int try_loading_module = 0 ; <S2SV_StartBug> int err ; <S2SV_EndBug> lookup_protocol : err = - ESOCKTNOSUPPORT ; rcu_read_lock ( ) ; list_for_each_entry_rcu ( answer , & inetsw6 [ sock -> type ] , list ) { err = 0 ; if ( protocol == answer -> protocol ) { if ( protocol != IPPROTO_IP ) break ; } else { if ( IPPROTO_IP == protocol ) { protocol = answer -> protocol ; break ; } if ( IPPROTO_IP == answer -> protocol ) break ; } err = - EPROTONOSUPPORT ; } if ( err ) { if ( try_loading_module < 2 ) { rcu_read_unlock ( ) ; if ( ++ try_loading_module == 1 ) request_module ( "net-pf-%d-proto-%d-type-%d" , PF_INET6 , protocol , sock -> type ) ; else request_module ( "net-pf-%d-proto-%d" , PF_INET6 , protocol ) ; goto lookup_protocol ; } else goto out_rcu_unlock ; } err = - EPERM ; if ( sock -> type == SOCK_RAW && ! kern && ! ns_capable ( net -> user_ns , CAP_NET_RAW ) ) goto out_rcu_unlock ; sock -> ops = answer -> ops ; answer_prot = answer -> prot ; answer_flags = answer -> flags ; rcu_read_unlock ( ) ; WARN_ON ( ! answer_prot -> slab ) ; err = - ENOBUFS ; sk = sk_alloc ( net , PF_INET6 , GFP_KERNEL , answer_prot , kern ) ; if ( ! sk ) goto out ; sock_init_data ( sock , sk ) ; err = 0 ; if ( INET_PROTOSW_REUSE & answer_flags ) sk -> sk_reuse = SK_CAN_REUSE ; inet = inet_sk ( sk ) ; inet -> is_icsk = ( INET_PROTOSW_ICSK & answer_flags ) != 0 ; if ( SOCK_RAW == sock -> type ) { inet -> inet_num = protocol ; if ( IPPROTO_RAW == protocol ) inet -> hdrincl = 1 ; } sk -> sk_destruct = inet_sock_destruct ; sk -> sk_family = PF_INET6 ; sk -> sk_protocol = protocol ; sk -> sk_backlog_rcv = answer -> prot -> backlog_rcv ; inet_sk ( sk ) -> pinet6 = np = inet6_sk_generic ( sk ) ; np -> hop_limit = - 1 ; np -> mcast_hops = IPV6_DEFAULT_MCASTHOPS ; np -> mc_loop = 1 ; np -> pmtudisc = IPV6_PMTUDISC_WANT ; np -> autoflowlabel = ip6_default_np_autolabel ( sock_net ( sk ) ) ; sk -> sk_ipv6only = net -> ipv6 . sysctl . bindv6only ; inet -> uc_ttl = - 1 ; inet -> mc_loop = 1 ; inet -> mc_ttl = 1 ; inet -> mc_index = 0 ; inet -> mc_list = NULL ; inet -> rcv_tos = 0 ; if ( net -> ipv4 . sysctl_ip_no_pmtu_disc ) inet -> pmtudisc = IP_PMTUDISC_DONT ; else inet -> pmtudisc = IP_PMTUDISC_WANT ; sk_refcnt_debug_inc ( sk ) ; if ( inet -> inet_num ) { inet -> inet_sport = htons ( inet -> inet_num ) ; sk -> sk_prot -> hash ( sk ) ; } if ( sk -> sk_prot -> init ) { err = sk -> sk_prot -> init ( sk ) ; if ( err ) { sk_common_release ( sk ) ; goto out ; } } out : return err ; out_rcu_unlock : rcu_read_unlock ( ) ; goto out ; }
CWE-000 static int irda_create ( struct net * net , struct socket * sock , int protocol , int kern ) { struct sock * sk ; struct irda_sock * self ; <S2SV_StartBug> if ( net != & init_net ) <S2SV_EndBug> return - EAFNOSUPPORT ; switch ( sock -> type ) { case SOCK_STREAM : case SOCK_SEQPACKET : case SOCK_DGRAM : break ; default : return - ESOCKTNOSUPPORT ; } sk = sk_alloc ( net , PF_IRDA , GFP_KERNEL , & irda_proto , kern ) ; if ( sk == NULL ) return - ENOMEM ; self = irda_sk ( sk ) ; pr_debug ( "%s()<S2SV_blank>:<S2SV_blank>self<S2SV_blank>is<S2SV_blank>%p\\n" , __func__ , self ) ; init_waitqueue_head ( & self -> query_wait ) ; switch ( sock -> type ) { case SOCK_STREAM : sock -> ops = & irda_stream_ops ; self -> max_sdu_size_rx = TTP_SAR_DISABLE ; break ; case SOCK_SEQPACKET : sock -> ops = & irda_seqpacket_ops ; self -> max_sdu_size_rx = TTP_SAR_UNBOUND ; break ; case SOCK_DGRAM : switch ( protocol ) { # ifdef CONFIG_IRDA_ULTRA case IRDAPROTO_ULTRA : sock -> ops = & irda_ultra_ops ; self -> max_data_size = ULTRA_MAX_DATA - LMP_PID_HEADER ; self -> max_header_size = IRDA_MAX_HEADER + LMP_PID_HEADER ; break ; # endif case IRDAPROTO_UNITDATA : sock -> ops = & irda_dgram_ops ; self -> max_sdu_size_rx = TTP_SAR_UNBOUND ; break ; default : sk_free ( sk ) ; return - ESOCKTNOSUPPORT ; } break ; default : sk_free ( sk ) ; return - ESOCKTNOSUPPORT ; } sock_init_data ( sock , sk ) ; sk -> sk_family = PF_IRDA ; sk -> sk_protocol = protocol ; self -> ckey = irlmp_register_client ( 0 , NULL , NULL , NULL ) ; self -> mask . word = 0xffff ; self -> rx_flow = self -> tx_flow = FLOW_START ; self -> nslots = DISCOVERY_DEFAULT_SLOTS ; self -> daddr = DEV_ADDR_ANY ; self -> saddr = 0x0 ; return 0 ; }
CWE-000 static struct sock * unix_create1 ( struct net * net , struct socket * sock , int kern ) { struct sock * sk = NULL ; struct unix_sock * u ; atomic_long_inc ( & unix_nr_socks ) ; if ( atomic_long_read ( & unix_nr_socks ) > 2 * get_max_files ( ) ) goto out ; sk = sk_alloc ( net , PF_UNIX , GFP_KERNEL , & unix_proto , kern ) ; if ( ! sk ) goto out ; sock_init_data ( sock , sk ) ; lockdep_set_class ( & sk -> sk_receive_queue . lock , & af_unix_sk_receive_queue_lock_key ) ; sk -> sk_write_space = unix_write_space ; sk -> sk_max_ack_backlog = net -> unx . sysctl_max_dgram_qlen ; sk -> sk_destruct = unix_sock_destructor ; u = unix_sk ( sk ) ; u -> path . dentry = NULL ; u -> path . mnt = NULL ; spin_lock_init ( & u -> lock ) ; atomic_long_set ( & u -> inflight , 0 ) ; INIT_LIST_HEAD ( & u -> link ) ; mutex_init ( & u -> readlock ) ; init_waitqueue_head ( & u -> peer_wait ) ; <S2SV_StartBug> unix_insert_socket ( unix_sockets_unbound ( sk ) , sk ) ; <S2SV_EndBug> out : if ( sk == NULL ) atomic_long_dec ( & unix_nr_socks ) ; else { local_bh_disable ( ) ; sock_prot_inuse_add ( sock_net ( sk ) , sk -> sk_prot , 1 ) ; local_bh_enable ( ) ; } return sk ; }
CWE-000 static int unix_dgram_connect ( struct socket * sock , struct sockaddr * addr , int alen , int flags ) { struct sock * sk = sock -> sk ; struct net * net = sock_net ( sk ) ; struct sockaddr_un * sunaddr = ( struct sockaddr_un * ) addr ; struct sock * other ; unsigned int hash ; int err ; if ( addr -> sa_family != AF_UNSPEC ) { err = unix_mkname ( sunaddr , alen , & hash ) ; if ( err < 0 ) goto out ; alen = err ; if ( test_bit ( SOCK_PASSCRED , & sock -> flags ) && ! unix_sk ( sk ) -> addr && ( err = unix_autobind ( sock ) ) != 0 ) goto out ; restart : other = unix_find_other ( net , sunaddr , alen , sock -> type , hash , & err ) ; if ( ! other ) goto out ; unix_state_double_lock ( sk , other ) ; if ( sock_flag ( other , SOCK_DEAD ) ) { unix_state_double_unlock ( sk , other ) ; sock_put ( other ) ; goto restart ; } err = - EPERM ; if ( ! unix_may_send ( sk , other ) ) goto out_unlock ; err = security_unix_may_send ( sk -> sk_socket , other -> sk_socket ) ; if ( err ) goto out_unlock ; } else { other = NULL ; unix_state_double_lock ( sk , other ) ; } if ( unix_peer ( sk ) ) { struct sock * old_peer = unix_peer ( sk ) ; unix_peer ( sk ) = other ; <S2SV_StartBug> unix_state_double_unlock ( sk , other ) ; <S2SV_EndBug> if ( other != old_peer ) unix_dgram_disconnected ( sk , old_peer ) ; sock_put ( old_peer ) ; } else { unix_peer ( sk ) = other ; unix_state_double_unlock ( sk , other ) ; } return 0 ; out_unlock : unix_state_double_unlock ( sk , other ) ; sock_put ( other ) ; out : return err ; }
CWE-000 static unsigned int unix_dgram_poll ( struct file * file , struct socket * sock , poll_table * wait ) { struct sock * sk = sock -> sk , * other ; unsigned int mask , writable ; sock_poll_wait ( file , sk_sleep ( sk ) , wait ) ; mask = 0 ; if ( sk -> sk_err || ! skb_queue_empty ( & sk -> sk_error_queue ) ) mask |= POLLERR | ( sock_flag ( sk , SOCK_SELECT_ERR_QUEUE ) ? POLLPRI : 0 ) ; if ( sk -> sk_shutdown & RCV_SHUTDOWN ) mask |= POLLRDHUP | POLLIN | POLLRDNORM ; if ( sk -> sk_shutdown == SHUTDOWN_MASK ) mask |= POLLHUP ; if ( ! skb_queue_empty ( & sk -> sk_receive_queue ) ) mask |= POLLIN | POLLRDNORM ; if ( sk -> sk_type == SOCK_SEQPACKET ) { if ( sk -> sk_state == TCP_CLOSE ) mask |= POLLHUP ; if ( sk -> sk_state == TCP_SYN_SENT ) return mask ; } if ( ! ( poll_requested_events ( wait ) & ( POLLWRBAND | POLLWRNORM | POLLOUT ) ) ) return mask ; writable = unix_writable ( sk ) ; <S2SV_StartBug> other = unix_peer_get ( sk ) ; <S2SV_EndBug> if ( other ) { <S2SV_StartBug> if ( unix_peer ( other ) != sk ) { <S2SV_EndBug> sock_poll_wait ( file , & unix_sk ( other ) -> peer_wait , wait ) ; <S2SV_StartBug> if ( unix_recvq_full ( other ) ) <S2SV_EndBug> writable = 0 ; <S2SV_StartBug> } <S2SV_EndBug> sock_put ( other ) ; } if ( writable ) mask |= POLLOUT | POLLWRNORM | POLLWRBAND ; else set_bit ( SOCK_ASYNC_NOSPACE , & sk -> sk_socket -> flags ) ; return mask ; }
CWE-000 static int unix_dgram_sendmsg ( struct socket * sock , struct msghdr * msg , size_t len ) { struct sock * sk = sock -> sk ; struct net * net = sock_net ( sk ) ; struct unix_sock * u = unix_sk ( sk ) ; DECLARE_SOCKADDR ( struct sockaddr_un * , sunaddr , msg -> msg_name ) ; struct sock * other = NULL ; int namelen = 0 ; int err ; unsigned int hash ; struct sk_buff * skb ; long timeo ; struct scm_cookie scm ; int max_level ; int data_len = 0 ; <S2SV_StartBug> wait_for_unix_gc ( ) ; <S2SV_EndBug> err = scm_send ( sock , msg , & scm , false ) ; if ( err < 0 ) return err ; err = - EOPNOTSUPP ; if ( msg -> msg_flags & MSG_OOB ) goto out ; if ( msg -> msg_namelen ) { err = unix_mkname ( sunaddr , msg -> msg_namelen , & hash ) ; if ( err < 0 ) goto out ; namelen = err ; } else { sunaddr = NULL ; err = - ENOTCONN ; other = unix_peer_get ( sk ) ; if ( ! other ) goto out ; } if ( test_bit ( SOCK_PASSCRED , & sock -> flags ) && ! u -> addr && ( err = unix_autobind ( sock ) ) != 0 ) goto out ; err = - EMSGSIZE ; if ( len > sk -> sk_sndbuf - 32 ) goto out ; if ( len > SKB_MAX_ALLOC ) { data_len = min_t ( size_t , len - SKB_MAX_ALLOC , MAX_SKB_FRAGS * PAGE_SIZE ) ; data_len = PAGE_ALIGN ( data_len ) ; BUILD_BUG_ON ( SKB_MAX_ALLOC < PAGE_SIZE ) ; } skb = sock_alloc_send_pskb ( sk , len - data_len , data_len , msg -> msg_flags & MSG_DONTWAIT , & err , PAGE_ALLOC_COSTLY_ORDER ) ; if ( skb == NULL ) goto out ; err = unix_scm_to_skb ( & scm , skb , true ) ; if ( err < 0 ) goto out_free ; max_level = err + 1 ; skb_put ( skb , len - data_len ) ; skb -> data_len = data_len ; skb -> len = len ; err = skb_copy_datagram_from_iter ( skb , 0 , & msg -> msg_iter , len ) ; if ( err ) goto out_free ; timeo = sock_sndtimeo ( sk , msg -> msg_flags & MSG_DONTWAIT ) ; restart : if ( ! other ) { err = - ECONNRESET ; if ( sunaddr == NULL ) goto out_free ; other = unix_find_other ( net , sunaddr , namelen , sk -> sk_type , hash , & err ) ; if ( other == NULL ) goto out_free ; } if ( sk_filter ( other , skb ) < 0 ) { err = len ; goto out_free ; } <S2SV_StartBug> unix_state_lock ( other ) ; <S2SV_EndBug> err = - EPERM ; if ( ! unix_may_send ( sk , other ) ) goto out_unlock ; <S2SV_StartBug> if ( sock_flag ( other , SOCK_DEAD ) ) { <S2SV_EndBug> unix_state_unlock ( other ) ; sock_put ( other ) ; <S2SV_StartBug> err = 0 ; <S2SV_EndBug> <S2SV_StartBug> unix_state_lock ( sk ) ; <S2SV_EndBug> if ( unix_peer ( sk ) == other ) { <S2SV_StartBug> unix_peer ( sk ) = NULL ; <S2SV_EndBug> unix_state_unlock ( sk ) ; unix_dgram_disconnected ( sk , other ) ; sock_put ( other ) ; err = - ECONNREFUSED ; } else { unix_state_unlock ( sk ) ; } other = NULL ; if ( err ) goto out_free ; goto restart ; } err = - EPIPE ; if ( other -> sk_shutdown & RCV_SHUTDOWN ) goto out_unlock ; if ( sk -> sk_type != SOCK_SEQPACKET ) { err = security_unix_may_send ( sk -> sk_socket , other -> sk_socket ) ; if ( err ) goto out_unlock ; } <S2SV_StartBug> if ( unix_peer ( other ) != sk && unix_recvq_full ( other ) ) { <S2SV_EndBug> <S2SV_StartBug> if ( ! timeo ) { <S2SV_EndBug> err = - EAGAIN ; <S2SV_StartBug> goto out_unlock ; <S2SV_EndBug> } <S2SV_StartBug> timeo = unix_wait_for_peer ( other , timeo ) ; <S2SV_EndBug> err = sock_intr_errno ( timeo ) ; if ( signal_pending ( current ) ) goto out_free ; goto restart ; } if ( sock_flag ( other , SOCK_RCVTSTAMP ) ) __net_timestamp ( skb ) ; maybe_add_creds ( skb , sock , other ) ; skb_queue_tail ( & other -> sk_receive_queue , skb ) ; if ( max_level > unix_sk ( other ) -> recursion_level ) unix_sk ( other ) -> recursion_level = max_level ; unix_state_unlock ( other ) ; other -> sk_data_ready ( other ) ; sock_put ( other ) ; scm_destroy ( & scm ) ; return len ; out_unlock : <S2SV_StartBug> unix_state_unlock ( other ) ; <S2SV_EndBug> out_free : kfree_skb ( skb ) ; out : if ( other ) sock_put ( other ) ; scm_destroy ( & scm ) ; return err ; }
CWE-000 static void unix_release_sock ( struct sock * sk , int embrion ) { struct unix_sock * u = unix_sk ( sk ) ; struct path path ; struct sock * skpair ; struct sk_buff * skb ; int state ; unix_remove_socket ( sk ) ; unix_state_lock ( sk ) ; sock_orphan ( sk ) ; sk -> sk_shutdown = SHUTDOWN_MASK ; path = u -> path ; u -> path . dentry = NULL ; u -> path . mnt = NULL ; state = sk -> sk_state ; sk -> sk_state = TCP_CLOSE ; unix_state_unlock ( sk ) ; wake_up_interruptible_all ( & u -> peer_wait ) ; skpair = unix_peer ( sk ) ; if ( skpair != NULL ) { if ( sk -> sk_type == SOCK_STREAM || sk -> sk_type == SOCK_SEQPACKET ) { unix_state_lock ( skpair ) ; skpair -> sk_shutdown = SHUTDOWN_MASK ; if ( ! skb_queue_empty ( & sk -> sk_receive_queue ) || embrion ) skpair -> sk_err = ECONNRESET ; unix_state_unlock ( skpair ) ; skpair -> sk_state_change ( skpair ) ; sk_wake_async ( skpair , SOCK_WAKE_WAITD , POLL_HUP ) ; } <S2SV_StartBug> sock_put ( skpair ) ; <S2SV_EndBug> unix_peer ( sk ) = NULL ; } while ( ( skb = skb_dequeue ( & sk -> sk_receive_queue ) ) != NULL ) { if ( state == TCP_LISTEN ) unix_release_sock ( skb -> sk , 1 ) ; UNIXCB ( skb ) . consumed = skb -> len ; kfree_skb ( skb ) ; } if ( path . dentry ) path_put ( & path ) ; sock_put ( sk ) ; if ( unix_tot_inflight ) unix_gc ( ) ; }
CWE-000 static int ghash_final ( struct shash_desc * desc , u8 * dst ) { struct ghash_desc_ctx * dctx = shash_desc_ctx ( desc ) ; struct ghash_ctx * ctx = crypto_shash_ctx ( desc -> tfm ) ; u8 * buf = dctx -> buffer ; <S2SV_StartBug> ghash_flush ( ctx , dctx ) ; <S2SV_EndBug> memcpy ( dst , buf , GHASH_BLOCK_SIZE ) ; return 0 ; }
CWE-000 static int ghash_update ( struct shash_desc * desc , const u8 * src , unsigned int srclen ) { struct ghash_desc_ctx * dctx = shash_desc_ctx ( desc ) ; struct ghash_ctx * ctx = crypto_shash_ctx ( desc -> tfm ) ; u8 * dst = dctx -> buffer ; <S2SV_StartBug> if ( dctx -> bytes ) { <S2SV_EndBug> int n = min ( srclen , dctx -> bytes ) ; u8 * pos = dst + ( GHASH_BLOCK_SIZE - dctx -> bytes ) ; dctx -> bytes -= n ; srclen -= n ; while ( n -- ) * pos ++ ^= * src ++ ; if ( ! dctx -> bytes ) gf128mul_4k_lle ( ( be128 * ) dst , ctx -> gf128 ) ; } while ( srclen >= GHASH_BLOCK_SIZE ) { crypto_xor ( dst , src , GHASH_BLOCK_SIZE ) ; gf128mul_4k_lle ( ( be128 * ) dst , ctx -> gf128 ) ; src += GHASH_BLOCK_SIZE ; srclen -= GHASH_BLOCK_SIZE ; } if ( srclen ) { dctx -> bytes = GHASH_BLOCK_SIZE - srclen ; while ( srclen -- ) * dst ++ ^= * src ++ ; } return 0 ; }
CWE-000 void pin_remove ( struct fs_pin * pin ) { spin_lock ( & pin_lock ) ; <S2SV_StartBug> hlist_del ( & pin -> m_list ) ; <S2SV_EndBug> <S2SV_StartBug> hlist_del ( & pin -> s_list ) ; <S2SV_EndBug> spin_unlock ( & pin_lock ) ; spin_lock_irq ( & pin -> wait . lock ) ; pin -> done = 1 ; wake_up_locked ( & pin -> wait ) ; spin_unlock_irq ( & pin -> wait . lock ) ; }
CWE-000 static int replace_map_fd_with_map_ptr ( struct verifier_env * env ) { struct bpf_insn * insn = env -> prog -> insnsi ; int insn_cnt = env -> prog -> len ; int i , j ; for ( i = 0 ; i < insn_cnt ; i ++ , insn ++ ) { if ( BPF_CLASS ( insn -> code ) == BPF_LDX && ( BPF_MODE ( insn -> code ) != BPF_MEM || insn -> imm != 0 ) ) { verbose ( "BPF_LDX<S2SV_blank>uses<S2SV_blank>reserved<S2SV_blank>fields\\n" ) ; return - EINVAL ; } if ( BPF_CLASS ( insn -> code ) == BPF_STX && ( ( BPF_MODE ( insn -> code ) != BPF_MEM && BPF_MODE ( insn -> code ) != BPF_XADD ) || insn -> imm != 0 ) ) { verbose ( "BPF_STX<S2SV_blank>uses<S2SV_blank>reserved<S2SV_blank>fields\\n" ) ; return - EINVAL ; } if ( insn [ 0 ] . code == ( BPF_LD | BPF_IMM | BPF_DW ) ) { struct bpf_map * map ; struct fd f ; if ( i == insn_cnt - 1 || insn [ 1 ] . code != 0 || insn [ 1 ] . dst_reg != 0 || insn [ 1 ] . src_reg != 0 || insn [ 1 ] . off != 0 ) { verbose ( "invalid<S2SV_blank>bpf_ld_imm64<S2SV_blank>insn\\n" ) ; return - EINVAL ; } if ( insn -> src_reg == 0 ) goto next_insn ; if ( insn -> src_reg != BPF_PSEUDO_MAP_FD ) { verbose ( "unrecognized<S2SV_blank>bpf_ld_imm64<S2SV_blank>insn\\n" ) ; return - EINVAL ; } f = fdget ( insn -> imm ) ; map = __bpf_map_get ( f ) ; if ( IS_ERR ( map ) ) { verbose ( "fd<S2SV_blank>%d<S2SV_blank>is<S2SV_blank>not<S2SV_blank>pointing<S2SV_blank>to<S2SV_blank>valid<S2SV_blank>bpf_map\\n" , insn -> imm ) ; <S2SV_StartBug> fdput ( f ) ; <S2SV_EndBug> return PTR_ERR ( map ) ; } insn [ 0 ] . imm = ( u32 ) ( unsigned long ) map ; insn [ 1 ] . imm = ( ( u64 ) ( unsigned long ) map ) >> 32 ; for ( j = 0 ; j < env -> used_map_cnt ; j ++ ) if ( env -> used_maps [ j ] == map ) { fdput ( f ) ; goto next_insn ; } if ( env -> used_map_cnt >= MAX_USED_MAPS ) { fdput ( f ) ; return - E2BIG ; } env -> used_maps [ env -> used_map_cnt ++ ] = map ; bpf_map_inc ( map , false ) ; fdput ( f ) ; next_insn : insn ++ ; i ++ ; } } return 0 ; }
CWE-000 static struct sock * dccp_v6_request_recv_sock ( const struct sock * sk , struct sk_buff * skb , struct request_sock * req , struct dst_entry * dst , struct request_sock * req_unhash , bool * own_req ) { struct inet_request_sock * ireq = inet_rsk ( req ) ; struct ipv6_pinfo * newnp ; const struct ipv6_pinfo * np = inet6_sk ( sk ) ; struct ipv6_txoptions * opt ; struct inet_sock * newinet ; struct dccp6_sock * newdp6 ; struct sock * newsk ; if ( skb -> protocol == htons ( ETH_P_IP ) ) { newsk = dccp_v4_request_recv_sock ( sk , skb , req , dst , req_unhash , own_req ) ; if ( newsk == NULL ) return NULL ; newdp6 = ( struct dccp6_sock * ) newsk ; newinet = inet_sk ( newsk ) ; newinet -> pinet6 = & newdp6 -> inet6 ; newnp = inet6_sk ( newsk ) ; memcpy ( newnp , np , sizeof ( struct ipv6_pinfo ) ) ; newnp -> saddr = newsk -> sk_v6_rcv_saddr ; inet_csk ( newsk ) -> icsk_af_ops = & dccp_ipv6_mapped ; newsk -> sk_backlog_rcv = dccp_v4_do_rcv ; newnp -> pktoptions = NULL ; newnp -> opt = NULL ; <S2SV_StartBug> newnp -> mcast_oif = inet6_iif ( skb ) ; <S2SV_EndBug> newnp -> mcast_hops = ipv6_hdr ( skb ) -> hop_limit ; dccp_sync_mss ( newsk , inet_csk ( newsk ) -> icsk_pmtu_cookie ) ; return newsk ; } if ( sk_acceptq_is_full ( sk ) ) goto out_overflow ; if ( ! dst ) { struct flowi6 fl6 ; dst = inet6_csk_route_req ( sk , & fl6 , req , IPPROTO_DCCP ) ; if ( ! dst ) goto out ; } newsk = dccp_create_openreq_child ( sk , req , skb ) ; if ( newsk == NULL ) goto out_nonewsk ; ip6_dst_store ( newsk , dst , NULL , NULL ) ; newsk -> sk_route_caps = dst -> dev -> features & ~ ( NETIF_F_IP_CSUM | NETIF_F_TSO ) ; newdp6 = ( struct dccp6_sock * ) newsk ; newinet = inet_sk ( newsk ) ; newinet -> pinet6 = & newdp6 -> inet6 ; newnp = inet6_sk ( newsk ) ; memcpy ( newnp , np , sizeof ( struct ipv6_pinfo ) ) ; newsk -> sk_v6_daddr = ireq -> ir_v6_rmt_addr ; newnp -> saddr = ireq -> ir_v6_loc_addr ; newsk -> sk_v6_rcv_saddr = ireq -> ir_v6_loc_addr ; newsk -> sk_bound_dev_if = ireq -> ir_iif ; newinet -> inet_opt = NULL ; newnp -> rxopt . all = np -> rxopt . all ; <S2SV_StartBug> newnp -> pktoptions = NULL ; <S2SV_EndBug> newnp -> opt = NULL ; newnp -> mcast_oif = inet6_iif ( skb ) ; newnp -> mcast_hops = ipv6_hdr ( skb ) -> hop_limit ; opt = ireq -> ipv6_opt ; if ( ! opt ) opt = rcu_dereference ( np -> opt ) ; if ( opt ) { opt = ipv6_dup_options ( newsk , opt ) ; RCU_INIT_POINTER ( newnp -> opt , opt ) ; } inet_csk ( newsk ) -> icsk_ext_hdr_len = 0 ; if ( opt ) inet_csk ( newsk ) -> icsk_ext_hdr_len = opt -> opt_nflen + opt -> opt_flen ; dccp_sync_mss ( newsk , dst_mtu ( dst ) ) ; newinet -> inet_daddr = newinet -> inet_saddr = LOOPBACK4_IPV6 ; newinet -> inet_rcv_saddr = LOOPBACK4_IPV6 ; if ( __inet_inherit_port ( sk , newsk ) < 0 ) { inet_csk_prepare_forced_close ( newsk ) ; dccp_done ( newsk ) ; goto out ; } * own_req = inet_ehash_nolisten ( newsk , req_to_sk ( req_unhash ) ) ; if ( * own_req && ireq -> pktopts ) { newnp -> pktoptions = skb_clone ( ireq -> pktopts , GFP_ATOMIC ) ; consume_skb ( ireq -> pktopts ) ; ireq -> pktopts = NULL ; if ( newnp -> pktoptions ) skb_set_owner_r ( newnp -> pktoptions , newsk ) ; } return newsk ; out_overflow : __NET_INC_STATS ( sock_net ( sk ) , LINUX_MIB_LISTENOVERFLOWS ) ; out_nonewsk : dst_release ( dst ) ; out : __NET_INC_STATS ( sock_net ( sk ) , LINUX_MIB_LISTENDROPS ) ; return NULL ; }
CWE-000 static struct sock * tcp_v6_syn_recv_sock ( const struct sock * sk , struct sk_buff * skb , struct request_sock * req , struct dst_entry * dst , struct request_sock * req_unhash , bool * own_req ) { struct inet_request_sock * ireq ; struct ipv6_pinfo * newnp ; const struct ipv6_pinfo * np = inet6_sk ( sk ) ; struct ipv6_txoptions * opt ; struct tcp6_sock * newtcp6sk ; struct inet_sock * newinet ; struct tcp_sock * newtp ; struct sock * newsk ; # ifdef CONFIG_TCP_MD5SIG struct tcp_md5sig_key * key ; # endif struct flowi6 fl6 ; if ( skb -> protocol == htons ( ETH_P_IP ) ) { newsk = tcp_v4_syn_recv_sock ( sk , skb , req , dst , req_unhash , own_req ) ; if ( ! newsk ) return NULL ; newtcp6sk = ( struct tcp6_sock * ) newsk ; inet_sk ( newsk ) -> pinet6 = & newtcp6sk -> inet6 ; newinet = inet_sk ( newsk ) ; newnp = inet6_sk ( newsk ) ; newtp = tcp_sk ( newsk ) ; memcpy ( newnp , np , sizeof ( struct ipv6_pinfo ) ) ; newnp -> saddr = newsk -> sk_v6_rcv_saddr ; inet_csk ( newsk ) -> icsk_af_ops = & ipv6_mapped ; newsk -> sk_backlog_rcv = tcp_v4_do_rcv ; # ifdef CONFIG_TCP_MD5SIG newtp -> af_specific = & tcp_sock_ipv6_mapped_specific ; # endif <S2SV_StartBug> newnp -> ipv6_ac_list = NULL ; <S2SV_EndBug> newnp -> ipv6_fl_list = NULL ; newnp -> pktoptions = NULL ; newnp -> opt = NULL ; newnp -> mcast_oif = tcp_v6_iif ( skb ) ; newnp -> mcast_hops = ipv6_hdr ( skb ) -> hop_limit ; newnp -> rcv_flowinfo = ip6_flowinfo ( ipv6_hdr ( skb ) ) ; if ( np -> repflow ) newnp -> flow_label = ip6_flowlabel ( ipv6_hdr ( skb ) ) ; tcp_sync_mss ( newsk , inet_csk ( newsk ) -> icsk_pmtu_cookie ) ; return newsk ; } ireq = inet_rsk ( req ) ; if ( sk_acceptq_is_full ( sk ) ) goto out_overflow ; if ( ! dst ) { dst = inet6_csk_route_req ( sk , & fl6 , req , IPPROTO_TCP ) ; if ( ! dst ) goto out ; } newsk = tcp_create_openreq_child ( sk , req , skb ) ; if ( ! newsk ) goto out_nonewsk ; newsk -> sk_gso_type = SKB_GSO_TCPV6 ; ip6_dst_store ( newsk , dst , NULL , NULL ) ; inet6_sk_rx_dst_set ( newsk , skb ) ; newtcp6sk = ( struct tcp6_sock * ) newsk ; inet_sk ( newsk ) -> pinet6 = & newtcp6sk -> inet6 ; newtp = tcp_sk ( newsk ) ; newinet = inet_sk ( newsk ) ; newnp = inet6_sk ( newsk ) ; memcpy ( newnp , np , sizeof ( struct ipv6_pinfo ) ) ; newsk -> sk_v6_daddr = ireq -> ir_v6_rmt_addr ; newnp -> saddr = ireq -> ir_v6_loc_addr ; newsk -> sk_v6_rcv_saddr = ireq -> ir_v6_loc_addr ; newsk -> sk_bound_dev_if = ireq -> ir_iif ; <S2SV_StartBug> newinet -> inet_opt = NULL ; <S2SV_EndBug> newnp -> ipv6_ac_list = NULL ; newnp -> ipv6_fl_list = NULL ; newnp -> rxopt . all = np -> rxopt . all ; newnp -> pktoptions = NULL ; newnp -> opt = NULL ; newnp -> mcast_oif = tcp_v6_iif ( skb ) ; newnp -> mcast_hops = ipv6_hdr ( skb ) -> hop_limit ; newnp -> rcv_flowinfo = ip6_flowinfo ( ipv6_hdr ( skb ) ) ; if ( np -> repflow ) newnp -> flow_label = ip6_flowlabel ( ipv6_hdr ( skb ) ) ; opt = ireq -> ipv6_opt ; if ( ! opt ) opt = rcu_dereference ( np -> opt ) ; if ( opt ) { opt = ipv6_dup_options ( newsk , opt ) ; RCU_INIT_POINTER ( newnp -> opt , opt ) ; } inet_csk ( newsk ) -> icsk_ext_hdr_len = 0 ; if ( opt ) inet_csk ( newsk ) -> icsk_ext_hdr_len = opt -> opt_nflen + opt -> opt_flen ; tcp_ca_openreq_child ( newsk , dst ) ; tcp_sync_mss ( newsk , dst_mtu ( dst ) ) ; newtp -> advmss = tcp_mss_clamp ( tcp_sk ( sk ) , dst_metric_advmss ( dst ) ) ; tcp_initialize_rcv_mss ( newsk ) ; newinet -> inet_daddr = newinet -> inet_saddr = LOOPBACK4_IPV6 ; newinet -> inet_rcv_saddr = LOOPBACK4_IPV6 ; # ifdef CONFIG_TCP_MD5SIG key = tcp_v6_md5_do_lookup ( sk , & newsk -> sk_v6_daddr ) ; if ( key ) { tcp_md5_do_add ( newsk , ( union tcp_md5_addr * ) & newsk -> sk_v6_daddr , AF_INET6 , key -> key , key -> keylen , sk_gfp_mask ( sk , GFP_ATOMIC ) ) ; } # endif if ( __inet_inherit_port ( sk , newsk ) < 0 ) { inet_csk_prepare_forced_close ( newsk ) ; tcp_done ( newsk ) ; goto out ; } * own_req = inet_ehash_nolisten ( newsk , req_to_sk ( req_unhash ) ) ; if ( * own_req ) { tcp_move_syn ( newtp , req ) ; if ( ireq -> pktopts ) { newnp -> pktoptions = skb_clone ( ireq -> pktopts , sk_gfp_mask ( sk , GFP_ATOMIC ) ) ; consume_skb ( ireq -> pktopts ) ; ireq -> pktopts = NULL ; if ( newnp -> pktoptions ) { tcp_v6_restore_cb ( newnp -> pktoptions ) ; skb_set_owner_r ( newnp -> pktoptions , newsk ) ; } } } return newsk ; out_overflow : __NET_INC_STATS ( sock_net ( sk ) , LINUX_MIB_LISTENOVERFLOWS ) ; out_nonewsk : dst_release ( dst ) ; out : tcp_listendrop ( sk ) ; return NULL ; }
CWE-000 static struct sk_buff * xfrm_state_netlink ( struct sk_buff * in_skb , struct xfrm_state * x , u32 seq ) { struct xfrm_dump_info info ; <S2SV_StartBug> struct sk_buff * skb ; <S2SV_EndBug> skb = nlmsg_new ( NLMSG_DEFAULT_SIZE , GFP_ATOMIC ) ; if ( ! skb ) return ERR_PTR ( - ENOMEM ) ; info . in_skb = in_skb ; info . out_skb = skb ; info . nlmsg_seq = seq ; info . nlmsg_flags = 0 ; <S2SV_StartBug> if ( dump_one_state ( x , 0 , & info ) ) { <S2SV_EndBug> kfree_skb ( skb ) ; <S2SV_StartBug> return NULL ; <S2SV_EndBug> } return skb ; }
CWE-000 int ip6_append_data ( struct sock * sk , int getfrag ( void * from , char * to , int offset , int len , int odd , struct sk_buff * skb ) , void * from , int length , int transhdrlen , int hlimit , int tclass , struct ipv6_txoptions * opt , struct flowi6 * fl6 , struct rt6_info * rt , unsigned int flags , int dontfrag ) { struct inet_sock * inet = inet_sk ( sk ) ; struct ipv6_pinfo * np = inet6_sk ( sk ) ; struct inet_cork * cork ; struct sk_buff * skb ; unsigned int maxfraglen , fragheaderlen ; int exthdrlen ; int hh_len ; int mtu ; int copy ; int err ; int offset = 0 ; int csummode = CHECKSUM_NONE ; __u8 tx_flags = 0 ; if ( flags & MSG_PROBE ) return 0 ; cork = & inet -> cork . base ; if ( skb_queue_empty ( & sk -> sk_write_queue ) ) { if ( opt ) { if ( WARN_ON ( np -> cork . opt ) ) return - EINVAL ; np -> cork . opt = kmalloc ( opt -> tot_len , sk -> sk_allocation ) ; if ( unlikely ( np -> cork . opt == NULL ) ) return - ENOBUFS ; np -> cork . opt -> tot_len = opt -> tot_len ; np -> cork . opt -> opt_flen = opt -> opt_flen ; np -> cork . opt -> opt_nflen = opt -> opt_nflen ; np -> cork . opt -> dst0opt = ip6_opt_dup ( opt -> dst0opt , sk -> sk_allocation ) ; if ( opt -> dst0opt && ! np -> cork . opt -> dst0opt ) return - ENOBUFS ; np -> cork . opt -> dst1opt = ip6_opt_dup ( opt -> dst1opt , sk -> sk_allocation ) ; if ( opt -> dst1opt && ! np -> cork . opt -> dst1opt ) return - ENOBUFS ; np -> cork . opt -> hopopt = ip6_opt_dup ( opt -> hopopt , sk -> sk_allocation ) ; if ( opt -> hopopt && ! np -> cork . opt -> hopopt ) return - ENOBUFS ; np -> cork . opt -> srcrt = ip6_rthdr_dup ( opt -> srcrt , sk -> sk_allocation ) ; if ( opt -> srcrt && ! np -> cork . opt -> srcrt ) return - ENOBUFS ; } dst_hold ( & rt -> dst ) ; cork -> dst = & rt -> dst ; inet -> cork . fl . u . ip6 = * fl6 ; np -> cork . hop_limit = hlimit ; np -> cork . tclass = tclass ; mtu = np -> pmtudisc == IPV6_PMTUDISC_PROBE ? rt -> dst . dev -> mtu : dst_mtu ( rt -> dst . path ) ; if ( np -> frag_size < mtu ) { if ( np -> frag_size ) mtu = np -> frag_size ; } cork -> fragsize = mtu ; if ( dst_allfrag ( rt -> dst . path ) ) cork -> flags |= IPCORK_ALLFRAG ; cork -> length = 0 ; sk -> sk_sndmsg_page = NULL ; sk -> sk_sndmsg_off = 0 ; exthdrlen = rt -> dst . header_len + ( opt ? opt -> opt_flen : 0 ) - rt -> rt6i_nfheader_len ; length += exthdrlen ; transhdrlen += exthdrlen ; } else { rt = ( struct rt6_info * ) cork -> dst ; fl6 = & inet -> cork . fl . u . ip6 ; opt = np -> cork . opt ; transhdrlen = 0 ; exthdrlen = 0 ; mtu = cork -> fragsize ; } hh_len = LL_RESERVED_SPACE ( rt -> dst . dev ) ; fragheaderlen = sizeof ( struct ipv6hdr ) + rt -> rt6i_nfheader_len + ( opt ? opt -> opt_nflen : 0 ) ; maxfraglen = ( ( mtu - fragheaderlen ) & ~ 7 ) + fragheaderlen - sizeof ( struct frag_hdr ) ; if ( mtu <= sizeof ( struct ipv6hdr ) + IPV6_MAXPLEN ) { if ( cork -> length + length > sizeof ( struct ipv6hdr ) + IPV6_MAXPLEN - fragheaderlen ) { ipv6_local_error ( sk , EMSGSIZE , fl6 , mtu - exthdrlen ) ; return - EMSGSIZE ; } } if ( sk -> sk_type == SOCK_DGRAM ) { err = sock_tx_timestamp ( sk , & tx_flags ) ; if ( err ) goto error ; } cork -> length += length ; if ( length > mtu ) { int proto = sk -> sk_protocol ; if ( dontfrag && ( proto == IPPROTO_UDP || proto == IPPROTO_RAW ) ) { ipv6_local_rxpmtu ( sk , fl6 , mtu - exthdrlen ) ; return - EMSGSIZE ; } if ( proto == IPPROTO_UDP && ( rt -> dst . dev -> features & NETIF_F_UFO ) ) { err = ip6_ufo_append_data ( sk , getfrag , from , length , hh_len , fragheaderlen , <S2SV_StartBug> transhdrlen , mtu , flags ) ; <S2SV_EndBug> if ( err ) goto error ; return 0 ; } } if ( ( skb = skb_peek_tail ( & sk -> sk_write_queue ) ) == NULL ) goto alloc_new_skb ; while ( length > 0 ) { copy = ( cork -> length <= mtu && ! ( cork -> flags & IPCORK_ALLFRAG ) ? mtu : maxfraglen ) - skb -> len ; if ( copy < length ) copy = maxfraglen - skb -> len ; if ( copy <= 0 ) { char * data ; unsigned int datalen ; unsigned int fraglen ; unsigned int fraggap ; unsigned int alloclen ; struct sk_buff * skb_prev ; alloc_new_skb : skb_prev = skb ; if ( skb_prev ) fraggap = skb_prev -> len - maxfraglen ; else fraggap = 0 ; datalen = length + fraggap ; if ( datalen > ( cork -> length <= mtu && ! ( cork -> flags & IPCORK_ALLFRAG ) ? mtu : maxfraglen ) - fragheaderlen ) datalen = maxfraglen - fragheaderlen ; fraglen = datalen + fragheaderlen ; if ( ( flags & MSG_MORE ) && ! ( rt -> dst . dev -> features & NETIF_F_SG ) ) alloclen = mtu ; else alloclen = datalen + fragheaderlen ; if ( datalen == length + fraggap ) alloclen += rt -> dst . trailer_len ; alloclen += sizeof ( struct frag_hdr ) ; if ( transhdrlen ) { skb = sock_alloc_send_skb ( sk , alloclen + hh_len , ( flags & MSG_DONTWAIT ) , & err ) ; } else { skb = NULL ; if ( atomic_read ( & sk -> sk_wmem_alloc ) <= 2 * sk -> sk_sndbuf ) skb = sock_wmalloc ( sk , alloclen + hh_len , 1 , sk -> sk_allocation ) ; if ( unlikely ( skb == NULL ) ) err = - ENOBUFS ; else { tx_flags = 0 ; } } if ( skb == NULL ) goto error ; skb -> ip_summed = csummode ; skb -> csum = 0 ; skb_reserve ( skb , hh_len + sizeof ( struct frag_hdr ) ) ; if ( sk -> sk_type == SOCK_DGRAM ) skb_shinfo ( skb ) -> tx_flags = tx_flags ; data = skb_put ( skb , fraglen ) ; skb_set_network_header ( skb , exthdrlen ) ; data += fragheaderlen ; skb -> transport_header = ( skb -> network_header + fragheaderlen ) ; if ( fraggap ) { skb -> csum = skb_copy_and_csum_bits ( skb_prev , maxfraglen , data + transhdrlen , fraggap , 0 ) ; skb_prev -> csum = csum_sub ( skb_prev -> csum , skb -> csum ) ; data += fraggap ; pskb_trim_unique ( skb_prev , maxfraglen ) ; } copy = datalen - transhdrlen - fraggap ; if ( copy < 0 ) { err = - EINVAL ; kfree_skb ( skb ) ; goto error ; } else if ( copy > 0 && getfrag ( from , data + transhdrlen , offset , copy , fraggap , skb ) < 0 ) { err = - EFAULT ; kfree_skb ( skb ) ; goto error ; } offset += copy ; length -= datalen - fraggap ; transhdrlen = 0 ; exthdrlen = 0 ; csummode = CHECKSUM_NONE ; __skb_queue_tail ( & sk -> sk_write_queue , skb ) ; continue ; } if ( copy > length ) copy = length ; if ( ! ( rt -> dst . dev -> features & NETIF_F_SG ) ) { unsigned int off ; off = skb -> len ; if ( getfrag ( from , skb_put ( skb , copy ) , offset , copy , off , skb ) < 0 ) { __skb_trim ( skb , off ) ; err = - EFAULT ; goto error ; } } else { int i = skb_shinfo ( skb ) -> nr_frags ; skb_frag_t * frag = & skb_shinfo ( skb ) -> frags [ i - 1 ] ; struct page * page = sk -> sk_sndmsg_page ; int off = sk -> sk_sndmsg_off ; unsigned int left ; if ( page && ( left = PAGE_SIZE - off ) > 0 ) { if ( copy >= left ) copy = left ; if ( page != frag -> page ) { if ( i == MAX_SKB_FRAGS ) { err = - EMSGSIZE ; goto error ; } get_page ( page ) ; skb_fill_page_desc ( skb , i , page , sk -> sk_sndmsg_off , 0 ) ; frag = & skb_shinfo ( skb ) -> frags [ i ] ; } } else if ( i < MAX_SKB_FRAGS ) { if ( copy > PAGE_SIZE ) copy = PAGE_SIZE ; page = alloc_pages ( sk -> sk_allocation , 0 ) ; if ( page == NULL ) { err = - ENOMEM ; goto error ; } sk -> sk_sndmsg_page = page ; sk -> sk_sndmsg_off = 0 ; skb_fill_page_desc ( skb , i , page , 0 , 0 ) ; frag = & skb_shinfo ( skb ) -> frags [ i ] ; } else { err = - EMSGSIZE ; goto error ; } if ( getfrag ( from , page_address ( frag -> page ) + frag -> page_offset + frag -> size , offset , copy , skb -> len , skb ) < 0 ) { err = - EFAULT ; goto error ; } sk -> sk_sndmsg_off += copy ; frag -> size += copy ; skb -> len += copy ; skb -> data_len += copy ; skb -> truesize += copy ; atomic_add ( copy , & sk -> sk_wmem_alloc ) ; } offset += copy ; length -= copy ; } return 0 ; error : cork -> length -= length ; IP6_INC_STATS ( sock_net ( sk ) , rt -> rt6i_idev , IPSTATS_MIB_OUTDISCARDS ) ; return err ; }
CWE-000 int ip6_fragment ( struct sk_buff * skb , int ( * output ) ( struct sk_buff * ) ) { struct sk_buff * frag ; struct rt6_info * rt = ( struct rt6_info * ) skb_dst ( skb ) ; struct ipv6_pinfo * np = skb -> sk ? inet6_sk ( skb -> sk ) : NULL ; struct ipv6hdr * tmp_hdr ; struct frag_hdr * fh ; unsigned int mtu , hlen , left , len ; __be32 frag_id = 0 ; int ptr , offset = 0 , err = 0 ; u8 * prevhdr , nexthdr = 0 ; struct net * net = dev_net ( skb_dst ( skb ) -> dev ) ; hlen = ip6_find_1stfragopt ( skb , & prevhdr ) ; nexthdr = * prevhdr ; mtu = ip6_skb_dst_mtu ( skb ) ; if ( ! skb -> local_df && skb -> len > mtu ) { skb -> dev = skb_dst ( skb ) -> dev ; icmpv6_send ( skb , ICMPV6_PKT_TOOBIG , 0 , mtu ) ; IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGFAILS ) ; kfree_skb ( skb ) ; return - EMSGSIZE ; } if ( np && np -> frag_size < mtu ) { if ( np -> frag_size ) mtu = np -> frag_size ; } mtu -= hlen + sizeof ( struct frag_hdr ) ; if ( skb_has_frag_list ( skb ) ) { int first_len = skb_pagelen ( skb ) ; struct sk_buff * frag2 ; if ( first_len - hlen > mtu || ( ( first_len - hlen ) & 7 ) || skb_cloned ( skb ) ) goto slow_path ; skb_walk_frags ( skb , frag ) { if ( frag -> len > mtu || ( ( frag -> len & 7 ) && frag -> next ) || skb_headroom ( frag ) < hlen ) goto slow_path_clean ; if ( skb_shared ( frag ) ) goto slow_path_clean ; BUG_ON ( frag -> sk ) ; if ( skb -> sk ) { frag -> sk = skb -> sk ; frag -> destructor = sock_wfree ; } skb -> truesize -= frag -> truesize ; } err = 0 ; offset = 0 ; frag = skb_shinfo ( skb ) -> frag_list ; skb_frag_list_init ( skb ) ; * prevhdr = NEXTHDR_FRAGMENT ; tmp_hdr = kmemdup ( skb_network_header ( skb ) , hlen , GFP_ATOMIC ) ; if ( ! tmp_hdr ) { IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGFAILS ) ; return - ENOMEM ; } __skb_pull ( skb , hlen ) ; fh = ( struct frag_hdr * ) __skb_push ( skb , sizeof ( struct frag_hdr ) ) ; __skb_push ( skb , hlen ) ; skb_reset_network_header ( skb ) ; memcpy ( skb_network_header ( skb ) , tmp_hdr , hlen ) ; <S2SV_StartBug> ipv6_select_ident ( fh ) ; <S2SV_EndBug> fh -> nexthdr = nexthdr ; fh -> reserved = 0 ; fh -> frag_off = htons ( IP6_MF ) ; frag_id = fh -> identification ; first_len = skb_pagelen ( skb ) ; skb -> data_len = first_len - skb_headlen ( skb ) ; skb -> len = first_len ; ipv6_hdr ( skb ) -> payload_len = htons ( first_len - sizeof ( struct ipv6hdr ) ) ; dst_hold ( & rt -> dst ) ; for ( ; ; ) { if ( frag ) { frag -> ip_summed = CHECKSUM_NONE ; skb_reset_transport_header ( frag ) ; fh = ( struct frag_hdr * ) __skb_push ( frag , sizeof ( struct frag_hdr ) ) ; __skb_push ( frag , hlen ) ; skb_reset_network_header ( frag ) ; memcpy ( skb_network_header ( frag ) , tmp_hdr , hlen ) ; offset += skb -> len - hlen - sizeof ( struct frag_hdr ) ; fh -> nexthdr = nexthdr ; fh -> reserved = 0 ; fh -> frag_off = htons ( offset ) ; if ( frag -> next != NULL ) fh -> frag_off |= htons ( IP6_MF ) ; fh -> identification = frag_id ; ipv6_hdr ( frag ) -> payload_len = htons ( frag -> len - sizeof ( struct ipv6hdr ) ) ; ip6_copy_metadata ( frag , skb ) ; } err = output ( skb ) ; if ( ! err ) IP6_INC_STATS ( net , ip6_dst_idev ( & rt -> dst ) , IPSTATS_MIB_FRAGCREATES ) ; if ( err || ! frag ) break ; skb = frag ; frag = skb -> next ; skb -> next = NULL ; } kfree ( tmp_hdr ) ; if ( err == 0 ) { IP6_INC_STATS ( net , ip6_dst_idev ( & rt -> dst ) , IPSTATS_MIB_FRAGOKS ) ; dst_release ( & rt -> dst ) ; return 0 ; } while ( frag ) { skb = frag -> next ; kfree_skb ( frag ) ; frag = skb ; } IP6_INC_STATS ( net , ip6_dst_idev ( & rt -> dst ) , IPSTATS_MIB_FRAGFAILS ) ; dst_release ( & rt -> dst ) ; return err ; slow_path_clean : skb_walk_frags ( skb , frag2 ) { if ( frag2 == frag ) break ; frag2 -> sk = NULL ; frag2 -> destructor = NULL ; skb -> truesize += frag2 -> truesize ; } } slow_path : left = skb -> len - hlen ; ptr = hlen ; * prevhdr = NEXTHDR_FRAGMENT ; while ( left > 0 ) { len = left ; if ( len > mtu ) len = mtu ; if ( len < left ) { len &= ~ 7 ; } if ( ( frag = alloc_skb ( len + hlen + sizeof ( struct frag_hdr ) + LL_ALLOCATED_SPACE ( rt -> dst . dev ) , GFP_ATOMIC ) ) == NULL ) { NETDEBUG ( KERN_INFO "IPv6:<S2SV_blank>frag:<S2SV_blank>no<S2SV_blank>memory<S2SV_blank>for<S2SV_blank>new<S2SV_blank>fragment!\\n" ) ; IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGFAILS ) ; err = - ENOMEM ; goto fail ; } ip6_copy_metadata ( frag , skb ) ; skb_reserve ( frag , LL_RESERVED_SPACE ( rt -> dst . dev ) ) ; skb_put ( frag , len + hlen + sizeof ( struct frag_hdr ) ) ; skb_reset_network_header ( frag ) ; fh = ( struct frag_hdr * ) ( skb_network_header ( frag ) + hlen ) ; frag -> transport_header = ( frag -> network_header + hlen + sizeof ( struct frag_hdr ) ) ; if ( skb -> sk ) skb_set_owner_w ( frag , skb -> sk ) ; skb_copy_from_linear_data ( skb , skb_network_header ( frag ) , hlen ) ; fh -> nexthdr = nexthdr ; fh -> reserved = 0 ; if ( ! frag_id ) { <S2SV_StartBug> ipv6_select_ident ( fh ) ; <S2SV_EndBug> frag_id = fh -> identification ; } else fh -> identification = frag_id ; if ( skb_copy_bits ( skb , ptr , skb_transport_header ( frag ) , len ) ) BUG ( ) ; left -= len ; fh -> frag_off = htons ( offset ) ; if ( left > 0 ) fh -> frag_off |= htons ( IP6_MF ) ; ipv6_hdr ( frag ) -> payload_len = htons ( frag -> len - sizeof ( struct ipv6hdr ) ) ; ptr += len ; offset += len ; err = output ( frag ) ; if ( err ) goto fail ; IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGCREATES ) ; } IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGOKS ) ; kfree_skb ( skb ) ; return err ; fail : IP6_INC_STATS ( net , ip6_dst_idev ( skb_dst ( skb ) ) , IPSTATS_MIB_FRAGFAILS ) ; kfree_skb ( skb ) ; return err ; }
CWE-000 static inline int ip6_ufo_append_data ( struct sock * sk , int getfrag ( void * from , char * to , int offset , int len , int odd , struct sk_buff * skb ) , void * from , int length , int hh_len , int fragheaderlen , <S2SV_StartBug> int transhdrlen , int mtu , unsigned int flags ) <S2SV_EndBug> { struct sk_buff * skb ; int err ; if ( ( skb = skb_peek_tail ( & sk -> sk_write_queue ) ) == NULL ) { skb = sock_alloc_send_skb ( sk , hh_len + fragheaderlen + transhdrlen + 20 , ( flags & MSG_DONTWAIT ) , & err ) ; if ( skb == NULL ) return - ENOMEM ; skb_reserve ( skb , hh_len ) ; skb_put ( skb , fragheaderlen + transhdrlen ) ; skb_reset_network_header ( skb ) ; skb -> transport_header = skb -> network_header + fragheaderlen ; skb -> ip_summed = CHECKSUM_PARTIAL ; skb -> csum = 0 ; } err = skb_append_datato_frags ( sk , skb , getfrag , from , ( length - transhdrlen ) ) ; if ( ! err ) { struct frag_hdr fhdr ; skb_shinfo ( skb ) -> gso_size = ( mtu - fragheaderlen - sizeof ( struct frag_hdr ) ) & ~ 7 ; skb_shinfo ( skb ) -> gso_type = SKB_GSO_UDP ; <S2SV_StartBug> ipv6_select_ident ( & fhdr ) ; <S2SV_EndBug> skb_shinfo ( skb ) -> ip6_frag_id = fhdr . identification ; __skb_queue_tail ( & sk -> sk_write_queue , skb ) ; return 0 ; } kfree_skb ( skb ) ; return err ; }
CWE-000 static struct sk_buff * udp6_ufo_fragment ( struct sk_buff * skb , u32 features ) { struct sk_buff * segs = ERR_PTR ( - EINVAL ) ; unsigned int mss ; unsigned int unfrag_ip6hlen , unfrag_len ; struct frag_hdr * fptr ; u8 * mac_start , * prevhdr ; u8 nexthdr ; u8 frag_hdr_sz = sizeof ( struct frag_hdr ) ; int offset ; __wsum csum ; mss = skb_shinfo ( skb ) -> gso_size ; if ( unlikely ( skb -> len <= mss ) ) goto out ; if ( skb_gso_ok ( skb , features | NETIF_F_GSO_ROBUST ) ) { int type = skb_shinfo ( skb ) -> gso_type ; if ( unlikely ( type & ~ ( SKB_GSO_UDP | SKB_GSO_DODGY ) || ! ( type & ( SKB_GSO_UDP ) ) ) ) goto out ; skb_shinfo ( skb ) -> gso_segs = DIV_ROUND_UP ( skb -> len , mss ) ; segs = NULL ; goto out ; } offset = skb_checksum_start_offset ( skb ) ; csum = skb_checksum ( skb , offset , skb -> len - offset , 0 ) ; offset += skb -> csum_offset ; * ( __sum16 * ) ( skb -> data + offset ) = csum_fold ( csum ) ; skb -> ip_summed = CHECKSUM_NONE ; if ( ( skb_mac_header ( skb ) < skb -> head + frag_hdr_sz ) && pskb_expand_head ( skb , frag_hdr_sz , 0 , GFP_ATOMIC ) ) goto out ; unfrag_ip6hlen = ip6_find_1stfragopt ( skb , & prevhdr ) ; nexthdr = * prevhdr ; * prevhdr = NEXTHDR_FRAGMENT ; unfrag_len = skb_network_header ( skb ) - skb_mac_header ( skb ) + unfrag_ip6hlen ; mac_start = skb_mac_header ( skb ) ; memmove ( mac_start - frag_hdr_sz , mac_start , unfrag_len ) ; skb -> mac_header -= frag_hdr_sz ; skb -> network_header -= frag_hdr_sz ; fptr = ( struct frag_hdr * ) ( skb_network_header ( skb ) + unfrag_ip6hlen ) ; fptr -> nexthdr = nexthdr ; fptr -> reserved = 0 ; <S2SV_StartBug> ipv6_select_ident ( fptr ) ; <S2SV_EndBug> segs = skb_segment ( skb , features ) ; out : return segs ; }
CWE-000 static int acm_probe ( struct usb_interface * intf , const struct usb_device_id * id ) { struct usb_cdc_union_desc * union_header = NULL ; struct usb_cdc_country_functional_desc * cfd = NULL ; unsigned char * buffer = intf -> altsetting -> extra ; int buflen = intf -> altsetting -> extralen ; struct usb_interface * control_interface ; struct usb_interface * data_interface ; struct usb_endpoint_descriptor * epctrl = NULL ; struct usb_endpoint_descriptor * epread = NULL ; struct usb_endpoint_descriptor * epwrite = NULL ; struct usb_device * usb_dev = interface_to_usbdev ( intf ) ; struct acm * acm ; int minor ; int ctrlsize , readsize ; u8 * buf ; u8 ac_management_function = 0 ; u8 call_management_function = 0 ; int call_interface_num = - 1 ; int data_interface_num = - 1 ; unsigned long quirks ; int num_rx_buf ; int i ; unsigned int elength = 0 ; int combined_interfaces = 0 ; struct device * tty_dev ; int rv = - ENOMEM ; quirks = ( unsigned long ) id -> driver_info ; if ( quirks == IGNORE_DEVICE ) return - ENODEV ; num_rx_buf = ( quirks == SINGLE_RX_URB ) ? 1 : ACM_NR ; if ( quirks == NO_UNION_NORMAL ) { data_interface = usb_ifnum_to_if ( usb_dev , 1 ) ; <S2SV_StartBug> control_interface = usb_ifnum_to_if ( usb_dev , 0 ) ; <S2SV_EndBug> goto skip_normal_probe ; } if ( ! buffer ) { dev_err ( & intf -> dev , "Weird<S2SV_blank>descriptor<S2SV_blank>references\\n" ) ; return - EINVAL ; } if ( ! buflen ) { if ( intf -> cur_altsetting -> endpoint && intf -> cur_altsetting -> endpoint -> extralen && intf -> cur_altsetting -> endpoint -> extra ) { dev_dbg ( & intf -> dev , "Seeking<S2SV_blank>extra<S2SV_blank>descriptors<S2SV_blank>on<S2SV_blank>endpoint\\n" ) ; buflen = intf -> cur_altsetting -> endpoint -> extralen ; buffer = intf -> cur_altsetting -> endpoint -> extra ; } else { dev_err ( & intf -> dev , "Zero<S2SV_blank>length<S2SV_blank>descriptor<S2SV_blank>references\\n" ) ; return - EINVAL ; } } while ( buflen > 0 ) { elength = buffer [ 0 ] ; if ( ! elength ) { dev_err ( & intf -> dev , "skipping<S2SV_blank>garbage<S2SV_blank>byte\\n" ) ; elength = 1 ; goto next_desc ; } if ( buffer [ 1 ] != USB_DT_CS_INTERFACE ) { dev_err ( & intf -> dev , "skipping<S2SV_blank>garbage\\n" ) ; goto next_desc ; } switch ( buffer [ 2 ] ) { case USB_CDC_UNION_TYPE : if ( elength < sizeof ( struct usb_cdc_union_desc ) ) goto next_desc ; if ( union_header ) { dev_err ( & intf -> dev , "More<S2SV_blank>than<S2SV_blank>one<S2SV_blank>" "union<S2SV_blank>descriptor,<S2SV_blank>skipping<S2SV_blank>...\\n" ) ; goto next_desc ; } union_header = ( struct usb_cdc_union_desc * ) buffer ; break ; case USB_CDC_COUNTRY_TYPE : if ( elength < sizeof ( struct usb_cdc_country_functional_desc ) ) goto next_desc ; cfd = ( struct usb_cdc_country_functional_desc * ) buffer ; break ; case USB_CDC_HEADER_TYPE : break ; case USB_CDC_ACM_TYPE : if ( elength < 4 ) goto next_desc ; ac_management_function = buffer [ 3 ] ; break ; case USB_CDC_CALL_MANAGEMENT_TYPE : if ( elength < 5 ) goto next_desc ; call_management_function = buffer [ 3 ] ; call_interface_num = buffer [ 4 ] ; break ; default : dev_dbg ( & intf -> dev , "Ignoring<S2SV_blank>descriptor:<S2SV_blank>" "type<S2SV_blank>%02x,<S2SV_blank>length<S2SV_blank>%ud\\n" , buffer [ 2 ] , elength ) ; break ; } next_desc : buflen -= elength ; buffer += elength ; } if ( ! union_header ) { if ( call_interface_num > 0 ) { dev_dbg ( & intf -> dev , "No<S2SV_blank>union<S2SV_blank>descriptor,<S2SV_blank>using<S2SV_blank>call<S2SV_blank>management<S2SV_blank>descriptor\\n" ) ; if ( quirks & NO_DATA_INTERFACE ) data_interface = usb_ifnum_to_if ( usb_dev , 0 ) ; else data_interface = usb_ifnum_to_if ( usb_dev , ( data_interface_num = call_interface_num ) ) ; control_interface = intf ; } else { if ( intf -> cur_altsetting -> desc . bNumEndpoints != 3 ) { dev_dbg ( & intf -> dev , "No<S2SV_blank>union<S2SV_blank>descriptor,<S2SV_blank>giving<S2SV_blank>up\\n" ) ; return - ENODEV ; } else { dev_warn ( & intf -> dev , "No<S2SV_blank>union<S2SV_blank>descriptor,<S2SV_blank>testing<S2SV_blank>for<S2SV_blank>castrated<S2SV_blank>device\\n" ) ; combined_interfaces = 1 ; control_interface = data_interface = intf ; goto look_for_collapsed_interface ; } } } else { control_interface = usb_ifnum_to_if ( usb_dev , union_header -> bMasterInterface0 ) ; data_interface = usb_ifnum_to_if ( usb_dev , ( data_interface_num = union_header -> bSlaveInterface0 ) ) ; } if ( ! control_interface || ! data_interface ) { dev_dbg ( & intf -> dev , "no<S2SV_blank>interfaces\\n" ) ; return - ENODEV ; } if ( data_interface_num != call_interface_num ) dev_dbg ( & intf -> dev , "Separate<S2SV_blank>call<S2SV_blank>control<S2SV_blank>interface.<S2SV_blank>That<S2SV_blank>is<S2SV_blank>not<S2SV_blank>fully<S2SV_blank>supported.\\n" ) ; if ( control_interface == data_interface ) { dev_warn ( & intf -> dev , "Control<S2SV_blank>and<S2SV_blank>data<S2SV_blank>interfaces<S2SV_blank>are<S2SV_blank>not<S2SV_blank>separated!\\n" ) ; combined_interfaces = 1 ; quirks |= NO_CAP_LINE ; if ( data_interface -> cur_altsetting -> desc . bNumEndpoints != 3 ) { dev_err ( & intf -> dev , "This<S2SV_blank>needs<S2SV_blank>exactly<S2SV_blank>3<S2SV_blank>endpoints\\n" ) ; return - EINVAL ; } look_for_collapsed_interface : for ( i = 0 ; i < 3 ; i ++ ) { struct usb_endpoint_descriptor * ep ; ep = & data_interface -> cur_altsetting -> endpoint [ i ] . desc ; if ( usb_endpoint_is_int_in ( ep ) ) epctrl = ep ; else if ( usb_endpoint_is_bulk_out ( ep ) ) epwrite = ep ; else if ( usb_endpoint_is_bulk_in ( ep ) ) epread = ep ; else return - EINVAL ; } if ( ! epctrl || ! epread || ! epwrite ) return - ENODEV ; else goto made_compressed_probe ; } skip_normal_probe : if ( data_interface -> cur_altsetting -> desc . bInterfaceClass != CDC_DATA_INTERFACE_TYPE ) { if ( control_interface -> cur_altsetting -> desc . bInterfaceClass == CDC_DATA_INTERFACE_TYPE ) { dev_dbg ( & intf -> dev , "Your<S2SV_blank>device<S2SV_blank>has<S2SV_blank>switched<S2SV_blank>interfaces.\\n" ) ; swap ( control_interface , data_interface ) ; } else { return - EINVAL ; } } if ( ! combined_interfaces && intf != control_interface ) return - ENODEV ; if ( ! combined_interfaces && usb_interface_claimed ( data_interface ) ) { dev_dbg ( & intf -> dev , "The<S2SV_blank>data<S2SV_blank>interface<S2SV_blank>isn\'t<S2SV_blank>available\\n" ) ; return - EBUSY ; } if ( data_interface -> cur_altsetting -> desc . bNumEndpoints < 2 || control_interface -> cur_altsetting -> desc . bNumEndpoints == 0 ) return - EINVAL ; epctrl = & control_interface -> cur_altsetting -> endpoint [ 0 ] . desc ; epread = & data_interface -> cur_altsetting -> endpoint [ 0 ] . desc ; epwrite = & data_interface -> cur_altsetting -> endpoint [ 1 ] . desc ; if ( ! usb_endpoint_dir_in ( epread ) ) { dev_dbg ( & intf -> dev , "The<S2SV_blank>data<S2SV_blank>interface<S2SV_blank>has<S2SV_blank>switched<S2SV_blank>endpoints\\n" ) ; swap ( epread , epwrite ) ; } made_compressed_probe : dev_dbg ( & intf -> dev , "interfaces<S2SV_blank>are<S2SV_blank>valid\\n" ) ; acm = kzalloc ( sizeof ( struct acm ) , GFP_KERNEL ) ; if ( acm == NULL ) goto alloc_fail ; minor = acm_alloc_minor ( acm ) ; if ( minor < 0 ) { dev_err ( & intf -> dev , "no<S2SV_blank>more<S2SV_blank>free<S2SV_blank>acm<S2SV_blank>devices\\n" ) ; kfree ( acm ) ; return - ENODEV ; } ctrlsize = usb_endpoint_maxp ( epctrl ) ; readsize = usb_endpoint_maxp ( epread ) * ( quirks == SINGLE_RX_URB ? 1 : 2 ) ; acm -> combined_interfaces = combined_interfaces ; acm -> writesize = usb_endpoint_maxp ( epwrite ) * 20 ; acm -> control = control_interface ; acm -> data = data_interface ; acm -> minor = minor ; acm -> dev = usb_dev ; acm -> ctrl_caps = ac_management_function ; if ( quirks & NO_CAP_LINE ) acm -> ctrl_caps &= ~ USB_CDC_CAP_LINE ; acm -> ctrlsize = ctrlsize ; acm -> readsize = readsize ; acm -> rx_buflimit = num_rx_buf ; INIT_WORK ( & acm -> work , acm_softint ) ; init_waitqueue_head ( & acm -> wioctl ) ; spin_lock_init ( & acm -> write_lock ) ; spin_lock_init ( & acm -> read_lock ) ; mutex_init ( & acm -> mutex ) ; acm -> rx_endpoint = usb_rcvbulkpipe ( usb_dev , epread -> bEndpointAddress ) ; acm -> is_int_ep = usb_endpoint_xfer_int ( epread ) ; if ( acm -> is_int_ep ) acm -> bInterval = epread -> bInterval ; tty_port_init ( & acm -> port ) ; acm -> port . ops = & acm_port_ops ; init_usb_anchor ( & acm -> delayed ) ; acm -> quirks = quirks ; buf = usb_alloc_coherent ( usb_dev , ctrlsize , GFP_KERNEL , & acm -> ctrl_dma ) ; if ( ! buf ) goto alloc_fail2 ; acm -> ctrl_buffer = buf ; if ( acm_write_buffers_alloc ( acm ) < 0 ) goto alloc_fail4 ; acm -> ctrlurb = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! acm -> ctrlurb ) goto alloc_fail5 ; for ( i = 0 ; i < num_rx_buf ; i ++ ) { struct acm_rb * rb = & ( acm -> read_buffers [ i ] ) ; struct urb * urb ; rb -> base = usb_alloc_coherent ( acm -> dev , readsize , GFP_KERNEL , & rb -> dma ) ; if ( ! rb -> base ) goto alloc_fail6 ; rb -> index = i ; rb -> instance = acm ; urb = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! urb ) goto alloc_fail6 ; urb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; urb -> transfer_dma = rb -> dma ; if ( acm -> is_int_ep ) { usb_fill_int_urb ( urb , acm -> dev , acm -> rx_endpoint , rb -> base , acm -> readsize , acm_read_bulk_callback , rb , acm -> bInterval ) ; } else { usb_fill_bulk_urb ( urb , acm -> dev , acm -> rx_endpoint , rb -> base , acm -> readsize , acm_read_bulk_callback , rb ) ; } acm -> read_urbs [ i ] = urb ; __set_bit ( i , & acm -> read_urbs_free ) ; } for ( i = 0 ; i < ACM_NW ; i ++ ) { struct acm_wb * snd = & ( acm -> wb [ i ] ) ; snd -> urb = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( snd -> urb == NULL ) goto alloc_fail7 ; if ( usb_endpoint_xfer_int ( epwrite ) ) usb_fill_int_urb ( snd -> urb , usb_dev , usb_sndintpipe ( usb_dev , epwrite -> bEndpointAddress ) , NULL , acm -> writesize , acm_write_bulk , snd , epwrite -> bInterval ) ; else usb_fill_bulk_urb ( snd -> urb , usb_dev , usb_sndbulkpipe ( usb_dev , epwrite -> bEndpointAddress ) , NULL , acm -> writesize , acm_write_bulk , snd ) ; snd -> urb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; if ( quirks & SEND_ZERO_PACKET ) snd -> urb -> transfer_flags |= URB_ZERO_PACKET ; snd -> instance = acm ; } usb_set_intfdata ( intf , acm ) ; i = device_create_file ( & intf -> dev , & dev_attr_bmCapabilities ) ; if ( i < 0 ) goto alloc_fail7 ; if ( cfd ) { acm -> country_codes = kmalloc ( cfd -> bLength - 4 , GFP_KERNEL ) ; if ( ! acm -> country_codes ) goto skip_countries ; acm -> country_code_size = cfd -> bLength - 4 ; memcpy ( acm -> country_codes , ( u8 * ) & cfd -> wCountyCode0 , cfd -> bLength - 4 ) ; acm -> country_rel_date = cfd -> iCountryCodeRelDate ; i = device_create_file ( & intf -> dev , & dev_attr_wCountryCodes ) ; if ( i < 0 ) { kfree ( acm -> country_codes ) ; acm -> country_codes = NULL ; acm -> country_code_size = 0 ; goto skip_countries ; } i = device_create_file ( & intf -> dev , & dev_attr_iCountryCodeRelDate ) ; if ( i < 0 ) { device_remove_file ( & intf -> dev , & dev_attr_wCountryCodes ) ; kfree ( acm -> country_codes ) ; acm -> country_codes = NULL ; acm -> country_code_size = 0 ; goto skip_countries ; } } skip_countries : usb_fill_int_urb ( acm -> ctrlurb , usb_dev , usb_rcvintpipe ( usb_dev , epctrl -> bEndpointAddress ) , acm -> ctrl_buffer , ctrlsize , acm_ctrl_irq , acm , epctrl -> bInterval ? epctrl -> bInterval : 16 ) ; acm -> ctrlurb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; acm -> ctrlurb -> transfer_dma = acm -> ctrl_dma ; dev_info ( & intf -> dev , "ttyACM%d:<S2SV_blank>USB<S2SV_blank>ACM<S2SV_blank>device\\n" , minor ) ; acm -> line . dwDTERate = cpu_to_le32 ( 9600 ) ; acm -> line . bDataBits = 8 ; acm_set_line ( acm , & acm -> line ) ; usb_driver_claim_interface ( & acm_driver , data_interface , acm ) ; usb_set_intfdata ( data_interface , acm ) ; usb_get_intf ( control_interface ) ; tty_dev = tty_port_register_device ( & acm -> port , acm_tty_driver , minor , & control_interface -> dev ) ; if ( IS_ERR ( tty_dev ) ) { rv = PTR_ERR ( tty_dev ) ; goto alloc_fail8 ; } if ( quirks & CLEAR_HALT_CONDITIONS ) { usb_clear_halt ( usb_dev , usb_rcvbulkpipe ( usb_dev , epread -> bEndpointAddress ) ) ; usb_clear_halt ( usb_dev , usb_sndbulkpipe ( usb_dev , epwrite -> bEndpointAddress ) ) ; } return 0 ; alloc_fail8 : if ( acm -> country_codes ) { device_remove_file ( & acm -> control -> dev , & dev_attr_wCountryCodes ) ; device_remove_file ( & acm -> control -> dev , & dev_attr_iCountryCodeRelDate ) ; kfree ( acm -> country_codes ) ; } device_remove_file ( & acm -> control -> dev , & dev_attr_bmCapabilities ) ; alloc_fail7 : usb_set_intfdata ( intf , NULL ) ; for ( i = 0 ; i < ACM_NW ; i ++ ) usb_free_urb ( acm -> wb [ i ] . urb ) ; alloc_fail6 : for ( i = 0 ; i < num_rx_buf ; i ++ ) usb_free_urb ( acm -> read_urbs [ i ] ) ; acm_read_buffers_free ( acm ) ; usb_free_urb ( acm -> ctrlurb ) ; alloc_fail5 : acm_write_buffers_free ( acm ) ; alloc_fail4 : usb_free_coherent ( usb_dev , ctrlsize , acm -> ctrl_buffer , acm -> ctrl_dma ) ; alloc_fail2 : acm_release_minor ( acm ) ; kfree ( acm ) ; alloc_fail : return rv ; }
CWE-000 static int aiptek_probe ( struct usb_interface * intf , const struct usb_device_id * id ) { struct usb_device * usbdev = interface_to_usbdev ( intf ) ; struct usb_endpoint_descriptor * endpoint ; struct aiptek * aiptek ; struct input_dev * inputdev ; int i ; int speeds [ ] = { 0 , AIPTEK_PROGRAMMABLE_DELAY_50 , AIPTEK_PROGRAMMABLE_DELAY_400 , AIPTEK_PROGRAMMABLE_DELAY_25 , AIPTEK_PROGRAMMABLE_DELAY_100 , AIPTEK_PROGRAMMABLE_DELAY_200 , AIPTEK_PROGRAMMABLE_DELAY_300 } ; int err = - ENOMEM ; speeds [ 0 ] = programmableDelay ; aiptek = kzalloc ( sizeof ( struct aiptek ) , GFP_KERNEL ) ; inputdev = input_allocate_device ( ) ; if ( ! aiptek || ! inputdev ) { dev_warn ( & intf -> dev , "cannot<S2SV_blank>allocate<S2SV_blank>memory<S2SV_blank>or<S2SV_blank>input<S2SV_blank>device\\n" ) ; goto fail1 ; } aiptek -> data = usb_alloc_coherent ( usbdev , AIPTEK_PACKET_LENGTH , GFP_ATOMIC , & aiptek -> data_dma ) ; if ( ! aiptek -> data ) { dev_warn ( & intf -> dev , "cannot<S2SV_blank>allocate<S2SV_blank>usb<S2SV_blank>buffer\\n" ) ; goto fail1 ; } aiptek -> urb = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! aiptek -> urb ) { dev_warn ( & intf -> dev , "cannot<S2SV_blank>allocate<S2SV_blank>urb\\n" ) ; goto fail2 ; } aiptek -> inputdev = inputdev ; aiptek -> usbdev = usbdev ; aiptek -> intf = intf ; aiptek -> ifnum = intf -> altsetting [ 0 ] . desc . bInterfaceNumber ; aiptek -> inDelay = 0 ; aiptek -> endDelay = 0 ; aiptek -> previousJitterable = 0 ; aiptek -> lastMacro = - 1 ; aiptek -> curSetting . pointerMode = AIPTEK_POINTER_EITHER_MODE ; aiptek -> curSetting . coordinateMode = AIPTEK_COORDINATE_ABSOLUTE_MODE ; aiptek -> curSetting . toolMode = AIPTEK_TOOL_BUTTON_PEN_MODE ; aiptek -> curSetting . xTilt = AIPTEK_TILT_DISABLE ; aiptek -> curSetting . yTilt = AIPTEK_TILT_DISABLE ; aiptek -> curSetting . mouseButtonLeft = AIPTEK_MOUSE_LEFT_BUTTON ; aiptek -> curSetting . mouseButtonMiddle = AIPTEK_MOUSE_MIDDLE_BUTTON ; aiptek -> curSetting . mouseButtonRight = AIPTEK_MOUSE_RIGHT_BUTTON ; aiptek -> curSetting . stylusButtonUpper = AIPTEK_STYLUS_UPPER_BUTTON ; aiptek -> curSetting . stylusButtonLower = AIPTEK_STYLUS_LOWER_BUTTON ; aiptek -> curSetting . jitterDelay = jitterDelay ; aiptek -> curSetting . programmableDelay = programmableDelay ; aiptek -> newSetting = aiptek -> curSetting ; usb_make_path ( usbdev , aiptek -> features . usbPath , sizeof ( aiptek -> features . usbPath ) ) ; strlcat ( aiptek -> features . usbPath , "/input0" , sizeof ( aiptek -> features . usbPath ) ) ; inputdev -> name = "Aiptek" ; inputdev -> phys = aiptek -> features . usbPath ; usb_to_input_id ( usbdev , & inputdev -> id ) ; inputdev -> dev . parent = & intf -> dev ; input_set_drvdata ( inputdev , aiptek ) ; inputdev -> open = aiptek_open ; inputdev -> close = aiptek_close ; for ( i = 0 ; i < ARRAY_SIZE ( eventTypes ) ; ++ i ) __set_bit ( eventTypes [ i ] , inputdev -> evbit ) ; for ( i = 0 ; i < ARRAY_SIZE ( absEvents ) ; ++ i ) __set_bit ( absEvents [ i ] , inputdev -> absbit ) ; for ( i = 0 ; i < ARRAY_SIZE ( relEvents ) ; ++ i ) __set_bit ( relEvents [ i ] , inputdev -> relbit ) ; __set_bit ( MSC_SERIAL , inputdev -> mscbit ) ; for ( i = 0 ; i < ARRAY_SIZE ( buttonEvents ) ; ++ i ) __set_bit ( buttonEvents [ i ] , inputdev -> keybit ) ; for ( i = 0 ; i < ARRAY_SIZE ( macroKeyEvents ) ; ++ i ) __set_bit ( macroKeyEvents [ i ] , inputdev -> keybit ) ; input_set_abs_params ( inputdev , ABS_X , 0 , 2999 , 0 , 0 ) ; input_set_abs_params ( inputdev , ABS_Y , 0 , 2249 , 0 , 0 ) ; input_set_abs_params ( inputdev , ABS_PRESSURE , 0 , 511 , 0 , 0 ) ; input_set_abs_params ( inputdev , ABS_TILT_X , AIPTEK_TILT_MIN , AIPTEK_TILT_MAX , 0 , 0 ) ; input_set_abs_params ( inputdev , ABS_TILT_Y , AIPTEK_TILT_MIN , AIPTEK_TILT_MAX , 0 , 0 ) ; input_set_abs_params ( inputdev , ABS_WHEEL , AIPTEK_WHEEL_MIN , AIPTEK_WHEEL_MAX - 1 , 0 , 0 ) ; <S2SV_StartBug> endpoint = & intf -> altsetting [ 0 ] . endpoint [ 0 ] . desc ; <S2SV_EndBug> usb_fill_int_urb ( aiptek -> urb , aiptek -> usbdev , usb_rcvintpipe ( aiptek -> usbdev , endpoint -> bEndpointAddress ) , aiptek -> data , 8 , aiptek_irq , aiptek , endpoint -> bInterval ) ; aiptek -> urb -> transfer_dma = aiptek -> data_dma ; aiptek -> urb -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; for ( i = 0 ; i < ARRAY_SIZE ( speeds ) ; ++ i ) { aiptek -> curSetting . programmableDelay = speeds [ i ] ; ( void ) aiptek_program_tablet ( aiptek ) ; if ( input_abs_get_max ( aiptek -> inputdev , ABS_X ) > 0 ) { dev_info ( & intf -> dev , "Aiptek<S2SV_blank>using<S2SV_blank>%d<S2SV_blank>ms<S2SV_blank>programming<S2SV_blank>speed\\n" , aiptek -> curSetting . programmableDelay ) ; break ; } } if ( i == ARRAY_SIZE ( speeds ) ) { dev_info ( & intf -> dev , "Aiptek<S2SV_blank>tried<S2SV_blank>all<S2SV_blank>speeds,<S2SV_blank>no<S2SV_blank>sane<S2SV_blank>response\\n" ) ; <S2SV_StartBug> goto fail3 ; <S2SV_EndBug> } usb_set_intfdata ( intf , aiptek ) ; err = sysfs_create_group ( & intf -> dev . kobj , & aiptek_attribute_group ) ; if ( err ) { dev_warn ( & intf -> dev , "cannot<S2SV_blank>create<S2SV_blank>sysfs<S2SV_blank>group<S2SV_blank>err:<S2SV_blank>%d\\n" , err ) ; goto fail3 ; } err = input_register_device ( aiptek -> inputdev ) ; if ( err ) { dev_warn ( & intf -> dev , "input_register_device<S2SV_blank>returned<S2SV_blank>err:<S2SV_blank>%d\\n" , err ) ; goto fail4 ; } return 0 ; fail4 : sysfs_remove_group ( & intf -> dev . kobj , & aiptek_attribute_group ) ; fail3 : usb_free_urb ( aiptek -> urb ) ; fail2 : usb_free_coherent ( usbdev , AIPTEK_PACKET_LENGTH , aiptek -> data , aiptek -> data_dma ) ; fail1 : usb_set_intfdata ( intf , NULL ) ; input_free_device ( inputdev ) ; kfree ( aiptek ) ; return err ; }
CWE-000 static void * bpf_any_get ( void * raw , enum bpf_type type ) { switch ( type ) { case BPF_TYPE_PROG : <S2SV_StartBug> atomic_inc ( & ( ( struct bpf_prog * ) raw ) -> aux -> refcnt ) ; <S2SV_EndBug> break ; case BPF_TYPE_MAP : <S2SV_StartBug> bpf_map_inc ( raw , true ) ; <S2SV_EndBug> break ; default : WARN_ON_ONCE ( 1 ) ; break ; } return raw ; }
CWE-000 static void * bpf_obj_do_get ( const struct filename * pathname , enum bpf_type * type ) { struct inode * inode ; struct path path ; void * raw ; int ret ; ret = kern_path ( pathname -> name , LOOKUP_FOLLOW , & path ) ; if ( ret ) return ERR_PTR ( ret ) ; inode = d_backing_inode ( path . dentry ) ; ret = inode_permission ( inode , MAY_WRITE ) ; if ( ret ) goto out ; ret = bpf_inode_type ( inode , type ) ; if ( ret ) goto out ; raw = bpf_any_get ( inode -> i_private , * type ) ; <S2SV_StartBug> touch_atime ( & path ) ; <S2SV_EndBug> path_put ( & path ) ; return raw ; out : path_put ( & path ) ; return ERR_PTR ( ret ) ; }
CWE-000 struct bpf_map * bpf_map_get_with_uref ( u32 ufd ) { struct fd f = fdget ( ufd ) ; struct bpf_map * map ; map = __bpf_map_get ( f ) ; if ( IS_ERR ( map ) ) return map ; <S2SV_StartBug> bpf_map_inc ( map , true ) ; <S2SV_EndBug> fdput ( f ) ; return map ; }
CWE-000 <S2SV_StartBug> void bpf_map_inc ( struct bpf_map * map , bool uref ) <S2SV_EndBug> { <S2SV_StartBug> atomic_inc ( & map -> refcnt ) ; <S2SV_EndBug> if ( uref ) atomic_inc ( & map -> usercnt ) ; <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 struct bpf_prog * bpf_prog_get ( u32 ufd ) { struct fd f = fdget ( ufd ) ; struct bpf_prog * prog ; prog = __bpf_prog_get ( f ) ; if ( IS_ERR ( prog ) ) return prog ; <S2SV_StartBug> atomic_inc ( & prog -> aux -> refcnt ) ; <S2SV_EndBug> fdput ( f ) ; return prog ; }
CWE-000 static int replace_map_fd_with_map_ptr ( struct verifier_env * env ) { struct bpf_insn * insn = env -> prog -> insnsi ; int insn_cnt = env -> prog -> len ; int i , j ; for ( i = 0 ; i < insn_cnt ; i ++ , insn ++ ) { if ( BPF_CLASS ( insn -> code ) == BPF_LDX && ( BPF_MODE ( insn -> code ) != BPF_MEM || insn -> imm != 0 ) ) { verbose ( "BPF_LDX<S2SV_blank>uses<S2SV_blank>reserved<S2SV_blank>fields\\n" ) ; return - EINVAL ; } if ( BPF_CLASS ( insn -> code ) == BPF_STX && ( ( BPF_MODE ( insn -> code ) != BPF_MEM && BPF_MODE ( insn -> code ) != BPF_XADD ) || insn -> imm != 0 ) ) { verbose ( "BPF_STX<S2SV_blank>uses<S2SV_blank>reserved<S2SV_blank>fields\\n" ) ; return - EINVAL ; } if ( insn [ 0 ] . code == ( BPF_LD | BPF_IMM | BPF_DW ) ) { struct bpf_map * map ; struct fd f ; if ( i == insn_cnt - 1 || insn [ 1 ] . code != 0 || insn [ 1 ] . dst_reg != 0 || insn [ 1 ] . src_reg != 0 || insn [ 1 ] . off != 0 ) { verbose ( "invalid<S2SV_blank>bpf_ld_imm64<S2SV_blank>insn\\n" ) ; return - EINVAL ; } if ( insn -> src_reg == 0 ) goto next_insn ; if ( insn -> src_reg != BPF_PSEUDO_MAP_FD ) { verbose ( "unrecognized<S2SV_blank>bpf_ld_imm64<S2SV_blank>insn\\n" ) ; return - EINVAL ; } f = fdget ( insn -> imm ) ; map = __bpf_map_get ( f ) ; if ( IS_ERR ( map ) ) { verbose ( "fd<S2SV_blank>%d<S2SV_blank>is<S2SV_blank>not<S2SV_blank>pointing<S2SV_blank>to<S2SV_blank>valid<S2SV_blank>bpf_map\\n" , insn -> imm ) ; return PTR_ERR ( map ) ; } insn [ 0 ] . imm = ( u32 ) ( unsigned long ) map ; insn [ 1 ] . imm = ( ( u64 ) ( unsigned long ) map ) >> 32 ; for ( j = 0 ; j < env -> used_map_cnt ; j ++ ) if ( env -> used_maps [ j ] == map ) { fdput ( f ) ; goto next_insn ; } if ( env -> used_map_cnt >= MAX_USED_MAPS ) { fdput ( f ) ; return - E2BIG ; } <S2SV_StartBug> env -> used_maps [ env -> used_map_cnt ++ ] = map ; <S2SV_EndBug> <S2SV_StartBug> bpf_map_inc ( map , false ) ; <S2SV_EndBug> fdput ( f ) ; next_insn : insn ++ ; i ++ ; } } return 0 ; }
CWE-000 unsigned int nf_nat_redirect_ipv4 ( struct sk_buff * skb , const struct nf_nat_ipv4_multi_range_compat * mr , unsigned int hooknum ) { struct nf_conn * ct ; enum ip_conntrack_info ctinfo ; __be32 newdst ; struct nf_nat_range newrange ; NF_CT_ASSERT ( hooknum == NF_INET_PRE_ROUTING || hooknum == NF_INET_LOCAL_OUT ) ; ct = nf_ct_get ( skb , & ctinfo ) ; NF_CT_ASSERT ( ct && ( ctinfo == IP_CT_NEW || ctinfo == IP_CT_RELATED ) ) ; if ( hooknum == NF_INET_LOCAL_OUT ) { newdst = htonl ( 0x7F000001 ) ; } else { struct in_device * indev ; struct in_ifaddr * ifa ; newdst = 0 ; rcu_read_lock ( ) ; indev = __in_dev_get_rcu ( skb -> dev ) ; <S2SV_StartBug> if ( indev != NULL ) { <S2SV_EndBug> ifa = indev -> ifa_list ; newdst = ifa -> ifa_local ; } rcu_read_unlock ( ) ; if ( ! newdst ) return NF_DROP ; } memset ( & newrange . min_addr , 0 , sizeof ( newrange . min_addr ) ) ; memset ( & newrange . max_addr , 0 , sizeof ( newrange . max_addr ) ) ; newrange . flags = mr -> range [ 0 ] . flags | NF_NAT_RANGE_MAP_IPS ; newrange . min_addr . ip = newdst ; newrange . max_addr . ip = newdst ; newrange . min_proto = mr -> range [ 0 ] . min ; newrange . max_proto = mr -> range [ 0 ] . max ; return nf_nat_setup_info ( ct , & newrange , NF_NAT_MANIP_DST ) ; }
CWE-000 static int ati_remote2_probe ( struct usb_interface * interface , const struct usb_device_id * id ) { struct usb_device * udev = interface_to_usbdev ( interface ) ; struct usb_host_interface * alt = interface -> cur_altsetting ; struct ati_remote2 * ar2 ; int r ; if ( alt -> desc . bInterfaceNumber ) return - ENODEV ; ar2 = kzalloc ( sizeof ( struct ati_remote2 ) , GFP_KERNEL ) ; if ( ! ar2 ) return - ENOMEM ; ar2 -> udev = udev ; <S2SV_StartBug> ar2 -> intf [ 0 ] = interface ; <S2SV_EndBug> ar2 -> ep [ 0 ] = & alt -> endpoint [ 0 ] . desc ; ar2 -> intf [ 1 ] = usb_ifnum_to_if ( udev , 1 ) ; <S2SV_StartBug> r = usb_driver_claim_interface ( & ati_remote2_driver , ar2 -> intf [ 1 ] , ar2 ) ; <S2SV_EndBug> if ( r ) goto fail1 ; alt = ar2 -> intf [ 1 ] -> cur_altsetting ; <S2SV_StartBug> ar2 -> ep [ 1 ] = & alt -> endpoint [ 0 ] . desc ; <S2SV_EndBug> r = ati_remote2_urb_init ( ar2 ) ; if ( r ) <S2SV_StartBug> goto fail2 ; <S2SV_EndBug> ar2 -> channel_mask = channel_mask ; ar2 -> mode_mask = mode_mask ; r = ati_remote2_setup ( ar2 , ar2 -> channel_mask ) ; if ( r ) <S2SV_StartBug> goto fail2 ; <S2SV_EndBug> usb_make_path ( udev , ar2 -> phys , sizeof ( ar2 -> phys ) ) ; strlcat ( ar2 -> phys , "/input0" , sizeof ( ar2 -> phys ) ) ; strlcat ( ar2 -> name , "ATI<S2SV_blank>Remote<S2SV_blank>Wonder<S2SV_blank>II" , sizeof ( ar2 -> name ) ) ; r = sysfs_create_group ( & udev -> dev . kobj , & ati_remote2_attr_group ) ; if ( r ) <S2SV_StartBug> goto fail2 ; <S2SV_EndBug> r = ati_remote2_input_init ( ar2 ) ; if ( r ) <S2SV_StartBug> goto fail3 ; <S2SV_EndBug> usb_set_intfdata ( interface , ar2 ) ; interface -> needs_remote_wakeup = 1 ; return 0 ; <S2SV_StartBug> fail3 : <S2SV_EndBug> sysfs_remove_group ( & udev -> dev . kobj , & ati_remote2_attr_group ) ; fail2 : <S2SV_StartBug> ati_remote2_urb_cleanup ( ar2 ) ; <S2SV_EndBug> usb_driver_release_interface ( & ati_remote2_driver , ar2 -> intf [ 1 ] ) ; fail1 : kfree ( ar2 ) ; return r ; }
CWE-000 int assoc_array_gc ( struct assoc_array * array , const struct assoc_array_ops * ops , bool ( * iterator ) ( void * object , void * iterator_data ) , void * iterator_data ) { struct assoc_array_shortcut * shortcut , * new_s ; struct assoc_array_node * node , * new_n ; struct assoc_array_edit * edit ; struct assoc_array_ptr * cursor , * ptr ; struct assoc_array_ptr * new_root , * new_parent , * * new_ptr_pp ; unsigned long nr_leaves_on_tree ; int keylen , slot , nr_free , next_slot , i ; pr_devel ( "-->%s()\\n" , __func__ ) ; if ( ! array -> root ) return 0 ; edit = kzalloc ( sizeof ( struct assoc_array_edit ) , GFP_KERNEL ) ; if ( ! edit ) return - ENOMEM ; edit -> array = array ; edit -> ops = ops ; edit -> ops_for_excised_subtree = ops ; edit -> set [ 0 ] . ptr = & array -> root ; edit -> excised_subtree = array -> root ; new_root = new_parent = NULL ; new_ptr_pp = & new_root ; cursor = array -> root ; descend : if ( assoc_array_ptr_is_shortcut ( cursor ) ) { shortcut = assoc_array_ptr_to_shortcut ( cursor ) ; keylen = round_up ( shortcut -> skip_to_level , ASSOC_ARRAY_KEY_CHUNK_SIZE ) ; keylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT ; new_s = kmalloc ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) , GFP_KERNEL ) ; if ( ! new_s ) goto enomem ; pr_devel ( "dup<S2SV_blank>shortcut<S2SV_blank>%p<S2SV_blank>-><S2SV_blank>%p\\n" , shortcut , new_s ) ; memcpy ( new_s , shortcut , ( sizeof ( struct assoc_array_shortcut ) + keylen * sizeof ( unsigned long ) ) ) ; new_s -> back_pointer = new_parent ; new_s -> parent_slot = shortcut -> parent_slot ; * new_ptr_pp = new_parent = assoc_array_shortcut_to_ptr ( new_s ) ; new_ptr_pp = & new_s -> next_node ; cursor = shortcut -> next_node ; } node = assoc_array_ptr_to_node ( cursor ) ; new_n = kzalloc ( sizeof ( struct assoc_array_node ) , GFP_KERNEL ) ; if ( ! new_n ) goto enomem ; pr_devel ( "dup<S2SV_blank>node<S2SV_blank>%p<S2SV_blank>-><S2SV_blank>%p\\n" , node , new_n ) ; new_n -> back_pointer = new_parent ; new_n -> parent_slot = node -> parent_slot ; * new_ptr_pp = new_parent = assoc_array_node_to_ptr ( new_n ) ; new_ptr_pp = NULL ; slot = 0 ; continue_node : for ( ; slot < ASSOC_ARRAY_FAN_OUT ; slot ++ ) { ptr = node -> slots [ slot ] ; if ( ! ptr ) continue ; if ( assoc_array_ptr_is_leaf ( ptr ) ) { if ( iterator ( assoc_array_ptr_to_leaf ( ptr ) , iterator_data ) ) new_n -> slots [ slot ] = ptr ; continue ; } new_ptr_pp = & new_n -> slots [ slot ] ; cursor = ptr ; goto descend ; } pr_devel ( "--<S2SV_blank>compress<S2SV_blank>node<S2SV_blank>%p<S2SV_blank>--\\n" , new_n ) ; new_n -> nr_leaves_on_branch = 0 ; nr_free = 0 ; for ( slot = 0 ; slot < ASSOC_ARRAY_FAN_OUT ; slot ++ ) { ptr = new_n -> slots [ slot ] ; if ( ! ptr ) nr_free ++ ; else if ( assoc_array_ptr_is_leaf ( ptr ) ) new_n -> nr_leaves_on_branch ++ ; } pr_devel ( "free=%d,<S2SV_blank>leaves=%lu\\n" , nr_free , new_n -> nr_leaves_on_branch ) ; next_slot = 0 ; for ( slot = 0 ; slot < ASSOC_ARRAY_FAN_OUT ; slot ++ ) { struct assoc_array_shortcut * s ; struct assoc_array_node * child ; ptr = new_n -> slots [ slot ] ; if ( ! ptr || assoc_array_ptr_is_leaf ( ptr ) ) continue ; s = NULL ; if ( assoc_array_ptr_is_shortcut ( ptr ) ) { s = assoc_array_ptr_to_shortcut ( ptr ) ; ptr = s -> next_node ; } child = assoc_array_ptr_to_node ( ptr ) ; new_n -> nr_leaves_on_branch += child -> nr_leaves_on_branch ; if ( child -> nr_leaves_on_branch <= nr_free + 1 ) { pr_devel ( "[%d]<S2SV_blank>fold<S2SV_blank>node<S2SV_blank>%lu/%d<S2SV_blank>[nx<S2SV_blank>%d]\\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ) ; BUG_ON ( s ) ; new_n -> slots [ slot ] = NULL ; nr_free ++ ; if ( slot < next_slot ) next_slot = slot ; for ( i = 0 ; i < ASSOC_ARRAY_FAN_OUT ; i ++ ) { struct assoc_array_ptr * p = child -> slots [ i ] ; if ( ! p ) continue ; BUG_ON ( assoc_array_ptr_is_meta ( p ) ) ; while ( new_n -> slots [ next_slot ] ) next_slot ++ ; BUG_ON ( next_slot >= ASSOC_ARRAY_FAN_OUT ) ; new_n -> slots [ next_slot ++ ] = p ; nr_free -- ; } kfree ( child ) ; } else { pr_devel ( "[%d]<S2SV_blank>retain<S2SV_blank>node<S2SV_blank>%lu/%d<S2SV_blank>[nx<S2SV_blank>%d]\\n" , slot , child -> nr_leaves_on_branch , nr_free + 1 , next_slot ) ; } } pr_devel ( "after:<S2SV_blank>%lu\\n" , new_n -> nr_leaves_on_branch ) ; nr_leaves_on_tree = new_n -> nr_leaves_on_branch ; if ( nr_free == ASSOC_ARRAY_FAN_OUT - 1 ) { for ( slot = 0 ; slot < ASSOC_ARRAY_FAN_OUT ; slot ++ ) if ( ( ptr = new_n -> slots [ slot ] ) ) break ; if ( assoc_array_ptr_is_meta ( ptr ) && assoc_array_ptr_is_shortcut ( ptr ) ) { pr_devel ( "excise<S2SV_blank>node<S2SV_blank>%p<S2SV_blank>with<S2SV_blank>1<S2SV_blank>shortcut\\n" , new_n ) ; new_s = assoc_array_ptr_to_shortcut ( ptr ) ; new_parent = new_n -> back_pointer ; slot = new_n -> parent_slot ; kfree ( new_n ) ; if ( ! new_parent ) { new_s -> back_pointer = NULL ; new_s -> parent_slot = 0 ; new_root = ptr ; goto gc_complete ; } if ( assoc_array_ptr_is_shortcut ( new_parent ) ) { struct assoc_array_shortcut * s = assoc_array_ptr_to_shortcut ( new_parent ) ; pr_devel ( "excise<S2SV_blank>preceding<S2SV_blank>shortcut\\n" ) ; new_parent = new_s -> back_pointer = s -> back_pointer ; slot = new_s -> parent_slot = s -> parent_slot ; kfree ( s ) ; if ( ! new_parent ) { new_s -> back_pointer = NULL ; new_s -> parent_slot = 0 ; new_root = ptr ; goto gc_complete ; } } new_s -> back_pointer = new_parent ; new_s -> parent_slot = slot ; new_n = assoc_array_ptr_to_node ( new_parent ) ; new_n -> slots [ slot ] = ptr ; goto ascend_old_tree ; } } ptr = new_n -> back_pointer ; if ( ! ptr ) goto gc_complete ; if ( assoc_array_ptr_is_shortcut ( ptr ) ) { new_s = assoc_array_ptr_to_shortcut ( ptr ) ; new_parent = new_s -> back_pointer ; slot = new_s -> parent_slot ; if ( new_n -> nr_leaves_on_branch <= ASSOC_ARRAY_FAN_OUT ) { struct assoc_array_node * n ; pr_devel ( "excise<S2SV_blank>shortcut\\n" ) ; new_n -> back_pointer = new_parent ; new_n -> parent_slot = slot ; kfree ( new_s ) ; if ( ! new_parent ) { new_root = assoc_array_node_to_ptr ( new_n ) ; goto gc_complete ; } n = assoc_array_ptr_to_node ( new_parent ) ; n -> slots [ slot ] = assoc_array_node_to_ptr ( new_n ) ; } } else { new_parent = ptr ; } new_n = assoc_array_ptr_to_node ( new_parent ) ; ascend_old_tree : ptr = node -> back_pointer ; if ( assoc_array_ptr_is_shortcut ( ptr ) ) { shortcut = assoc_array_ptr_to_shortcut ( ptr ) ; slot = shortcut -> parent_slot ; cursor = shortcut -> back_pointer ; <S2SV_StartBug> } else { <S2SV_EndBug> slot = node -> parent_slot ; cursor = ptr ; } <S2SV_StartBug> BUG_ON ( ! ptr ) ; <S2SV_EndBug> node = assoc_array_ptr_to_node ( cursor ) ; slot ++ ; goto continue_node ; gc_complete : edit -> set [ 0 ] . to = new_root ; assoc_array_apply_edit ( edit ) ; array -> nr_leaves_on_tree = nr_leaves_on_tree ; return 0 ; enomem : pr_devel ( "enomem\\n" ) ; assoc_array_destroy_subtree ( new_root , edit -> ops ) ; kfree ( edit ) ; return - ENOMEM ; }
CWE-000 int main ( void ) { int fd , len , sock_opt ; int error ; struct cn_msg * message ; struct pollfd pfd ; struct nlmsghdr * incoming_msg ; struct cn_msg * incoming_cn_msg ; struct hv_kvp_msg * hv_msg ; char * p ; char * key_value ; char * key_name ; int op ; int pool ; char * if_name ; struct hv_kvp_ipaddr_value * kvp_ip_val ; daemon ( 1 , 0 ) ; openlog ( "KVP" , 0 , LOG_USER ) ; syslog ( LOG_INFO , "KVP<S2SV_blank>starting;<S2SV_blank>pid<S2SV_blank>is:%d" , getpid ( ) ) ; kvp_get_os_info ( ) ; if ( kvp_file_init ( ) ) { syslog ( LOG_ERR , "Failed<S2SV_blank>to<S2SV_blank>initialize<S2SV_blank>the<S2SV_blank>pools" ) ; exit ( EXIT_FAILURE ) ; } fd = socket ( AF_NETLINK , SOCK_DGRAM , NETLINK_CONNECTOR ) ; if ( fd < 0 ) { syslog ( LOG_ERR , "netlink<S2SV_blank>socket<S2SV_blank>creation<S2SV_blank>failed;<S2SV_blank>error:%d" , fd ) ; exit ( EXIT_FAILURE ) ; } addr . nl_family = AF_NETLINK ; addr . nl_pad = 0 ; addr . nl_pid = 0 ; addr . nl_groups = CN_KVP_IDX ; error = bind ( fd , ( struct sockaddr * ) & addr , sizeof ( addr ) ) ; if ( error < 0 ) { syslog ( LOG_ERR , "bind<S2SV_blank>failed;<S2SV_blank>error:%d" , error ) ; close ( fd ) ; exit ( EXIT_FAILURE ) ; } sock_opt = addr . nl_groups ; setsockopt ( fd , 270 , 1 , & sock_opt , sizeof ( sock_opt ) ) ; message = ( struct cn_msg * ) kvp_send_buffer ; message -> id . idx = CN_KVP_IDX ; message -> id . val = CN_KVP_VAL ; hv_msg = ( struct hv_kvp_msg * ) message -> data ; hv_msg -> kvp_hdr . operation = KVP_OP_REGISTER1 ; message -> ack = 0 ; message -> len = sizeof ( struct hv_kvp_msg ) ; len = netlink_send ( fd , message ) ; if ( len < 0 ) { syslog ( LOG_ERR , "netlink_send<S2SV_blank>failed;<S2SV_blank>error:%d" , len ) ; close ( fd ) ; exit ( EXIT_FAILURE ) ; } pfd . fd = fd ; while ( 1 ) { struct sockaddr * addr_p = ( struct sockaddr * ) & addr ; socklen_t addr_l = sizeof ( addr ) ; pfd . events = POLLIN ; pfd . revents = 0 ; poll ( & pfd , 1 , - 1 ) ; len = recvfrom ( fd , kvp_recv_buffer , sizeof ( kvp_recv_buffer ) , 0 , addr_p , & addr_l ) ; <S2SV_StartBug> if ( len < 0 || addr . nl_pid ) { <S2SV_EndBug> syslog ( LOG_ERR , "recvfrom<S2SV_blank>failed;<S2SV_blank>pid:%u<S2SV_blank>error:%d<S2SV_blank>%s" , addr . nl_pid , errno , strerror ( errno ) ) ; close ( fd ) ; return - 1 ; } <S2SV_StartBug> incoming_msg = ( struct nlmsghdr * ) kvp_recv_buffer ; <S2SV_EndBug> incoming_cn_msg = ( struct cn_msg * ) NLMSG_DATA ( incoming_msg ) ; hv_msg = ( struct hv_kvp_msg * ) incoming_cn_msg -> data ; op = hv_msg -> kvp_hdr . operation ; pool = hv_msg -> kvp_hdr . pool ; hv_msg -> error = HV_S_OK ; if ( ( in_hand_shake ) && ( op == KVP_OP_REGISTER1 ) ) { in_hand_shake = 0 ; p = ( char * ) hv_msg -> body . kvp_register . version ; lic_version = malloc ( strlen ( p ) + 1 ) ; if ( lic_version ) { strcpy ( lic_version , p ) ; syslog ( LOG_INFO , "KVP<S2SV_blank>LIC<S2SV_blank>Version:<S2SV_blank>%s" , lic_version ) ; } else { syslog ( LOG_ERR , "malloc<S2SV_blank>failed" ) ; } continue ; } switch ( op ) { case KVP_OP_GET_IP_INFO : kvp_ip_val = & hv_msg -> body . kvp_ip_val ; if_name = kvp_mac_to_if_name ( ( char * ) kvp_ip_val -> adapter_id ) ; if ( if_name == NULL ) { hv_msg -> error = HV_E_FAIL ; break ; } error = kvp_get_ip_info ( 0 , if_name , KVP_OP_GET_IP_INFO , kvp_ip_val , ( MAX_IP_ADDR_SIZE * 2 ) ) ; if ( error ) hv_msg -> error = error ; free ( if_name ) ; break ; case KVP_OP_SET_IP_INFO : kvp_ip_val = & hv_msg -> body . kvp_ip_val ; if_name = kvp_get_if_name ( ( char * ) kvp_ip_val -> adapter_id ) ; if ( if_name == NULL ) { hv_msg -> error = HV_GUID_NOTFOUND ; break ; } error = kvp_set_ip_info ( if_name , kvp_ip_val ) ; if ( error ) hv_msg -> error = error ; free ( if_name ) ; break ; case KVP_OP_SET : if ( kvp_key_add_or_modify ( pool , hv_msg -> body . kvp_set . data . key , hv_msg -> body . kvp_set . data . key_size , hv_msg -> body . kvp_set . data . value , hv_msg -> body . kvp_set . data . value_size ) ) hv_msg -> error = HV_S_CONT ; break ; case KVP_OP_GET : if ( kvp_get_value ( pool , hv_msg -> body . kvp_set . data . key , hv_msg -> body . kvp_set . data . key_size , hv_msg -> body . kvp_set . data . value , hv_msg -> body . kvp_set . data . value_size ) ) hv_msg -> error = HV_S_CONT ; break ; case KVP_OP_DELETE : if ( kvp_key_delete ( pool , hv_msg -> body . kvp_delete . key , hv_msg -> body . kvp_delete . key_size ) ) hv_msg -> error = HV_S_CONT ; break ; default : break ; } if ( op != KVP_OP_ENUMERATE ) goto kvp_done ; if ( pool != KVP_POOL_AUTO ) { if ( kvp_pool_enumerate ( pool , hv_msg -> body . kvp_enum_data . index , hv_msg -> body . kvp_enum_data . data . key , HV_KVP_EXCHANGE_MAX_KEY_SIZE , hv_msg -> body . kvp_enum_data . data . value , HV_KVP_EXCHANGE_MAX_VALUE_SIZE ) ) hv_msg -> error = HV_S_CONT ; goto kvp_done ; } hv_msg = ( struct hv_kvp_msg * ) incoming_cn_msg -> data ; key_name = ( char * ) hv_msg -> body . kvp_enum_data . data . key ; key_value = ( char * ) hv_msg -> body . kvp_enum_data . data . value ; switch ( hv_msg -> body . kvp_enum_data . index ) { case FullyQualifiedDomainName : kvp_get_domain_name ( key_value , HV_KVP_EXCHANGE_MAX_VALUE_SIZE ) ; strcpy ( key_name , "FullyQualifiedDomainName" ) ; break ; case IntegrationServicesVersion : strcpy ( key_name , "IntegrationServicesVersion" ) ; strcpy ( key_value , lic_version ) ; break ; case NetworkAddressIPv4 : kvp_get_ip_info ( AF_INET , NULL , KVP_OP_ENUMERATE , key_value , HV_KVP_EXCHANGE_MAX_VALUE_SIZE ) ; strcpy ( key_name , "NetworkAddressIPv4" ) ; break ; case NetworkAddressIPv6 : kvp_get_ip_info ( AF_INET6 , NULL , KVP_OP_ENUMERATE , key_value , HV_KVP_EXCHANGE_MAX_VALUE_SIZE ) ; strcpy ( key_name , "NetworkAddressIPv6" ) ; break ; case OSBuildNumber : strcpy ( key_value , os_build ) ; strcpy ( key_name , "OSBuildNumber" ) ; break ; case OSName : strcpy ( key_value , os_name ) ; strcpy ( key_name , "OSName" ) ; break ; case OSMajorVersion : strcpy ( key_value , os_major ) ; strcpy ( key_name , "OSMajorVersion" ) ; break ; case OSMinorVersion : strcpy ( key_value , os_minor ) ; strcpy ( key_name , "OSMinorVersion" ) ; break ; case OSVersion : strcpy ( key_value , os_version ) ; strcpy ( key_name , "OSVersion" ) ; break ; case ProcessorArchitecture : strcpy ( key_value , processor_arch ) ; strcpy ( key_name , "ProcessorArchitecture" ) ; break ; default : hv_msg -> error = HV_S_CONT ; break ; } kvp_done : incoming_cn_msg -> id . idx = CN_KVP_IDX ; incoming_cn_msg -> id . val = CN_KVP_VAL ; incoming_cn_msg -> ack = 0 ; incoming_cn_msg -> len = sizeof ( struct hv_kvp_msg ) ; len = netlink_send ( fd , incoming_cn_msg ) ; if ( len < 0 ) { syslog ( LOG_ERR , "net_link<S2SV_blank>send<S2SV_blank>failed;<S2SV_blank>error:%d" , len ) ; exit ( EXIT_FAILURE ) ; } } }
CWE-000 asmlinkage void bad_mode ( struct pt_regs * regs , int reason , unsigned int esr ) <S2SV_StartBug> { <S2SV_EndBug> console_verbose ( ) ; pr_crit ( "Bad<S2SV_blank>mode<S2SV_blank>in<S2SV_blank>%s<S2SV_blank>handler<S2SV_blank>detected,<S2SV_blank>code<S2SV_blank>0x%08x\\n" , handler [ reason ] , esr ) ; <S2SV_StartBug> die ( "Oops<S2SV_blank>-<S2SV_blank>bad<S2SV_blank>mode" , regs , 0 ) ; <S2SV_EndBug> local_irq_disable ( ) ; panic ( "bad<S2SV_blank>mode" ) ; }
CWE-000 static int powermate_probe ( struct usb_interface * intf , const struct usb_device_id * id ) { struct usb_device * udev = interface_to_usbdev ( intf ) ; struct usb_host_interface * interface ; struct usb_endpoint_descriptor * endpoint ; struct powermate_device * pm ; struct input_dev * input_dev ; int pipe , maxp ; int error = - ENOMEM ; <S2SV_StartBug> interface = intf -> cur_altsetting ; <S2SV_EndBug> endpoint = & interface -> endpoint [ 0 ] . desc ; if ( ! usb_endpoint_is_int_in ( endpoint ) ) return - EIO ; usb_control_msg ( udev , usb_sndctrlpipe ( udev , 0 ) , 0x0a , USB_TYPE_CLASS | USB_RECIP_INTERFACE , 0 , interface -> desc . bInterfaceNumber , NULL , 0 , USB_CTRL_SET_TIMEOUT ) ; pm = kzalloc ( sizeof ( struct powermate_device ) , GFP_KERNEL ) ; input_dev = input_allocate_device ( ) ; if ( ! pm || ! input_dev ) goto fail1 ; if ( powermate_alloc_buffers ( udev , pm ) ) goto fail2 ; pm -> irq = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! pm -> irq ) goto fail2 ; pm -> config = usb_alloc_urb ( 0 , GFP_KERNEL ) ; if ( ! pm -> config ) goto fail3 ; pm -> udev = udev ; pm -> intf = intf ; pm -> input = input_dev ; usb_make_path ( udev , pm -> phys , sizeof ( pm -> phys ) ) ; strlcat ( pm -> phys , "/input0" , sizeof ( pm -> phys ) ) ; spin_lock_init ( & pm -> lock ) ; switch ( le16_to_cpu ( udev -> descriptor . idProduct ) ) { case POWERMATE_PRODUCT_NEW : input_dev -> name = pm_name_powermate ; break ; case POWERMATE_PRODUCT_OLD : input_dev -> name = pm_name_soundknob ; break ; default : input_dev -> name = pm_name_soundknob ; printk ( KERN_WARNING "powermate:<S2SV_blank>unknown<S2SV_blank>product<S2SV_blank>id<S2SV_blank>%04x\\n" , le16_to_cpu ( udev -> descriptor . idProduct ) ) ; } input_dev -> phys = pm -> phys ; usb_to_input_id ( udev , & input_dev -> id ) ; input_dev -> dev . parent = & intf -> dev ; input_set_drvdata ( input_dev , pm ) ; input_dev -> event = powermate_input_event ; input_dev -> evbit [ 0 ] = BIT_MASK ( EV_KEY ) | BIT_MASK ( EV_REL ) | BIT_MASK ( EV_MSC ) ; input_dev -> keybit [ BIT_WORD ( BTN_0 ) ] = BIT_MASK ( BTN_0 ) ; input_dev -> relbit [ BIT_WORD ( REL_DIAL ) ] = BIT_MASK ( REL_DIAL ) ; input_dev -> mscbit [ BIT_WORD ( MSC_PULSELED ) ] = BIT_MASK ( MSC_PULSELED ) ; pipe = usb_rcvintpipe ( udev , endpoint -> bEndpointAddress ) ; maxp = usb_maxpacket ( udev , pipe , usb_pipeout ( pipe ) ) ; if ( maxp < POWERMATE_PAYLOAD_SIZE_MIN || maxp > POWERMATE_PAYLOAD_SIZE_MAX ) { printk ( KERN_WARNING "powermate:<S2SV_blank>Expected<S2SV_blank>payload<S2SV_blank>of<S2SV_blank>%d--%d<S2SV_blank>bytes,<S2SV_blank>found<S2SV_blank>%d<S2SV_blank>bytes!\\n" , POWERMATE_PAYLOAD_SIZE_MIN , POWERMATE_PAYLOAD_SIZE_MAX , maxp ) ; maxp = POWERMATE_PAYLOAD_SIZE_MAX ; } usb_fill_int_urb ( pm -> irq , udev , pipe , pm -> data , maxp , powermate_irq , pm , endpoint -> bInterval ) ; pm -> irq -> transfer_dma = pm -> data_dma ; pm -> irq -> transfer_flags |= URB_NO_TRANSFER_DMA_MAP ; if ( usb_submit_urb ( pm -> irq , GFP_KERNEL ) ) { error = - EIO ; goto fail4 ; } error = input_register_device ( pm -> input ) ; if ( error ) goto fail5 ; pm -> requires_update = UPDATE_PULSE_ASLEEP | UPDATE_PULSE_AWAKE | UPDATE_PULSE_MODE | UPDATE_STATIC_BRIGHTNESS ; powermate_pulse_led ( pm , 0x80 , 255 , 0 , 1 , 0 ) ; usb_set_intfdata ( intf , pm ) ; return 0 ; fail5 : usb_kill_urb ( pm -> irq ) ; fail4 : usb_free_urb ( pm -> config ) ; fail3 : usb_free_urb ( pm -> irq ) ; fail2 : powermate_free_buffers ( udev , pm ) ; fail1 : input_free_device ( input_dev ) ; kfree ( pm ) ; return error ; }
CWE-000 struct sk_buff * nf_ct_frag6_gather ( struct sk_buff * skb , u32 user ) { struct sk_buff * clone ; struct net_device * dev = skb -> dev ; struct frag_hdr * fhdr ; struct nf_ct_frag6_queue * fq ; struct ipv6hdr * hdr ; int fhoff , nhoff ; u8 prevhdr ; struct sk_buff * ret_skb = NULL ; if ( ipv6_hdr ( skb ) -> payload_len == 0 ) { pr_debug ( "payload<S2SV_blank>len<S2SV_blank>=<S2SV_blank>0\\n" ) ; return skb ; } if ( find_prev_fhdr ( skb , & prevhdr , & nhoff , & fhoff ) < 0 ) return skb ; clone = skb_clone ( skb , GFP_ATOMIC ) ; if ( clone == NULL ) { pr_debug ( "Can\'t<S2SV_blank>clone<S2SV_blank>skb\\n" ) ; return skb ; } NFCT_FRAG6_CB ( clone ) -> orig = skb ; if ( ! pskb_may_pull ( clone , fhoff + sizeof ( * fhdr ) ) ) { pr_debug ( "message<S2SV_blank>is<S2SV_blank>too<S2SV_blank>short.\\n" ) ; goto ret_orig ; } skb_set_transport_header ( clone , fhoff ) ; hdr = ipv6_hdr ( clone ) ; fhdr = ( struct frag_hdr * ) skb_transport_header ( clone ) ; <S2SV_StartBug> if ( ! ( fhdr -> frag_off & htons ( 0xFFF9 ) ) ) { <S2SV_EndBug> pr_debug ( "Invalid<S2SV_blank>fragment<S2SV_blank>offset\\n" ) ; goto ret_orig ; } if ( atomic_read ( & nf_init_frags . mem ) > nf_init_frags . high_thresh ) nf_ct_frag6_evictor ( ) ; fq = fq_find ( fhdr -> identification , user , & hdr -> saddr , & hdr -> daddr ) ; if ( fq == NULL ) { pr_debug ( "Can\'t<S2SV_blank>find<S2SV_blank>and<S2SV_blank>can\'t<S2SV_blank>create<S2SV_blank>new<S2SV_blank>queue\\n" ) ; goto ret_orig ; } spin_lock_bh ( & fq -> q . lock ) ; if ( nf_ct_frag6_queue ( fq , clone , fhdr , nhoff ) < 0 ) { spin_unlock_bh ( & fq -> q . lock ) ; pr_debug ( "Can\'t<S2SV_blank>insert<S2SV_blank>skb<S2SV_blank>to<S2SV_blank>queue\\n" ) ; fq_put ( fq ) ; goto ret_orig ; } if ( fq -> q . last_in == ( INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN ) && fq -> q . meat == fq -> q . len ) { ret_skb = nf_ct_frag6_reasm ( fq , dev ) ; if ( ret_skb == NULL ) pr_debug ( "Can\'t<S2SV_blank>reassemble<S2SV_blank>fragmented<S2SV_blank>packets\\n" ) ; } spin_unlock_bh ( & fq -> q . lock ) ; fq_put ( fq ) ; return ret_skb ; ret_orig : kfree_skb ( clone ) ; return skb ; }
CWE-000 static struct sk_buff * nf_ct_frag6_reasm ( struct nf_ct_frag6_queue * fq , struct net_device * dev ) { struct sk_buff * fp , * op , * head = fq -> q . fragments ; int payload_len ; fq_kill ( fq ) ; WARN_ON ( head == NULL ) ; WARN_ON ( NFCT_FRAG6_CB ( head ) -> offset != 0 ) ; payload_len = ( ( head -> data - skb_network_header ( head ) ) - sizeof ( struct ipv6hdr ) + fq -> q . len - sizeof ( struct frag_hdr ) ) ; if ( payload_len > IPV6_MAXPLEN ) { pr_debug ( "payload<S2SV_blank>len<S2SV_blank>is<S2SV_blank>too<S2SV_blank>large.\\n" ) ; goto out_oversize ; } if ( skb_cloned ( head ) && pskb_expand_head ( head , 0 , 0 , GFP_ATOMIC ) ) { pr_debug ( "skb<S2SV_blank>is<S2SV_blank>cloned<S2SV_blank>but<S2SV_blank>can\'t<S2SV_blank>expand<S2SV_blank>head" ) ; goto out_oom ; } if ( skb_has_frags ( head ) ) { struct sk_buff * clone ; int i , plen = 0 ; if ( ( clone = alloc_skb ( 0 , GFP_ATOMIC ) ) == NULL ) { pr_debug ( "Can\'t<S2SV_blank>alloc<S2SV_blank>skb\\n" ) ; goto out_oom ; } clone -> next = head -> next ; head -> next = clone ; skb_shinfo ( clone ) -> frag_list = skb_shinfo ( head ) -> frag_list ; skb_frag_list_init ( head ) ; for ( i = 0 ; i < skb_shinfo ( head ) -> nr_frags ; i ++ ) plen += skb_shinfo ( head ) -> frags [ i ] . size ; clone -> len = clone -> data_len = head -> data_len - plen ; head -> data_len -= clone -> len ; head -> len -= clone -> len ; clone -> csum = 0 ; clone -> ip_summed = head -> ip_summed ; NFCT_FRAG6_CB ( clone ) -> orig = NULL ; atomic_add ( clone -> truesize , & nf_init_frags . mem ) ; } skb_network_header ( head ) [ fq -> nhoffset ] = skb_transport_header ( head ) [ 0 ] ; memmove ( head -> head + sizeof ( struct frag_hdr ) , head -> head , ( head -> data - head -> head ) - sizeof ( struct frag_hdr ) ) ; head -> mac_header += sizeof ( struct frag_hdr ) ; head -> network_header += sizeof ( struct frag_hdr ) ; skb_shinfo ( head ) -> frag_list = head -> next ; skb_reset_transport_header ( head ) ; skb_push ( head , head -> data - skb_network_header ( head ) ) ; atomic_sub ( head -> truesize , & nf_init_frags . mem ) ; for ( fp = head -> next ; fp ; fp = fp -> next ) { head -> data_len += fp -> len ; head -> len += fp -> len ; if ( head -> ip_summed != fp -> ip_summed ) head -> ip_summed = CHECKSUM_NONE ; else if ( head -> ip_summed == CHECKSUM_COMPLETE ) head -> csum = csum_add ( head -> csum , fp -> csum ) ; head -> truesize += fp -> truesize ; atomic_sub ( fp -> truesize , & nf_init_frags . mem ) ; } head -> next = NULL ; head -> dev = dev ; head -> tstamp = fq -> q . stamp ; ipv6_hdr ( head ) -> payload_len = htons ( payload_len ) ; if ( head -> ip_summed == CHECKSUM_COMPLETE ) head -> csum = csum_partial ( skb_network_header ( head ) , skb_network_header_len ( head ) , head -> csum ) ; fq -> q . fragments = NULL ; fp = skb_shinfo ( head ) -> frag_list ; <S2SV_StartBug> if ( NFCT_FRAG6_CB ( fp ) -> orig == NULL ) <S2SV_EndBug> fp = fp -> next ; op = NFCT_FRAG6_CB ( head ) -> orig ; for ( ; fp ; fp = fp -> next ) { struct sk_buff * orig = NFCT_FRAG6_CB ( fp ) -> orig ; op -> next = orig ; op = orig ; NFCT_FRAG6_CB ( fp ) -> orig = NULL ; } return head ; out_oversize : if ( net_ratelimit ( ) ) printk ( KERN_DEBUG "nf_ct_frag6_reasm:<S2SV_blank>payload<S2SV_blank>len<S2SV_blank>=<S2SV_blank>%d\\n" , payload_len ) ; goto out_fail ; out_oom : if ( net_ratelimit ( ) ) printk ( KERN_DEBUG "nf_ct_frag6_reasm:<S2SV_blank>no<S2SV_blank>memory<S2SV_blank>for<S2SV_blank>reassembly\\n" ) ; out_fail : return NULL ; }
CWE-000 static int ims_pcu_parse_cdc_data ( struct usb_interface * intf , struct ims_pcu * pcu ) { const struct usb_cdc_union_desc * union_desc ; struct usb_host_interface * alt ; union_desc = ims_pcu_get_cdc_union_desc ( intf ) ; if ( ! union_desc ) return - EINVAL ; pcu -> ctrl_intf = usb_ifnum_to_if ( pcu -> udev , union_desc -> bMasterInterface0 ) ; <S2SV_StartBug> alt = pcu -> ctrl_intf -> cur_altsetting ; <S2SV_EndBug> pcu -> ep_ctrl = & alt -> endpoint [ 0 ] . desc ; pcu -> max_ctrl_size = usb_endpoint_maxp ( pcu -> ep_ctrl ) ; pcu -> data_intf = usb_ifnum_to_if ( pcu -> udev , union_desc -> bSlaveInterface0 ) ; <S2SV_StartBug> alt = pcu -> data_intf -> cur_altsetting ; <S2SV_EndBug> if ( alt -> desc . bNumEndpoints != 2 ) { dev_err ( pcu -> dev , "Incorrect<S2SV_blank>number<S2SV_blank>of<S2SV_blank>endpoints<S2SV_blank>on<S2SV_blank>data<S2SV_blank>interface<S2SV_blank>(%d)\\n" , alt -> desc . bNumEndpoints ) ; return - EINVAL ; } pcu -> ep_out = & alt -> endpoint [ 0 ] . desc ; if ( ! usb_endpoint_is_bulk_out ( pcu -> ep_out ) ) { dev_err ( pcu -> dev , "First<S2SV_blank>endpoint<S2SV_blank>on<S2SV_blank>data<S2SV_blank>interface<S2SV_blank>is<S2SV_blank>not<S2SV_blank>BULK<S2SV_blank>OUT\\n" ) ; return - EINVAL ; } pcu -> max_out_size = usb_endpoint_maxp ( pcu -> ep_out ) ; if ( pcu -> max_out_size < 8 ) { dev_err ( pcu -> dev , "Max<S2SV_blank>OUT<S2SV_blank>packet<S2SV_blank>size<S2SV_blank>is<S2SV_blank>too<S2SV_blank>small<S2SV_blank>(%zd)\\n" , pcu -> max_out_size ) ; return - EINVAL ; } pcu -> ep_in = & alt -> endpoint [ 1 ] . desc ; if ( ! usb_endpoint_is_bulk_in ( pcu -> ep_in ) ) { dev_err ( pcu -> dev , "Second<S2SV_blank>endpoint<S2SV_blank>on<S2SV_blank>data<S2SV_blank>interface<S2SV_blank>is<S2SV_blank>not<S2SV_blank>BULK<S2SV_blank>IN\\n" ) ; return - EINVAL ; } pcu -> max_in_size = usb_endpoint_maxp ( pcu -> ep_in ) ; if ( pcu -> max_in_size < 8 ) { dev_err ( pcu -> dev , "Max<S2SV_blank>IN<S2SV_blank>packet<S2SV_blank>size<S2SV_blank>is<S2SV_blank>too<S2SV_blank>small<S2SV_blank>(%zd)\\n" , pcu -> max_in_size ) ; return - EINVAL ; } return 0 ; }
CWE-000 void ping_unhash ( struct sock * sk ) { struct inet_sock * isk = inet_sk ( sk ) ; pr_debug ( "ping_unhash(isk=%p,isk->num=%u)\\n" , isk , isk -> inet_num ) ; if ( sk_hashed ( sk ) ) { write_lock_bh ( & ping_table . lock ) ; hlist_nulls_del ( & sk -> sk_nulls_node ) ; <S2SV_StartBug> sock_put ( sk ) ; <S2SV_EndBug> isk -> inet_num = 0 ; isk -> inet_sport = 0 ; sock_prot_inuse_add ( sock_net ( sk ) , sk -> sk_prot , - 1 ) ; write_unlock_bh ( & ping_table . lock ) ; } }
CWE-000 int evm_update_evmxattr ( struct dentry * dentry , const char * xattr_name , const char * xattr_value , size_t xattr_value_len ) { struct inode * inode = dentry -> d_inode ; struct evm_ima_xattr_data xattr_data ; int rc = 0 ; rc = evm_calc_hmac ( dentry , xattr_name , xattr_value , xattr_value_len , xattr_data . digest ) ; if ( rc == 0 ) { xattr_data . type = EVM_XATTR_HMAC ; rc = __vfs_setxattr_noperm ( dentry , XATTR_NAME_EVM , & xattr_data , sizeof ( xattr_data ) , 0 ) ; } <S2SV_StartBug> else if ( rc == - ENODATA ) <S2SV_EndBug> rc = inode -> i_op -> removexattr ( dentry , XATTR_NAME_EVM ) ; <S2SV_StartBug> return rc ; <S2SV_EndBug> }
CWE-000 static ssize_t aio_setup_iocb ( struct kiocb * kiocb , bool compat ) { struct file * file = kiocb -> ki_filp ; ssize_t ret = 0 ; switch ( kiocb -> ki_opcode ) { case IOCB_CMD_PREAD : ret = - EBADF ; if ( unlikely ( ! ( file -> f_mode & FMODE_READ ) ) ) break ; ret = - EFAULT ; if ( unlikely ( ! access_ok ( VERIFY_WRITE , kiocb -> ki_buf , kiocb -> ki_left ) ) ) break ; <S2SV_StartBug> ret = security_file_permission ( file , MAY_READ ) ; <S2SV_EndBug> if ( unlikely ( ret ) ) break ; ret = aio_setup_single_vector ( kiocb ) ; if ( ret ) break ; ret = - EINVAL ; if ( file -> f_op -> aio_read ) kiocb -> ki_retry = aio_rw_vect_retry ; break ; case IOCB_CMD_PWRITE : ret = - EBADF ; if ( unlikely ( ! ( file -> f_mode & FMODE_WRITE ) ) ) break ; ret = - EFAULT ; if ( unlikely ( ! access_ok ( VERIFY_READ , kiocb -> ki_buf , kiocb -> ki_left ) ) ) break ; <S2SV_StartBug> ret = security_file_permission ( file , MAY_WRITE ) ; <S2SV_EndBug> if ( unlikely ( ret ) ) break ; ret = aio_setup_single_vector ( kiocb ) ; if ( ret ) break ; ret = - EINVAL ; if ( file -> f_op -> aio_write ) kiocb -> ki_retry = aio_rw_vect_retry ; break ; case IOCB_CMD_PREADV : ret = - EBADF ; if ( unlikely ( ! ( file -> f_mode & FMODE_READ ) ) ) break ; <S2SV_StartBug> ret = security_file_permission ( file , MAY_READ ) ; <S2SV_EndBug> if ( unlikely ( ret ) ) break ; ret = aio_setup_vectored_rw ( READ , kiocb , compat ) ; if ( ret ) break ; ret = - EINVAL ; if ( file -> f_op -> aio_read ) kiocb -> ki_retry = aio_rw_vect_retry ; break ; case IOCB_CMD_PWRITEV : ret = - EBADF ; if ( unlikely ( ! ( file -> f_mode & FMODE_WRITE ) ) ) break ; <S2SV_StartBug> ret = security_file_permission ( file , MAY_WRITE ) ; <S2SV_EndBug> if ( unlikely ( ret ) ) break ; ret = aio_setup_vectored_rw ( WRITE , kiocb , compat ) ; if ( ret ) break ; ret = - EINVAL ; if ( file -> f_op -> aio_write ) kiocb -> ki_retry = aio_rw_vect_retry ; break ; case IOCB_CMD_FDSYNC : ret = - EINVAL ; if ( file -> f_op -> aio_fsync ) kiocb -> ki_retry = aio_fdsync ; break ; case IOCB_CMD_FSYNC : ret = - EINVAL ; if ( file -> f_op -> aio_fsync ) kiocb -> ki_retry = aio_fsync ; break ; default : dprintk ( "EINVAL:<S2SV_blank>io_submit:<S2SV_blank>no<S2SV_blank>operation<S2SV_blank>provided\\n" ) ; ret = - EINVAL ; } if ( ! kiocb -> ki_retry ) return ret ; return 0 ; }
CWE-000 <S2SV_StartBug> static ssize_t aio_setup_single_vector ( struct kiocb * kiocb ) <S2SV_EndBug> <S2SV_StartBug> { <S2SV_EndBug> kiocb -> ki_iovec = & kiocb -> ki_inline_vec ; kiocb -> ki_iovec -> iov_base = kiocb -> ki_buf ; <S2SV_StartBug> kiocb -> ki_iovec -> iov_len = kiocb -> ki_left ; <S2SV_EndBug> kiocb -> ki_nr_segs = 1 ; kiocb -> ki_cur_seg = 0 ; return 0 ; }
CWE-000 static ssize_t aio_setup_vectored_rw ( int type , struct kiocb * kiocb , bool compat ) { ssize_t ret ; # ifdef CONFIG_COMPAT if ( compat ) ret = compat_rw_copy_check_uvector ( type , ( struct compat_iovec __user * ) kiocb -> ki_buf , kiocb -> ki_nbytes , 1 , & kiocb -> ki_inline_vec , & kiocb -> ki_iovec , 1 ) ; else # endif ret = rw_copy_check_uvector ( type , ( struct iovec __user * ) kiocb -> ki_buf , kiocb -> ki_nbytes , 1 , & kiocb -> ki_inline_vec , & kiocb -> ki_iovec , 1 ) ; if ( ret < 0 ) goto out ; <S2SV_StartBug> kiocb -> ki_nr_segs = kiocb -> ki_nbytes ; <S2SV_EndBug> kiocb -> ki_cur_seg = 0 ; kiocb -> ki_nbytes = ret ; kiocb -> ki_left = ret ; ret = 0 ; out : return ret ; }
CWE-000 int perf_config ( config_fn_t fn , void * data ) { <S2SV_StartBug> int ret = 0 , found = 0 ; <S2SV_EndBug> char * repo_config = NULL ; const char * home = NULL ; if ( config_exclusive_filename ) return perf_config_from_file ( fn , config_exclusive_filename , data ) ; if ( perf_config_system ( ) && ! access ( perf_etc_perfconfig ( ) , R_OK ) ) { ret += perf_config_from_file ( fn , perf_etc_perfconfig ( ) , data ) ; found += 1 ; } home = getenv ( "HOME" ) ; if ( perf_config_global ( ) && home ) { char * user_config = strdup ( mkpath ( "%s/.perfconfig" , home ) ) ; if ( ! access ( user_config , R_OK ) ) { ret += perf_config_from_file ( fn , user_config , data ) ; found += 1 ; } free ( user_config ) ; } <S2SV_StartBug> repo_config = perf_pathdup ( "config" ) ; <S2SV_EndBug> if ( ! access ( repo_config , R_OK ) ) { ret += perf_config_from_file ( fn , repo_config , data ) ; found += 1 ; } free ( repo_config ) ; if ( found == 0 ) return - 1 ; return ret ; }
CWE-000 static int snd_compr_allocate_buffer ( struct snd_compr_stream * stream , struct snd_compr_params * params ) { unsigned int buffer_size ; <S2SV_StartBug> void * buffer ; <S2SV_EndBug> buffer_size = params -> buffer . fragment_size * params -> buffer . fragments ; if ( stream -> ops -> copy ) { buffer = NULL ; } else { buffer = kmalloc ( buffer_size , GFP_KERNEL ) ; if ( ! buffer ) return - ENOMEM ; } stream -> runtime -> fragment_size = params -> buffer . fragment_size ; stream -> runtime -> fragments = params -> buffer . fragments ; stream -> runtime -> buffer = buffer ; stream -> runtime -> buffer_size = buffer_size ; return 0 ; }
CWE-000 static int sanity_check_raw_super ( struct f2fs_sb_info * sbi , struct buffer_head * bh ) { struct f2fs_super_block * raw_super = ( struct f2fs_super_block * ) ( bh -> b_data + F2FS_SUPER_OFFSET ) ; struct super_block * sb = sbi -> sb ; unsigned int blocksize ; if ( F2FS_SUPER_MAGIC != le32_to_cpu ( raw_super -> magic ) ) { f2fs_msg ( sb , KERN_INFO , "Magic<S2SV_blank>Mismatch,<S2SV_blank>valid(0x%x)<S2SV_blank>-<S2SV_blank>read(0x%x)" , F2FS_SUPER_MAGIC , le32_to_cpu ( raw_super -> magic ) ) ; return 1 ; } if ( F2FS_BLKSIZE != PAGE_SIZE ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>page_cache_size<S2SV_blank>(%lu),<S2SV_blank>supports<S2SV_blank>only<S2SV_blank>4KB\\n" , PAGE_SIZE ) ; return 1 ; } blocksize = 1 << le32_to_cpu ( raw_super -> log_blocksize ) ; if ( blocksize != F2FS_BLKSIZE ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>blocksize<S2SV_blank>(%u),<S2SV_blank>supports<S2SV_blank>only<S2SV_blank>4KB\\n" , blocksize ) ; return 1 ; } if ( le32_to_cpu ( raw_super -> log_blocks_per_seg ) != 9 ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>log<S2SV_blank>blocks<S2SV_blank>per<S2SV_blank>segment<S2SV_blank>(%u)\\n" , le32_to_cpu ( raw_super -> log_blocks_per_seg ) ) ; return 1 ; } if ( le32_to_cpu ( raw_super -> log_sectorsize ) > F2FS_MAX_LOG_SECTOR_SIZE || le32_to_cpu ( raw_super -> log_sectorsize ) < F2FS_MIN_LOG_SECTOR_SIZE ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>log<S2SV_blank>sectorsize<S2SV_blank>(%u)" , le32_to_cpu ( raw_super -> log_sectorsize ) ) ; return 1 ; } if ( le32_to_cpu ( raw_super -> log_sectors_per_block ) + le32_to_cpu ( raw_super -> log_sectorsize ) != F2FS_MAX_LOG_SECTOR_SIZE ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>log<S2SV_blank>sectors<S2SV_blank>per<S2SV_blank>block(%u)<S2SV_blank>log<S2SV_blank>sectorsize(%u)" , le32_to_cpu ( raw_super -> log_sectors_per_block ) , le32_to_cpu ( raw_super -> log_sectorsize ) ) ; return 1 ; } if ( le32_to_cpu ( raw_super -> node_ino ) != 1 || le32_to_cpu ( raw_super -> meta_ino ) != 2 || le32_to_cpu ( raw_super -> root_ino ) != 3 ) { f2fs_msg ( sb , KERN_INFO , "Invalid<S2SV_blank>Fs<S2SV_blank>Meta<S2SV_blank>Ino:<S2SV_blank>node(%u)<S2SV_blank>meta(%u)<S2SV_blank>root(%u)" , le32_to_cpu ( raw_super -> node_ino ) , le32_to_cpu ( raw_super -> meta_ino ) , le32_to_cpu ( raw_super -> root_ino ) ) ; return 1 ; } <S2SV_StartBug> if ( sanity_check_area_boundary ( sbi , bh ) ) <S2SV_EndBug> return 1 ; return 0 ; }
CWE-000 static int __sys_sendmsg ( struct socket * sock , struct msghdr __user * msg , struct msghdr * msg_sys , unsigned flags , struct used_address * used_address ) { struct compat_msghdr __user * msg_compat = ( struct compat_msghdr __user * ) msg ; struct sockaddr_storage address ; struct iovec iovstack [ UIO_FASTIOV ] , * iov = iovstack ; unsigned char ctl [ sizeof ( struct cmsghdr ) + 20 ] __attribute__ ( ( aligned ( sizeof ( __kernel_size_t ) ) ) ) ; unsigned char * ctl_buf = ctl ; int err , ctl_len , iov_size , total_len ; err = - EFAULT ; if ( MSG_CMSG_COMPAT & flags ) { if ( get_compat_msghdr ( msg_sys , msg_compat ) ) return - EFAULT ; } else if ( copy_from_user ( msg_sys , msg , sizeof ( struct msghdr ) ) ) return - EFAULT ; err = - EMSGSIZE ; if ( msg_sys -> msg_iovlen > UIO_MAXIOV ) goto out ; err = - ENOMEM ; iov_size = msg_sys -> msg_iovlen * sizeof ( struct iovec ) ; if ( msg_sys -> msg_iovlen > UIO_FASTIOV ) { iov = sock_kmalloc ( sock -> sk , iov_size , GFP_KERNEL ) ; if ( ! iov ) goto out ; } if ( MSG_CMSG_COMPAT & flags ) { err = verify_compat_iovec ( msg_sys , iov , ( struct sockaddr * ) & address , VERIFY_READ ) ; } else err = verify_iovec ( msg_sys , iov , ( struct sockaddr * ) & address , VERIFY_READ ) ; if ( err < 0 ) goto out_freeiov ; total_len = err ; err = - ENOBUFS ; if ( msg_sys -> msg_controllen > INT_MAX ) goto out_freeiov ; ctl_len = msg_sys -> msg_controllen ; if ( ( MSG_CMSG_COMPAT & flags ) && ctl_len ) { err = cmsghdr_from_user_compat_to_kern ( msg_sys , sock -> sk , ctl , sizeof ( ctl ) ) ; if ( err ) goto out_freeiov ; ctl_buf = msg_sys -> msg_control ; ctl_len = msg_sys -> msg_controllen ; } else if ( ctl_len ) { if ( ctl_len > sizeof ( ctl ) ) { ctl_buf = sock_kmalloc ( sock -> sk , ctl_len , GFP_KERNEL ) ; if ( ctl_buf == NULL ) goto out_freeiov ; } err = - EFAULT ; if ( copy_from_user ( ctl_buf , ( void __user __force * ) msg_sys -> msg_control , ctl_len ) ) goto out_freectl ; msg_sys -> msg_control = ctl_buf ; } msg_sys -> msg_flags = flags ; if ( sock -> file -> f_flags & O_NONBLOCK ) msg_sys -> msg_flags |= MSG_DONTWAIT ; <S2SV_StartBug> if ( used_address && used_address -> name_len == msg_sys -> msg_namelen && <S2SV_EndBug> <S2SV_StartBug> ! memcmp ( & used_address -> name , msg -> msg_name , <S2SV_EndBug> used_address -> name_len ) ) { err = sock_sendmsg_nosec ( sock , msg_sys , total_len ) ; goto out_freectl ; } err = sock_sendmsg ( sock , msg_sys , total_len ) ; if ( used_address && err >= 0 ) { used_address -> name_len = msg_sys -> msg_namelen ; <S2SV_StartBug> memcpy ( & used_address -> name , msg -> msg_name , <S2SV_EndBug> used_address -> name_len ) ; } out_freectl : if ( ctl_buf != ctl ) sock_kfree_s ( sock -> sk , ctl_buf , ctl_len ) ; out_freeiov : if ( iov != iovstack ) sock_kfree_s ( sock -> sk , iov , iov_size ) ; out : return err ; }
CWE-000 static int translate_desc ( struct vhost_dev * dev , u64 addr , u32 len , struct iovec iov [ ] , int iov_size ) { const struct vhost_memory_region * reg ; struct vhost_memory * mem ; struct iovec * _iov ; u64 s = 0 ; int ret = 0 ; rcu_read_lock ( ) ; mem = rcu_dereference ( dev -> memory ) ; while ( ( u64 ) len > s ) { u64 size ; if ( unlikely ( ret >= iov_size ) ) { ret = - ENOBUFS ; break ; } reg = find_region ( mem , addr , len ) ; if ( unlikely ( ! reg ) ) { ret = - EFAULT ; break ; } _iov = iov + ret ; size = reg -> memory_size - addr + reg -> guest_phys_addr ; <S2SV_StartBug> _iov -> iov_len = min ( ( u64 ) len , size ) ; <S2SV_EndBug> _iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ) ; s += size ; addr += size ; ++ ret ; } rcu_read_unlock ( ) ; return ret ; }
CWE-000 static int em_syscall ( struct x86_emulate_ctxt * ctxt ) { struct x86_emulate_ops * ops = ctxt -> ops ; struct desc_struct cs , ss ; u64 msr_data ; u16 cs_sel , ss_sel ; u64 efer = 0 ; if ( ctxt -> mode == X86EMUL_MODE_REAL || ctxt -> mode == X86EMUL_MODE_VM86 ) return emulate_ud ( ctxt ) ; <S2SV_StartBug> ops -> get_msr ( ctxt , MSR_EFER , & efer ) ; <S2SV_EndBug> <S2SV_StartBug> setup_syscalls_segments ( ctxt , & cs , & ss ) ; <S2SV_EndBug> ops -> get_msr ( ctxt , MSR_STAR , & msr_data ) ; msr_data >>= 32 ; cs_sel = ( u16 ) ( msr_data & 0xfffc ) ; ss_sel = ( u16 ) ( msr_data + 8 ) ; if ( efer & EFER_LMA ) { cs . d = 0 ; cs . l = 1 ; } ops -> set_segment ( ctxt , cs_sel , & cs , 0 , VCPU_SREG_CS ) ; ops -> set_segment ( ctxt , ss_sel , & ss , 0 , VCPU_SREG_SS ) ; ctxt -> regs [ VCPU_REGS_RCX ] = ctxt -> _eip ; if ( efer & EFER_LMA ) { # ifdef CONFIG_X86_64 ctxt -> regs [ VCPU_REGS_R11 ] = ctxt -> eflags & ~ EFLG_RF ; ops -> get_msr ( ctxt , ctxt -> mode == X86EMUL_MODE_PROT64 ? MSR_LSTAR : MSR_CSTAR , & msr_data ) ; ctxt -> _eip = msr_data ; ops -> get_msr ( ctxt , MSR_SYSCALL_MASK , & msr_data ) ; ctxt -> eflags &= ~ ( msr_data | EFLG_RF ) ; # endif } else { ops -> get_msr ( ctxt , MSR_STAR , & msr_data ) ; ctxt -> _eip = ( u32 ) msr_data ; ctxt -> eflags &= ~ ( EFLG_VM | EFLG_IF | EFLG_RF ) ; } return X86EMUL_CONTINUE ; }
CWE-000 static int tty_open ( struct inode * inode , struct file * filp ) { struct tty_struct * tty = NULL ; int noctty , retval ; struct tty_driver * driver ; int index ; dev_t device = inode -> i_rdev ; unsigned saved_flags = filp -> f_flags ; nonseekable_open ( inode , filp ) ; retry_open : noctty = filp -> f_flags & O_NOCTTY ; index = - 1 ; retval = 0 ; mutex_lock ( & tty_mutex ) ; tty_lock ( ) ; if ( device == MKDEV ( TTYAUX_MAJOR , 0 ) ) { tty = get_current_tty ( ) ; if ( ! tty ) { tty_unlock ( ) ; mutex_unlock ( & tty_mutex ) ; return - ENXIO ; } driver = tty_driver_kref_get ( tty -> driver ) ; index = tty -> index ; filp -> f_flags |= O_NONBLOCK ; tty_kref_put ( tty ) ; goto got_driver ; } # ifdef CONFIG_VT if ( device == MKDEV ( TTY_MAJOR , 0 ) ) { extern struct tty_driver * console_driver ; driver = tty_driver_kref_get ( console_driver ) ; index = fg_console ; noctty = 1 ; goto got_driver ; } # endif if ( device == MKDEV ( TTYAUX_MAJOR , 1 ) ) { struct tty_driver * console_driver = console_device ( & index ) ; if ( console_driver ) { driver = tty_driver_kref_get ( console_driver ) ; if ( driver ) { filp -> f_flags |= O_NONBLOCK ; noctty = 1 ; goto got_driver ; } } tty_unlock ( ) ; mutex_unlock ( & tty_mutex ) ; return - ENODEV ; } driver = get_tty_driver ( device , & index ) ; if ( ! driver ) { tty_unlock ( ) ; mutex_unlock ( & tty_mutex ) ; return - ENODEV ; } got_driver : if ( ! tty ) { tty = tty_driver_lookup_tty ( driver , inode , index ) ; if ( IS_ERR ( tty ) ) { tty_unlock ( ) ; mutex_unlock ( & tty_mutex ) ; <S2SV_StartBug> return PTR_ERR ( tty ) ; <S2SV_EndBug> } } if ( tty ) { retval = tty_reopen ( tty ) ; if ( retval ) tty = ERR_PTR ( retval ) ; } else tty = tty_init_dev ( driver , index , 0 ) ; mutex_unlock ( & tty_mutex ) ; tty_driver_kref_put ( driver ) ; if ( IS_ERR ( tty ) ) { tty_unlock ( ) ; return PTR_ERR ( tty ) ; } retval = tty_add_file ( tty , filp ) ; if ( retval ) { tty_unlock ( ) ; tty_release ( inode , filp ) ; return retval ; } check_tty_count ( tty , "tty_open" ) ; if ( tty -> driver -> type == TTY_DRIVER_TYPE_PTY && tty -> driver -> subtype == PTY_TYPE_MASTER ) noctty = 1 ; # ifdef TTY_DEBUG_HANGUP printk ( KERN_DEBUG "opening<S2SV_blank>%s..." , tty -> name ) ; # endif if ( tty -> ops -> open ) retval = tty -> ops -> open ( tty , filp ) ; else retval = - ENODEV ; filp -> f_flags = saved_flags ; if ( ! retval && test_bit ( TTY_EXCLUSIVE , & tty -> flags ) && ! capable ( CAP_SYS_ADMIN ) ) retval = - EBUSY ; if ( retval ) { # ifdef TTY_DEBUG_HANGUP printk ( KERN_DEBUG "error<S2SV_blank>%d<S2SV_blank>in<S2SV_blank>opening<S2SV_blank>%s..." , retval , tty -> name ) ; # endif tty_unlock ( ) ; tty_release ( inode , filp ) ; if ( retval != - ERESTARTSYS ) return retval ; if ( signal_pending ( current ) ) return retval ; schedule ( ) ; tty_lock ( ) ; if ( filp -> f_op == & hung_up_tty_fops ) filp -> f_op = & tty_fops ; tty_unlock ( ) ; goto retry_open ; } tty_unlock ( ) ; mutex_lock ( & tty_mutex ) ; tty_lock ( ) ; spin_lock_irq ( & current -> sighand -> siglock ) ; if ( ! noctty && current -> signal -> leader && ! current -> signal -> tty && tty -> session == NULL ) __proc_set_tty ( current , tty ) ; spin_unlock_irq ( & current -> sighand -> siglock ) ; tty_unlock ( ) ; mutex_unlock ( & tty_mutex ) ; return 0 ; }
CWE-000 static ssize_t aio_setup_single_vector ( struct kiocb * kiocb , int rw , char __user * buf , unsigned long * nr_segs , struct iovec * iovec ) { <S2SV_StartBug> if ( unlikely ( ! access_ok ( ! rw , buf , kiocb -> ki_nbytes ) ) ) <S2SV_EndBug> return - EFAULT ; iovec -> iov_base = buf ; <S2SV_StartBug> iovec -> iov_len = kiocb -> ki_nbytes ; <S2SV_EndBug> * nr_segs = 1 ; return 0 ; }
CWE-000 static int cypress_generic_port_probe ( struct usb_serial_port * port ) { struct usb_serial * serial = port -> serial ; struct cypress_private * priv ; <S2SV_StartBug> priv = kzalloc ( sizeof ( struct cypress_private ) , GFP_KERNEL ) ; <S2SV_EndBug> if ( ! priv ) return - ENOMEM ; priv -> comm_is_ok = ! 0 ; spin_lock_init ( & priv -> lock ) ; if ( kfifo_alloc ( & priv -> write_fifo , CYPRESS_BUF_SIZE , GFP_KERNEL ) ) { kfree ( priv ) ; return - ENOMEM ; } if ( ! is_frwd ( serial -> dev ) ) usb_reset_configuration ( serial -> dev ) ; priv -> cmd_ctrl = 0 ; priv -> line_control = 0 ; priv -> termios_initialized = 0 ; priv -> rx_flags = 0 ; if ( port -> interrupt_out_size > 9 ) priv -> pkt_fmt = packet_format_1 ; else priv -> pkt_fmt = packet_format_2 ; if ( interval > 0 ) { priv -> write_urb_interval = interval ; priv -> read_urb_interval = interval ; dev_dbg ( & port -> dev , "%s<S2SV_blank>-<S2SV_blank>read<S2SV_blank>&<S2SV_blank>write<S2SV_blank>intervals<S2SV_blank>forced<S2SV_blank>to<S2SV_blank>%d\\n" , __func__ , interval ) ; } else { priv -> write_urb_interval = port -> interrupt_out_urb -> interval ; priv -> read_urb_interval = port -> interrupt_in_urb -> interval ; dev_dbg ( & port -> dev , "%s<S2SV_blank>-<S2SV_blank>intervals:<S2SV_blank>read=%d<S2SV_blank>write=%d\\n" , __func__ , priv -> read_urb_interval , priv -> write_urb_interval ) ; } usb_set_serial_port_data ( port , priv ) ; port -> port . drain_delay = 256 ; return 0 ; }
CWE-000 static int cypress_open ( struct tty_struct * tty , struct usb_serial_port * port ) { struct cypress_private * priv = usb_get_serial_port_data ( port ) ; struct usb_serial * serial = port -> serial ; unsigned long flags ; int result = 0 ; if ( ! priv -> comm_is_ok ) return - EIO ; usb_clear_halt ( serial -> dev , 0x81 ) ; usb_clear_halt ( serial -> dev , 0x02 ) ; spin_lock_irqsave ( & priv -> lock , flags ) ; priv -> bytes_in = 0 ; priv -> bytes_out = 0 ; priv -> cmd_count = 0 ; priv -> rx_flags = 0 ; spin_unlock_irqrestore ( & priv -> lock , flags ) ; cypress_send ( port ) ; if ( tty ) cypress_set_termios ( tty , port , & priv -> tmp_termios ) ; <S2SV_StartBug> if ( ! port -> interrupt_in_urb ) { <S2SV_EndBug> dev_err ( & port -> dev , "%s<S2SV_blank>-<S2SV_blank>interrupt_in_urb<S2SV_blank>is<S2SV_blank>empty!\\n" , __func__ ) ; return - 1 ; } usb_fill_int_urb ( port -> interrupt_in_urb , serial -> dev , usb_rcvintpipe ( serial -> dev , port -> interrupt_in_endpointAddress ) , port -> interrupt_in_urb -> transfer_buffer , port -> interrupt_in_urb -> transfer_buffer_length , cypress_read_int_callback , port , priv -> read_urb_interval ) ; result = usb_submit_urb ( port -> interrupt_in_urb , GFP_KERNEL ) ; if ( result ) { dev_err ( & port -> dev , "%s<S2SV_blank>-<S2SV_blank>failed<S2SV_blank>submitting<S2SV_blank>read<S2SV_blank>urb,<S2SV_blank>error<S2SV_blank>%d\\n" , __func__ , result ) ; cypress_set_dead ( port ) ; } return result ; }
CWE-000 static int treo_attach ( struct usb_serial * serial ) { struct usb_serial_port * swap_port ; if ( ! ( ( le16_to_cpu ( serial -> dev -> descriptor . idVendor ) == HANDSPRING_VENDOR_ID ) || ( le16_to_cpu ( serial -> dev -> descriptor . idVendor ) == KYOCERA_VENDOR_ID ) ) || ( serial -> num_interrupt_in == 0 ) ) return 0 ; <S2SV_StartBug> # define COPY_PORT ( dest , src ) do { int i ; for ( i = 0 ; i < ARRAY_SIZE ( src -> read_urbs ) ; ++ i ) { dest -> read_urbs [ i ] = src -> read_urbs [ i ] ; dest -> read_urbs [ i ] -> context = dest ; dest -> bulk_in_buffers [ i ] = src -> bulk_in_buffers [ i ] ; } dest -> read_urb = src -> read_urb ; dest -> bulk_in_endpointAddress = src -> bulk_in_endpointAddress ; dest -> bulk_in_buffer = src -> bulk_in_buffer ; dest -> bulk_in_size = src -> bulk_in_size ; dest -> interrupt_in_urb = src -> interrupt_in_urb ; dest -> interrupt_in_urb -> context = dest ; dest -> interrupt_in_endpointAddress = src -> interrupt_in_endpointAddress ; dest -> interrupt_in_buffer = src -> interrupt_in_buffer ; } while ( 0 ) ; <S2SV_EndBug> swap_port = kmalloc ( sizeof ( * swap_port ) , GFP_KERNEL ) ; if ( ! swap_port ) return - ENOMEM ; COPY_PORT ( swap_port , serial -> port [ 0 ] ) ; COPY_PORT ( serial -> port [ 0 ] , serial -> port [ 1 ] ) ; COPY_PORT ( serial -> port [ 1 ] , swap_port ) ; kfree ( swap_port ) ; return 0 ; }
CWE-000 static int clie_5_attach ( struct usb_serial * serial ) { struct usb_serial_port * port ; unsigned int pipe ; int j ; <S2SV_StartBug> if ( serial -> num_ports < 2 ) <S2SV_EndBug> return - 1 ; port = serial -> port [ 0 ] ; port -> bulk_out_endpointAddress = serial -> port [ 1 ] -> bulk_out_endpointAddress ; pipe = usb_sndbulkpipe ( serial -> dev , port -> bulk_out_endpointAddress ) ; for ( j = 0 ; j < ARRAY_SIZE ( port -> write_urbs ) ; ++ j ) port -> write_urbs [ j ] -> pipe = pipe ; return 0 ; }
CWE-000 struct vfsmount * collect_mounts ( struct path * path ) { struct mount * tree ; <S2SV_StartBug> namespace_lock ( ) ; <S2SV_EndBug> tree = copy_tree ( real_mount ( path -> mnt ) , path -> dentry , CL_COPY_ALL | CL_PRIVATE ) ; namespace_unlock ( ) ; if ( IS_ERR ( tree ) ) return ERR_CAST ( tree ) ; return & tree -> mnt ; }
CWE-000 int ping_recvmsg ( struct kiocb * iocb , struct sock * sk , struct msghdr * msg , size_t len , int noblock , int flags , int * addr_len ) { struct inet_sock * isk = inet_sk ( sk ) ; int family = sk -> sk_family ; struct sk_buff * skb ; int copied , err ; pr_debug ( "ping_recvmsg(sk=%p,sk->num=%u)\\n" , isk , isk -> inet_num ) ; err = - EOPNOTSUPP ; if ( flags & MSG_OOB ) goto out ; if ( flags & MSG_ERRQUEUE ) { if ( family == AF_INET ) { return ip_recv_error ( sk , msg , len ) ; # if IS_ENABLED ( CONFIG_IPV6 ) } else if ( family == AF_INET6 ) { return pingv6_ops . ipv6_recv_error ( sk , msg , len ) ; # endif } } skb = skb_recv_datagram ( sk , flags , noblock , & err ) ; if ( ! skb ) goto out ; copied = skb -> len ; if ( copied > len ) { msg -> msg_flags |= MSG_TRUNC ; copied = len ; } err = skb_copy_datagram_iovec ( skb , 0 , msg -> msg_iov , copied ) ; if ( err ) goto done ; sock_recv_timestamp ( msg , sk , skb ) ; if ( family == AF_INET ) { struct sockaddr_in * sin = ( struct sockaddr_in * ) msg -> msg_name ; <S2SV_StartBug> sin -> sin_family = AF_INET ; <S2SV_EndBug> sin -> sin_port = 0 ; sin -> sin_addr . s_addr = ip_hdr ( skb ) -> saddr ; memset ( sin -> sin_zero , 0 , sizeof ( sin -> sin_zero ) ) ; * addr_len = sizeof ( * sin ) ; <S2SV_StartBug> if ( isk -> cmsg_flags ) <S2SV_EndBug> ip_cmsg_recv ( msg , skb ) ; # if IS_ENABLED ( CONFIG_IPV6 ) } else if ( family == AF_INET6 ) { struct ipv6_pinfo * np = inet6_sk ( sk ) ; struct ipv6hdr * ip6 = ipv6_hdr ( skb ) ; struct sockaddr_in6 * sin6 = ( struct sockaddr_in6 * ) msg -> msg_name ; <S2SV_StartBug> sin6 -> sin6_family = AF_INET6 ; <S2SV_EndBug> sin6 -> sin6_port = 0 ; sin6 -> sin6_addr = ip6 -> saddr ; sin6 -> sin6_flowinfo = 0 ; if ( np -> sndflow ) sin6 -> sin6_flowinfo = ip6_flowinfo ( ip6 ) ; sin6 -> sin6_scope_id = ipv6_iface_scope_id ( & sin6 -> sin6_addr , IP6CB ( skb ) -> iif ) ; <S2SV_StartBug> * addr_len = sizeof ( * sin6 ) ; <S2SV_EndBug> if ( inet6_sk ( sk ) -> rxopt . all ) pingv6_ops . ip6_datagram_recv_ctl ( sk , msg , skb ) ; # endif } else { BUG ( ) ; } err = copied ; done : skb_free_datagram ( sk , skb ) ; out : pr_debug ( "ping_recvmsg<S2SV_blank>-><S2SV_blank>%d\\n" , err ) ; return err ; }
CWE-000 SYSCALL_DEFINE3 ( rt_sigqueueinfo , pid_t , pid , int , sig , siginfo_t __user * , uinfo ) { siginfo_t info ; if ( copy_from_user ( & info , uinfo , sizeof ( siginfo_t ) ) ) return - EFAULT ; <S2SV_StartBug> if ( info . si_code >= 0 ) <S2SV_EndBug> <S2SV_StartBug> return - EPERM ; <S2SV_EndBug> info . si_signo = sig ; return kill_proc_info ( sig , & info , pid ) ; }
CWE-000 long do_rt_tgsigqueueinfo ( pid_t tgid , pid_t pid , int sig , siginfo_t * info ) { if ( pid <= 0 || tgid <= 0 ) return - EINVAL ; <S2SV_StartBug> if ( info -> si_code >= 0 ) <S2SV_EndBug> <S2SV_StartBug> return - EPERM ; <S2SV_EndBug> info -> si_signo = sig ; return do_send_specific ( tgid , pid , sig , info ) ; }
CWE-000 <S2SV_StartBug> struct nfs_open_context * nfs_find_open_context ( struct inode * inode , struct rpc_cred * cred , int mode ) <S2SV_EndBug> { struct nfs_inode * nfsi = NFS_I ( inode ) ; struct nfs_open_context * pos , * ctx = NULL ; spin_lock ( & inode -> i_lock ) ; list_for_each_entry ( pos , & nfsi -> open_files , list ) { if ( cred != NULL && pos -> cred != cred ) continue ; if ( ( pos -> mode & mode ) == mode ) { ctx = get_nfs_open_context ( pos ) ; break ; } } spin_unlock ( & inode -> i_lock ) ; return ctx ; }
CWE-000 static void hub_activate ( struct usb_hub * hub , enum hub_activation_type type ) { struct usb_device * hdev = hub -> hdev ; struct usb_hcd * hcd ; int ret ; int port1 ; int status ; bool need_debounce_delay = false ; unsigned delay ; <S2SV_StartBug> if ( type == HUB_INIT2 ) <S2SV_EndBug> goto init2 ; <S2SV_StartBug> if ( type == HUB_INIT3 ) <S2SV_EndBug> goto init3 ; if ( type != HUB_RESUME ) { if ( hdev -> parent && hub_is_superspeed ( hdev ) ) { ret = usb_control_msg ( hdev , usb_sndctrlpipe ( hdev , 0 ) , HUB_SET_DEPTH , USB_RT_HUB , hdev -> level - 1 , 0 , NULL , 0 , USB_CTRL_SET_TIMEOUT ) ; if ( ret < 0 ) dev_err ( hub -> intfdev , "set<S2SV_blank>hub<S2SV_blank>depth<S2SV_blank>failed\\n" ) ; } if ( type == HUB_INIT ) { delay = hub_power_on_good_delay ( hub ) ; hub_power_on ( hub , false ) ; INIT_DELAYED_WORK ( & hub -> init_work , hub_init_func2 ) ; queue_delayed_work ( system_power_efficient_wq , & hub -> init_work , msecs_to_jiffies ( delay ) ) ; usb_autopm_get_interface_no_resume ( to_usb_interface ( hub -> intfdev ) ) ; return ; } else if ( type == HUB_RESET_RESUME ) { hcd = bus_to_hcd ( hdev -> bus ) ; if ( hcd -> driver -> update_hub_device ) { ret = hcd -> driver -> update_hub_device ( hcd , hdev , & hub -> tt , GFP_NOIO ) ; if ( ret < 0 ) { dev_err ( hub -> intfdev , "Host<S2SV_blank>not<S2SV_blank>" "accepting<S2SV_blank>hub<S2SV_blank>info<S2SV_blank>" "update.\\n" ) ; dev_err ( hub -> intfdev , "LS/FS<S2SV_blank>devices<S2SV_blank>" "and<S2SV_blank>hubs<S2SV_blank>may<S2SV_blank>not<S2SV_blank>work<S2SV_blank>" "under<S2SV_blank>this<S2SV_blank>hub\\n." ) ; } } hub_power_on ( hub , true ) ; } else { hub_power_on ( hub , true ) ; } } init2 : for ( port1 = 1 ; port1 <= hdev -> maxchild ; ++ port1 ) { struct usb_port * port_dev = hub -> ports [ port1 - 1 ] ; struct usb_device * udev = port_dev -> child ; u16 portstatus , portchange ; portstatus = portchange = 0 ; status = hub_port_status ( hub , port1 , & portstatus , & portchange ) ; if ( udev || ( portstatus & USB_PORT_STAT_CONNECTION ) ) dev_dbg ( & port_dev -> dev , "status<S2SV_blank>%04x<S2SV_blank>change<S2SV_blank>%04x\\n" , portstatus , portchange ) ; if ( ( portstatus & USB_PORT_STAT_ENABLE ) && ( type != HUB_RESUME || ! ( portstatus & USB_PORT_STAT_CONNECTION ) || ! udev || udev -> state == USB_STATE_NOTATTACHED ) ) { portstatus &= ~ USB_PORT_STAT_ENABLE ; if ( ! hub_is_superspeed ( hdev ) ) usb_clear_port_feature ( hdev , port1 , USB_PORT_FEAT_ENABLE ) ; } if ( portchange & USB_PORT_STAT_C_CONNECTION ) { need_debounce_delay = true ; usb_clear_port_feature ( hub -> hdev , port1 , USB_PORT_FEAT_C_CONNECTION ) ; } if ( portchange & USB_PORT_STAT_C_ENABLE ) { need_debounce_delay = true ; usb_clear_port_feature ( hub -> hdev , port1 , USB_PORT_FEAT_C_ENABLE ) ; } if ( portchange & USB_PORT_STAT_C_RESET ) { need_debounce_delay = true ; usb_clear_port_feature ( hub -> hdev , port1 , USB_PORT_FEAT_C_RESET ) ; } if ( ( portchange & USB_PORT_STAT_C_BH_RESET ) && hub_is_superspeed ( hub -> hdev ) ) { need_debounce_delay = true ; usb_clear_port_feature ( hub -> hdev , port1 , USB_PORT_FEAT_C_BH_PORT_RESET ) ; } if ( ! ( portstatus & USB_PORT_STAT_CONNECTION ) || ( portchange & USB_PORT_STAT_C_CONNECTION ) ) clear_bit ( port1 , hub -> removed_bits ) ; if ( ! udev || udev -> state == USB_STATE_NOTATTACHED ) { if ( udev || ( portstatus & USB_PORT_STAT_CONNECTION ) || ( portstatus & USB_PORT_STAT_OVERCURRENT ) ) set_bit ( port1 , hub -> change_bits ) ; } else if ( portstatus & USB_PORT_STAT_ENABLE ) { bool port_resumed = ( portstatus & USB_PORT_STAT_LINK_STATE ) == USB_SS_PORT_LS_U0 ; if ( portchange || ( hub_is_superspeed ( hub -> hdev ) && port_resumed ) ) set_bit ( port1 , hub -> change_bits ) ; } else if ( udev -> persist_enabled ) { # ifdef CONFIG_PM udev -> reset_resume = 1 ; # endif if ( test_bit ( port1 , hub -> power_bits ) ) set_bit ( port1 , hub -> change_bits ) ; } else { usb_set_device_state ( udev , USB_STATE_NOTATTACHED ) ; set_bit ( port1 , hub -> change_bits ) ; } } if ( need_debounce_delay ) { delay = HUB_DEBOUNCE_STABLE ; if ( type == HUB_INIT2 ) { INIT_DELAYED_WORK ( & hub -> init_work , hub_init_func3 ) ; queue_delayed_work ( system_power_efficient_wq , & hub -> init_work , msecs_to_jiffies ( delay ) ) ; <S2SV_StartBug> return ; <S2SV_EndBug> } else { msleep ( delay ) ; } } init3 : hub -> quiescing = 0 ; status = usb_submit_urb ( hub -> urb , GFP_NOIO ) ; if ( status < 0 ) dev_err ( hub -> intfdev , "activate<S2SV_blank>--><S2SV_blank>%d\\n" , status ) ; if ( hub -> has_indicators && blinkenlights ) queue_delayed_work ( system_power_efficient_wq , & hub -> leds , LED_CYCLE_PERIOD ) ; kick_hub_wq ( hub ) ; if ( type <= HUB_INIT3 ) usb_autopm_put_interface_async ( to_usb_interface ( hub -> intfdev ) ) ; <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 static void sctp_sock_migrate ( struct sock * oldsk , struct sock * newsk , struct sctp_association * assoc , sctp_socket_type_t type ) { struct sctp_sock * oldsp = sctp_sk ( oldsk ) ; struct sctp_sock * newsp = sctp_sk ( newsk ) ; struct sctp_bind_bucket * pp ; struct sctp_endpoint * newep = newsp -> ep ; struct sk_buff * skb , * tmp ; struct sctp_ulpevent * event ; int flags = 0 ; newsk -> sk_sndbuf = oldsk -> sk_sndbuf ; newsk -> sk_rcvbuf = oldsk -> sk_rcvbuf ; inet_sk_copy_descendant ( newsk , oldsk ) ; newsp -> ep = newep ; newsp -> hmac = NULL ; pp = sctp_sk ( oldsk ) -> bind_hash ; sk_add_bind_node ( newsk , & pp -> owner ) ; sctp_sk ( newsk ) -> bind_hash = pp ; inet_sk ( newsk ) -> num = inet_sk ( oldsk ) -> num ; if ( PF_INET6 == assoc -> base . sk -> sk_family ) flags = SCTP_ADDR6_ALLOWED ; if ( assoc -> peer . ipv4_address ) flags |= SCTP_ADDR4_PEERSUPP ; if ( assoc -> peer . ipv6_address ) flags |= SCTP_ADDR6_PEERSUPP ; sctp_bind_addr_copy ( & newsp -> ep -> base . bind_addr , & oldsp -> ep -> base . bind_addr , SCTP_SCOPE_GLOBAL , GFP_KERNEL , flags ) ; sctp_skb_for_each ( skb , & oldsk -> sk_receive_queue , tmp ) { event = sctp_skb2event ( skb ) ; if ( event -> asoc == assoc ) { <S2SV_StartBug> sctp_sock_rfree ( skb ) ; <S2SV_EndBug> __skb_unlink ( skb , & oldsk -> sk_receive_queue ) ; __skb_queue_tail ( & newsk -> sk_receive_queue , skb ) ; <S2SV_StartBug> sctp_skb_set_owner_r ( skb , newsk ) ; <S2SV_EndBug> } } skb_queue_head_init ( & newsp -> pd_lobby ) ; sctp_sk ( newsk ) -> pd_mode = assoc -> ulpq . pd_mode ; if ( sctp_sk ( oldsk ) -> pd_mode ) { struct sk_buff_head * queue ; if ( assoc -> ulpq . pd_mode ) { queue = & newsp -> pd_lobby ; } else queue = & newsk -> sk_receive_queue ; sctp_skb_for_each ( skb , & oldsp -> pd_lobby , tmp ) { event = sctp_skb2event ( skb ) ; if ( event -> asoc == assoc ) { <S2SV_StartBug> sctp_sock_rfree ( skb ) ; <S2SV_EndBug> __skb_unlink ( skb , & oldsp -> pd_lobby ) ; __skb_queue_tail ( queue , skb ) ; <S2SV_StartBug> sctp_skb_set_owner_r ( skb , newsk ) ; <S2SV_EndBug> } } if ( assoc -> ulpq . pd_mode ) <S2SV_StartBug> sctp_clear_pd ( oldsk ) ; <S2SV_EndBug> } newsp -> type = type ; sctp_lock_sock ( newsk ) ; sctp_assoc_migrate ( assoc , newsk ) ; if ( sctp_state ( assoc , CLOSED ) && sctp_style ( newsk , TCP ) ) newsk -> sk_shutdown |= RCV_SHUTDOWN ; newsk -> sk_state = SCTP_SS_ESTABLISHED ; sctp_release_sock ( newsk ) ; }
CWE-000 static long aio_read_events_ring ( struct kioctx * ctx , struct io_event __user * event , long nr ) { struct aio_ring * ring ; unsigned head , tail , pos ; long ret = 0 ; int copy_ret ; mutex_lock ( & ctx -> ring_lock ) ; ring = kmap_atomic ( ctx -> ring_pages [ 0 ] ) ; head = ring -> head ; tail = ring -> tail ; kunmap_atomic ( ring ) ; pr_debug ( "h%u<S2SV_blank>t%u<S2SV_blank>m%u\\n" , head , tail , ctx -> nr_events ) ; if ( head == tail ) goto out ; <S2SV_StartBug> while ( ret < nr ) { <S2SV_EndBug> long avail ; struct io_event * ev ; struct page * page ; avail = ( head <= tail ? tail : ctx -> nr_events ) - head ; if ( head == tail ) break ; avail = min ( avail , nr - ret ) ; avail = min_t ( long , avail , AIO_EVENTS_PER_PAGE - ( ( head + AIO_EVENTS_OFFSET ) % AIO_EVENTS_PER_PAGE ) ) ; pos = head + AIO_EVENTS_OFFSET ; page = ctx -> ring_pages [ pos / AIO_EVENTS_PER_PAGE ] ; pos %= AIO_EVENTS_PER_PAGE ; ev = kmap ( page ) ; copy_ret = copy_to_user ( event + ret , ev + pos , sizeof ( * ev ) * avail ) ; kunmap ( page ) ; if ( unlikely ( copy_ret ) ) { ret = - EFAULT ; goto out ; } ret += avail ; head += avail ; head %= ctx -> nr_events ; } ring = kmap_atomic ( ctx -> ring_pages [ 0 ] ) ; ring -> head = head ; kunmap_atomic ( ring ) ; flush_dcache_page ( ctx -> ring_pages [ 0 ] ) ; pr_debug ( "%li<S2SV_blank><S2SV_blank>h%u<S2SV_blank>t%u\\n" , ret , head , tail ) ; out : mutex_unlock ( & ctx -> ring_lock ) ; return ret ; }
CWE-000 static struct file * path_openat ( int dfd , struct filename * pathname , struct nameidata * nd , const struct open_flags * op , int flags ) { struct file * file ; struct path path ; int opened = 0 ; int error ; file = get_empty_filp ( ) ; if ( IS_ERR ( file ) ) return file ; file -> f_flags = op -> open_flag ; if ( unlikely ( file -> f_flags & __O_TMPFILE ) ) { error = do_tmpfile ( dfd , pathname , nd , flags , op , file , & opened ) ; <S2SV_StartBug> goto out ; <S2SV_EndBug> } error = path_init ( dfd , pathname , flags , nd ) ; if ( unlikely ( error ) ) goto out ; error = do_last ( nd , & path , file , op , & opened , pathname ) ; while ( unlikely ( error > 0 ) ) { struct path link = path ; void * cookie ; if ( ! ( nd -> flags & LOOKUP_FOLLOW ) ) { path_put_conditional ( & path , nd ) ; path_put ( & nd -> path ) ; error = - ELOOP ; break ; } error = may_follow_link ( & link , nd ) ; if ( unlikely ( error ) ) break ; nd -> flags |= LOOKUP_PARENT ; nd -> flags &= ~ ( LOOKUP_OPEN | LOOKUP_CREATE | LOOKUP_EXCL ) ; error = follow_link ( & link , nd , & cookie ) ; if ( unlikely ( error ) ) break ; error = do_last ( nd , & path , file , op , & opened , pathname ) ; put_link ( nd , & link , cookie ) ; } out : path_cleanup ( nd ) ; <S2SV_StartBug> if ( ! ( opened & FILE_OPENED ) ) { <S2SV_EndBug> BUG_ON ( ! error ) ; put_filp ( file ) ; } if ( unlikely ( error ) ) { if ( error == - EOPENSTALE ) { if ( flags & LOOKUP_RCU ) error = - ECHILD ; else error = - ESTALE ; } file = ERR_PTR ( error ) ; } return file ; }
CWE-000 static void check_preempt_curr ( struct rq * rq , struct task_struct * p , int flags ) { const struct sched_class * class ; if ( p -> sched_class == rq -> curr -> sched_class ) { rq -> curr -> sched_class -> check_preempt_curr ( rq , p , flags ) ; } else { for_each_class ( class ) { if ( class == rq -> curr -> sched_class ) break ; if ( class == p -> sched_class ) { resched_task ( rq -> curr ) ; break ; } } } <S2SV_StartBug> if ( test_tsk_need_resched ( rq -> curr ) ) <S2SV_EndBug> rq -> skip_clock_update = 1 ; }
CWE-000 static void put_prev_task ( struct rq * rq , struct task_struct * prev ) { if ( prev -> se . on_rq ) update_rq_clock ( rq ) ; <S2SV_StartBug> rq -> skip_clock_update = 0 ; <S2SV_EndBug> prev -> sched_class -> put_prev_task ( rq , prev ) ; }
CWE-000 inline void update_rq_clock ( struct rq * rq ) <S2SV_StartBug> { <S2SV_EndBug> if ( ! rq -> skip_clock_update ) { int cpu = cpu_of ( rq ) ; <S2SV_StartBug> u64 irq_time ; <S2SV_EndBug> rq -> clock = sched_clock_cpu ( cpu ) ; irq_time = irq_time_cpu ( cpu ) ; if ( rq -> clock - irq_time > rq -> clock_task ) rq -> clock_task = rq -> clock - irq_time ; sched_irq_time_avg_update ( rq , irq_time ) ; } <S2SV_StartBug> } <S2SV_EndBug>
CWE-000 sctp_disposition_t sctp_sf_do_5_2_4_dupcook ( struct net * net , const struct sctp_endpoint * ep , const struct sctp_association * asoc , const sctp_subtype_t type , void * arg , sctp_cmd_seq_t * commands ) { sctp_disposition_t retval ; struct sctp_chunk * chunk = arg ; struct sctp_association * new_asoc ; int error = 0 ; char action ; struct sctp_chunk * err_chk_p ; if ( ! sctp_chunk_length_valid ( chunk , sizeof ( sctp_chunkhdr_t ) ) ) return sctp_sf_violation_chunklen ( net , ep , asoc , type , arg , commands ) ; chunk -> subh . cookie_hdr = ( struct sctp_signed_cookie * ) chunk -> skb -> data ; if ( ! pskb_pull ( chunk -> skb , ntohs ( chunk -> chunk_hdr -> length ) - sizeof ( sctp_chunkhdr_t ) ) ) goto nomem ; new_asoc = sctp_unpack_cookie ( ep , asoc , chunk , GFP_ATOMIC , & error , & err_chk_p ) ; if ( ! new_asoc ) { switch ( error ) { case - SCTP_IERROR_NOMEM : goto nomem ; case - SCTP_IERROR_STALE_COOKIE : sctp_send_stale_cookie_err ( net , ep , asoc , chunk , commands , err_chk_p ) ; return sctp_sf_pdiscard ( net , ep , asoc , type , arg , commands ) ; case - SCTP_IERROR_BAD_SIG : default : return sctp_sf_pdiscard ( net , ep , asoc , type , arg , commands ) ; } } action = sctp_tietags_compare ( new_asoc , asoc ) ; switch ( action ) { case 'A' : retval = sctp_sf_do_dupcook_a ( net , ep , asoc , chunk , commands , new_asoc ) ; break ; case 'B' : retval = sctp_sf_do_dupcook_b ( net , ep , asoc , chunk , commands , new_asoc ) ; break ; case 'C' : retval = sctp_sf_do_dupcook_c ( net , ep , asoc , chunk , commands , new_asoc ) ; break ; case 'D' : retval = sctp_sf_do_dupcook_d ( net , ep , asoc , chunk , commands , new_asoc ) ; break ; default : retval = sctp_sf_pdiscard ( net , ep , asoc , type , arg , commands ) ; break ; } <S2SV_StartBug> sctp_add_cmd_sf ( commands , SCTP_CMD_NEW_ASOC , SCTP_ASOC ( new_asoc ) ) ; <S2SV_EndBug> sctp_add_cmd_sf ( commands , SCTP_CMD_DELETE_TCB , SCTP_NULL ( ) ) ; sctp_add_cmd_sf ( commands , SCTP_CMD_SET_ASOC , SCTP_ASOC ( ( struct sctp_association * ) asoc ) ) ; return retval ; nomem : return SCTP_DISPOSITION_NOMEM ; }
CWE-000 static int crypto_report_acomp ( struct sk_buff * skb , struct crypto_alg * alg ) { struct crypto_report_acomp racomp ; <S2SV_StartBug> strlcpy ( racomp . type , "acomp" , sizeof ( racomp . type ) ) ; <S2SV_EndBug> if ( nla_put ( skb , CRYPTOCFGA_REPORT_ACOMP , sizeof ( struct crypto_report_acomp ) , & racomp ) ) goto nla_put_failure ; return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static int crypto_report_akcipher ( struct sk_buff * skb , struct crypto_alg * alg ) { struct crypto_report_akcipher rakcipher ; <S2SV_StartBug> strlcpy ( rakcipher . type , "akcipher" , sizeof ( rakcipher . type ) ) ; <S2SV_EndBug> if ( nla_put ( skb , CRYPTOCFGA_REPORT_AKCIPHER , sizeof ( struct crypto_report_akcipher ) , & rakcipher ) ) goto nla_put_failure ; return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static int crypto_report_cipher ( struct sk_buff * skb , struct crypto_alg * alg ) { struct crypto_report_cipher rcipher ; <S2SV_StartBug> strlcpy ( rcipher . type , "cipher" , sizeof ( rcipher . type ) ) ; <S2SV_EndBug> rcipher . blocksize = alg -> cra_blocksize ; rcipher . min_keysize = alg -> cra_cipher . cia_min_keysize ; rcipher . max_keysize = alg -> cra_cipher . cia_max_keysize ; if ( nla_put ( skb , CRYPTOCFGA_REPORT_CIPHER , sizeof ( struct crypto_report_cipher ) , & rcipher ) ) goto nla_put_failure ; return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static int crypto_report_comp ( struct sk_buff * skb , struct crypto_alg * alg ) { struct crypto_report_comp rcomp ; <S2SV_StartBug> strlcpy ( rcomp . type , "compression" , sizeof ( rcomp . type ) ) ; <S2SV_EndBug> if ( nla_put ( skb , CRYPTOCFGA_REPORT_COMPRESS , sizeof ( struct crypto_report_comp ) , & rcomp ) ) goto nla_put_failure ; return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static int crypto_report_kpp ( struct sk_buff * skb , struct crypto_alg * alg ) { struct crypto_report_kpp rkpp ; <S2SV_StartBug> strlcpy ( rkpp . type , "kpp" , sizeof ( rkpp . type ) ) ; <S2SV_EndBug> if ( nla_put ( skb , CRYPTOCFGA_REPORT_KPP , sizeof ( struct crypto_report_kpp ) , & rkpp ) ) goto nla_put_failure ; return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static int crypto_report_one ( struct crypto_alg * alg , struct crypto_user_alg * ualg , struct sk_buff * skb ) { <S2SV_StartBug> strlcpy ( ualg -> cru_name , alg -> cra_name , sizeof ( ualg -> cru_name ) ) ; <S2SV_EndBug> <S2SV_StartBug> strlcpy ( ualg -> cru_driver_name , alg -> cra_driver_name , <S2SV_EndBug> sizeof ( ualg -> cru_driver_name ) ) ; <S2SV_StartBug> strlcpy ( ualg -> cru_module_name , module_name ( alg -> cra_module ) , <S2SV_EndBug> sizeof ( ualg -> cru_module_name ) ) ; ualg -> cru_type = 0 ; ualg -> cru_mask = 0 ; ualg -> cru_flags = alg -> cra_flags ; ualg -> cru_refcnt = refcount_read ( & alg -> cra_refcnt ) ; if ( nla_put_u32 ( skb , CRYPTOCFGA_PRIORITY_VAL , alg -> cra_priority ) ) goto nla_put_failure ; if ( alg -> cra_flags & CRYPTO_ALG_LARVAL ) { struct crypto_report_larval rl ; <S2SV_StartBug> strlcpy ( rl . type , "larval" , sizeof ( rl . type ) ) ; <S2SV_EndBug> if ( nla_put ( skb , CRYPTOCFGA_REPORT_LARVAL , sizeof ( struct crypto_report_larval ) , & rl ) ) goto nla_put_failure ; goto out ; } if ( alg -> cra_type && alg -> cra_type -> report ) { if ( alg -> cra_type -> report ( skb , alg ) ) goto nla_put_failure ; goto out ; } switch ( alg -> cra_flags & ( CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_LARVAL ) ) { case CRYPTO_ALG_TYPE_CIPHER : if ( crypto_report_cipher ( skb , alg ) ) goto nla_put_failure ; break ; case CRYPTO_ALG_TYPE_COMPRESS : if ( crypto_report_comp ( skb , alg ) ) goto nla_put_failure ; break ; case CRYPTO_ALG_TYPE_ACOMPRESS : if ( crypto_report_acomp ( skb , alg ) ) goto nla_put_failure ; break ; case CRYPTO_ALG_TYPE_AKCIPHER : if ( crypto_report_akcipher ( skb , alg ) ) goto nla_put_failure ; break ; case CRYPTO_ALG_TYPE_KPP : if ( crypto_report_kpp ( skb , alg ) ) goto nla_put_failure ; break ; } out : return 0 ; nla_put_failure : return - EMSGSIZE ; }
CWE-000 static inline int xfrm_replay_verify_len ( struct xfrm_replay_state_esn * replay_esn , struct nlattr * rp ) { struct xfrm_replay_state_esn * up ; int ulen ; if ( ! replay_esn || ! rp ) return 0 ; up = nla_data ( rp ) ; ulen = xfrm_replay_state_esn_len ( up ) ; <S2SV_StartBug> if ( nla_len ( rp ) < ulen || xfrm_replay_state_esn_len ( replay_esn ) != ulen ) <S2SV_EndBug> return - EINVAL ; if ( up -> replay_window > up -> bmp_len * sizeof ( __u32 ) * 8 ) return - EINVAL ; return 0 ; }
CWE-000 int snd_ctl_add ( struct snd_card * card , struct snd_kcontrol * kcontrol ) { struct snd_ctl_elem_id id ; unsigned int idx ; <S2SV_StartBug> int err = - EINVAL ; <S2SV_EndBug> if ( ! kcontrol ) return err ; if ( snd_BUG_ON ( ! card || ! kcontrol -> info ) ) goto error ; id = kcontrol -> id ; down_write ( & card -> controls_rwsem ) ; if ( snd_ctl_find_id ( card , & id ) ) { up_write ( & card -> controls_rwsem ) ; dev_err ( card -> dev , "control<S2SV_blank>%i:%i:%i:%s:%i<S2SV_blank>is<S2SV_blank>already<S2SV_blank>present\\n" , id . iface , id . device , id . subdevice , id . name , id . index ) ; err = - EBUSY ; goto error ; } if ( snd_ctl_find_hole ( card , kcontrol -> count ) < 0 ) { up_write ( & card -> controls_rwsem ) ; err = - ENOMEM ; goto error ; } list_add_tail ( & kcontrol -> list , & card -> controls ) ; card -> controls_count += kcontrol -> count ; kcontrol -> id . numid = card -> last_numid + 1 ; card -> last_numid += kcontrol -> count ; <S2SV_StartBug> up_write ( & card -> controls_rwsem ) ; <S2SV_EndBug> <S2SV_StartBug> for ( idx = 0 ; idx < kcontrol -> count ; idx ++ , id . index ++ , id . numid ++ ) <S2SV_EndBug> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_ADD , & id ) ; return 0 ; error : snd_ctl_free_one ( kcontrol ) ; return err ; }
CWE-000 static int snd_ctl_elem_write ( struct snd_card * card , struct snd_ctl_file * file , struct snd_ctl_elem_value * control ) { struct snd_kcontrol * kctl ; struct snd_kcontrol_volatile * vd ; unsigned int index_offset ; int result ; down_read ( & card -> controls_rwsem ) ; kctl = snd_ctl_find_id ( card , & control -> id ) ; if ( kctl == NULL ) { result = - ENOENT ; } else { index_offset = snd_ctl_get_ioff ( kctl , & control -> id ) ; vd = & kctl -> vd [ index_offset ] ; if ( ! ( vd -> access & SNDRV_CTL_ELEM_ACCESS_WRITE ) || kctl -> put == NULL || ( file && vd -> owner && vd -> owner != file ) ) { result = - EPERM ; } else { snd_ctl_build_ioff ( & control -> id , kctl , index_offset ) ; result = kctl -> put ( kctl , control ) ; } if ( result > 0 ) { <S2SV_StartBug> up_read ( & card -> controls_rwsem ) ; <S2SV_EndBug> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_VALUE , <S2SV_StartBug> & control -> id ) ; <S2SV_EndBug> return 0 ; } } up_read ( & card -> controls_rwsem ) ; return result ; }
CWE-000 int snd_ctl_replace ( struct snd_card * card , struct snd_kcontrol * kcontrol , bool add_on_replace ) { <S2SV_StartBug> struct snd_ctl_elem_id id ; <S2SV_EndBug> unsigned int idx ; struct snd_kcontrol * old ; int ret ; if ( ! kcontrol ) return - EINVAL ; if ( snd_BUG_ON ( ! card || ! kcontrol -> info ) ) { ret = - EINVAL ; goto error ; } id = kcontrol -> id ; down_write ( & card -> controls_rwsem ) ; old = snd_ctl_find_id ( card , & id ) ; if ( ! old ) { if ( add_on_replace ) goto add ; up_write ( & card -> controls_rwsem ) ; ret = - EINVAL ; goto error ; } ret = snd_ctl_remove ( card , old ) ; if ( ret < 0 ) { up_write ( & card -> controls_rwsem ) ; goto error ; } add : if ( snd_ctl_find_hole ( card , kcontrol -> count ) < 0 ) { up_write ( & card -> controls_rwsem ) ; ret = - ENOMEM ; goto error ; } list_add_tail ( & kcontrol -> list , & card -> controls ) ; card -> controls_count += kcontrol -> count ; kcontrol -> id . numid = card -> last_numid + 1 ; card -> last_numid += kcontrol -> count ; <S2SV_StartBug> up_write ( & card -> controls_rwsem ) ; <S2SV_EndBug> <S2SV_StartBug> for ( idx = 0 ; idx < kcontrol -> count ; idx ++ , id . index ++ , id . numid ++ ) <S2SV_EndBug> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_ADD , & id ) ; return 0 ; error : snd_ctl_free_one ( kcontrol ) ; return ret ; }
CWE-000 static int snd_ctl_tlv_ioctl ( struct snd_ctl_file * file , struct snd_ctl_tlv __user * _tlv , int op_flag ) { struct snd_card * card = file -> card ; struct snd_ctl_tlv tlv ; struct snd_kcontrol * kctl ; struct snd_kcontrol_volatile * vd ; unsigned int len ; int err = 0 ; if ( copy_from_user ( & tlv , _tlv , sizeof ( tlv ) ) ) return - EFAULT ; if ( tlv . length < sizeof ( unsigned int ) * 2 ) return - EINVAL ; down_read ( & card -> controls_rwsem ) ; kctl = snd_ctl_find_numid ( card , tlv . numid ) ; if ( kctl == NULL ) { err = - ENOENT ; goto __kctl_end ; } if ( kctl -> tlv . p == NULL ) { err = - ENXIO ; goto __kctl_end ; } vd = & kctl -> vd [ tlv . numid - kctl -> id . numid ] ; if ( ( op_flag == 0 && ( vd -> access & SNDRV_CTL_ELEM_ACCESS_TLV_READ ) == 0 ) || ( op_flag > 0 && ( vd -> access & SNDRV_CTL_ELEM_ACCESS_TLV_WRITE ) == 0 ) || ( op_flag < 0 && ( vd -> access & SNDRV_CTL_ELEM_ACCESS_TLV_COMMAND ) == 0 ) ) { err = - ENXIO ; goto __kctl_end ; } if ( vd -> access & SNDRV_CTL_ELEM_ACCESS_TLV_CALLBACK ) { if ( vd -> owner != NULL && vd -> owner != file ) { err = - EPERM ; goto __kctl_end ; } err = kctl -> tlv . c ( kctl , op_flag , tlv . length , _tlv -> tlv ) ; if ( err > 0 ) { <S2SV_StartBug> up_read ( & card -> controls_rwsem ) ; <S2SV_EndBug> <S2SV_StartBug> snd_ctl_notify ( card , SNDRV_CTL_EVENT_MASK_TLV , & kctl -> id ) ; <S2SV_EndBug> return 0 ; } } else { if ( op_flag ) { err = - ENXIO ; goto __kctl_end ; } len = kctl -> tlv . p [ 1 ] + 2 * sizeof ( unsigned int ) ; if ( tlv . length < len ) { err = - ENOMEM ; goto __kctl_end ; } if ( copy_to_user ( _tlv -> tlv , kctl -> tlv . p , len ) ) err = - EFAULT ; } __kctl_end : up_read ( & card -> controls_rwsem ) ; return err ; }
CWE-000 static struct sock * sctp_v6_create_accept_sk ( struct sock * sk , struct sctp_association * asoc , bool kern ) { struct sock * newsk ; struct ipv6_pinfo * newnp , * np = inet6_sk ( sk ) ; struct sctp6_sock * newsctp6sk ; struct ipv6_txoptions * opt ; newsk = sk_alloc ( sock_net ( sk ) , PF_INET6 , GFP_KERNEL , sk -> sk_prot , kern ) ; if ( ! newsk ) goto out ; sock_init_data ( NULL , newsk ) ; sctp_copy_sock ( newsk , sk , asoc ) ; sock_reset_flag ( sk , SOCK_ZAPPED ) ; newsctp6sk = ( struct sctp6_sock * ) newsk ; inet_sk ( newsk ) -> pinet6 = & newsctp6sk -> inet6 ; sctp_sk ( newsk ) -> v4mapped = sctp_sk ( sk ) -> v4mapped ; newnp = inet6_sk ( newsk ) ; <S2SV_StartBug> memcpy ( newnp , np , sizeof ( struct ipv6_pinfo ) ) ; <S2SV_EndBug> rcu_read_lock ( ) ; opt = rcu_dereference ( np -> opt ) ; if ( opt ) opt = ipv6_dup_options ( newsk , opt ) ; RCU_INIT_POINTER ( newnp -> opt , opt ) ; rcu_read_unlock ( ) ; sctp_v6_to_sk_daddr ( & asoc -> peer . primary_addr , newsk ) ; newsk -> sk_v6_rcv_saddr = sk -> sk_v6_rcv_saddr ; sk_refcnt_debug_inc ( newsk ) ; if ( newsk -> sk_prot -> init ( newsk ) ) { sk_common_release ( newsk ) ; newsk = NULL ; } out : return newsk ; }
CWE-000 uint16_t http_DissectRequest ( struct sess * sp ) { struct http_conn * htc ; struct http * hp ; uint16_t retval ; CHECK_OBJ_NOTNULL ( sp , SESS_MAGIC ) ; htc = sp -> htc ; CHECK_OBJ_NOTNULL ( htc , HTTP_CONN_MAGIC ) ; hp = sp -> http ; CHECK_OBJ_NOTNULL ( hp , HTTP_MAGIC ) ; hp -> logtag = HTTP_Rx ; retval = http_splitline ( sp -> wrk , sp -> fd , hp , htc , HTTP_HDR_REQ , HTTP_HDR_URL , HTTP_HDR_PROTO ) ; if ( retval != 0 ) { WSPR ( sp , SLT_HttpGarbage , htc -> rxbuf ) ; return ( retval ) ; } http_ProtoVer ( hp ) ; <S2SV_StartBug> retval = htc_request_check_host_hdr ( hp ) ; <S2SV_EndBug> if ( retval != 0 ) { <S2SV_StartBug> WSP ( sp , SLT_Error , "Duplicated<S2SV_blank>Host<S2SV_blank>header" ) ; <S2SV_EndBug> return ( retval ) ; } <S2SV_StartBug> return ( retval ) ; <S2SV_EndBug> }
CWE-000 static uint16_t http_dissect_hdrs ( struct worker * w , struct http * hp , int fd , char * p , const struct http_conn * htc ) { char * q , * r ; txt t = htc -> rxbuf ; if ( * p == '\\r' ) p ++ ; hp -> nhd = HTTP_HDR_FIRST ; hp -> conds = 0 ; r = NULL ; for ( ; p < t . e ; p = r ) { q = r = p ; while ( r < t . e ) { <S2SV_StartBug> if ( ! vct_iscrlf ( * r ) ) { <S2SV_EndBug> r ++ ; continue ; } q = r ; assert ( r < t . e ) ; r += vct_skipcrlf ( r ) ; if ( r >= t . e ) break ; if ( ! vct_issp ( * r ) ) break ; while ( vct_islws ( * q ) ) * q ++ = '<S2SV_blank>' ; } if ( q - p > htc -> maxhdr ) { VSC_C_main -> losthdr ++ ; WSL ( w , SLT_LostHeader , fd , "%.*s" , q - p > 20 ? 20 : q - p , p ) ; return ( 413 ) ; } if ( p == q ) break ; if ( ( p [ 0 ] == 'i' || p [ 0 ] == 'I' ) && ( p [ 1 ] == 'f' || p [ 1 ] == 'F' ) && p [ 2 ] == '-' ) hp -> conds = 1 ; while ( q > p && vct_issp ( q [ - 1 ] ) ) q -- ; * q = '\\0' ; if ( hp -> nhd < hp -> shd ) { hp -> hdf [ hp -> nhd ] = 0 ; hp -> hd [ hp -> nhd ] . b = p ; hp -> hd [ hp -> nhd ] . e = q ; WSLH ( w , fd , hp , hp -> nhd ) ; hp -> nhd ++ ; } else { VSC_C_main -> losthdr ++ ; WSL ( w , SLT_LostHeader , fd , "%.*s" , q - p > 20 ? 20 : q - p , p ) ; return ( 413 ) ; } } return ( 0 ) ; }
CWE-000 static uint16_t http_splitline ( struct worker * w , int fd , struct http * hp , const struct http_conn * htc , int h1 , int h2 , int h3 ) { char * p , * q ; CHECK_OBJ_NOTNULL ( htc , HTTP_CONN_MAGIC ) ; CHECK_OBJ_NOTNULL ( hp , HTTP_MAGIC ) ; Tcheck ( htc -> rxbuf ) ; for ( p = htc -> rxbuf . b ; vct_islws ( * p ) ; p ++ ) continue ; q = p ; for ( ; ! vct_issp ( * p ) ; p ++ ) { if ( vct_isctl ( * p ) ) return ( 400 ) ; } hp -> hd [ h1 ] . b = q ; hp -> hd [ h1 ] . e = p ; for ( ; vct_issp ( * p ) ; p ++ ) { if ( vct_isctl ( * p ) ) return ( 400 ) ; } q = p ; for ( ; ! vct_islws ( * p ) ; p ++ ) { if ( vct_isctl ( * p ) ) return ( 400 ) ; } hp -> hd [ h2 ] . b = q ; hp -> hd [ h2 ] . e = p ; if ( ! Tlen ( hp -> hd [ h2 ] ) ) return ( 400 ) ; for ( ; vct_issp ( * p ) ; p ++ ) { if ( vct_isctl ( * p ) ) return ( 400 ) ; } q = p ; <S2SV_StartBug> if ( ! vct_iscrlf ( * p ) ) { <S2SV_EndBug> <S2SV_StartBug> for ( ; ! vct_iscrlf ( * p ) ; p ++ ) <S2SV_EndBug> if ( ! vct_issep ( * p ) && vct_isctl ( * p ) ) return ( 400 ) ; } hp -> hd [ h3 ] . b = q ; hp -> hd [ h3 ] . e = p ; p += vct_skipcrlf ( p ) ; * hp -> hd [ h1 ] . e = '\\0' ; WSLH ( w , fd , hp , h1 ) ; * hp -> hd [ h2 ] . e = '\\0' ; WSLH ( w , fd , hp , h2 ) ; if ( hp -> hd [ h3 ] . e != NULL ) { * hp -> hd [ h3 ] . e = '\\0' ; WSLH ( w , fd , hp , h3 ) ; } return ( http_dissect_hdrs ( w , hp , fd , p , htc ) ) ; }
CWE-000 static int http_rxchunk ( struct http * hp ) { char * q ; int l , i ; l = hp -> prxbuf ; do ( void ) http_rxchar ( hp , 1 , 0 ) ; while ( hp -> rxbuf [ hp -> prxbuf - 1 ] != '\\n' ) ; vtc_dump ( hp -> vl , 4 , "len" , hp -> rxbuf + l , - 1 ) ; i = strtoul ( hp -> rxbuf + l , & q , 16 ) ; bprintf ( hp -> chunklen , "%d" , i ) ; if ( ( q == hp -> rxbuf + l ) || ( * q != '\\0' && ! vct_islws ( * q ) ) ) { vtc_log ( hp -> vl , hp -> fatal , "chunked<S2SV_blank>fail<S2SV_blank>%02x<S2SV_blank>@<S2SV_blank>%d" , * q , q - ( hp -> rxbuf + l ) ) ; } assert ( q != hp -> rxbuf + l ) ; assert ( * q == '\\0' || vct_islws ( * q ) ) ; hp -> prxbuf = l ; if ( i > 0 ) { ( void ) http_rxchar ( hp , i , 0 ) ; vtc_dump ( hp -> vl , 4 , "chunk" , hp -> rxbuf + l , i ) ; } l = hp -> prxbuf ; ( void ) http_rxchar ( hp , 2 , 0 ) ; <S2SV_StartBug> if ( ! vct_iscrlf ( hp -> rxbuf [ l ] ) ) <S2SV_EndBug> vtc_log ( hp -> vl , hp -> fatal , "Wrong<S2SV_blank>chunk<S2SV_blank>tail[0]<S2SV_blank>=<S2SV_blank>%02x" , hp -> rxbuf [ l ] & 0xff ) ; <S2SV_StartBug> if ( ! vct_iscrlf ( hp -> rxbuf [ l + 1 ] ) ) <S2SV_EndBug> vtc_log ( hp -> vl , hp -> fatal , "Wrong<S2SV_blank>chunk<S2SV_blank>tail[1]<S2SV_blank>=<S2SV_blank>%02x" , hp -> rxbuf [ l + 1 ] & 0xff ) ; hp -> prxbuf = l ; hp -> rxbuf [ l ] = '\\0' ; return ( i ) ; }
CWE-000 static void http_splitheader ( struct http * hp , int req ) { char * p , * q , * * hh ; int n ; char buf [ 20 ] ; CHECK_OBJ_NOTNULL ( hp , HTTP_MAGIC ) ; if ( req ) { memset ( hp -> req , 0 , sizeof hp -> req ) ; hh = hp -> req ; } else { memset ( hp -> resp , 0 , sizeof hp -> resp ) ; hh = hp -> resp ; } n = 0 ; p = hp -> rxbuf ; while ( vct_islws ( * p ) ) p ++ ; hh [ n ++ ] = p ; while ( ! vct_islws ( * p ) ) p ++ ; <S2SV_StartBug> assert ( ! vct_iscrlf ( * p ) ) ; <S2SV_EndBug> * p ++ = '\\0' ; while ( vct_issp ( * p ) ) p ++ ; <S2SV_StartBug> assert ( ! vct_iscrlf ( * p ) ) ; <S2SV_EndBug> hh [ n ++ ] = p ; while ( ! vct_islws ( * p ) ) p ++ ; <S2SV_StartBug> if ( vct_iscrlf ( * p ) ) { <S2SV_EndBug> hh [ n ++ ] = NULL ; q = p ; p += vct_skipcrlf ( p ) ; * q = '\\0' ; } else { * p ++ = '\\0' ; while ( vct_issp ( * p ) ) p ++ ; hh [ n ++ ] = p ; <S2SV_StartBug> while ( ! vct_iscrlf ( * p ) ) <S2SV_EndBug> p ++ ; q = p ; p += vct_skipcrlf ( p ) ; * q = '\\0' ; } assert ( n == 3 ) ; while ( * p != '\\0' ) { assert ( n < MAX_HDR ) ; <S2SV_StartBug> if ( vct_iscrlf ( * p ) ) <S2SV_EndBug> break ; hh [ n ++ ] = p ++ ; <S2SV_StartBug> while ( * p != '\\0' && ! vct_iscrlf ( * p ) ) <S2SV_EndBug> p ++ ; q = p ; p += vct_skipcrlf ( p ) ; * q = '\\0' ; } p += vct_skipcrlf ( p ) ; assert ( * p == '\\0' ) ; for ( n = 0 ; n < 3 || hh [ n ] != NULL ; n ++ ) { sprintf ( buf , "http[%2d]<S2SV_blank>" , n ) ; vtc_dump ( hp -> vl , 4 , buf , hh [ n ] , - 1 ) ; } }
